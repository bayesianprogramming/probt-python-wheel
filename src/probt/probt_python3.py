# -*- coding: utf-8 -*-
# This file was automatically generated by SWIG (http://www.swig.org).
# Version 3.0.12
#
# Do not make changes to this file unless you know what you are doing--modify
# the SWIG interface file instead.

from sys import version_info as _swig_python_version_info
if _swig_python_version_info >= (2, 7, 0):
    def swig_import_helper():
        import importlib
        pkg = __name__.rpartition('.')[0]
        mname = '.'.join((pkg, '_probt_python3')).lstrip('.')
        try:
            return importlib.import_module(mname)
        except ImportError:
            return importlib.import_module('_probt_python3')
    _probt_python3 = swig_import_helper()
    del swig_import_helper
elif _swig_python_version_info >= (2, 6, 0):
    def swig_import_helper():
        from os.path import dirname
        import imp
        fp = None
        try:
            fp, pathname, description = imp.find_module('_probt_python3', [dirname(__file__)])
        except ImportError:
            import _probt_python3
            return _probt_python3
        try:
            _mod = imp.load_module('_probt_python3', fp, pathname, description)
        finally:
            if fp is not None:
                fp.close()
        return _mod
    _probt_python3 = swig_import_helper()
    del swig_import_helper
else:
    import _probt_python3
del _swig_python_version_info

try:
    _swig_property = property
except NameError:
    pass  # Python < 2.2 doesn't have 'property'.

try:
    import builtins as __builtin__
except ImportError:
    import __builtin__

def _swig_setattr_nondynamic(self, class_type, name, value, static=1):
    if (name == "thisown"):
        return self.this.own(value)
    if (name == "this"):
        if type(value).__name__ == 'SwigPyObject':
            self.__dict__[name] = value
            return
    method = class_type.__swig_setmethods__.get(name, None)
    if method:
        return method(self, value)
    if (not static):
        if _newclass:
            object.__setattr__(self, name, value)
        else:
            self.__dict__[name] = value
    else:
        raise AttributeError("You cannot add attributes to %s" % self)


def _swig_setattr(self, class_type, name, value):
    return _swig_setattr_nondynamic(self, class_type, name, value, 0)


def _swig_getattr(self, class_type, name):
    if (name == "thisown"):
        return self.this.own()
    method = class_type.__swig_getmethods__.get(name, None)
    if method:
        return method(self)
    raise AttributeError("'%s' object has no attribute '%s'" % (class_type.__name__, name))


def _swig_repr(self):
    try:
        strthis = "proxy of " + self.this.__repr__()
    except __builtin__.Exception:
        strthis = ""
    return "<%s.%s; %s >" % (self.__class__.__module__, self.__class__.__name__, strthis,)

try:
    _object = object
    _newclass = 1
except __builtin__.Exception:
    class _object:
        pass
    _newclass = 0

try:
    import weakref
    weakref_proxy = weakref.proxy
except __builtin__.Exception:
    weakref_proxy = lambda x: x




def fixup_args(args, mapping, indices=None):
    """Apply a mapping to an array of arguments.

    The mapping is a list of (type, function) pairs. Each argument is
    mapped if it is an instance of a type in the mapping. An argument
    is mapped at most once. The indices argument allows to restrict
    the arguments that are considered for mutation.

    The mapped argument list is returned.

    """
    if indices is None:
        indices = range(len(args))
    args = list(args)
    n = len(args)
    for i in indices:
        if i >= n:
            continue
        for t, f in mapping:
            if isinstance(args[i], t):
                args[i] = f(args[i])
                continue
    return args

def fixup_dataframe_input(class_, method_name, indices):
    import functools
    orig = getattr(class_, method_name)
    @functools.wraps(orig)
    def f(self, *args):
        import pandas
        def fixup_dataframe(arg):
            return  plDataDescriptor.create_from_python_data(arg, self.get_variables())
        args = fixup_args(args, [(pandas.DataFrame, fixup_dataframe)], indices)
        return orig(self, *args)
    setattr(class_, method_name, f)

def _create_column(nrows, var):
    import numpy
    vtype = var.get_var_type()
    if vtype == PL_LABEL: return ['' for i in range(nrows)]
    if vtype == PL_INTEGER: return numpy.full((nrows,), plDataDescriptor.get_undef_int(), dtype=int)
    return numpy.full((nrows,), numpy.nan, dtype=float)

def dataframe_of_values(values):
    import pandas
    import numpy
    data = {}
    nrows = len(values)
    for row, vals in enumerate(values):
        for var, val in vals:
            vn = var.name()
            if not vn in data:
                data[vn] = _create_column(nrows, var)
            data[vn][row] = val
    df = pandas.DataFrame(data=data) if len(data) > 0 else pandas.DataFrame(numpy.full(len(values), np.nan), columns=['?'])
    return df

def patch(f):
    """Decorator for patching methods.
    """
    import functools
    (class_name, method_name) = f.__name__.split('_', 1)
    class_ = globals()[class_name]
    orig = getattr(class_, method_name)
    @functools.wraps(orig)
    def new(self, *args, **kwargs):
        return f(orig, self, *args, **kwargs)
    setattr(class_, method_name, new)
    return new

PL_ENABLE_SPL = _probt_python3.PL_ENABLE_SPL
PL_HAVE_TCC = _probt_python3.PL_HAVE_TCC
PL_S11N_COMPAT = _probt_python3.PL_S11N_COMPAT
PL_USE_XML_S11N = _probt_python3.PL_USE_XML_S11N
PL_ENABLE_SL = _probt_python3.PL_ENABLE_SL
PL_DOUBLE_PRECISION = _probt_python3.PL_DOUBLE_PRECISION
PL_USE_VISIBILITY = _probt_python3.PL_USE_VISIBILITY
PL_ENABLE_CONVERTER = _probt_python3.PL_ENABLE_CONVERTER
class SwigPyIterator(_object):
    __swig_setmethods__ = {}
    __setattr__ = lambda self, name, value: _swig_setattr(self, SwigPyIterator, name, value)
    __swig_getmethods__ = {}
    __getattr__ = lambda self, name: _swig_getattr(self, SwigPyIterator, name)

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined - class is abstract")
    __repr__ = _swig_repr
    __swig_destroy__ = _probt_python3.delete_SwigPyIterator
    __del__ = lambda self: None

    def value(self) -> "PyObject *":
        return _probt_python3.SwigPyIterator_value(self)

    def incr(self, n: 'size_t'=1) -> "swig::SwigPyIterator *":
        return _probt_python3.SwigPyIterator_incr(self, n)

    def decr(self, n: 'size_t'=1) -> "swig::SwigPyIterator *":
        return _probt_python3.SwigPyIterator_decr(self, n)

    def distance(self, x: 'SwigPyIterator') -> "ptrdiff_t":
        return _probt_python3.SwigPyIterator_distance(self, x)

    def equal(self, x: 'SwigPyIterator') -> "bool":
        return _probt_python3.SwigPyIterator_equal(self, x)

    def copy(self) -> "swig::SwigPyIterator *":
        return _probt_python3.SwigPyIterator_copy(self)

    def next(self) -> "PyObject *":
        return _probt_python3.SwigPyIterator_next(self)

    def __next__(self) -> "PyObject *":
        return _probt_python3.SwigPyIterator___next__(self)

    def previous(self) -> "PyObject *":
        return _probt_python3.SwigPyIterator_previous(self)

    def advance(self, n: 'ptrdiff_t') -> "swig::SwigPyIterator *":
        return _probt_python3.SwigPyIterator_advance(self, n)

    def __eq__(self, x: 'SwigPyIterator') -> "bool":
        return _probt_python3.SwigPyIterator___eq__(self, x)

    def __ne__(self, x: 'SwigPyIterator') -> "bool":
        return _probt_python3.SwigPyIterator___ne__(self, x)

    def __iadd__(self, n: 'ptrdiff_t') -> "swig::SwigPyIterator &":
        return _probt_python3.SwigPyIterator___iadd__(self, n)

    def __isub__(self, n: 'ptrdiff_t') -> "swig::SwigPyIterator &":
        return _probt_python3.SwigPyIterator___isub__(self, n)

    def __add__(self, n: 'ptrdiff_t') -> "swig::SwigPyIterator *":
        return _probt_python3.SwigPyIterator___add__(self, n)

    def __sub__(self, *args) -> "ptrdiff_t":
        return _probt_python3.SwigPyIterator___sub__(self, *args)
    def __iter__(self):
        return self
SwigPyIterator_swigregister = _probt_python3.SwigPyIterator_swigregister
SwigPyIterator_swigregister(SwigPyIterator)

PROBT_MAJOR = _probt_python3.PROBT_MAJOR
PROBT_MINOR = _probt_python3.PROBT_MINOR
PROBT_REVISION = _probt_python3.PROBT_REVISION
PROBT_VERSION = _probt_python3.PROBT_VERSION
class plVersion(_object):
    """

    `plVersion()`  
    `plVersion(unsigned int maj, unsigned int min, unsigned int rev, unsigned int
        compat=0)`  
    `plVersion(const std::string &version_string)`  

    Holds a ProBT version triplet (major,minor,revision).  

    Constructors
    ------------
    * `plVersion()`  

        Default constructor.  

    * `plVersion(unsigned int maj, unsigned int min, unsigned int rev, unsigned int
        compat=0)`  

        Constructor.  

    * `plVersion(const std::string &version_string)`  

        Parse from a "major.minor.revision" string.  

    Attributes
    ----------
    * `major_` : `unsigned int`  
        Major version.  

    * `minor_` : `unsigned int`  
        Minor version.  

    * `revision_` : `unsigned int`  
        Revision.  

    * `s11n_compat_` : `unsigned int`  
        Serialization compatibility number.  

    C++ includes: plVersion.h

    """

    __swig_setmethods__ = {}
    __setattr__ = lambda self, name, value: _swig_setattr(self, plVersion, name, value)
    __swig_getmethods__ = {}
    __getattr__ = lambda self, name: _swig_getattr(self, plVersion, name)
    __repr__ = _swig_repr
    __swig_setmethods__["major_"] = _probt_python3.plVersion_major__set
    __swig_getmethods__["major_"] = _probt_python3.plVersion_major__get
    if _newclass:
        major_ = _swig_property(_probt_python3.plVersion_major__get, _probt_python3.plVersion_major__set)
    __swig_setmethods__["minor_"] = _probt_python3.plVersion_minor__set
    __swig_getmethods__["minor_"] = _probt_python3.plVersion_minor__get
    if _newclass:
        minor_ = _swig_property(_probt_python3.plVersion_minor__get, _probt_python3.plVersion_minor__set)
    __swig_setmethods__["revision_"] = _probt_python3.plVersion_revision__set
    __swig_getmethods__["revision_"] = _probt_python3.plVersion_revision__get
    if _newclass:
        revision_ = _swig_property(_probt_python3.plVersion_revision__get, _probt_python3.plVersion_revision__set)
    __swig_setmethods__["s11n_compat_"] = _probt_python3.plVersion_s11n_compat__set
    __swig_getmethods__["s11n_compat_"] = _probt_python3.plVersion_s11n_compat__get
    if _newclass:
        s11n_compat_ = _swig_property(_probt_python3.plVersion_s11n_compat__get, _probt_python3.plVersion_s11n_compat__set)

    def __init__(self, *args):
        """
        __init__(self) -> plVersion
        __init__(self, maj, min, rev, compat=0) -> plVersion
        __init__(self, maj, min, rev) -> plVersion
        __init__(self, version_string) -> plVersion


        `plVersion()`  
        `plVersion(unsigned int maj, unsigned int min, unsigned int rev, unsigned int
            compat=0)`  
        `plVersion(const std::string &version_string)`  

        Overloaded function
        -------------------
        * `plVersion()`  

            Default constructor.  

        * `plVersion(unsigned int maj, unsigned int min, unsigned int rev, unsigned int
            compat=0)`  

            Constructor.  

        * `plVersion(const std::string &version_string)`  

            Parse from a "major.minor.revision" string.  

        """
        this = _probt_python3.new_plVersion(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def _print(self) -> "std::string":
        """
        _print(self) -> std::string


        `print() const -> std::string`  

        Print as "major.minor.revision".  

        """
        return _probt_python3.plVersion__print(self)


    def __lt__(self, o: 'plVersion') -> "bool":
        """__lt__(self, o) -> bool"""
        return _probt_python3.plVersion___lt__(self, o)


    def less(self, o: 'plVersion') -> "bool":
        """
        less(self, o) -> bool


        `less(const plVersion &o) const -> bool`  

        "less than"  

        """
        return _probt_python3.plVersion_less(self, o)


    def get_version() -> "plVersion":
        """
        get_version() -> plVersion


        `get_version() -> plVersion`  

        Return the ProBT release version.  

        """
        return _probt_python3.plVersion_get_version()

    get_version = staticmethod(get_version)

    def get_expiration_date() -> "std::string":
        """
        get_expiration_date() -> std::string


        `get_expiration_date() -> std::string`  

        Get ProBT's expiration date in yyyy-mm-dd format.  

        Returns "0000-00-00" if it is not a time-limited version.  

        """
        return _probt_python3.plVersion_get_expiration_date()

    get_expiration_date = staticmethod(get_expiration_date)

    def has_expired() -> "bool":
        """
        has_expired() -> bool


        `has_expired() -> bool`  

        Returns true if and only if this ProBT package has expired.  

        Once ProBT has reached its expiration date, it will raise a plExpirationError
        when trying to create a ProBT object.  

        """
        return _probt_python3.plVersion_has_expired()

    has_expired = staticmethod(has_expired)
    __swig_destroy__ = _probt_python3.delete_plVersion
    __del__ = lambda self: None
plVersion_swigregister = _probt_python3.plVersion_swigregister
plVersion_swigregister(plVersion)

def plVersion_get_version() -> "plVersion":
    """
    plVersion_get_version() -> plVersion


    `get_version() -> plVersion`  

    Return the ProBT release version.  

    """
    return _probt_python3.plVersion_get_version()

def plVersion_get_expiration_date() -> "std::string":
    """
    plVersion_get_expiration_date() -> std::string


    `get_expiration_date() -> std::string`  

    Get ProBT's expiration date in yyyy-mm-dd format.  

    Returns "0000-00-00" if it is not a time-limited version.  

    """
    return _probt_python3.plVersion_get_expiration_date()

def plVersion_has_expired() -> "bool":
    """
    plVersion_has_expired() -> bool


    `has_expired() -> bool`  

    Returns true if and only if this ProBT package has expired.  

    Once ProBT has reached its expiration date, it will raise a plExpirationError
    when trying to create a ProBT object.  

    """
    return _probt_python3.plVersion_has_expired()

_USE_MATH_DEFINES = _probt_python3._USE_MATH_DEFINES
M_PI = _probt_python3.M_PI
PL_LOG_OF_2 = _probt_python3.PL_LOG_OF_2
PL_PI_2 = _probt_python3.PL_PI_2
PL_PI = _probt_python3.PL_PI
PL_2PI = _probt_python3.PL_2PI
PL_INV_SQRT_2PI = _probt_python3.PL_INV_SQRT_2PI
PL_SQRT_PI = _probt_python3.PL_SQRT_PI
PL_LOG_ROOT_2_PI = _probt_python3.PL_LOG_ROOT_2_PI
PL_ZERO = _probt_python3.PL_ZERO
PL_HALF = _probt_python3.PL_HALF
PL_ONE = _probt_python3.PL_ONE
PL_TWO = _probt_python3.PL_TWO
PL_SQRT_2 = _probt_python3.PL_SQRT_2
PL_E = _probt_python3.PL_E
PL_MIN_EXP = _probt_python3.PL_MIN_EXP
PL_LOG_OF_10_BASE2 = _probt_python3.PL_LOG_OF_10_BASE2
PL_MINUS_ONE = _probt_python3.PL_MINUS_ONE
PL_LOG_SQRT_2PI = _probt_python3.PL_LOG_SQRT_2PI

def plLogBase2(v: 'plFloat') -> "plFloat":
    """
    plLogBase2(v) -> plFloat


    `plLogBase2(plFloat v) -> plFloat`  

    Get the base 2 logarithm.  

    """
    return _probt_python3.plLogBase2(v)

def plNbBits(int_val: 'int') -> "int":
    """
    plNbBits(int_val) -> int


    `plNbBits(int int_val) -> int`  

    """
    return _probt_python3.plNbBits(int_val)

def plRound(x: 'plFloat') -> "int":
    """
    plRound(x) -> int


    `plRound(plFloat x) -> int`  

    Get the closest integer value.  

    """
    return _probt_python3.plRound(x)

def plConvergedLogLikelihood(old_loglikelihood: 'plFloat', loglikelihood: 'plFloat', convergence_threshold: 'plFloat') -> "bool":
    """
    plConvergedLogLikelihood(old_loglikelihood, loglikelihood, convergence_threshold) -> bool


    `plConvergedLogLikelihood(plFloat old_loglikelihood, plFloat loglikelihood,
        plFloat convergence_threshold) -> bool`  

    Convergence test given two log-likelihood values.  

    """
    return _probt_python3.plConvergedLogLikelihood(old_loglikelihood, loglikelihood, convergence_threshold)
PL_ZERO_PROB = _probt_python3.PL_ZERO_PROB
PL_HALF_PROB = _probt_python3.PL_HALF_PROB
PL_ONE_PROB = _probt_python3.PL_ONE_PROB
PL_TWO_PROB = _probt_python3.PL_TWO_PROB
PL_INVALID_PROB = _probt_python3.PL_INVALID_PROB
PL_DISTRIB_TRUNCATION_THRESHOLD = _probt_python3.PL_DISTRIB_TRUNCATION_THRESHOLD
PL_CHOOSE_GENERATOR_FOR_ME = _probt_python3.PL_CHOOSE_GENERATOR_FOR_ME
PL_EXHAUSTIVE_GENERATOR = _probt_python3.PL_EXHAUSTIVE_GENERATOR
PL_GA_GENERATOR = _probt_python3.PL_GA_GENERATOR
PL_RANDOM_GENERATOR = _probt_python3.PL_RANDOM_GENERATOR
PL_MC_GENERATOR = _probt_python3.PL_MC_GENERATOR
PL_CHOOSE_COMP_TYPE_FOR_ME = _probt_python3.PL_CHOOSE_COMP_TYPE_FOR_ME
PL_MRBT = _probt_python3.PL_MRBT
PL_TABLE = _probt_python3.PL_TABLE
PL_MAP = _probt_python3.PL_MAP
PL_OPTIMIZE_COMPILATION_TIME = _probt_python3.PL_OPTIMIZE_COMPILATION_TIME
PL_OPTIMIZE_UPDATE_TIME = _probt_python3.PL_OPTIMIZE_UPDATE_TIME
PL_OPTIMIZE_MEMORY_USE = _probt_python3.PL_OPTIMIZE_MEMORY_USE
PL_NO_OPTIMIZATION = _probt_python3.PL_NO_OPTIMIZATION
class plVariableDiscretizer(_object):
    """

    `plVariableDiscretizer()`  

    Base class for all variable discretization algorithms.  

    See also: plDataDescriptor::use_for_discretization()  

    Constructors
    ------------
    * `plVariableDiscretizer()`  

        Default constructor.  

    C++ includes: plVariableDiscretizer.h

    """

    __swig_setmethods__ = {}
    __setattr__ = lambda self, name, value: _swig_setattr(self, plVariableDiscretizer, name, value)
    __swig_getmethods__ = {}
    __getattr__ = lambda self, name: _swig_getattr(self, plVariableDiscretizer, name)

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined - class is abstract")
    __repr__ = _swig_repr
    __swig_destroy__ = _probt_python3.delete_plVariableDiscretizer
    __del__ = lambda self: None

    def add_point(self, val: 'plFloat') -> "void":
        """
        add_point(self, val)


        `add_point(plFloat val)=0`  

        Insert a point.  

        """
        return _probt_python3.plVariableDiscretizer_add_point(self, val)


    def get_intervals(self) -> "std::vector< plFloat,std::allocator< plFloat > >":
        """
        get_intervals(self) -> DoubleVector


        `get_intervals() const =0 -> std::vector< plFloat >`  

        Return the discretization interval values based on the points inserted using
        add_point()  

        """
        return _probt_python3.plVariableDiscretizer_get_intervals(self)


    def reset(self) -> "void":
        """
        reset(self)


        `reset()=0`  

        Forget all the points inserted using add_point()  

        """
        return _probt_python3.plVariableDiscretizer_reset(self)


    def run(self, *args) -> "std::vector< plFloat,std::allocator< plFloat > >":
        """
        run(self, data, variable_column) -> DoubleVector
        run(self, data_values) -> DoubleVector


        `run(plDataDescriptor &data, unsigned int variable_column) -> std::vector<
            plFloat >`  
        `run(const std::vector< plFloat > &data_values) -> std::vector< plFloat >`  

        Overloaded function
        -------------------
        * `run(plDataDescriptor &data, unsigned int variable_column) -> std::vector<
            plFloat >`  

            Use the data set *data* to discretize the variable corresponding to column
            *variable_column* in *data*.  

        * `run(const std::vector< plFloat > &data_values) -> std::vector< plFloat >`  

            Use the data values *data_values* to discretize the corresponding variable.  

        """
        return _probt_python3.plVariableDiscretizer_run(self, *args)

plVariableDiscretizer_swigregister = _probt_python3.plVariableDiscretizer_swigregister
plVariableDiscretizer_swigregister(plVariableDiscretizer)
cvar = _probt_python3.cvar
PL_NUMBER_OF_BITS_BY_CHAR = cvar.PL_NUMBER_OF_BITS_BY_CHAR

class plEqualFrequenciesVariableDiscretizer(plVariableDiscretizer):
    """

    `plEqualFrequenciesVariableDiscretizer(size_t n=0)`  

    Simple discretization algorithm providing n intervals with the same number of
    data points.  

    See also: plDataDescriptor::use_for_discretization()  

    Constructors
    ------------
    * `plEqualFrequenciesVariableDiscretizer(size_t n=0)`  

        Constructor using the requested number of intervals.  

    C++ includes: plVariableDiscretizer.h

    """

    __swig_setmethods__ = {}
    for _s in [plVariableDiscretizer]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plEqualFrequenciesVariableDiscretizer, name, value)
    __swig_getmethods__ = {}
    for _s in [plVariableDiscretizer]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plEqualFrequenciesVariableDiscretizer, name)
    __repr__ = _swig_repr

    def __init__(self, n: 'size_t'=0):
        """
        __init__(self, n=0) -> plEqualFrequenciesVariableDiscretizer
        __init__(self) -> plEqualFrequenciesVariableDiscretizer


        `plEqualFrequenciesVariableDiscretizer(size_t n=0)`  

        Constructor using the requested number of intervals.  

        """
        this = _probt_python3.new_plEqualFrequenciesVariableDiscretizer(n)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def set_n_intervals(self, n: 'size_t') -> "void":
        """
        set_n_intervals(self, n)


        `set_n_intervals(size_t n)`  

        Set the number of intervals.  

        """
        return _probt_python3.plEqualFrequenciesVariableDiscretizer_set_n_intervals(self, n)


    def add_point(self, val: 'plFloat') -> "void":
        """
        add_point(self, val)


        `add_point(plFloat val)`  

        Insert a point.  

        """
        return _probt_python3.plEqualFrequenciesVariableDiscretizer_add_point(self, val)


    def get_intervals(self) -> "std::vector< plFloat,std::allocator< plFloat > >":
        """
        get_intervals(self) -> DoubleVector


        `get_intervals() const -> std::vector< plFloat >`  

        Return the discretization interval values based on the points inserted using
        add_point()  

        """
        return _probt_python3.plEqualFrequenciesVariableDiscretizer_get_intervals(self)


    def reset(self) -> "void":
        """
        reset(self)


        `reset()`  

        Forget all the points inserted using add_point()  

        """
        return _probt_python3.plEqualFrequenciesVariableDiscretizer_reset(self)


    def set_values(self, points: 'DoubleVector') -> "void":
        """
        set_values(self, points)


        `set_values(const std::vector< plFloat > &points)`  

        Set the values of the discretizer Equivalent to adding each point of *points*
        using add_point()  

        """
        return _probt_python3.plEqualFrequenciesVariableDiscretizer_set_values(self, points)

    __swig_destroy__ = _probt_python3.delete_plEqualFrequenciesVariableDiscretizer
    __del__ = lambda self: None
plEqualFrequenciesVariableDiscretizer_swigregister = _probt_python3.plEqualFrequenciesVariableDiscretizer_swigregister
plEqualFrequenciesVariableDiscretizer_swigregister(plEqualFrequenciesVariableDiscretizer)


fixup_dataframe_input(plVariableDiscretizer, 'run', [0])

class PairUi(_object):
    """Proxy of C++ std::pair<(unsigned int,unsigned int)> class."""

    __swig_setmethods__ = {}
    __setattr__ = lambda self, name, value: _swig_setattr(self, PairUi, name, value)
    __swig_getmethods__ = {}
    __getattr__ = lambda self, name: _swig_getattr(self, PairUi, name)
    __repr__ = _swig_repr

    def __init__(self, *args):
        """
        __init__(self) -> PairUi
        __init__(self, first, second) -> PairUi
        __init__(self, p) -> PairUi
        """
        this = _probt_python3.new_PairUi(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this
    __swig_setmethods__["first"] = _probt_python3.PairUi_first_set
    __swig_getmethods__["first"] = _probt_python3.PairUi_first_get
    if _newclass:
        first = _swig_property(_probt_python3.PairUi_first_get, _probt_python3.PairUi_first_set)
    __swig_setmethods__["second"] = _probt_python3.PairUi_second_set
    __swig_getmethods__["second"] = _probt_python3.PairUi_second_get
    if _newclass:
        second = _swig_property(_probt_python3.PairUi_second_get, _probt_python3.PairUi_second_set)
    def __len__(self):
        return 2
    def __repr__(self):
        return str((self.first, self.second))
    def __getitem__(self, index): 
        if not (index % 2):
            return self.first
        else:
            return self.second
    def __setitem__(self, index, val):
        if not (index % 2):
            self.first = val
        else:
            self.second = val
    __swig_destroy__ = _probt_python3.delete_PairUi
    __del__ = lambda self: None
PairUi_swigregister = _probt_python3.PairUi_swigregister
PairUi_swigregister(PairUi)

class PairUiVector(_object):
    """Proxy of C++ std::vector<(std::pair<(unsigned int,unsigned int)>)> class."""

    __swig_setmethods__ = {}
    __setattr__ = lambda self, name, value: _swig_setattr(self, PairUiVector, name, value)
    __swig_getmethods__ = {}
    __getattr__ = lambda self, name: _swig_getattr(self, PairUiVector, name)
    __repr__ = _swig_repr

    def iterator(self) -> "swig::SwigPyIterator *":
        """iterator(self) -> SwigPyIterator"""
        return _probt_python3.PairUiVector_iterator(self)

    def __iter__(self):
        return self.iterator()

    def __nonzero__(self) -> "bool":
        """__nonzero__(self) -> bool"""
        return _probt_python3.PairUiVector___nonzero__(self)


    def __bool__(self) -> "bool":
        """__bool__(self) -> bool"""
        return _probt_python3.PairUiVector___bool__(self)


    def __len__(self) -> "std::vector< std::pair< unsigned int,unsigned int > >::size_type":
        """__len__(self) -> std::vector< std::pair< unsigned int,unsigned int > >::size_type"""
        return _probt_python3.PairUiVector___len__(self)


    def __getslice__(self, i: 'std::vector< std::pair< unsigned int,unsigned int > >::difference_type', j: 'std::vector< std::pair< unsigned int,unsigned int > >::difference_type') -> "std::vector< std::pair< unsigned int,unsigned int >,std::allocator< std::pair< unsigned int,unsigned int > > > *":
        """__getslice__(self, i, j) -> PairUiVector"""
        return _probt_python3.PairUiVector___getslice__(self, i, j)


    def __setslice__(self, *args) -> "void":
        """
        __setslice__(self, i, j)
        __setslice__(self, i, j, v)
        """
        return _probt_python3.PairUiVector___setslice__(self, *args)


    def __delslice__(self, i: 'std::vector< std::pair< unsigned int,unsigned int > >::difference_type', j: 'std::vector< std::pair< unsigned int,unsigned int > >::difference_type') -> "void":
        """__delslice__(self, i, j)"""
        return _probt_python3.PairUiVector___delslice__(self, i, j)


    def __delitem__(self, *args) -> "void":
        """
        __delitem__(self, i)
        __delitem__(self, slice)
        """
        return _probt_python3.PairUiVector___delitem__(self, *args)


    def __getitem__(self, *args) -> "std::vector< std::pair< unsigned int,unsigned int > >::value_type const &":
        """
        __getitem__(self, slice) -> PairUiVector
        __getitem__(self, i) -> PairUi
        """
        return _probt_python3.PairUiVector___getitem__(self, *args)


    def __setitem__(self, *args) -> "void":
        """
        __setitem__(self, slice, v)
        __setitem__(self, slice)
        __setitem__(self, i, x)
        """
        return _probt_python3.PairUiVector___setitem__(self, *args)


    def pop(self) -> "std::vector< std::pair< unsigned int,unsigned int > >::value_type":
        """pop(self) -> PairUi"""
        return _probt_python3.PairUiVector_pop(self)


    def append(self, x: 'PairUi') -> "void":
        """append(self, x)"""
        return _probt_python3.PairUiVector_append(self, x)


    def empty(self) -> "bool":
        """empty(self) -> bool"""
        return _probt_python3.PairUiVector_empty(self)


    def size(self) -> "std::vector< std::pair< unsigned int,unsigned int > >::size_type":
        """size(self) -> std::vector< std::pair< unsigned int,unsigned int > >::size_type"""
        return _probt_python3.PairUiVector_size(self)


    def swap(self, v: 'PairUiVector') -> "void":
        """swap(self, v)"""
        return _probt_python3.PairUiVector_swap(self, v)


    def begin(self) -> "std::vector< std::pair< unsigned int,unsigned int > >::iterator":
        """begin(self) -> std::vector< std::pair< unsigned int,unsigned int > >::iterator"""
        return _probt_python3.PairUiVector_begin(self)


    def end(self) -> "std::vector< std::pair< unsigned int,unsigned int > >::iterator":
        """end(self) -> std::vector< std::pair< unsigned int,unsigned int > >::iterator"""
        return _probt_python3.PairUiVector_end(self)


    def rbegin(self) -> "std::vector< std::pair< unsigned int,unsigned int > >::reverse_iterator":
        """rbegin(self) -> std::vector< std::pair< unsigned int,unsigned int > >::reverse_iterator"""
        return _probt_python3.PairUiVector_rbegin(self)


    def rend(self) -> "std::vector< std::pair< unsigned int,unsigned int > >::reverse_iterator":
        """rend(self) -> std::vector< std::pair< unsigned int,unsigned int > >::reverse_iterator"""
        return _probt_python3.PairUiVector_rend(self)


    def clear(self) -> "void":
        """clear(self)"""
        return _probt_python3.PairUiVector_clear(self)


    def get_allocator(self) -> "std::vector< std::pair< unsigned int,unsigned int > >::allocator_type":
        """get_allocator(self) -> std::vector< std::pair< unsigned int,unsigned int > >::allocator_type"""
        return _probt_python3.PairUiVector_get_allocator(self)


    def pop_back(self) -> "void":
        """pop_back(self)"""
        return _probt_python3.PairUiVector_pop_back(self)


    def erase(self, *args) -> "std::vector< std::pair< unsigned int,unsigned int > >::iterator":
        """
        erase(self, pos) -> std::vector< std::pair< unsigned int,unsigned int > >::iterator
        erase(self, first, last) -> std::vector< std::pair< unsigned int,unsigned int > >::iterator
        """
        return _probt_python3.PairUiVector_erase(self, *args)


    def __init__(self, *args):
        """
        __init__(self) -> PairUiVector
        __init__(self, arg2) -> PairUiVector
        __init__(self, size) -> PairUiVector
        __init__(self, size, value) -> PairUiVector
        """
        this = _probt_python3.new_PairUiVector(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def push_back(self, x: 'PairUi') -> "void":
        """push_back(self, x)"""
        return _probt_python3.PairUiVector_push_back(self, x)


    def front(self) -> "std::vector< std::pair< unsigned int,unsigned int > >::value_type const &":
        """front(self) -> PairUi"""
        return _probt_python3.PairUiVector_front(self)


    def back(self) -> "std::vector< std::pair< unsigned int,unsigned int > >::value_type const &":
        """back(self) -> PairUi"""
        return _probt_python3.PairUiVector_back(self)


    def assign(self, n: 'std::vector< std::pair< unsigned int,unsigned int > >::size_type', x: 'PairUi') -> "void":
        """assign(self, n, x)"""
        return _probt_python3.PairUiVector_assign(self, n, x)


    def resize(self, *args) -> "void":
        """
        resize(self, new_size)
        resize(self, new_size, x)
        """
        return _probt_python3.PairUiVector_resize(self, *args)


    def insert(self, *args) -> "void":
        """
        insert(self, pos, x) -> std::vector< std::pair< unsigned int,unsigned int > >::iterator
        insert(self, pos, n, x)
        """
        return _probt_python3.PairUiVector_insert(self, *args)


    def reserve(self, n: 'std::vector< std::pair< unsigned int,unsigned int > >::size_type') -> "void":
        """reserve(self, n)"""
        return _probt_python3.PairUiVector_reserve(self, n)


    def capacity(self) -> "std::vector< std::pair< unsigned int,unsigned int > >::size_type":
        """capacity(self) -> std::vector< std::pair< unsigned int,unsigned int > >::size_type"""
        return _probt_python3.PairUiVector_capacity(self)

    __swig_destroy__ = _probt_python3.delete_PairUiVector
    __del__ = lambda self: None
PairUiVector_swigregister = _probt_python3.PairUiVector_swigregister
PairUiVector_swigregister(PairUiVector)

class PairVPV(_object):
    """Proxy of C++ std::pair<(plValues,plProbValue)> class."""

    __swig_setmethods__ = {}
    __setattr__ = lambda self, name, value: _swig_setattr(self, PairVPV, name, value)
    __swig_getmethods__ = {}
    __getattr__ = lambda self, name: _swig_getattr(self, PairVPV, name)
    __repr__ = _swig_repr

    def __init__(self, *args):
        """
        __init__(self) -> PairVPV
        __init__(self, first, second) -> PairVPV
        __init__(self, p) -> PairVPV
        """
        this = _probt_python3.new_PairVPV(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this
    __swig_setmethods__["first"] = _probt_python3.PairVPV_first_set
    __swig_getmethods__["first"] = _probt_python3.PairVPV_first_get
    if _newclass:
        first = _swig_property(_probt_python3.PairVPV_first_get, _probt_python3.PairVPV_first_set)
    __swig_setmethods__["second"] = _probt_python3.PairVPV_second_set
    __swig_getmethods__["second"] = _probt_python3.PairVPV_second_get
    if _newclass:
        second = _swig_property(_probt_python3.PairVPV_second_get, _probt_python3.PairVPV_second_set)
    def __len__(self):
        return 2
    def __repr__(self):
        return str((self.first, self.second))
    def __getitem__(self, index): 
        if not (index % 2):
            return self.first
        else:
            return self.second
    def __setitem__(self, index, val):
        if not (index % 2):
            self.first = val
        else:
            self.second = val
    __swig_destroy__ = _probt_python3.delete_PairVPV
    __del__ = lambda self: None
PairVPV_swigregister = _probt_python3.PairVPV_swigregister
PairVPV_swigregister(PairVPV)

class PairVPVVector(_object):
    """Proxy of C++ std::vector<(std::pair<(plValues,plProbValue)>)> class."""

    __swig_setmethods__ = {}
    __setattr__ = lambda self, name, value: _swig_setattr(self, PairVPVVector, name, value)
    __swig_getmethods__ = {}
    __getattr__ = lambda self, name: _swig_getattr(self, PairVPVVector, name)
    __repr__ = _swig_repr

    def iterator(self) -> "swig::SwigPyIterator *":
        """iterator(self) -> SwigPyIterator"""
        return _probt_python3.PairVPVVector_iterator(self)

    def __iter__(self):
        return self.iterator()

    def __nonzero__(self) -> "bool":
        """__nonzero__(self) -> bool"""
        return _probt_python3.PairVPVVector___nonzero__(self)


    def __bool__(self) -> "bool":
        """__bool__(self) -> bool"""
        return _probt_python3.PairVPVVector___bool__(self)


    def __len__(self) -> "std::vector< std::pair< plValues,double > >::size_type":
        """__len__(self) -> std::vector< std::pair< plValues,double > >::size_type"""
        return _probt_python3.PairVPVVector___len__(self)


    def __getslice__(self, i: 'std::vector< std::pair< plValues,double > >::difference_type', j: 'std::vector< std::pair< plValues,double > >::difference_type') -> "std::vector< std::pair< plValues,plProbValue >,std::allocator< std::pair< plValues,plProbValue > > > *":
        """__getslice__(self, i, j) -> PairVPVVector"""
        return _probt_python3.PairVPVVector___getslice__(self, i, j)


    def __setslice__(self, *args) -> "void":
        """
        __setslice__(self, i, j)
        __setslice__(self, i, j, v)
        """
        return _probt_python3.PairVPVVector___setslice__(self, *args)


    def __delslice__(self, i: 'std::vector< std::pair< plValues,double > >::difference_type', j: 'std::vector< std::pair< plValues,double > >::difference_type') -> "void":
        """__delslice__(self, i, j)"""
        return _probt_python3.PairVPVVector___delslice__(self, i, j)


    def __delitem__(self, *args) -> "void":
        """
        __delitem__(self, i)
        __delitem__(self, slice)
        """
        return _probt_python3.PairVPVVector___delitem__(self, *args)


    def __getitem__(self, *args) -> "std::vector< std::pair< plValues,double > >::value_type const &":
        """
        __getitem__(self, slice) -> PairVPVVector
        __getitem__(self, i) -> PairVPV
        """
        return _probt_python3.PairVPVVector___getitem__(self, *args)


    def __setitem__(self, *args) -> "void":
        """
        __setitem__(self, slice, v)
        __setitem__(self, slice)
        __setitem__(self, i, x)
        """
        return _probt_python3.PairVPVVector___setitem__(self, *args)


    def pop(self) -> "std::vector< std::pair< plValues,double > >::value_type":
        """pop(self) -> PairVPV"""
        return _probt_python3.PairVPVVector_pop(self)


    def append(self, x: 'PairVPV') -> "void":
        """append(self, x)"""
        return _probt_python3.PairVPVVector_append(self, x)


    def empty(self) -> "bool":
        """empty(self) -> bool"""
        return _probt_python3.PairVPVVector_empty(self)


    def size(self) -> "std::vector< std::pair< plValues,double > >::size_type":
        """size(self) -> std::vector< std::pair< plValues,double > >::size_type"""
        return _probt_python3.PairVPVVector_size(self)


    def swap(self, v: 'PairVPVVector') -> "void":
        """swap(self, v)"""
        return _probt_python3.PairVPVVector_swap(self, v)


    def begin(self) -> "std::vector< std::pair< plValues,double > >::iterator":
        """begin(self) -> std::vector< std::pair< plValues,double > >::iterator"""
        return _probt_python3.PairVPVVector_begin(self)


    def end(self) -> "std::vector< std::pair< plValues,double > >::iterator":
        """end(self) -> std::vector< std::pair< plValues,double > >::iterator"""
        return _probt_python3.PairVPVVector_end(self)


    def rbegin(self) -> "std::vector< std::pair< plValues,double > >::reverse_iterator":
        """rbegin(self) -> std::vector< std::pair< plValues,double > >::reverse_iterator"""
        return _probt_python3.PairVPVVector_rbegin(self)


    def rend(self) -> "std::vector< std::pair< plValues,double > >::reverse_iterator":
        """rend(self) -> std::vector< std::pair< plValues,double > >::reverse_iterator"""
        return _probt_python3.PairVPVVector_rend(self)


    def clear(self) -> "void":
        """clear(self)"""
        return _probt_python3.PairVPVVector_clear(self)


    def get_allocator(self) -> "std::vector< std::pair< plValues,double > >::allocator_type":
        """get_allocator(self) -> std::vector< std::pair< plValues,double > >::allocator_type"""
        return _probt_python3.PairVPVVector_get_allocator(self)


    def pop_back(self) -> "void":
        """pop_back(self)"""
        return _probt_python3.PairVPVVector_pop_back(self)


    def erase(self, *args) -> "std::vector< std::pair< plValues,double > >::iterator":
        """
        erase(self, pos) -> std::vector< std::pair< plValues,double > >::iterator
        erase(self, first, last) -> std::vector< std::pair< plValues,double > >::iterator
        """
        return _probt_python3.PairVPVVector_erase(self, *args)


    def __init__(self, *args):
        """
        __init__(self) -> PairVPVVector
        __init__(self, arg2) -> PairVPVVector
        __init__(self, size) -> PairVPVVector
        __init__(self, size, value) -> PairVPVVector
        """
        this = _probt_python3.new_PairVPVVector(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def push_back(self, x: 'PairVPV') -> "void":
        """push_back(self, x)"""
        return _probt_python3.PairVPVVector_push_back(self, x)


    def front(self) -> "std::vector< std::pair< plValues,double > >::value_type const &":
        """front(self) -> PairVPV"""
        return _probt_python3.PairVPVVector_front(self)


    def back(self) -> "std::vector< std::pair< plValues,double > >::value_type const &":
        """back(self) -> PairVPV"""
        return _probt_python3.PairVPVVector_back(self)


    def assign(self, n: 'std::vector< std::pair< plValues,double > >::size_type', x: 'PairVPV') -> "void":
        """assign(self, n, x)"""
        return _probt_python3.PairVPVVector_assign(self, n, x)


    def resize(self, *args) -> "void":
        """
        resize(self, new_size)
        resize(self, new_size, x)
        """
        return _probt_python3.PairVPVVector_resize(self, *args)


    def insert(self, *args) -> "void":
        """
        insert(self, pos, x) -> std::vector< std::pair< plValues,double > >::iterator
        insert(self, pos, n, x)
        """
        return _probt_python3.PairVPVVector_insert(self, *args)


    def reserve(self, n: 'std::vector< std::pair< plValues,double > >::size_type') -> "void":
        """reserve(self, n)"""
        return _probt_python3.PairVPVVector_reserve(self, n)


    def capacity(self) -> "std::vector< std::pair< plValues,double > >::size_type":
        """capacity(self) -> std::vector< std::pair< plValues,double > >::size_type"""
        return _probt_python3.PairVPVVector_capacity(self)

    __swig_destroy__ = _probt_python3.delete_PairVPVVector
    __del__ = lambda self: None
PairVPVVector_swigregister = _probt_python3.PairVPVVector_swigregister
PairVPVVector_swigregister(PairVPVVector)

class PairStringUiVector(_object):
    """Proxy of C++ std::vector<(std::pair<(std::string,unsigned int)>)> class."""

    __swig_setmethods__ = {}
    __setattr__ = lambda self, name, value: _swig_setattr(self, PairStringUiVector, name, value)
    __swig_getmethods__ = {}
    __getattr__ = lambda self, name: _swig_getattr(self, PairStringUiVector, name)
    __repr__ = _swig_repr

    def iterator(self) -> "swig::SwigPyIterator *":
        """iterator(self) -> SwigPyIterator"""
        return _probt_python3.PairStringUiVector_iterator(self)

    def __iter__(self):
        return self.iterator()

    def __nonzero__(self) -> "bool":
        """__nonzero__(self) -> bool"""
        return _probt_python3.PairStringUiVector___nonzero__(self)


    def __bool__(self) -> "bool":
        """__bool__(self) -> bool"""
        return _probt_python3.PairStringUiVector___bool__(self)


    def __len__(self) -> "std::vector< std::pair< std::string,unsigned int > >::size_type":
        """__len__(self) -> std::vector< std::pair< std::string,unsigned int > >::size_type"""
        return _probt_python3.PairStringUiVector___len__(self)


    def __getslice__(self, i: 'std::vector< std::pair< std::string,unsigned int > >::difference_type', j: 'std::vector< std::pair< std::string,unsigned int > >::difference_type') -> "std::vector< std::pair< std::string,unsigned int >,std::allocator< std::pair< std::string,unsigned int > > > *":
        """__getslice__(self, i, j) -> PairStringUiVector"""
        return _probt_python3.PairStringUiVector___getslice__(self, i, j)


    def __setslice__(self, *args) -> "void":
        """
        __setslice__(self, i, j)
        __setslice__(self, i, j, v)
        """
        return _probt_python3.PairStringUiVector___setslice__(self, *args)


    def __delslice__(self, i: 'std::vector< std::pair< std::string,unsigned int > >::difference_type', j: 'std::vector< std::pair< std::string,unsigned int > >::difference_type') -> "void":
        """__delslice__(self, i, j)"""
        return _probt_python3.PairStringUiVector___delslice__(self, i, j)


    def __delitem__(self, *args) -> "void":
        """
        __delitem__(self, i)
        __delitem__(self, slice)
        """
        return _probt_python3.PairStringUiVector___delitem__(self, *args)


    def __getitem__(self, *args) -> "std::vector< std::pair< std::string,unsigned int > >::value_type const &":
        """
        __getitem__(self, slice) -> PairStringUiVector
        __getitem__(self, i) -> std::vector< std::pair< std::string,unsigned int > >::value_type const &
        """
        return _probt_python3.PairStringUiVector___getitem__(self, *args)


    def __setitem__(self, *args) -> "void":
        """
        __setitem__(self, slice, v)
        __setitem__(self, slice)
        __setitem__(self, i, x)
        """
        return _probt_python3.PairStringUiVector___setitem__(self, *args)


    def pop(self) -> "std::vector< std::pair< std::string,unsigned int > >::value_type":
        """pop(self) -> std::vector< std::pair< std::string,unsigned int > >::value_type"""
        return _probt_python3.PairStringUiVector_pop(self)


    def append(self, x: 'std::vector< std::pair< std::string,unsigned int > >::value_type const &') -> "void":
        """append(self, x)"""
        return _probt_python3.PairStringUiVector_append(self, x)


    def empty(self) -> "bool":
        """empty(self) -> bool"""
        return _probt_python3.PairStringUiVector_empty(self)


    def size(self) -> "std::vector< std::pair< std::string,unsigned int > >::size_type":
        """size(self) -> std::vector< std::pair< std::string,unsigned int > >::size_type"""
        return _probt_python3.PairStringUiVector_size(self)


    def swap(self, v: 'PairStringUiVector') -> "void":
        """swap(self, v)"""
        return _probt_python3.PairStringUiVector_swap(self, v)


    def begin(self) -> "std::vector< std::pair< std::string,unsigned int > >::iterator":
        """begin(self) -> std::vector< std::pair< std::string,unsigned int > >::iterator"""
        return _probt_python3.PairStringUiVector_begin(self)


    def end(self) -> "std::vector< std::pair< std::string,unsigned int > >::iterator":
        """end(self) -> std::vector< std::pair< std::string,unsigned int > >::iterator"""
        return _probt_python3.PairStringUiVector_end(self)


    def rbegin(self) -> "std::vector< std::pair< std::string,unsigned int > >::reverse_iterator":
        """rbegin(self) -> std::vector< std::pair< std::string,unsigned int > >::reverse_iterator"""
        return _probt_python3.PairStringUiVector_rbegin(self)


    def rend(self) -> "std::vector< std::pair< std::string,unsigned int > >::reverse_iterator":
        """rend(self) -> std::vector< std::pair< std::string,unsigned int > >::reverse_iterator"""
        return _probt_python3.PairStringUiVector_rend(self)


    def clear(self) -> "void":
        """clear(self)"""
        return _probt_python3.PairStringUiVector_clear(self)


    def get_allocator(self) -> "std::vector< std::pair< std::string,unsigned int > >::allocator_type":
        """get_allocator(self) -> std::vector< std::pair< std::string,unsigned int > >::allocator_type"""
        return _probt_python3.PairStringUiVector_get_allocator(self)


    def pop_back(self) -> "void":
        """pop_back(self)"""
        return _probt_python3.PairStringUiVector_pop_back(self)


    def erase(self, *args) -> "std::vector< std::pair< std::string,unsigned int > >::iterator":
        """
        erase(self, pos) -> std::vector< std::pair< std::string,unsigned int > >::iterator
        erase(self, first, last) -> std::vector< std::pair< std::string,unsigned int > >::iterator
        """
        return _probt_python3.PairStringUiVector_erase(self, *args)


    def __init__(self, *args):
        """
        __init__(self) -> PairStringUiVector
        __init__(self, arg2) -> PairStringUiVector
        __init__(self, size) -> PairStringUiVector
        __init__(self, size, value) -> PairStringUiVector
        """
        this = _probt_python3.new_PairStringUiVector(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def push_back(self, x: 'std::vector< std::pair< std::string,unsigned int > >::value_type const &') -> "void":
        """push_back(self, x)"""
        return _probt_python3.PairStringUiVector_push_back(self, x)


    def front(self) -> "std::vector< std::pair< std::string,unsigned int > >::value_type const &":
        """front(self) -> std::vector< std::pair< std::string,unsigned int > >::value_type const &"""
        return _probt_python3.PairStringUiVector_front(self)


    def back(self) -> "std::vector< std::pair< std::string,unsigned int > >::value_type const &":
        """back(self) -> std::vector< std::pair< std::string,unsigned int > >::value_type const &"""
        return _probt_python3.PairStringUiVector_back(self)


    def assign(self, n: 'std::vector< std::pair< std::string,unsigned int > >::size_type', x: 'std::vector< std::pair< std::string,unsigned int > >::value_type const &') -> "void":
        """assign(self, n, x)"""
        return _probt_python3.PairStringUiVector_assign(self, n, x)


    def resize(self, *args) -> "void":
        """
        resize(self, new_size)
        resize(self, new_size, x)
        """
        return _probt_python3.PairStringUiVector_resize(self, *args)


    def insert(self, *args) -> "void":
        """
        insert(self, pos, x) -> std::vector< std::pair< std::string,unsigned int > >::iterator
        insert(self, pos, n, x)
        """
        return _probt_python3.PairStringUiVector_insert(self, *args)


    def reserve(self, n: 'std::vector< std::pair< std::string,unsigned int > >::size_type') -> "void":
        """reserve(self, n)"""
        return _probt_python3.PairStringUiVector_reserve(self, n)


    def capacity(self) -> "std::vector< std::pair< std::string,unsigned int > >::size_type":
        """capacity(self) -> std::vector< std::pair< std::string,unsigned int > >::size_type"""
        return _probt_python3.PairStringUiVector_capacity(self)

    __swig_destroy__ = _probt_python3.delete_PairStringUiVector
    __del__ = lambda self: None
PairStringUiVector_swigregister = _probt_python3.PairStringUiVector_swigregister
PairStringUiVector_swigregister(PairStringUiVector)

class IntVector(_object):
    """Proxy of C++ std::vector<(int)> class."""

    __swig_setmethods__ = {}
    __setattr__ = lambda self, name, value: _swig_setattr(self, IntVector, name, value)
    __swig_getmethods__ = {}
    __getattr__ = lambda self, name: _swig_getattr(self, IntVector, name)
    __repr__ = _swig_repr

    def iterator(self) -> "swig::SwigPyIterator *":
        """iterator(self) -> SwigPyIterator"""
        return _probt_python3.IntVector_iterator(self)

    def __iter__(self):
        return self.iterator()

    def __nonzero__(self) -> "bool":
        """__nonzero__(self) -> bool"""
        return _probt_python3.IntVector___nonzero__(self)


    def __bool__(self) -> "bool":
        """__bool__(self) -> bool"""
        return _probt_python3.IntVector___bool__(self)


    def __len__(self) -> "std::vector< int >::size_type":
        """__len__(self) -> std::vector< int >::size_type"""
        return _probt_python3.IntVector___len__(self)


    def __getslice__(self, i: 'std::vector< int >::difference_type', j: 'std::vector< int >::difference_type') -> "std::vector< int,std::allocator< int > > *":
        """__getslice__(self, i, j) -> IntVector"""
        return _probt_python3.IntVector___getslice__(self, i, j)


    def __setslice__(self, *args) -> "void":
        """
        __setslice__(self, i, j)
        __setslice__(self, i, j, v)
        """
        return _probt_python3.IntVector___setslice__(self, *args)


    def __delslice__(self, i: 'std::vector< int >::difference_type', j: 'std::vector< int >::difference_type') -> "void":
        """__delslice__(self, i, j)"""
        return _probt_python3.IntVector___delslice__(self, i, j)


    def __delitem__(self, *args) -> "void":
        """
        __delitem__(self, i)
        __delitem__(self, slice)
        """
        return _probt_python3.IntVector___delitem__(self, *args)


    def __getitem__(self, *args) -> "std::vector< int >::value_type const &":
        """
        __getitem__(self, slice) -> IntVector
        __getitem__(self, i) -> std::vector< int >::value_type const &
        """
        return _probt_python3.IntVector___getitem__(self, *args)


    def __setitem__(self, *args) -> "void":
        """
        __setitem__(self, slice, v)
        __setitem__(self, slice)
        __setitem__(self, i, x)
        """
        return _probt_python3.IntVector___setitem__(self, *args)


    def pop(self) -> "std::vector< int >::value_type":
        """pop(self) -> std::vector< int >::value_type"""
        return _probt_python3.IntVector_pop(self)


    def append(self, x: 'std::vector< int >::value_type const &') -> "void":
        """append(self, x)"""
        return _probt_python3.IntVector_append(self, x)


    def empty(self) -> "bool":
        """empty(self) -> bool"""
        return _probt_python3.IntVector_empty(self)


    def size(self) -> "std::vector< int >::size_type":
        """size(self) -> std::vector< int >::size_type"""
        return _probt_python3.IntVector_size(self)


    def swap(self, v: 'IntVector') -> "void":
        """swap(self, v)"""
        return _probt_python3.IntVector_swap(self, v)


    def begin(self) -> "std::vector< int >::iterator":
        """begin(self) -> std::vector< int >::iterator"""
        return _probt_python3.IntVector_begin(self)


    def end(self) -> "std::vector< int >::iterator":
        """end(self) -> std::vector< int >::iterator"""
        return _probt_python3.IntVector_end(self)


    def rbegin(self) -> "std::vector< int >::reverse_iterator":
        """rbegin(self) -> std::vector< int >::reverse_iterator"""
        return _probt_python3.IntVector_rbegin(self)


    def rend(self) -> "std::vector< int >::reverse_iterator":
        """rend(self) -> std::vector< int >::reverse_iterator"""
        return _probt_python3.IntVector_rend(self)


    def clear(self) -> "void":
        """clear(self)"""
        return _probt_python3.IntVector_clear(self)


    def get_allocator(self) -> "std::vector< int >::allocator_type":
        """get_allocator(self) -> std::vector< int >::allocator_type"""
        return _probt_python3.IntVector_get_allocator(self)


    def pop_back(self) -> "void":
        """pop_back(self)"""
        return _probt_python3.IntVector_pop_back(self)


    def erase(self, *args) -> "std::vector< int >::iterator":
        """
        erase(self, pos) -> std::vector< int >::iterator
        erase(self, first, last) -> std::vector< int >::iterator
        """
        return _probt_python3.IntVector_erase(self, *args)


    def __init__(self, *args):
        """
        __init__(self) -> IntVector
        __init__(self, arg2) -> IntVector
        __init__(self, size) -> IntVector
        __init__(self, size, value) -> IntVector
        """
        this = _probt_python3.new_IntVector(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def push_back(self, x: 'std::vector< int >::value_type const &') -> "void":
        """push_back(self, x)"""
        return _probt_python3.IntVector_push_back(self, x)


    def front(self) -> "std::vector< int >::value_type const &":
        """front(self) -> std::vector< int >::value_type const &"""
        return _probt_python3.IntVector_front(self)


    def back(self) -> "std::vector< int >::value_type const &":
        """back(self) -> std::vector< int >::value_type const &"""
        return _probt_python3.IntVector_back(self)


    def assign(self, n: 'std::vector< int >::size_type', x: 'std::vector< int >::value_type const &') -> "void":
        """assign(self, n, x)"""
        return _probt_python3.IntVector_assign(self, n, x)


    def resize(self, *args) -> "void":
        """
        resize(self, new_size)
        resize(self, new_size, x)
        """
        return _probt_python3.IntVector_resize(self, *args)


    def insert(self, *args) -> "void":
        """
        insert(self, pos, x) -> std::vector< int >::iterator
        insert(self, pos, n, x)
        """
        return _probt_python3.IntVector_insert(self, *args)


    def reserve(self, n: 'std::vector< int >::size_type') -> "void":
        """reserve(self, n)"""
        return _probt_python3.IntVector_reserve(self, n)


    def capacity(self) -> "std::vector< int >::size_type":
        """capacity(self) -> std::vector< int >::size_type"""
        return _probt_python3.IntVector_capacity(self)

    __swig_destroy__ = _probt_python3.delete_IntVector
    __del__ = lambda self: None
IntVector_swigregister = _probt_python3.IntVector_swigregister
IntVector_swigregister(IntVector)

class IntVectorVector(_object):
    """Proxy of C++ std::vector<(std::vector<(int)>)> class."""

    __swig_setmethods__ = {}
    __setattr__ = lambda self, name, value: _swig_setattr(self, IntVectorVector, name, value)
    __swig_getmethods__ = {}
    __getattr__ = lambda self, name: _swig_getattr(self, IntVectorVector, name)
    __repr__ = _swig_repr

    def iterator(self) -> "swig::SwigPyIterator *":
        """iterator(self) -> SwigPyIterator"""
        return _probt_python3.IntVectorVector_iterator(self)

    def __iter__(self):
        return self.iterator()

    def __nonzero__(self) -> "bool":
        """__nonzero__(self) -> bool"""
        return _probt_python3.IntVectorVector___nonzero__(self)


    def __bool__(self) -> "bool":
        """__bool__(self) -> bool"""
        return _probt_python3.IntVectorVector___bool__(self)


    def __len__(self) -> "std::vector< std::vector< int > >::size_type":
        """__len__(self) -> std::vector< std::vector< int > >::size_type"""
        return _probt_python3.IntVectorVector___len__(self)


    def __getslice__(self, i: 'std::vector< std::vector< int > >::difference_type', j: 'std::vector< std::vector< int > >::difference_type') -> "std::vector< std::vector< int,std::allocator< int > >,std::allocator< std::vector< int,std::allocator< int > > > > *":
        """__getslice__(self, i, j) -> IntVectorVector"""
        return _probt_python3.IntVectorVector___getslice__(self, i, j)


    def __setslice__(self, *args) -> "void":
        """
        __setslice__(self, i, j)
        __setslice__(self, i, j, v)
        """
        return _probt_python3.IntVectorVector___setslice__(self, *args)


    def __delslice__(self, i: 'std::vector< std::vector< int > >::difference_type', j: 'std::vector< std::vector< int > >::difference_type') -> "void":
        """__delslice__(self, i, j)"""
        return _probt_python3.IntVectorVector___delslice__(self, i, j)


    def __delitem__(self, *args) -> "void":
        """
        __delitem__(self, i)
        __delitem__(self, slice)
        """
        return _probt_python3.IntVectorVector___delitem__(self, *args)


    def __getitem__(self, *args) -> "std::vector< std::vector< int > >::value_type const &":
        """
        __getitem__(self, slice) -> IntVectorVector
        __getitem__(self, i) -> IntVector
        """
        return _probt_python3.IntVectorVector___getitem__(self, *args)


    def __setitem__(self, *args) -> "void":
        """
        __setitem__(self, slice, v)
        __setitem__(self, slice)
        __setitem__(self, i, x)
        """
        return _probt_python3.IntVectorVector___setitem__(self, *args)


    def pop(self) -> "std::vector< std::vector< int > >::value_type":
        """pop(self) -> IntVector"""
        return _probt_python3.IntVectorVector_pop(self)


    def append(self, x: 'IntVector') -> "void":
        """append(self, x)"""
        return _probt_python3.IntVectorVector_append(self, x)


    def empty(self) -> "bool":
        """empty(self) -> bool"""
        return _probt_python3.IntVectorVector_empty(self)


    def size(self) -> "std::vector< std::vector< int > >::size_type":
        """size(self) -> std::vector< std::vector< int > >::size_type"""
        return _probt_python3.IntVectorVector_size(self)


    def swap(self, v: 'IntVectorVector') -> "void":
        """swap(self, v)"""
        return _probt_python3.IntVectorVector_swap(self, v)


    def begin(self) -> "std::vector< std::vector< int > >::iterator":
        """begin(self) -> std::vector< std::vector< int > >::iterator"""
        return _probt_python3.IntVectorVector_begin(self)


    def end(self) -> "std::vector< std::vector< int > >::iterator":
        """end(self) -> std::vector< std::vector< int > >::iterator"""
        return _probt_python3.IntVectorVector_end(self)


    def rbegin(self) -> "std::vector< std::vector< int > >::reverse_iterator":
        """rbegin(self) -> std::vector< std::vector< int > >::reverse_iterator"""
        return _probt_python3.IntVectorVector_rbegin(self)


    def rend(self) -> "std::vector< std::vector< int > >::reverse_iterator":
        """rend(self) -> std::vector< std::vector< int > >::reverse_iterator"""
        return _probt_python3.IntVectorVector_rend(self)


    def clear(self) -> "void":
        """clear(self)"""
        return _probt_python3.IntVectorVector_clear(self)


    def get_allocator(self) -> "std::vector< std::vector< int > >::allocator_type":
        """get_allocator(self) -> std::vector< std::vector< int > >::allocator_type"""
        return _probt_python3.IntVectorVector_get_allocator(self)


    def pop_back(self) -> "void":
        """pop_back(self)"""
        return _probt_python3.IntVectorVector_pop_back(self)


    def erase(self, *args) -> "std::vector< std::vector< int > >::iterator":
        """
        erase(self, pos) -> std::vector< std::vector< int > >::iterator
        erase(self, first, last) -> std::vector< std::vector< int > >::iterator
        """
        return _probt_python3.IntVectorVector_erase(self, *args)


    def __init__(self, *args):
        """
        __init__(self) -> IntVectorVector
        __init__(self, arg2) -> IntVectorVector
        __init__(self, size) -> IntVectorVector
        __init__(self, size, value) -> IntVectorVector
        """
        this = _probt_python3.new_IntVectorVector(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def push_back(self, x: 'IntVector') -> "void":
        """push_back(self, x)"""
        return _probt_python3.IntVectorVector_push_back(self, x)


    def front(self) -> "std::vector< std::vector< int > >::value_type const &":
        """front(self) -> IntVector"""
        return _probt_python3.IntVectorVector_front(self)


    def back(self) -> "std::vector< std::vector< int > >::value_type const &":
        """back(self) -> IntVector"""
        return _probt_python3.IntVectorVector_back(self)


    def assign(self, n: 'std::vector< std::vector< int > >::size_type', x: 'IntVector') -> "void":
        """assign(self, n, x)"""
        return _probt_python3.IntVectorVector_assign(self, n, x)


    def resize(self, *args) -> "void":
        """
        resize(self, new_size)
        resize(self, new_size, x)
        """
        return _probt_python3.IntVectorVector_resize(self, *args)


    def insert(self, *args) -> "void":
        """
        insert(self, pos, x) -> std::vector< std::vector< int > >::iterator
        insert(self, pos, n, x)
        """
        return _probt_python3.IntVectorVector_insert(self, *args)


    def reserve(self, n: 'std::vector< std::vector< int > >::size_type') -> "void":
        """reserve(self, n)"""
        return _probt_python3.IntVectorVector_reserve(self, n)


    def capacity(self) -> "std::vector< std::vector< int > >::size_type":
        """capacity(self) -> std::vector< std::vector< int > >::size_type"""
        return _probt_python3.IntVectorVector_capacity(self)

    __swig_destroy__ = _probt_python3.delete_IntVectorVector
    __del__ = lambda self: None
IntVectorVector_swigregister = _probt_python3.IntVectorVector_swigregister
IntVectorVector_swigregister(IntVectorVector)

class UnsignedIntVector(_object):
    """Proxy of C++ std::vector<(unsigned int)> class."""

    __swig_setmethods__ = {}
    __setattr__ = lambda self, name, value: _swig_setattr(self, UnsignedIntVector, name, value)
    __swig_getmethods__ = {}
    __getattr__ = lambda self, name: _swig_getattr(self, UnsignedIntVector, name)
    __repr__ = _swig_repr

    def iterator(self) -> "swig::SwigPyIterator *":
        """iterator(self) -> SwigPyIterator"""
        return _probt_python3.UnsignedIntVector_iterator(self)

    def __iter__(self):
        return self.iterator()

    def __nonzero__(self) -> "bool":
        """__nonzero__(self) -> bool"""
        return _probt_python3.UnsignedIntVector___nonzero__(self)


    def __bool__(self) -> "bool":
        """__bool__(self) -> bool"""
        return _probt_python3.UnsignedIntVector___bool__(self)


    def __len__(self) -> "std::vector< unsigned int >::size_type":
        """__len__(self) -> std::vector< unsigned int >::size_type"""
        return _probt_python3.UnsignedIntVector___len__(self)


    def __getslice__(self, i: 'std::vector< unsigned int >::difference_type', j: 'std::vector< unsigned int >::difference_type') -> "std::vector< unsigned int,std::allocator< unsigned int > > *":
        """__getslice__(self, i, j) -> UnsignedIntVector"""
        return _probt_python3.UnsignedIntVector___getslice__(self, i, j)


    def __setslice__(self, *args) -> "void":
        """
        __setslice__(self, i, j)
        __setslice__(self, i, j, v)
        """
        return _probt_python3.UnsignedIntVector___setslice__(self, *args)


    def __delslice__(self, i: 'std::vector< unsigned int >::difference_type', j: 'std::vector< unsigned int >::difference_type') -> "void":
        """__delslice__(self, i, j)"""
        return _probt_python3.UnsignedIntVector___delslice__(self, i, j)


    def __delitem__(self, *args) -> "void":
        """
        __delitem__(self, i)
        __delitem__(self, slice)
        """
        return _probt_python3.UnsignedIntVector___delitem__(self, *args)


    def __getitem__(self, *args) -> "std::vector< unsigned int >::value_type const &":
        """
        __getitem__(self, slice) -> UnsignedIntVector
        __getitem__(self, i) -> std::vector< unsigned int >::value_type const &
        """
        return _probt_python3.UnsignedIntVector___getitem__(self, *args)


    def __setitem__(self, *args) -> "void":
        """
        __setitem__(self, slice, v)
        __setitem__(self, slice)
        __setitem__(self, i, x)
        """
        return _probt_python3.UnsignedIntVector___setitem__(self, *args)


    def pop(self) -> "std::vector< unsigned int >::value_type":
        """pop(self) -> std::vector< unsigned int >::value_type"""
        return _probt_python3.UnsignedIntVector_pop(self)


    def append(self, x: 'std::vector< unsigned int >::value_type const &') -> "void":
        """append(self, x)"""
        return _probt_python3.UnsignedIntVector_append(self, x)


    def empty(self) -> "bool":
        """empty(self) -> bool"""
        return _probt_python3.UnsignedIntVector_empty(self)


    def size(self) -> "std::vector< unsigned int >::size_type":
        """size(self) -> std::vector< unsigned int >::size_type"""
        return _probt_python3.UnsignedIntVector_size(self)


    def swap(self, v: 'UnsignedIntVector') -> "void":
        """swap(self, v)"""
        return _probt_python3.UnsignedIntVector_swap(self, v)


    def begin(self) -> "std::vector< unsigned int >::iterator":
        """begin(self) -> std::vector< unsigned int >::iterator"""
        return _probt_python3.UnsignedIntVector_begin(self)


    def end(self) -> "std::vector< unsigned int >::iterator":
        """end(self) -> std::vector< unsigned int >::iterator"""
        return _probt_python3.UnsignedIntVector_end(self)


    def rbegin(self) -> "std::vector< unsigned int >::reverse_iterator":
        """rbegin(self) -> std::vector< unsigned int >::reverse_iterator"""
        return _probt_python3.UnsignedIntVector_rbegin(self)


    def rend(self) -> "std::vector< unsigned int >::reverse_iterator":
        """rend(self) -> std::vector< unsigned int >::reverse_iterator"""
        return _probt_python3.UnsignedIntVector_rend(self)


    def clear(self) -> "void":
        """clear(self)"""
        return _probt_python3.UnsignedIntVector_clear(self)


    def get_allocator(self) -> "std::vector< unsigned int >::allocator_type":
        """get_allocator(self) -> std::vector< unsigned int >::allocator_type"""
        return _probt_python3.UnsignedIntVector_get_allocator(self)


    def pop_back(self) -> "void":
        """pop_back(self)"""
        return _probt_python3.UnsignedIntVector_pop_back(self)


    def erase(self, *args) -> "std::vector< unsigned int >::iterator":
        """
        erase(self, pos) -> std::vector< unsigned int >::iterator
        erase(self, first, last) -> std::vector< unsigned int >::iterator
        """
        return _probt_python3.UnsignedIntVector_erase(self, *args)


    def __init__(self, *args):
        """
        __init__(self) -> UnsignedIntVector
        __init__(self, arg2) -> UnsignedIntVector
        __init__(self, size) -> UnsignedIntVector
        __init__(self, size, value) -> UnsignedIntVector
        """
        this = _probt_python3.new_UnsignedIntVector(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def push_back(self, x: 'std::vector< unsigned int >::value_type const &') -> "void":
        """push_back(self, x)"""
        return _probt_python3.UnsignedIntVector_push_back(self, x)


    def front(self) -> "std::vector< unsigned int >::value_type const &":
        """front(self) -> std::vector< unsigned int >::value_type const &"""
        return _probt_python3.UnsignedIntVector_front(self)


    def back(self) -> "std::vector< unsigned int >::value_type const &":
        """back(self) -> std::vector< unsigned int >::value_type const &"""
        return _probt_python3.UnsignedIntVector_back(self)


    def assign(self, n: 'std::vector< unsigned int >::size_type', x: 'std::vector< unsigned int >::value_type const &') -> "void":
        """assign(self, n, x)"""
        return _probt_python3.UnsignedIntVector_assign(self, n, x)


    def resize(self, *args) -> "void":
        """
        resize(self, new_size)
        resize(self, new_size, x)
        """
        return _probt_python3.UnsignedIntVector_resize(self, *args)


    def insert(self, *args) -> "void":
        """
        insert(self, pos, x) -> std::vector< unsigned int >::iterator
        insert(self, pos, n, x)
        """
        return _probt_python3.UnsignedIntVector_insert(self, *args)


    def reserve(self, n: 'std::vector< unsigned int >::size_type') -> "void":
        """reserve(self, n)"""
        return _probt_python3.UnsignedIntVector_reserve(self, n)


    def capacity(self) -> "std::vector< unsigned int >::size_type":
        """capacity(self) -> std::vector< unsigned int >::size_type"""
        return _probt_python3.UnsignedIntVector_capacity(self)

    __swig_destroy__ = _probt_python3.delete_UnsignedIntVector
    __del__ = lambda self: None
UnsignedIntVector_swigregister = _probt_python3.UnsignedIntVector_swigregister
UnsignedIntVector_swigregister(UnsignedIntVector)

class UnsignedIntVectorVector(_object):
    """Proxy of C++ std::vector<(std::vector<(unsigned int)>)> class."""

    __swig_setmethods__ = {}
    __setattr__ = lambda self, name, value: _swig_setattr(self, UnsignedIntVectorVector, name, value)
    __swig_getmethods__ = {}
    __getattr__ = lambda self, name: _swig_getattr(self, UnsignedIntVectorVector, name)
    __repr__ = _swig_repr

    def iterator(self) -> "swig::SwigPyIterator *":
        """iterator(self) -> SwigPyIterator"""
        return _probt_python3.UnsignedIntVectorVector_iterator(self)

    def __iter__(self):
        return self.iterator()

    def __nonzero__(self) -> "bool":
        """__nonzero__(self) -> bool"""
        return _probt_python3.UnsignedIntVectorVector___nonzero__(self)


    def __bool__(self) -> "bool":
        """__bool__(self) -> bool"""
        return _probt_python3.UnsignedIntVectorVector___bool__(self)


    def __len__(self) -> "std::vector< std::vector< unsigned int > >::size_type":
        """__len__(self) -> std::vector< std::vector< unsigned int > >::size_type"""
        return _probt_python3.UnsignedIntVectorVector___len__(self)


    def __getslice__(self, i: 'std::vector< std::vector< unsigned int > >::difference_type', j: 'std::vector< std::vector< unsigned int > >::difference_type') -> "std::vector< std::vector< unsigned int,std::allocator< unsigned int > >,std::allocator< std::vector< unsigned int,std::allocator< unsigned int > > > > *":
        """__getslice__(self, i, j) -> UnsignedIntVectorVector"""
        return _probt_python3.UnsignedIntVectorVector___getslice__(self, i, j)


    def __setslice__(self, *args) -> "void":
        """
        __setslice__(self, i, j)
        __setslice__(self, i, j, v)
        """
        return _probt_python3.UnsignedIntVectorVector___setslice__(self, *args)


    def __delslice__(self, i: 'std::vector< std::vector< unsigned int > >::difference_type', j: 'std::vector< std::vector< unsigned int > >::difference_type') -> "void":
        """__delslice__(self, i, j)"""
        return _probt_python3.UnsignedIntVectorVector___delslice__(self, i, j)


    def __delitem__(self, *args) -> "void":
        """
        __delitem__(self, i)
        __delitem__(self, slice)
        """
        return _probt_python3.UnsignedIntVectorVector___delitem__(self, *args)


    def __getitem__(self, *args) -> "std::vector< std::vector< unsigned int > >::value_type const &":
        """
        __getitem__(self, slice) -> UnsignedIntVectorVector
        __getitem__(self, i) -> UnsignedIntVector
        """
        return _probt_python3.UnsignedIntVectorVector___getitem__(self, *args)


    def __setitem__(self, *args) -> "void":
        """
        __setitem__(self, slice, v)
        __setitem__(self, slice)
        __setitem__(self, i, x)
        """
        return _probt_python3.UnsignedIntVectorVector___setitem__(self, *args)


    def pop(self) -> "std::vector< std::vector< unsigned int > >::value_type":
        """pop(self) -> UnsignedIntVector"""
        return _probt_python3.UnsignedIntVectorVector_pop(self)


    def append(self, x: 'UnsignedIntVector') -> "void":
        """append(self, x)"""
        return _probt_python3.UnsignedIntVectorVector_append(self, x)


    def empty(self) -> "bool":
        """empty(self) -> bool"""
        return _probt_python3.UnsignedIntVectorVector_empty(self)


    def size(self) -> "std::vector< std::vector< unsigned int > >::size_type":
        """size(self) -> std::vector< std::vector< unsigned int > >::size_type"""
        return _probt_python3.UnsignedIntVectorVector_size(self)


    def swap(self, v: 'UnsignedIntVectorVector') -> "void":
        """swap(self, v)"""
        return _probt_python3.UnsignedIntVectorVector_swap(self, v)


    def begin(self) -> "std::vector< std::vector< unsigned int > >::iterator":
        """begin(self) -> std::vector< std::vector< unsigned int > >::iterator"""
        return _probt_python3.UnsignedIntVectorVector_begin(self)


    def end(self) -> "std::vector< std::vector< unsigned int > >::iterator":
        """end(self) -> std::vector< std::vector< unsigned int > >::iterator"""
        return _probt_python3.UnsignedIntVectorVector_end(self)


    def rbegin(self) -> "std::vector< std::vector< unsigned int > >::reverse_iterator":
        """rbegin(self) -> std::vector< std::vector< unsigned int > >::reverse_iterator"""
        return _probt_python3.UnsignedIntVectorVector_rbegin(self)


    def rend(self) -> "std::vector< std::vector< unsigned int > >::reverse_iterator":
        """rend(self) -> std::vector< std::vector< unsigned int > >::reverse_iterator"""
        return _probt_python3.UnsignedIntVectorVector_rend(self)


    def clear(self) -> "void":
        """clear(self)"""
        return _probt_python3.UnsignedIntVectorVector_clear(self)


    def get_allocator(self) -> "std::vector< std::vector< unsigned int > >::allocator_type":
        """get_allocator(self) -> std::vector< std::vector< unsigned int > >::allocator_type"""
        return _probt_python3.UnsignedIntVectorVector_get_allocator(self)


    def pop_back(self) -> "void":
        """pop_back(self)"""
        return _probt_python3.UnsignedIntVectorVector_pop_back(self)


    def erase(self, *args) -> "std::vector< std::vector< unsigned int > >::iterator":
        """
        erase(self, pos) -> std::vector< std::vector< unsigned int > >::iterator
        erase(self, first, last) -> std::vector< std::vector< unsigned int > >::iterator
        """
        return _probt_python3.UnsignedIntVectorVector_erase(self, *args)


    def __init__(self, *args):
        """
        __init__(self) -> UnsignedIntVectorVector
        __init__(self, arg2) -> UnsignedIntVectorVector
        __init__(self, size) -> UnsignedIntVectorVector
        __init__(self, size, value) -> UnsignedIntVectorVector
        """
        this = _probt_python3.new_UnsignedIntVectorVector(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def push_back(self, x: 'UnsignedIntVector') -> "void":
        """push_back(self, x)"""
        return _probt_python3.UnsignedIntVectorVector_push_back(self, x)


    def front(self) -> "std::vector< std::vector< unsigned int > >::value_type const &":
        """front(self) -> UnsignedIntVector"""
        return _probt_python3.UnsignedIntVectorVector_front(self)


    def back(self) -> "std::vector< std::vector< unsigned int > >::value_type const &":
        """back(self) -> UnsignedIntVector"""
        return _probt_python3.UnsignedIntVectorVector_back(self)


    def assign(self, n: 'std::vector< std::vector< unsigned int > >::size_type', x: 'UnsignedIntVector') -> "void":
        """assign(self, n, x)"""
        return _probt_python3.UnsignedIntVectorVector_assign(self, n, x)


    def resize(self, *args) -> "void":
        """
        resize(self, new_size)
        resize(self, new_size, x)
        """
        return _probt_python3.UnsignedIntVectorVector_resize(self, *args)


    def insert(self, *args) -> "void":
        """
        insert(self, pos, x) -> std::vector< std::vector< unsigned int > >::iterator
        insert(self, pos, n, x)
        """
        return _probt_python3.UnsignedIntVectorVector_insert(self, *args)


    def reserve(self, n: 'std::vector< std::vector< unsigned int > >::size_type') -> "void":
        """reserve(self, n)"""
        return _probt_python3.UnsignedIntVectorVector_reserve(self, n)


    def capacity(self) -> "std::vector< std::vector< unsigned int > >::size_type":
        """capacity(self) -> std::vector< std::vector< unsigned int > >::size_type"""
        return _probt_python3.UnsignedIntVectorVector_capacity(self)

    __swig_destroy__ = _probt_python3.delete_UnsignedIntVectorVector
    __del__ = lambda self: None
UnsignedIntVectorVector_swigregister = _probt_python3.UnsignedIntVectorVector_swigregister
UnsignedIntVectorVector_swigregister(UnsignedIntVectorVector)

class StringVector(_object):
    """Proxy of C++ std::vector<(std::string)> class."""

    __swig_setmethods__ = {}
    __setattr__ = lambda self, name, value: _swig_setattr(self, StringVector, name, value)
    __swig_getmethods__ = {}
    __getattr__ = lambda self, name: _swig_getattr(self, StringVector, name)
    __repr__ = _swig_repr

    def iterator(self) -> "swig::SwigPyIterator *":
        """iterator(self) -> SwigPyIterator"""
        return _probt_python3.StringVector_iterator(self)

    def __iter__(self):
        return self.iterator()

    def __nonzero__(self) -> "bool":
        """__nonzero__(self) -> bool"""
        return _probt_python3.StringVector___nonzero__(self)


    def __bool__(self) -> "bool":
        """__bool__(self) -> bool"""
        return _probt_python3.StringVector___bool__(self)


    def __len__(self) -> "std::vector< std::string >::size_type":
        """__len__(self) -> std::vector< std::string >::size_type"""
        return _probt_python3.StringVector___len__(self)


    def __getslice__(self, i: 'std::vector< std::string >::difference_type', j: 'std::vector< std::string >::difference_type') -> "std::vector< std::string,std::allocator< std::string > > *":
        """__getslice__(self, i, j) -> StringVector"""
        return _probt_python3.StringVector___getslice__(self, i, j)


    def __setslice__(self, *args) -> "void":
        """
        __setslice__(self, i, j)
        __setslice__(self, i, j, v)
        """
        return _probt_python3.StringVector___setslice__(self, *args)


    def __delslice__(self, i: 'std::vector< std::string >::difference_type', j: 'std::vector< std::string >::difference_type') -> "void":
        """__delslice__(self, i, j)"""
        return _probt_python3.StringVector___delslice__(self, i, j)


    def __delitem__(self, *args) -> "void":
        """
        __delitem__(self, i)
        __delitem__(self, slice)
        """
        return _probt_python3.StringVector___delitem__(self, *args)


    def __getitem__(self, *args) -> "std::vector< std::string >::value_type const &":
        """
        __getitem__(self, slice) -> StringVector
        __getitem__(self, i) -> std::vector< std::string >::value_type const &
        """
        return _probt_python3.StringVector___getitem__(self, *args)


    def __setitem__(self, *args) -> "void":
        """
        __setitem__(self, slice, v)
        __setitem__(self, slice)
        __setitem__(self, i, x)
        """
        return _probt_python3.StringVector___setitem__(self, *args)


    def pop(self) -> "std::vector< std::string >::value_type":
        """pop(self) -> std::vector< std::string >::value_type"""
        return _probt_python3.StringVector_pop(self)


    def append(self, x: 'std::vector< std::string >::value_type const &') -> "void":
        """append(self, x)"""
        return _probt_python3.StringVector_append(self, x)


    def empty(self) -> "bool":
        """empty(self) -> bool"""
        return _probt_python3.StringVector_empty(self)


    def size(self) -> "std::vector< std::string >::size_type":
        """size(self) -> std::vector< std::string >::size_type"""
        return _probt_python3.StringVector_size(self)


    def swap(self, v: 'StringVector') -> "void":
        """swap(self, v)"""
        return _probt_python3.StringVector_swap(self, v)


    def begin(self) -> "std::vector< std::string >::iterator":
        """begin(self) -> std::vector< std::string >::iterator"""
        return _probt_python3.StringVector_begin(self)


    def end(self) -> "std::vector< std::string >::iterator":
        """end(self) -> std::vector< std::string >::iterator"""
        return _probt_python3.StringVector_end(self)


    def rbegin(self) -> "std::vector< std::string >::reverse_iterator":
        """rbegin(self) -> std::vector< std::string >::reverse_iterator"""
        return _probt_python3.StringVector_rbegin(self)


    def rend(self) -> "std::vector< std::string >::reverse_iterator":
        """rend(self) -> std::vector< std::string >::reverse_iterator"""
        return _probt_python3.StringVector_rend(self)


    def clear(self) -> "void":
        """clear(self)"""
        return _probt_python3.StringVector_clear(self)


    def get_allocator(self) -> "std::vector< std::string >::allocator_type":
        """get_allocator(self) -> std::vector< std::string >::allocator_type"""
        return _probt_python3.StringVector_get_allocator(self)


    def pop_back(self) -> "void":
        """pop_back(self)"""
        return _probt_python3.StringVector_pop_back(self)


    def erase(self, *args) -> "std::vector< std::string >::iterator":
        """
        erase(self, pos) -> std::vector< std::string >::iterator
        erase(self, first, last) -> std::vector< std::string >::iterator
        """
        return _probt_python3.StringVector_erase(self, *args)


    def __init__(self, *args):
        """
        __init__(self) -> StringVector
        __init__(self, arg2) -> StringVector
        __init__(self, size) -> StringVector
        __init__(self, size, value) -> StringVector
        """
        this = _probt_python3.new_StringVector(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def push_back(self, x: 'std::vector< std::string >::value_type const &') -> "void":
        """push_back(self, x)"""
        return _probt_python3.StringVector_push_back(self, x)


    def front(self) -> "std::vector< std::string >::value_type const &":
        """front(self) -> std::vector< std::string >::value_type const &"""
        return _probt_python3.StringVector_front(self)


    def back(self) -> "std::vector< std::string >::value_type const &":
        """back(self) -> std::vector< std::string >::value_type const &"""
        return _probt_python3.StringVector_back(self)


    def assign(self, n: 'std::vector< std::string >::size_type', x: 'std::vector< std::string >::value_type const &') -> "void":
        """assign(self, n, x)"""
        return _probt_python3.StringVector_assign(self, n, x)


    def resize(self, *args) -> "void":
        """
        resize(self, new_size)
        resize(self, new_size, x)
        """
        return _probt_python3.StringVector_resize(self, *args)


    def insert(self, *args) -> "void":
        """
        insert(self, pos, x) -> std::vector< std::string >::iterator
        insert(self, pos, n, x)
        """
        return _probt_python3.StringVector_insert(self, *args)


    def reserve(self, n: 'std::vector< std::string >::size_type') -> "void":
        """reserve(self, n)"""
        return _probt_python3.StringVector_reserve(self, n)


    def capacity(self) -> "std::vector< std::string >::size_type":
        """capacity(self) -> std::vector< std::string >::size_type"""
        return _probt_python3.StringVector_capacity(self)

    __swig_destroy__ = _probt_python3.delete_StringVector
    __del__ = lambda self: None
StringVector_swigregister = _probt_python3.StringVector_swigregister
StringVector_swigregister(StringVector)

class StringVectorVector(_object):
    """Proxy of C++ std::vector<(std::vector<(std::string)>)> class."""

    __swig_setmethods__ = {}
    __setattr__ = lambda self, name, value: _swig_setattr(self, StringVectorVector, name, value)
    __swig_getmethods__ = {}
    __getattr__ = lambda self, name: _swig_getattr(self, StringVectorVector, name)
    __repr__ = _swig_repr

    def iterator(self) -> "swig::SwigPyIterator *":
        """iterator(self) -> SwigPyIterator"""
        return _probt_python3.StringVectorVector_iterator(self)

    def __iter__(self):
        return self.iterator()

    def __nonzero__(self) -> "bool":
        """__nonzero__(self) -> bool"""
        return _probt_python3.StringVectorVector___nonzero__(self)


    def __bool__(self) -> "bool":
        """__bool__(self) -> bool"""
        return _probt_python3.StringVectorVector___bool__(self)


    def __len__(self) -> "std::vector< std::vector< std::string > >::size_type":
        """__len__(self) -> std::vector< std::vector< std::string > >::size_type"""
        return _probt_python3.StringVectorVector___len__(self)


    def __getslice__(self, i: 'std::vector< std::vector< std::string > >::difference_type', j: 'std::vector< std::vector< std::string > >::difference_type') -> "std::vector< std::vector< std::string,std::allocator< std::string > >,std::allocator< std::vector< std::string,std::allocator< std::string > > > > *":
        """__getslice__(self, i, j) -> StringVectorVector"""
        return _probt_python3.StringVectorVector___getslice__(self, i, j)


    def __setslice__(self, *args) -> "void":
        """
        __setslice__(self, i, j)
        __setslice__(self, i, j, v)
        """
        return _probt_python3.StringVectorVector___setslice__(self, *args)


    def __delslice__(self, i: 'std::vector< std::vector< std::string > >::difference_type', j: 'std::vector< std::vector< std::string > >::difference_type') -> "void":
        """__delslice__(self, i, j)"""
        return _probt_python3.StringVectorVector___delslice__(self, i, j)


    def __delitem__(self, *args) -> "void":
        """
        __delitem__(self, i)
        __delitem__(self, slice)
        """
        return _probt_python3.StringVectorVector___delitem__(self, *args)


    def __getitem__(self, *args) -> "std::vector< std::vector< std::string > >::value_type const &":
        """
        __getitem__(self, slice) -> StringVectorVector
        __getitem__(self, i) -> StringVector
        """
        return _probt_python3.StringVectorVector___getitem__(self, *args)


    def __setitem__(self, *args) -> "void":
        """
        __setitem__(self, slice, v)
        __setitem__(self, slice)
        __setitem__(self, i, x)
        """
        return _probt_python3.StringVectorVector___setitem__(self, *args)


    def pop(self) -> "std::vector< std::vector< std::string > >::value_type":
        """pop(self) -> StringVector"""
        return _probt_python3.StringVectorVector_pop(self)


    def append(self, x: 'StringVector') -> "void":
        """append(self, x)"""
        return _probt_python3.StringVectorVector_append(self, x)


    def empty(self) -> "bool":
        """empty(self) -> bool"""
        return _probt_python3.StringVectorVector_empty(self)


    def size(self) -> "std::vector< std::vector< std::string > >::size_type":
        """size(self) -> std::vector< std::vector< std::string > >::size_type"""
        return _probt_python3.StringVectorVector_size(self)


    def swap(self, v: 'StringVectorVector') -> "void":
        """swap(self, v)"""
        return _probt_python3.StringVectorVector_swap(self, v)


    def begin(self) -> "std::vector< std::vector< std::string > >::iterator":
        """begin(self) -> std::vector< std::vector< std::string > >::iterator"""
        return _probt_python3.StringVectorVector_begin(self)


    def end(self) -> "std::vector< std::vector< std::string > >::iterator":
        """end(self) -> std::vector< std::vector< std::string > >::iterator"""
        return _probt_python3.StringVectorVector_end(self)


    def rbegin(self) -> "std::vector< std::vector< std::string > >::reverse_iterator":
        """rbegin(self) -> std::vector< std::vector< std::string > >::reverse_iterator"""
        return _probt_python3.StringVectorVector_rbegin(self)


    def rend(self) -> "std::vector< std::vector< std::string > >::reverse_iterator":
        """rend(self) -> std::vector< std::vector< std::string > >::reverse_iterator"""
        return _probt_python3.StringVectorVector_rend(self)


    def clear(self) -> "void":
        """clear(self)"""
        return _probt_python3.StringVectorVector_clear(self)


    def get_allocator(self) -> "std::vector< std::vector< std::string > >::allocator_type":
        """get_allocator(self) -> std::vector< std::vector< std::string > >::allocator_type"""
        return _probt_python3.StringVectorVector_get_allocator(self)


    def pop_back(self) -> "void":
        """pop_back(self)"""
        return _probt_python3.StringVectorVector_pop_back(self)


    def erase(self, *args) -> "std::vector< std::vector< std::string > >::iterator":
        """
        erase(self, pos) -> std::vector< std::vector< std::string > >::iterator
        erase(self, first, last) -> std::vector< std::vector< std::string > >::iterator
        """
        return _probt_python3.StringVectorVector_erase(self, *args)


    def __init__(self, *args):
        """
        __init__(self) -> StringVectorVector
        __init__(self, arg2) -> StringVectorVector
        __init__(self, size) -> StringVectorVector
        __init__(self, size, value) -> StringVectorVector
        """
        this = _probt_python3.new_StringVectorVector(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def push_back(self, x: 'StringVector') -> "void":
        """push_back(self, x)"""
        return _probt_python3.StringVectorVector_push_back(self, x)


    def front(self) -> "std::vector< std::vector< std::string > >::value_type const &":
        """front(self) -> StringVector"""
        return _probt_python3.StringVectorVector_front(self)


    def back(self) -> "std::vector< std::vector< std::string > >::value_type const &":
        """back(self) -> StringVector"""
        return _probt_python3.StringVectorVector_back(self)


    def assign(self, n: 'std::vector< std::vector< std::string > >::size_type', x: 'StringVector') -> "void":
        """assign(self, n, x)"""
        return _probt_python3.StringVectorVector_assign(self, n, x)


    def resize(self, *args) -> "void":
        """
        resize(self, new_size)
        resize(self, new_size, x)
        """
        return _probt_python3.StringVectorVector_resize(self, *args)


    def insert(self, *args) -> "void":
        """
        insert(self, pos, x) -> std::vector< std::vector< std::string > >::iterator
        insert(self, pos, n, x)
        """
        return _probt_python3.StringVectorVector_insert(self, *args)


    def reserve(self, n: 'std::vector< std::vector< std::string > >::size_type') -> "void":
        """reserve(self, n)"""
        return _probt_python3.StringVectorVector_reserve(self, n)


    def capacity(self) -> "std::vector< std::vector< std::string > >::size_type":
        """capacity(self) -> std::vector< std::vector< std::string > >::size_type"""
        return _probt_python3.StringVectorVector_capacity(self)

    __swig_destroy__ = _probt_python3.delete_StringVectorVector
    __del__ = lambda self: None
StringVectorVector_swigregister = _probt_python3.StringVectorVector_swigregister
StringVectorVector_swigregister(StringVectorVector)

class BoolVector(_object):
    """Proxy of C++ std::vector<(bool)> class."""

    __swig_setmethods__ = {}
    __setattr__ = lambda self, name, value: _swig_setattr(self, BoolVector, name, value)
    __swig_getmethods__ = {}
    __getattr__ = lambda self, name: _swig_getattr(self, BoolVector, name)
    __repr__ = _swig_repr

    def iterator(self) -> "swig::SwigPyIterator *":
        """iterator(self) -> SwigPyIterator"""
        return _probt_python3.BoolVector_iterator(self)

    def __iter__(self):
        return self.iterator()

    def __nonzero__(self) -> "bool":
        """__nonzero__(self) -> bool"""
        return _probt_python3.BoolVector___nonzero__(self)


    def __bool__(self) -> "bool":
        """__bool__(self) -> bool"""
        return _probt_python3.BoolVector___bool__(self)


    def __len__(self) -> "std::vector< bool >::size_type":
        """__len__(self) -> std::vector< bool >::size_type"""
        return _probt_python3.BoolVector___len__(self)


    def __getslice__(self, i: 'std::vector< bool >::difference_type', j: 'std::vector< bool >::difference_type') -> "std::vector< bool,std::allocator< bool > > *":
        """__getslice__(self, i, j) -> BoolVector"""
        return _probt_python3.BoolVector___getslice__(self, i, j)


    def __setslice__(self, *args) -> "void":
        """
        __setslice__(self, i, j)
        __setslice__(self, i, j, v)
        """
        return _probt_python3.BoolVector___setslice__(self, *args)


    def __delslice__(self, i: 'std::vector< bool >::difference_type', j: 'std::vector< bool >::difference_type') -> "void":
        """__delslice__(self, i, j)"""
        return _probt_python3.BoolVector___delslice__(self, i, j)


    def __delitem__(self, *args) -> "void":
        """
        __delitem__(self, i)
        __delitem__(self, slice)
        """
        return _probt_python3.BoolVector___delitem__(self, *args)


    def __getitem__(self, *args) -> "std::vector< bool >::value_type":
        """
        __getitem__(self, slice) -> BoolVector
        __getitem__(self, i) -> std::vector< bool >::value_type
        """
        return _probt_python3.BoolVector___getitem__(self, *args)


    def __setitem__(self, *args) -> "void":
        """
        __setitem__(self, slice, v)
        __setitem__(self, slice)
        __setitem__(self, i, x)
        """
        return _probt_python3.BoolVector___setitem__(self, *args)


    def pop(self) -> "std::vector< bool >::value_type":
        """pop(self) -> std::vector< bool >::value_type"""
        return _probt_python3.BoolVector_pop(self)


    def append(self, x: 'std::vector< bool >::value_type') -> "void":
        """append(self, x)"""
        return _probt_python3.BoolVector_append(self, x)


    def empty(self) -> "bool":
        """empty(self) -> bool"""
        return _probt_python3.BoolVector_empty(self)


    def size(self) -> "std::vector< bool >::size_type":
        """size(self) -> std::vector< bool >::size_type"""
        return _probt_python3.BoolVector_size(self)


    def swap(self, v: 'BoolVector') -> "void":
        """swap(self, v)"""
        return _probt_python3.BoolVector_swap(self, v)


    def begin(self) -> "std::vector< bool >::iterator":
        """begin(self) -> std::vector< bool >::iterator"""
        return _probt_python3.BoolVector_begin(self)


    def end(self) -> "std::vector< bool >::iterator":
        """end(self) -> std::vector< bool >::iterator"""
        return _probt_python3.BoolVector_end(self)


    def rbegin(self) -> "std::vector< bool >::reverse_iterator":
        """rbegin(self) -> std::vector< bool >::reverse_iterator"""
        return _probt_python3.BoolVector_rbegin(self)


    def rend(self) -> "std::vector< bool >::reverse_iterator":
        """rend(self) -> std::vector< bool >::reverse_iterator"""
        return _probt_python3.BoolVector_rend(self)


    def clear(self) -> "void":
        """clear(self)"""
        return _probt_python3.BoolVector_clear(self)


    def get_allocator(self) -> "std::vector< bool >::allocator_type":
        """get_allocator(self) -> std::vector< bool >::allocator_type"""
        return _probt_python3.BoolVector_get_allocator(self)


    def pop_back(self) -> "void":
        """pop_back(self)"""
        return _probt_python3.BoolVector_pop_back(self)


    def erase(self, *args) -> "std::vector< bool >::iterator":
        """
        erase(self, pos) -> std::vector< bool >::iterator
        erase(self, first, last) -> std::vector< bool >::iterator
        """
        return _probt_python3.BoolVector_erase(self, *args)


    def __init__(self, *args):
        """
        __init__(self) -> BoolVector
        __init__(self, arg2) -> BoolVector
        __init__(self, size) -> BoolVector
        __init__(self, size, value) -> BoolVector
        """
        this = _probt_python3.new_BoolVector(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def push_back(self, x: 'std::vector< bool >::value_type') -> "void":
        """push_back(self, x)"""
        return _probt_python3.BoolVector_push_back(self, x)


    def front(self) -> "std::vector< bool >::value_type":
        """front(self) -> std::vector< bool >::value_type"""
        return _probt_python3.BoolVector_front(self)


    def back(self) -> "std::vector< bool >::value_type":
        """back(self) -> std::vector< bool >::value_type"""
        return _probt_python3.BoolVector_back(self)


    def assign(self, n: 'std::vector< bool >::size_type', x: 'std::vector< bool >::value_type') -> "void":
        """assign(self, n, x)"""
        return _probt_python3.BoolVector_assign(self, n, x)


    def resize(self, *args) -> "void":
        """
        resize(self, new_size)
        resize(self, new_size, x)
        """
        return _probt_python3.BoolVector_resize(self, *args)


    def insert(self, *args) -> "void":
        """
        insert(self, pos, x) -> std::vector< bool >::iterator
        insert(self, pos, n, x)
        """
        return _probt_python3.BoolVector_insert(self, *args)


    def reserve(self, n: 'std::vector< bool >::size_type') -> "void":
        """reserve(self, n)"""
        return _probt_python3.BoolVector_reserve(self, n)


    def capacity(self) -> "std::vector< bool >::size_type":
        """capacity(self) -> std::vector< bool >::size_type"""
        return _probt_python3.BoolVector_capacity(self)

    __swig_destroy__ = _probt_python3.delete_BoolVector
    __del__ = lambda self: None
BoolVector_swigregister = _probt_python3.BoolVector_swigregister
BoolVector_swigregister(BoolVector)

class BoolVectorVector(_object):
    """Proxy of C++ std::vector<(std::vector<(bool)>)> class."""

    __swig_setmethods__ = {}
    __setattr__ = lambda self, name, value: _swig_setattr(self, BoolVectorVector, name, value)
    __swig_getmethods__ = {}
    __getattr__ = lambda self, name: _swig_getattr(self, BoolVectorVector, name)
    __repr__ = _swig_repr

    def iterator(self) -> "swig::SwigPyIterator *":
        """iterator(self) -> SwigPyIterator"""
        return _probt_python3.BoolVectorVector_iterator(self)

    def __iter__(self):
        return self.iterator()

    def __nonzero__(self) -> "bool":
        """__nonzero__(self) -> bool"""
        return _probt_python3.BoolVectorVector___nonzero__(self)


    def __bool__(self) -> "bool":
        """__bool__(self) -> bool"""
        return _probt_python3.BoolVectorVector___bool__(self)


    def __len__(self) -> "std::vector< std::vector< bool > >::size_type":
        """__len__(self) -> std::vector< std::vector< bool > >::size_type"""
        return _probt_python3.BoolVectorVector___len__(self)


    def __getslice__(self, i: 'std::vector< std::vector< bool > >::difference_type', j: 'std::vector< std::vector< bool > >::difference_type') -> "std::vector< std::vector< bool,std::allocator< bool > >,std::allocator< std::vector< bool,std::allocator< bool > > > > *":
        """__getslice__(self, i, j) -> BoolVectorVector"""
        return _probt_python3.BoolVectorVector___getslice__(self, i, j)


    def __setslice__(self, *args) -> "void":
        """
        __setslice__(self, i, j)
        __setslice__(self, i, j, v)
        """
        return _probt_python3.BoolVectorVector___setslice__(self, *args)


    def __delslice__(self, i: 'std::vector< std::vector< bool > >::difference_type', j: 'std::vector< std::vector< bool > >::difference_type') -> "void":
        """__delslice__(self, i, j)"""
        return _probt_python3.BoolVectorVector___delslice__(self, i, j)


    def __delitem__(self, *args) -> "void":
        """
        __delitem__(self, i)
        __delitem__(self, slice)
        """
        return _probt_python3.BoolVectorVector___delitem__(self, *args)


    def __getitem__(self, *args) -> "std::vector< std::vector< bool > >::value_type const &":
        """
        __getitem__(self, slice) -> BoolVectorVector
        __getitem__(self, i) -> BoolVector
        """
        return _probt_python3.BoolVectorVector___getitem__(self, *args)


    def __setitem__(self, *args) -> "void":
        """
        __setitem__(self, slice, v)
        __setitem__(self, slice)
        __setitem__(self, i, x)
        """
        return _probt_python3.BoolVectorVector___setitem__(self, *args)


    def pop(self) -> "std::vector< std::vector< bool > >::value_type":
        """pop(self) -> BoolVector"""
        return _probt_python3.BoolVectorVector_pop(self)


    def append(self, x: 'BoolVector') -> "void":
        """append(self, x)"""
        return _probt_python3.BoolVectorVector_append(self, x)


    def empty(self) -> "bool":
        """empty(self) -> bool"""
        return _probt_python3.BoolVectorVector_empty(self)


    def size(self) -> "std::vector< std::vector< bool > >::size_type":
        """size(self) -> std::vector< std::vector< bool > >::size_type"""
        return _probt_python3.BoolVectorVector_size(self)


    def swap(self, v: 'BoolVectorVector') -> "void":
        """swap(self, v)"""
        return _probt_python3.BoolVectorVector_swap(self, v)


    def begin(self) -> "std::vector< std::vector< bool > >::iterator":
        """begin(self) -> std::vector< std::vector< bool > >::iterator"""
        return _probt_python3.BoolVectorVector_begin(self)


    def end(self) -> "std::vector< std::vector< bool > >::iterator":
        """end(self) -> std::vector< std::vector< bool > >::iterator"""
        return _probt_python3.BoolVectorVector_end(self)


    def rbegin(self) -> "std::vector< std::vector< bool > >::reverse_iterator":
        """rbegin(self) -> std::vector< std::vector< bool > >::reverse_iterator"""
        return _probt_python3.BoolVectorVector_rbegin(self)


    def rend(self) -> "std::vector< std::vector< bool > >::reverse_iterator":
        """rend(self) -> std::vector< std::vector< bool > >::reverse_iterator"""
        return _probt_python3.BoolVectorVector_rend(self)


    def clear(self) -> "void":
        """clear(self)"""
        return _probt_python3.BoolVectorVector_clear(self)


    def get_allocator(self) -> "std::vector< std::vector< bool > >::allocator_type":
        """get_allocator(self) -> std::vector< std::vector< bool > >::allocator_type"""
        return _probt_python3.BoolVectorVector_get_allocator(self)


    def pop_back(self) -> "void":
        """pop_back(self)"""
        return _probt_python3.BoolVectorVector_pop_back(self)


    def erase(self, *args) -> "std::vector< std::vector< bool > >::iterator":
        """
        erase(self, pos) -> std::vector< std::vector< bool > >::iterator
        erase(self, first, last) -> std::vector< std::vector< bool > >::iterator
        """
        return _probt_python3.BoolVectorVector_erase(self, *args)


    def __init__(self, *args):
        """
        __init__(self) -> BoolVectorVector
        __init__(self, arg2) -> BoolVectorVector
        __init__(self, size) -> BoolVectorVector
        __init__(self, size, value) -> BoolVectorVector
        """
        this = _probt_python3.new_BoolVectorVector(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def push_back(self, x: 'BoolVector') -> "void":
        """push_back(self, x)"""
        return _probt_python3.BoolVectorVector_push_back(self, x)


    def front(self) -> "std::vector< std::vector< bool > >::value_type const &":
        """front(self) -> BoolVector"""
        return _probt_python3.BoolVectorVector_front(self)


    def back(self) -> "std::vector< std::vector< bool > >::value_type const &":
        """back(self) -> BoolVector"""
        return _probt_python3.BoolVectorVector_back(self)


    def assign(self, n: 'std::vector< std::vector< bool > >::size_type', x: 'BoolVector') -> "void":
        """assign(self, n, x)"""
        return _probt_python3.BoolVectorVector_assign(self, n, x)


    def resize(self, *args) -> "void":
        """
        resize(self, new_size)
        resize(self, new_size, x)
        """
        return _probt_python3.BoolVectorVector_resize(self, *args)


    def insert(self, *args) -> "void":
        """
        insert(self, pos, x) -> std::vector< std::vector< bool > >::iterator
        insert(self, pos, n, x)
        """
        return _probt_python3.BoolVectorVector_insert(self, *args)


    def reserve(self, n: 'std::vector< std::vector< bool > >::size_type') -> "void":
        """reserve(self, n)"""
        return _probt_python3.BoolVectorVector_reserve(self, n)


    def capacity(self) -> "std::vector< std::vector< bool > >::size_type":
        """capacity(self) -> std::vector< std::vector< bool > >::size_type"""
        return _probt_python3.BoolVectorVector_capacity(self)

    __swig_destroy__ = _probt_python3.delete_BoolVectorVector
    __del__ = lambda self: None
BoolVectorVector_swigregister = _probt_python3.BoolVectorVector_swigregister
BoolVectorVector_swigregister(BoolVectorVector)

class FloatVector(_object):
    """Proxy of C++ std::vector<(float)> class."""

    __swig_setmethods__ = {}
    __setattr__ = lambda self, name, value: _swig_setattr(self, FloatVector, name, value)
    __swig_getmethods__ = {}
    __getattr__ = lambda self, name: _swig_getattr(self, FloatVector, name)
    __repr__ = _swig_repr

    def iterator(self) -> "swig::SwigPyIterator *":
        """iterator(self) -> SwigPyIterator"""
        return _probt_python3.FloatVector_iterator(self)

    def __iter__(self):
        return self.iterator()

    def __nonzero__(self) -> "bool":
        """__nonzero__(self) -> bool"""
        return _probt_python3.FloatVector___nonzero__(self)


    def __bool__(self) -> "bool":
        """__bool__(self) -> bool"""
        return _probt_python3.FloatVector___bool__(self)


    def __len__(self) -> "std::vector< float >::size_type":
        """__len__(self) -> std::vector< float >::size_type"""
        return _probt_python3.FloatVector___len__(self)


    def __getslice__(self, i: 'std::vector< float >::difference_type', j: 'std::vector< float >::difference_type') -> "std::vector< float,std::allocator< float > > *":
        """__getslice__(self, i, j) -> FloatVector"""
        return _probt_python3.FloatVector___getslice__(self, i, j)


    def __setslice__(self, *args) -> "void":
        """
        __setslice__(self, i, j)
        __setslice__(self, i, j, v)
        """
        return _probt_python3.FloatVector___setslice__(self, *args)


    def __delslice__(self, i: 'std::vector< float >::difference_type', j: 'std::vector< float >::difference_type') -> "void":
        """__delslice__(self, i, j)"""
        return _probt_python3.FloatVector___delslice__(self, i, j)


    def __delitem__(self, *args) -> "void":
        """
        __delitem__(self, i)
        __delitem__(self, slice)
        """
        return _probt_python3.FloatVector___delitem__(self, *args)


    def __getitem__(self, *args) -> "std::vector< float >::value_type const &":
        """
        __getitem__(self, slice) -> FloatVector
        __getitem__(self, i) -> std::vector< float >::value_type const &
        """
        return _probt_python3.FloatVector___getitem__(self, *args)


    def __setitem__(self, *args) -> "void":
        """
        __setitem__(self, slice, v)
        __setitem__(self, slice)
        __setitem__(self, i, x)
        """
        return _probt_python3.FloatVector___setitem__(self, *args)


    def pop(self) -> "std::vector< float >::value_type":
        """pop(self) -> std::vector< float >::value_type"""
        return _probt_python3.FloatVector_pop(self)


    def append(self, x: 'std::vector< float >::value_type const &') -> "void":
        """append(self, x)"""
        return _probt_python3.FloatVector_append(self, x)


    def empty(self) -> "bool":
        """empty(self) -> bool"""
        return _probt_python3.FloatVector_empty(self)


    def size(self) -> "std::vector< float >::size_type":
        """size(self) -> std::vector< float >::size_type"""
        return _probt_python3.FloatVector_size(self)


    def swap(self, v: 'FloatVector') -> "void":
        """swap(self, v)"""
        return _probt_python3.FloatVector_swap(self, v)


    def begin(self) -> "std::vector< float >::iterator":
        """begin(self) -> std::vector< float >::iterator"""
        return _probt_python3.FloatVector_begin(self)


    def end(self) -> "std::vector< float >::iterator":
        """end(self) -> std::vector< float >::iterator"""
        return _probt_python3.FloatVector_end(self)


    def rbegin(self) -> "std::vector< float >::reverse_iterator":
        """rbegin(self) -> std::vector< float >::reverse_iterator"""
        return _probt_python3.FloatVector_rbegin(self)


    def rend(self) -> "std::vector< float >::reverse_iterator":
        """rend(self) -> std::vector< float >::reverse_iterator"""
        return _probt_python3.FloatVector_rend(self)


    def clear(self) -> "void":
        """clear(self)"""
        return _probt_python3.FloatVector_clear(self)


    def get_allocator(self) -> "std::vector< float >::allocator_type":
        """get_allocator(self) -> std::vector< float >::allocator_type"""
        return _probt_python3.FloatVector_get_allocator(self)


    def pop_back(self) -> "void":
        """pop_back(self)"""
        return _probt_python3.FloatVector_pop_back(self)


    def erase(self, *args) -> "std::vector< float >::iterator":
        """
        erase(self, pos) -> std::vector< float >::iterator
        erase(self, first, last) -> std::vector< float >::iterator
        """
        return _probt_python3.FloatVector_erase(self, *args)


    def __init__(self, *args):
        """
        __init__(self) -> FloatVector
        __init__(self, arg2) -> FloatVector
        __init__(self, size) -> FloatVector
        __init__(self, size, value) -> FloatVector
        """
        this = _probt_python3.new_FloatVector(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def push_back(self, x: 'std::vector< float >::value_type const &') -> "void":
        """push_back(self, x)"""
        return _probt_python3.FloatVector_push_back(self, x)


    def front(self) -> "std::vector< float >::value_type const &":
        """front(self) -> std::vector< float >::value_type const &"""
        return _probt_python3.FloatVector_front(self)


    def back(self) -> "std::vector< float >::value_type const &":
        """back(self) -> std::vector< float >::value_type const &"""
        return _probt_python3.FloatVector_back(self)


    def assign(self, n: 'std::vector< float >::size_type', x: 'std::vector< float >::value_type const &') -> "void":
        """assign(self, n, x)"""
        return _probt_python3.FloatVector_assign(self, n, x)


    def resize(self, *args) -> "void":
        """
        resize(self, new_size)
        resize(self, new_size, x)
        """
        return _probt_python3.FloatVector_resize(self, *args)


    def insert(self, *args) -> "void":
        """
        insert(self, pos, x) -> std::vector< float >::iterator
        insert(self, pos, n, x)
        """
        return _probt_python3.FloatVector_insert(self, *args)


    def reserve(self, n: 'std::vector< float >::size_type') -> "void":
        """reserve(self, n)"""
        return _probt_python3.FloatVector_reserve(self, n)


    def capacity(self) -> "std::vector< float >::size_type":
        """capacity(self) -> std::vector< float >::size_type"""
        return _probt_python3.FloatVector_capacity(self)

    __swig_destroy__ = _probt_python3.delete_FloatVector
    __del__ = lambda self: None
FloatVector_swigregister = _probt_python3.FloatVector_swigregister
FloatVector_swigregister(FloatVector)

class FloatVectorVector(_object):
    """Proxy of C++ std::vector<(std::vector<(float)>)> class."""

    __swig_setmethods__ = {}
    __setattr__ = lambda self, name, value: _swig_setattr(self, FloatVectorVector, name, value)
    __swig_getmethods__ = {}
    __getattr__ = lambda self, name: _swig_getattr(self, FloatVectorVector, name)
    __repr__ = _swig_repr

    def iterator(self) -> "swig::SwigPyIterator *":
        """iterator(self) -> SwigPyIterator"""
        return _probt_python3.FloatVectorVector_iterator(self)

    def __iter__(self):
        return self.iterator()

    def __nonzero__(self) -> "bool":
        """__nonzero__(self) -> bool"""
        return _probt_python3.FloatVectorVector___nonzero__(self)


    def __bool__(self) -> "bool":
        """__bool__(self) -> bool"""
        return _probt_python3.FloatVectorVector___bool__(self)


    def __len__(self) -> "std::vector< std::vector< float > >::size_type":
        """__len__(self) -> std::vector< std::vector< float > >::size_type"""
        return _probt_python3.FloatVectorVector___len__(self)


    def __getslice__(self, i: 'std::vector< std::vector< float > >::difference_type', j: 'std::vector< std::vector< float > >::difference_type') -> "std::vector< std::vector< float,std::allocator< float > >,std::allocator< std::vector< float,std::allocator< float > > > > *":
        """__getslice__(self, i, j) -> FloatVectorVector"""
        return _probt_python3.FloatVectorVector___getslice__(self, i, j)


    def __setslice__(self, *args) -> "void":
        """
        __setslice__(self, i, j)
        __setslice__(self, i, j, v)
        """
        return _probt_python3.FloatVectorVector___setslice__(self, *args)


    def __delslice__(self, i: 'std::vector< std::vector< float > >::difference_type', j: 'std::vector< std::vector< float > >::difference_type') -> "void":
        """__delslice__(self, i, j)"""
        return _probt_python3.FloatVectorVector___delslice__(self, i, j)


    def __delitem__(self, *args) -> "void":
        """
        __delitem__(self, i)
        __delitem__(self, slice)
        """
        return _probt_python3.FloatVectorVector___delitem__(self, *args)


    def __getitem__(self, *args) -> "std::vector< std::vector< float > >::value_type const &":
        """
        __getitem__(self, slice) -> FloatVectorVector
        __getitem__(self, i) -> FloatVector
        """
        return _probt_python3.FloatVectorVector___getitem__(self, *args)


    def __setitem__(self, *args) -> "void":
        """
        __setitem__(self, slice, v)
        __setitem__(self, slice)
        __setitem__(self, i, x)
        """
        return _probt_python3.FloatVectorVector___setitem__(self, *args)


    def pop(self) -> "std::vector< std::vector< float > >::value_type":
        """pop(self) -> FloatVector"""
        return _probt_python3.FloatVectorVector_pop(self)


    def append(self, x: 'FloatVector') -> "void":
        """append(self, x)"""
        return _probt_python3.FloatVectorVector_append(self, x)


    def empty(self) -> "bool":
        """empty(self) -> bool"""
        return _probt_python3.FloatVectorVector_empty(self)


    def size(self) -> "std::vector< std::vector< float > >::size_type":
        """size(self) -> std::vector< std::vector< float > >::size_type"""
        return _probt_python3.FloatVectorVector_size(self)


    def swap(self, v: 'FloatVectorVector') -> "void":
        """swap(self, v)"""
        return _probt_python3.FloatVectorVector_swap(self, v)


    def begin(self) -> "std::vector< std::vector< float > >::iterator":
        """begin(self) -> std::vector< std::vector< float > >::iterator"""
        return _probt_python3.FloatVectorVector_begin(self)


    def end(self) -> "std::vector< std::vector< float > >::iterator":
        """end(self) -> std::vector< std::vector< float > >::iterator"""
        return _probt_python3.FloatVectorVector_end(self)


    def rbegin(self) -> "std::vector< std::vector< float > >::reverse_iterator":
        """rbegin(self) -> std::vector< std::vector< float > >::reverse_iterator"""
        return _probt_python3.FloatVectorVector_rbegin(self)


    def rend(self) -> "std::vector< std::vector< float > >::reverse_iterator":
        """rend(self) -> std::vector< std::vector< float > >::reverse_iterator"""
        return _probt_python3.FloatVectorVector_rend(self)


    def clear(self) -> "void":
        """clear(self)"""
        return _probt_python3.FloatVectorVector_clear(self)


    def get_allocator(self) -> "std::vector< std::vector< float > >::allocator_type":
        """get_allocator(self) -> std::vector< std::vector< float > >::allocator_type"""
        return _probt_python3.FloatVectorVector_get_allocator(self)


    def pop_back(self) -> "void":
        """pop_back(self)"""
        return _probt_python3.FloatVectorVector_pop_back(self)


    def erase(self, *args) -> "std::vector< std::vector< float > >::iterator":
        """
        erase(self, pos) -> std::vector< std::vector< float > >::iterator
        erase(self, first, last) -> std::vector< std::vector< float > >::iterator
        """
        return _probt_python3.FloatVectorVector_erase(self, *args)


    def __init__(self, *args):
        """
        __init__(self) -> FloatVectorVector
        __init__(self, arg2) -> FloatVectorVector
        __init__(self, size) -> FloatVectorVector
        __init__(self, size, value) -> FloatVectorVector
        """
        this = _probt_python3.new_FloatVectorVector(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def push_back(self, x: 'FloatVector') -> "void":
        """push_back(self, x)"""
        return _probt_python3.FloatVectorVector_push_back(self, x)


    def front(self) -> "std::vector< std::vector< float > >::value_type const &":
        """front(self) -> FloatVector"""
        return _probt_python3.FloatVectorVector_front(self)


    def back(self) -> "std::vector< std::vector< float > >::value_type const &":
        """back(self) -> FloatVector"""
        return _probt_python3.FloatVectorVector_back(self)


    def assign(self, n: 'std::vector< std::vector< float > >::size_type', x: 'FloatVector') -> "void":
        """assign(self, n, x)"""
        return _probt_python3.FloatVectorVector_assign(self, n, x)


    def resize(self, *args) -> "void":
        """
        resize(self, new_size)
        resize(self, new_size, x)
        """
        return _probt_python3.FloatVectorVector_resize(self, *args)


    def insert(self, *args) -> "void":
        """
        insert(self, pos, x) -> std::vector< std::vector< float > >::iterator
        insert(self, pos, n, x)
        """
        return _probt_python3.FloatVectorVector_insert(self, *args)


    def reserve(self, n: 'std::vector< std::vector< float > >::size_type') -> "void":
        """reserve(self, n)"""
        return _probt_python3.FloatVectorVector_reserve(self, n)


    def capacity(self) -> "std::vector< std::vector< float > >::size_type":
        """capacity(self) -> std::vector< std::vector< float > >::size_type"""
        return _probt_python3.FloatVectorVector_capacity(self)

    __swig_destroy__ = _probt_python3.delete_FloatVectorVector
    __del__ = lambda self: None
FloatVectorVector_swigregister = _probt_python3.FloatVectorVector_swigregister
FloatVectorVector_swigregister(FloatVectorVector)

class FloatVectorVectorVector(_object):
    """Proxy of C++ std::vector<(std::vector<(std::vector<(float)>)>)> class."""

    __swig_setmethods__ = {}
    __setattr__ = lambda self, name, value: _swig_setattr(self, FloatVectorVectorVector, name, value)
    __swig_getmethods__ = {}
    __getattr__ = lambda self, name: _swig_getattr(self, FloatVectorVectorVector, name)
    __repr__ = _swig_repr

    def iterator(self) -> "swig::SwigPyIterator *":
        """iterator(self) -> SwigPyIterator"""
        return _probt_python3.FloatVectorVectorVector_iterator(self)

    def __iter__(self):
        return self.iterator()

    def __nonzero__(self) -> "bool":
        """__nonzero__(self) -> bool"""
        return _probt_python3.FloatVectorVectorVector___nonzero__(self)


    def __bool__(self) -> "bool":
        """__bool__(self) -> bool"""
        return _probt_python3.FloatVectorVectorVector___bool__(self)


    def __len__(self) -> "std::vector< std::vector< std::vector< float > > >::size_type":
        """__len__(self) -> std::vector< std::vector< std::vector< float > > >::size_type"""
        return _probt_python3.FloatVectorVectorVector___len__(self)


    def __getslice__(self, i: 'std::vector< std::vector< std::vector< float > > >::difference_type', j: 'std::vector< std::vector< std::vector< float > > >::difference_type') -> "std::vector< std::vector< std::vector< float,std::allocator< float > >,std::allocator< std::vector< float,std::allocator< float > > > >,std::allocator< std::vector< std::vector< float,std::allocator< float > >,std::allocator< std::vector< float,std::allocator< float > > > > > > *":
        """__getslice__(self, i, j) -> FloatVectorVectorVector"""
        return _probt_python3.FloatVectorVectorVector___getslice__(self, i, j)


    def __setslice__(self, *args) -> "void":
        """
        __setslice__(self, i, j)
        __setslice__(self, i, j, v)
        """
        return _probt_python3.FloatVectorVectorVector___setslice__(self, *args)


    def __delslice__(self, i: 'std::vector< std::vector< std::vector< float > > >::difference_type', j: 'std::vector< std::vector< std::vector< float > > >::difference_type') -> "void":
        """__delslice__(self, i, j)"""
        return _probt_python3.FloatVectorVectorVector___delslice__(self, i, j)


    def __delitem__(self, *args) -> "void":
        """
        __delitem__(self, i)
        __delitem__(self, slice)
        """
        return _probt_python3.FloatVectorVectorVector___delitem__(self, *args)


    def __getitem__(self, *args) -> "std::vector< std::vector< std::vector< float > > >::value_type const &":
        """
        __getitem__(self, slice) -> FloatVectorVectorVector
        __getitem__(self, i) -> FloatVectorVector
        """
        return _probt_python3.FloatVectorVectorVector___getitem__(self, *args)


    def __setitem__(self, *args) -> "void":
        """
        __setitem__(self, slice, v)
        __setitem__(self, slice)
        __setitem__(self, i, x)
        """
        return _probt_python3.FloatVectorVectorVector___setitem__(self, *args)


    def pop(self) -> "std::vector< std::vector< std::vector< float > > >::value_type":
        """pop(self) -> FloatVectorVector"""
        return _probt_python3.FloatVectorVectorVector_pop(self)


    def append(self, x: 'FloatVectorVector') -> "void":
        """append(self, x)"""
        return _probt_python3.FloatVectorVectorVector_append(self, x)


    def empty(self) -> "bool":
        """empty(self) -> bool"""
        return _probt_python3.FloatVectorVectorVector_empty(self)


    def size(self) -> "std::vector< std::vector< std::vector< float > > >::size_type":
        """size(self) -> std::vector< std::vector< std::vector< float > > >::size_type"""
        return _probt_python3.FloatVectorVectorVector_size(self)


    def swap(self, v: 'FloatVectorVectorVector') -> "void":
        """swap(self, v)"""
        return _probt_python3.FloatVectorVectorVector_swap(self, v)


    def begin(self) -> "std::vector< std::vector< std::vector< float > > >::iterator":
        """begin(self) -> std::vector< std::vector< std::vector< float > > >::iterator"""
        return _probt_python3.FloatVectorVectorVector_begin(self)


    def end(self) -> "std::vector< std::vector< std::vector< float > > >::iterator":
        """end(self) -> std::vector< std::vector< std::vector< float > > >::iterator"""
        return _probt_python3.FloatVectorVectorVector_end(self)


    def rbegin(self) -> "std::vector< std::vector< std::vector< float > > >::reverse_iterator":
        """rbegin(self) -> std::vector< std::vector< std::vector< float > > >::reverse_iterator"""
        return _probt_python3.FloatVectorVectorVector_rbegin(self)


    def rend(self) -> "std::vector< std::vector< std::vector< float > > >::reverse_iterator":
        """rend(self) -> std::vector< std::vector< std::vector< float > > >::reverse_iterator"""
        return _probt_python3.FloatVectorVectorVector_rend(self)


    def clear(self) -> "void":
        """clear(self)"""
        return _probt_python3.FloatVectorVectorVector_clear(self)


    def get_allocator(self) -> "std::vector< std::vector< std::vector< float > > >::allocator_type":
        """get_allocator(self) -> std::vector< std::vector< std::vector< float > > >::allocator_type"""
        return _probt_python3.FloatVectorVectorVector_get_allocator(self)


    def pop_back(self) -> "void":
        """pop_back(self)"""
        return _probt_python3.FloatVectorVectorVector_pop_back(self)


    def erase(self, *args) -> "std::vector< std::vector< std::vector< float > > >::iterator":
        """
        erase(self, pos) -> std::vector< std::vector< std::vector< float > > >::iterator
        erase(self, first, last) -> std::vector< std::vector< std::vector< float > > >::iterator
        """
        return _probt_python3.FloatVectorVectorVector_erase(self, *args)


    def __init__(self, *args):
        """
        __init__(self) -> FloatVectorVectorVector
        __init__(self, arg2) -> FloatVectorVectorVector
        __init__(self, size) -> FloatVectorVectorVector
        __init__(self, size, value) -> FloatVectorVectorVector
        """
        this = _probt_python3.new_FloatVectorVectorVector(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def push_back(self, x: 'FloatVectorVector') -> "void":
        """push_back(self, x)"""
        return _probt_python3.FloatVectorVectorVector_push_back(self, x)


    def front(self) -> "std::vector< std::vector< std::vector< float > > >::value_type const &":
        """front(self) -> FloatVectorVector"""
        return _probt_python3.FloatVectorVectorVector_front(self)


    def back(self) -> "std::vector< std::vector< std::vector< float > > >::value_type const &":
        """back(self) -> FloatVectorVector"""
        return _probt_python3.FloatVectorVectorVector_back(self)


    def assign(self, n: 'std::vector< std::vector< std::vector< float > > >::size_type', x: 'FloatVectorVector') -> "void":
        """assign(self, n, x)"""
        return _probt_python3.FloatVectorVectorVector_assign(self, n, x)


    def resize(self, *args) -> "void":
        """
        resize(self, new_size)
        resize(self, new_size, x)
        """
        return _probt_python3.FloatVectorVectorVector_resize(self, *args)


    def insert(self, *args) -> "void":
        """
        insert(self, pos, x) -> std::vector< std::vector< std::vector< float > > >::iterator
        insert(self, pos, n, x)
        """
        return _probt_python3.FloatVectorVectorVector_insert(self, *args)


    def reserve(self, n: 'std::vector< std::vector< std::vector< float > > >::size_type') -> "void":
        """reserve(self, n)"""
        return _probt_python3.FloatVectorVectorVector_reserve(self, n)


    def capacity(self) -> "std::vector< std::vector< std::vector< float > > >::size_type":
        """capacity(self) -> std::vector< std::vector< std::vector< float > > >::size_type"""
        return _probt_python3.FloatVectorVectorVector_capacity(self)

    __swig_destroy__ = _probt_python3.delete_FloatVectorVectorVector
    __del__ = lambda self: None
FloatVectorVectorVector_swigregister = _probt_python3.FloatVectorVectorVector_swigregister
FloatVectorVectorVector_swigregister(FloatVectorVectorVector)

class DoubleVector(_object):
    """Proxy of C++ std::vector<(double)> class."""

    __swig_setmethods__ = {}
    __setattr__ = lambda self, name, value: _swig_setattr(self, DoubleVector, name, value)
    __swig_getmethods__ = {}
    __getattr__ = lambda self, name: _swig_getattr(self, DoubleVector, name)
    __repr__ = _swig_repr

    def iterator(self) -> "swig::SwigPyIterator *":
        """iterator(self) -> SwigPyIterator"""
        return _probt_python3.DoubleVector_iterator(self)

    def __iter__(self):
        return self.iterator()

    def __nonzero__(self) -> "bool":
        """__nonzero__(self) -> bool"""
        return _probt_python3.DoubleVector___nonzero__(self)


    def __bool__(self) -> "bool":
        """__bool__(self) -> bool"""
        return _probt_python3.DoubleVector___bool__(self)


    def __len__(self) -> "std::vector< double >::size_type":
        """__len__(self) -> std::vector< double >::size_type"""
        return _probt_python3.DoubleVector___len__(self)


    def __getslice__(self, i: 'std::vector< double >::difference_type', j: 'std::vector< double >::difference_type') -> "std::vector< double,std::allocator< double > > *":
        """__getslice__(self, i, j) -> DoubleVector"""
        return _probt_python3.DoubleVector___getslice__(self, i, j)


    def __setslice__(self, *args) -> "void":
        """
        __setslice__(self, i, j)
        __setslice__(self, i, j, v)
        """
        return _probt_python3.DoubleVector___setslice__(self, *args)


    def __delslice__(self, i: 'std::vector< double >::difference_type', j: 'std::vector< double >::difference_type') -> "void":
        """__delslice__(self, i, j)"""
        return _probt_python3.DoubleVector___delslice__(self, i, j)


    def __delitem__(self, *args) -> "void":
        """
        __delitem__(self, i)
        __delitem__(self, slice)
        """
        return _probt_python3.DoubleVector___delitem__(self, *args)


    def __getitem__(self, *args) -> "std::vector< double >::value_type const &":
        """
        __getitem__(self, slice) -> DoubleVector
        __getitem__(self, i) -> std::vector< double >::value_type const &
        """
        return _probt_python3.DoubleVector___getitem__(self, *args)


    def __setitem__(self, *args) -> "void":
        """
        __setitem__(self, slice, v)
        __setitem__(self, slice)
        __setitem__(self, i, x)
        """
        return _probt_python3.DoubleVector___setitem__(self, *args)


    def pop(self) -> "std::vector< double >::value_type":
        """pop(self) -> std::vector< double >::value_type"""
        return _probt_python3.DoubleVector_pop(self)


    def append(self, x: 'std::vector< double >::value_type const &') -> "void":
        """append(self, x)"""
        return _probt_python3.DoubleVector_append(self, x)


    def empty(self) -> "bool":
        """empty(self) -> bool"""
        return _probt_python3.DoubleVector_empty(self)


    def size(self) -> "std::vector< double >::size_type":
        """size(self) -> std::vector< double >::size_type"""
        return _probt_python3.DoubleVector_size(self)


    def swap(self, v: 'DoubleVector') -> "void":
        """swap(self, v)"""
        return _probt_python3.DoubleVector_swap(self, v)


    def begin(self) -> "std::vector< double >::iterator":
        """begin(self) -> std::vector< double >::iterator"""
        return _probt_python3.DoubleVector_begin(self)


    def end(self) -> "std::vector< double >::iterator":
        """end(self) -> std::vector< double >::iterator"""
        return _probt_python3.DoubleVector_end(self)


    def rbegin(self) -> "std::vector< double >::reverse_iterator":
        """rbegin(self) -> std::vector< double >::reverse_iterator"""
        return _probt_python3.DoubleVector_rbegin(self)


    def rend(self) -> "std::vector< double >::reverse_iterator":
        """rend(self) -> std::vector< double >::reverse_iterator"""
        return _probt_python3.DoubleVector_rend(self)


    def clear(self) -> "void":
        """clear(self)"""
        return _probt_python3.DoubleVector_clear(self)


    def get_allocator(self) -> "std::vector< double >::allocator_type":
        """get_allocator(self) -> std::vector< double >::allocator_type"""
        return _probt_python3.DoubleVector_get_allocator(self)


    def pop_back(self) -> "void":
        """pop_back(self)"""
        return _probt_python3.DoubleVector_pop_back(self)


    def erase(self, *args) -> "std::vector< double >::iterator":
        """
        erase(self, pos) -> std::vector< double >::iterator
        erase(self, first, last) -> std::vector< double >::iterator
        """
        return _probt_python3.DoubleVector_erase(self, *args)


    def __init__(self, *args):
        """
        __init__(self) -> DoubleVector
        __init__(self, arg2) -> DoubleVector
        __init__(self, size) -> DoubleVector
        __init__(self, size, value) -> DoubleVector
        """
        this = _probt_python3.new_DoubleVector(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def push_back(self, x: 'std::vector< double >::value_type const &') -> "void":
        """push_back(self, x)"""
        return _probt_python3.DoubleVector_push_back(self, x)


    def front(self) -> "std::vector< double >::value_type const &":
        """front(self) -> std::vector< double >::value_type const &"""
        return _probt_python3.DoubleVector_front(self)


    def back(self) -> "std::vector< double >::value_type const &":
        """back(self) -> std::vector< double >::value_type const &"""
        return _probt_python3.DoubleVector_back(self)


    def assign(self, n: 'std::vector< double >::size_type', x: 'std::vector< double >::value_type const &') -> "void":
        """assign(self, n, x)"""
        return _probt_python3.DoubleVector_assign(self, n, x)


    def resize(self, *args) -> "void":
        """
        resize(self, new_size)
        resize(self, new_size, x)
        """
        return _probt_python3.DoubleVector_resize(self, *args)


    def insert(self, *args) -> "void":
        """
        insert(self, pos, x) -> std::vector< double >::iterator
        insert(self, pos, n, x)
        """
        return _probt_python3.DoubleVector_insert(self, *args)


    def reserve(self, n: 'std::vector< double >::size_type') -> "void":
        """reserve(self, n)"""
        return _probt_python3.DoubleVector_reserve(self, n)


    def capacity(self) -> "std::vector< double >::size_type":
        """capacity(self) -> std::vector< double >::size_type"""
        return _probt_python3.DoubleVector_capacity(self)

    __swig_destroy__ = _probt_python3.delete_DoubleVector
    __del__ = lambda self: None
DoubleVector_swigregister = _probt_python3.DoubleVector_swigregister
DoubleVector_swigregister(DoubleVector)

class DoubleVectorVector(_object):
    """Proxy of C++ std::vector<(std::vector<(double)>)> class."""

    __swig_setmethods__ = {}
    __setattr__ = lambda self, name, value: _swig_setattr(self, DoubleVectorVector, name, value)
    __swig_getmethods__ = {}
    __getattr__ = lambda self, name: _swig_getattr(self, DoubleVectorVector, name)
    __repr__ = _swig_repr

    def iterator(self) -> "swig::SwigPyIterator *":
        """iterator(self) -> SwigPyIterator"""
        return _probt_python3.DoubleVectorVector_iterator(self)

    def __iter__(self):
        return self.iterator()

    def __nonzero__(self) -> "bool":
        """__nonzero__(self) -> bool"""
        return _probt_python3.DoubleVectorVector___nonzero__(self)


    def __bool__(self) -> "bool":
        """__bool__(self) -> bool"""
        return _probt_python3.DoubleVectorVector___bool__(self)


    def __len__(self) -> "std::vector< std::vector< double > >::size_type":
        """__len__(self) -> std::vector< std::vector< double > >::size_type"""
        return _probt_python3.DoubleVectorVector___len__(self)


    def __getslice__(self, i: 'std::vector< std::vector< double > >::difference_type', j: 'std::vector< std::vector< double > >::difference_type') -> "std::vector< std::vector< double,std::allocator< double > >,std::allocator< std::vector< double,std::allocator< double > > > > *":
        """__getslice__(self, i, j) -> DoubleVectorVector"""
        return _probt_python3.DoubleVectorVector___getslice__(self, i, j)


    def __setslice__(self, *args) -> "void":
        """
        __setslice__(self, i, j)
        __setslice__(self, i, j, v)
        """
        return _probt_python3.DoubleVectorVector___setslice__(self, *args)


    def __delslice__(self, i: 'std::vector< std::vector< double > >::difference_type', j: 'std::vector< std::vector< double > >::difference_type') -> "void":
        """__delslice__(self, i, j)"""
        return _probt_python3.DoubleVectorVector___delslice__(self, i, j)


    def __delitem__(self, *args) -> "void":
        """
        __delitem__(self, i)
        __delitem__(self, slice)
        """
        return _probt_python3.DoubleVectorVector___delitem__(self, *args)


    def __getitem__(self, *args) -> "std::vector< std::vector< double > >::value_type const &":
        """
        __getitem__(self, slice) -> DoubleVectorVector
        __getitem__(self, i) -> DoubleVector
        """
        return _probt_python3.DoubleVectorVector___getitem__(self, *args)


    def __setitem__(self, *args) -> "void":
        """
        __setitem__(self, slice, v)
        __setitem__(self, slice)
        __setitem__(self, i, x)
        """
        return _probt_python3.DoubleVectorVector___setitem__(self, *args)


    def pop(self) -> "std::vector< std::vector< double > >::value_type":
        """pop(self) -> DoubleVector"""
        return _probt_python3.DoubleVectorVector_pop(self)


    def append(self, x: 'DoubleVector') -> "void":
        """append(self, x)"""
        return _probt_python3.DoubleVectorVector_append(self, x)


    def empty(self) -> "bool":
        """empty(self) -> bool"""
        return _probt_python3.DoubleVectorVector_empty(self)


    def size(self) -> "std::vector< std::vector< double > >::size_type":
        """size(self) -> std::vector< std::vector< double > >::size_type"""
        return _probt_python3.DoubleVectorVector_size(self)


    def swap(self, v: 'DoubleVectorVector') -> "void":
        """swap(self, v)"""
        return _probt_python3.DoubleVectorVector_swap(self, v)


    def begin(self) -> "std::vector< std::vector< double > >::iterator":
        """begin(self) -> std::vector< std::vector< double > >::iterator"""
        return _probt_python3.DoubleVectorVector_begin(self)


    def end(self) -> "std::vector< std::vector< double > >::iterator":
        """end(self) -> std::vector< std::vector< double > >::iterator"""
        return _probt_python3.DoubleVectorVector_end(self)


    def rbegin(self) -> "std::vector< std::vector< double > >::reverse_iterator":
        """rbegin(self) -> std::vector< std::vector< double > >::reverse_iterator"""
        return _probt_python3.DoubleVectorVector_rbegin(self)


    def rend(self) -> "std::vector< std::vector< double > >::reverse_iterator":
        """rend(self) -> std::vector< std::vector< double > >::reverse_iterator"""
        return _probt_python3.DoubleVectorVector_rend(self)


    def clear(self) -> "void":
        """clear(self)"""
        return _probt_python3.DoubleVectorVector_clear(self)


    def get_allocator(self) -> "std::vector< std::vector< double > >::allocator_type":
        """get_allocator(self) -> std::vector< std::vector< double > >::allocator_type"""
        return _probt_python3.DoubleVectorVector_get_allocator(self)


    def pop_back(self) -> "void":
        """pop_back(self)"""
        return _probt_python3.DoubleVectorVector_pop_back(self)


    def erase(self, *args) -> "std::vector< std::vector< double > >::iterator":
        """
        erase(self, pos) -> std::vector< std::vector< double > >::iterator
        erase(self, first, last) -> std::vector< std::vector< double > >::iterator
        """
        return _probt_python3.DoubleVectorVector_erase(self, *args)


    def __init__(self, *args):
        """
        __init__(self) -> DoubleVectorVector
        __init__(self, arg2) -> DoubleVectorVector
        __init__(self, size) -> DoubleVectorVector
        __init__(self, size, value) -> DoubleVectorVector
        """
        this = _probt_python3.new_DoubleVectorVector(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def push_back(self, x: 'DoubleVector') -> "void":
        """push_back(self, x)"""
        return _probt_python3.DoubleVectorVector_push_back(self, x)


    def front(self) -> "std::vector< std::vector< double > >::value_type const &":
        """front(self) -> DoubleVector"""
        return _probt_python3.DoubleVectorVector_front(self)


    def back(self) -> "std::vector< std::vector< double > >::value_type const &":
        """back(self) -> DoubleVector"""
        return _probt_python3.DoubleVectorVector_back(self)


    def assign(self, n: 'std::vector< std::vector< double > >::size_type', x: 'DoubleVector') -> "void":
        """assign(self, n, x)"""
        return _probt_python3.DoubleVectorVector_assign(self, n, x)


    def resize(self, *args) -> "void":
        """
        resize(self, new_size)
        resize(self, new_size, x)
        """
        return _probt_python3.DoubleVectorVector_resize(self, *args)


    def insert(self, *args) -> "void":
        """
        insert(self, pos, x) -> std::vector< std::vector< double > >::iterator
        insert(self, pos, n, x)
        """
        return _probt_python3.DoubleVectorVector_insert(self, *args)


    def reserve(self, n: 'std::vector< std::vector< double > >::size_type') -> "void":
        """reserve(self, n)"""
        return _probt_python3.DoubleVectorVector_reserve(self, n)


    def capacity(self) -> "std::vector< std::vector< double > >::size_type":
        """capacity(self) -> std::vector< std::vector< double > >::size_type"""
        return _probt_python3.DoubleVectorVector_capacity(self)

    __swig_destroy__ = _probt_python3.delete_DoubleVectorVector
    __del__ = lambda self: None
DoubleVectorVector_swigregister = _probt_python3.DoubleVectorVector_swigregister
DoubleVectorVector_swigregister(DoubleVectorVector)

class DoubleVectorVectorVector(_object):
    """Proxy of C++ std::vector<(std::vector<(std::vector<(double)>)>)> class."""

    __swig_setmethods__ = {}
    __setattr__ = lambda self, name, value: _swig_setattr(self, DoubleVectorVectorVector, name, value)
    __swig_getmethods__ = {}
    __getattr__ = lambda self, name: _swig_getattr(self, DoubleVectorVectorVector, name)
    __repr__ = _swig_repr

    def iterator(self) -> "swig::SwigPyIterator *":
        """iterator(self) -> SwigPyIterator"""
        return _probt_python3.DoubleVectorVectorVector_iterator(self)

    def __iter__(self):
        return self.iterator()

    def __nonzero__(self) -> "bool":
        """__nonzero__(self) -> bool"""
        return _probt_python3.DoubleVectorVectorVector___nonzero__(self)


    def __bool__(self) -> "bool":
        """__bool__(self) -> bool"""
        return _probt_python3.DoubleVectorVectorVector___bool__(self)


    def __len__(self) -> "std::vector< std::vector< std::vector< double > > >::size_type":
        """__len__(self) -> std::vector< std::vector< std::vector< double > > >::size_type"""
        return _probt_python3.DoubleVectorVectorVector___len__(self)


    def __getslice__(self, i: 'std::vector< std::vector< std::vector< double > > >::difference_type', j: 'std::vector< std::vector< std::vector< double > > >::difference_type') -> "std::vector< std::vector< std::vector< double,std::allocator< double > >,std::allocator< std::vector< double,std::allocator< double > > > >,std::allocator< std::vector< std::vector< double,std::allocator< double > >,std::allocator< std::vector< double,std::allocator< double > > > > > > *":
        """__getslice__(self, i, j) -> DoubleVectorVectorVector"""
        return _probt_python3.DoubleVectorVectorVector___getslice__(self, i, j)


    def __setslice__(self, *args) -> "void":
        """
        __setslice__(self, i, j)
        __setslice__(self, i, j, v)
        """
        return _probt_python3.DoubleVectorVectorVector___setslice__(self, *args)


    def __delslice__(self, i: 'std::vector< std::vector< std::vector< double > > >::difference_type', j: 'std::vector< std::vector< std::vector< double > > >::difference_type') -> "void":
        """__delslice__(self, i, j)"""
        return _probt_python3.DoubleVectorVectorVector___delslice__(self, i, j)


    def __delitem__(self, *args) -> "void":
        """
        __delitem__(self, i)
        __delitem__(self, slice)
        """
        return _probt_python3.DoubleVectorVectorVector___delitem__(self, *args)


    def __getitem__(self, *args) -> "std::vector< std::vector< std::vector< double > > >::value_type const &":
        """
        __getitem__(self, slice) -> DoubleVectorVectorVector
        __getitem__(self, i) -> DoubleVectorVector
        """
        return _probt_python3.DoubleVectorVectorVector___getitem__(self, *args)


    def __setitem__(self, *args) -> "void":
        """
        __setitem__(self, slice, v)
        __setitem__(self, slice)
        __setitem__(self, i, x)
        """
        return _probt_python3.DoubleVectorVectorVector___setitem__(self, *args)


    def pop(self) -> "std::vector< std::vector< std::vector< double > > >::value_type":
        """pop(self) -> DoubleVectorVector"""
        return _probt_python3.DoubleVectorVectorVector_pop(self)


    def append(self, x: 'DoubleVectorVector') -> "void":
        """append(self, x)"""
        return _probt_python3.DoubleVectorVectorVector_append(self, x)


    def empty(self) -> "bool":
        """empty(self) -> bool"""
        return _probt_python3.DoubleVectorVectorVector_empty(self)


    def size(self) -> "std::vector< std::vector< std::vector< double > > >::size_type":
        """size(self) -> std::vector< std::vector< std::vector< double > > >::size_type"""
        return _probt_python3.DoubleVectorVectorVector_size(self)


    def swap(self, v: 'DoubleVectorVectorVector') -> "void":
        """swap(self, v)"""
        return _probt_python3.DoubleVectorVectorVector_swap(self, v)


    def begin(self) -> "std::vector< std::vector< std::vector< double > > >::iterator":
        """begin(self) -> std::vector< std::vector< std::vector< double > > >::iterator"""
        return _probt_python3.DoubleVectorVectorVector_begin(self)


    def end(self) -> "std::vector< std::vector< std::vector< double > > >::iterator":
        """end(self) -> std::vector< std::vector< std::vector< double > > >::iterator"""
        return _probt_python3.DoubleVectorVectorVector_end(self)


    def rbegin(self) -> "std::vector< std::vector< std::vector< double > > >::reverse_iterator":
        """rbegin(self) -> std::vector< std::vector< std::vector< double > > >::reverse_iterator"""
        return _probt_python3.DoubleVectorVectorVector_rbegin(self)


    def rend(self) -> "std::vector< std::vector< std::vector< double > > >::reverse_iterator":
        """rend(self) -> std::vector< std::vector< std::vector< double > > >::reverse_iterator"""
        return _probt_python3.DoubleVectorVectorVector_rend(self)


    def clear(self) -> "void":
        """clear(self)"""
        return _probt_python3.DoubleVectorVectorVector_clear(self)


    def get_allocator(self) -> "std::vector< std::vector< std::vector< double > > >::allocator_type":
        """get_allocator(self) -> std::vector< std::vector< std::vector< double > > >::allocator_type"""
        return _probt_python3.DoubleVectorVectorVector_get_allocator(self)


    def pop_back(self) -> "void":
        """pop_back(self)"""
        return _probt_python3.DoubleVectorVectorVector_pop_back(self)


    def erase(self, *args) -> "std::vector< std::vector< std::vector< double > > >::iterator":
        """
        erase(self, pos) -> std::vector< std::vector< std::vector< double > > >::iterator
        erase(self, first, last) -> std::vector< std::vector< std::vector< double > > >::iterator
        """
        return _probt_python3.DoubleVectorVectorVector_erase(self, *args)


    def __init__(self, *args):
        """
        __init__(self) -> DoubleVectorVectorVector
        __init__(self, arg2) -> DoubleVectorVectorVector
        __init__(self, size) -> DoubleVectorVectorVector
        __init__(self, size, value) -> DoubleVectorVectorVector
        """
        this = _probt_python3.new_DoubleVectorVectorVector(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def push_back(self, x: 'DoubleVectorVector') -> "void":
        """push_back(self, x)"""
        return _probt_python3.DoubleVectorVectorVector_push_back(self, x)


    def front(self) -> "std::vector< std::vector< std::vector< double > > >::value_type const &":
        """front(self) -> DoubleVectorVector"""
        return _probt_python3.DoubleVectorVectorVector_front(self)


    def back(self) -> "std::vector< std::vector< std::vector< double > > >::value_type const &":
        """back(self) -> DoubleVectorVector"""
        return _probt_python3.DoubleVectorVectorVector_back(self)


    def assign(self, n: 'std::vector< std::vector< std::vector< double > > >::size_type', x: 'DoubleVectorVector') -> "void":
        """assign(self, n, x)"""
        return _probt_python3.DoubleVectorVectorVector_assign(self, n, x)


    def resize(self, *args) -> "void":
        """
        resize(self, new_size)
        resize(self, new_size, x)
        """
        return _probt_python3.DoubleVectorVectorVector_resize(self, *args)


    def insert(self, *args) -> "void":
        """
        insert(self, pos, x) -> std::vector< std::vector< std::vector< double > > >::iterator
        insert(self, pos, n, x)
        """
        return _probt_python3.DoubleVectorVectorVector_insert(self, *args)


    def reserve(self, n: 'std::vector< std::vector< std::vector< double > > >::size_type') -> "void":
        """reserve(self, n)"""
        return _probt_python3.DoubleVectorVectorVector_reserve(self, n)


    def capacity(self) -> "std::vector< std::vector< std::vector< double > > >::size_type":
        """capacity(self) -> std::vector< std::vector< std::vector< double > > >::size_type"""
        return _probt_python3.DoubleVectorVectorVector_capacity(self)

    __swig_destroy__ = _probt_python3.delete_DoubleVectorVectorVector
    __del__ = lambda self: None
DoubleVectorVectorVector_swigregister = _probt_python3.DoubleVectorVectorVector_swigregister
DoubleVectorVectorVector_swigregister(DoubleVectorVectorVector)

class DoubleVectorVectorVectorVector(_object):
    """Proxy of C++ std::vector<(std::vector<(std::vector<(std::vector<(double)>)>)>)> class."""

    __swig_setmethods__ = {}
    __setattr__ = lambda self, name, value: _swig_setattr(self, DoubleVectorVectorVectorVector, name, value)
    __swig_getmethods__ = {}
    __getattr__ = lambda self, name: _swig_getattr(self, DoubleVectorVectorVectorVector, name)
    __repr__ = _swig_repr

    def iterator(self) -> "swig::SwigPyIterator *":
        """iterator(self) -> SwigPyIterator"""
        return _probt_python3.DoubleVectorVectorVectorVector_iterator(self)

    def __iter__(self):
        return self.iterator()

    def __nonzero__(self) -> "bool":
        """__nonzero__(self) -> bool"""
        return _probt_python3.DoubleVectorVectorVectorVector___nonzero__(self)


    def __bool__(self) -> "bool":
        """__bool__(self) -> bool"""
        return _probt_python3.DoubleVectorVectorVectorVector___bool__(self)


    def __len__(self) -> "std::vector< std::vector< std::vector< std::vector< double > > > >::size_type":
        """__len__(self) -> std::vector< std::vector< std::vector< std::vector< double > > > >::size_type"""
        return _probt_python3.DoubleVectorVectorVectorVector___len__(self)


    def __getslice__(self, i: 'std::vector< std::vector< std::vector< std::vector< double > > > >::difference_type', j: 'std::vector< std::vector< std::vector< std::vector< double > > > >::difference_type') -> "std::vector< std::vector< std::vector< std::vector< double,std::allocator< double > >,std::allocator< std::vector< double,std::allocator< double > > > >,std::allocator< std::vector< std::vector< double,std::allocator< double > >,std::allocator< std::vector< double,std::allocator< double > > > > > >,std::allocator< std::vector< std::vector< std::vector< double,std::allocator< double > >,std::allocator< std::vector< double,std::allocator< double > > > >,std::allocator< std::vector< std::vector< double,std::allocator< double > >,std::allocator< std::vector< double,std::allocator< double > > > > > > > > *":
        """__getslice__(self, i, j) -> DoubleVectorVectorVectorVector"""
        return _probt_python3.DoubleVectorVectorVectorVector___getslice__(self, i, j)


    def __setslice__(self, *args) -> "void":
        """
        __setslice__(self, i, j)
        __setslice__(self, i, j, v)
        """
        return _probt_python3.DoubleVectorVectorVectorVector___setslice__(self, *args)


    def __delslice__(self, i: 'std::vector< std::vector< std::vector< std::vector< double > > > >::difference_type', j: 'std::vector< std::vector< std::vector< std::vector< double > > > >::difference_type') -> "void":
        """__delslice__(self, i, j)"""
        return _probt_python3.DoubleVectorVectorVectorVector___delslice__(self, i, j)


    def __delitem__(self, *args) -> "void":
        """
        __delitem__(self, i)
        __delitem__(self, slice)
        """
        return _probt_python3.DoubleVectorVectorVectorVector___delitem__(self, *args)


    def __getitem__(self, *args) -> "std::vector< std::vector< std::vector< std::vector< double > > > >::value_type const &":
        """
        __getitem__(self, slice) -> DoubleVectorVectorVectorVector
        __getitem__(self, i) -> DoubleVectorVectorVector
        """
        return _probt_python3.DoubleVectorVectorVectorVector___getitem__(self, *args)


    def __setitem__(self, *args) -> "void":
        """
        __setitem__(self, slice, v)
        __setitem__(self, slice)
        __setitem__(self, i, x)
        """
        return _probt_python3.DoubleVectorVectorVectorVector___setitem__(self, *args)


    def pop(self) -> "std::vector< std::vector< std::vector< std::vector< double > > > >::value_type":
        """pop(self) -> DoubleVectorVectorVector"""
        return _probt_python3.DoubleVectorVectorVectorVector_pop(self)


    def append(self, x: 'DoubleVectorVectorVector') -> "void":
        """append(self, x)"""
        return _probt_python3.DoubleVectorVectorVectorVector_append(self, x)


    def empty(self) -> "bool":
        """empty(self) -> bool"""
        return _probt_python3.DoubleVectorVectorVectorVector_empty(self)


    def size(self) -> "std::vector< std::vector< std::vector< std::vector< double > > > >::size_type":
        """size(self) -> std::vector< std::vector< std::vector< std::vector< double > > > >::size_type"""
        return _probt_python3.DoubleVectorVectorVectorVector_size(self)


    def swap(self, v: 'DoubleVectorVectorVectorVector') -> "void":
        """swap(self, v)"""
        return _probt_python3.DoubleVectorVectorVectorVector_swap(self, v)


    def begin(self) -> "std::vector< std::vector< std::vector< std::vector< double > > > >::iterator":
        """begin(self) -> std::vector< std::vector< std::vector< std::vector< double > > > >::iterator"""
        return _probt_python3.DoubleVectorVectorVectorVector_begin(self)


    def end(self) -> "std::vector< std::vector< std::vector< std::vector< double > > > >::iterator":
        """end(self) -> std::vector< std::vector< std::vector< std::vector< double > > > >::iterator"""
        return _probt_python3.DoubleVectorVectorVectorVector_end(self)


    def rbegin(self) -> "std::vector< std::vector< std::vector< std::vector< double > > > >::reverse_iterator":
        """rbegin(self) -> std::vector< std::vector< std::vector< std::vector< double > > > >::reverse_iterator"""
        return _probt_python3.DoubleVectorVectorVectorVector_rbegin(self)


    def rend(self) -> "std::vector< std::vector< std::vector< std::vector< double > > > >::reverse_iterator":
        """rend(self) -> std::vector< std::vector< std::vector< std::vector< double > > > >::reverse_iterator"""
        return _probt_python3.DoubleVectorVectorVectorVector_rend(self)


    def clear(self) -> "void":
        """clear(self)"""
        return _probt_python3.DoubleVectorVectorVectorVector_clear(self)


    def get_allocator(self) -> "std::vector< std::vector< std::vector< std::vector< double > > > >::allocator_type":
        """get_allocator(self) -> std::vector< std::vector< std::vector< std::vector< double > > > >::allocator_type"""
        return _probt_python3.DoubleVectorVectorVectorVector_get_allocator(self)


    def pop_back(self) -> "void":
        """pop_back(self)"""
        return _probt_python3.DoubleVectorVectorVectorVector_pop_back(self)


    def erase(self, *args) -> "std::vector< std::vector< std::vector< std::vector< double > > > >::iterator":
        """
        erase(self, pos) -> std::vector< std::vector< std::vector< std::vector< double > > > >::iterator
        erase(self, first, last) -> std::vector< std::vector< std::vector< std::vector< double > > > >::iterator
        """
        return _probt_python3.DoubleVectorVectorVectorVector_erase(self, *args)


    def __init__(self, *args):
        """
        __init__(self) -> DoubleVectorVectorVectorVector
        __init__(self, arg2) -> DoubleVectorVectorVectorVector
        __init__(self, size) -> DoubleVectorVectorVectorVector
        __init__(self, size, value) -> DoubleVectorVectorVectorVector
        """
        this = _probt_python3.new_DoubleVectorVectorVectorVector(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def push_back(self, x: 'DoubleVectorVectorVector') -> "void":
        """push_back(self, x)"""
        return _probt_python3.DoubleVectorVectorVectorVector_push_back(self, x)


    def front(self) -> "std::vector< std::vector< std::vector< std::vector< double > > > >::value_type const &":
        """front(self) -> DoubleVectorVectorVector"""
        return _probt_python3.DoubleVectorVectorVectorVector_front(self)


    def back(self) -> "std::vector< std::vector< std::vector< std::vector< double > > > >::value_type const &":
        """back(self) -> DoubleVectorVectorVector"""
        return _probt_python3.DoubleVectorVectorVectorVector_back(self)


    def assign(self, n: 'std::vector< std::vector< std::vector< std::vector< double > > > >::size_type', x: 'DoubleVectorVectorVector') -> "void":
        """assign(self, n, x)"""
        return _probt_python3.DoubleVectorVectorVectorVector_assign(self, n, x)


    def resize(self, *args) -> "void":
        """
        resize(self, new_size)
        resize(self, new_size, x)
        """
        return _probt_python3.DoubleVectorVectorVectorVector_resize(self, *args)


    def insert(self, *args) -> "void":
        """
        insert(self, pos, x) -> std::vector< std::vector< std::vector< std::vector< double > > > >::iterator
        insert(self, pos, n, x)
        """
        return _probt_python3.DoubleVectorVectorVectorVector_insert(self, *args)


    def reserve(self, n: 'std::vector< std::vector< std::vector< std::vector< double > > > >::size_type') -> "void":
        """reserve(self, n)"""
        return _probt_python3.DoubleVectorVectorVectorVector_reserve(self, n)


    def capacity(self) -> "std::vector< std::vector< std::vector< std::vector< double > > > >::size_type":
        """capacity(self) -> std::vector< std::vector< std::vector< std::vector< double > > > >::size_type"""
        return _probt_python3.DoubleVectorVectorVectorVector_capacity(self)

    __swig_destroy__ = _probt_python3.delete_DoubleVectorVectorVectorVector
    __del__ = lambda self: None
DoubleVectorVectorVectorVector_swigregister = _probt_python3.DoubleVectorVectorVectorVector_swigregister
DoubleVectorVectorVectorVector_swigregister(DoubleVectorVectorVectorVector)

class LongDoubleVector(_object):
    """Proxy of C++ std::vector<(long double)> class."""

    __swig_setmethods__ = {}
    __setattr__ = lambda self, name, value: _swig_setattr(self, LongDoubleVector, name, value)
    __swig_getmethods__ = {}
    __getattr__ = lambda self, name: _swig_getattr(self, LongDoubleVector, name)
    __repr__ = _swig_repr

    def iterator(self) -> "swig::SwigPyIterator *":
        """iterator(self) -> SwigPyIterator"""
        return _probt_python3.LongDoubleVector_iterator(self)

    def __iter__(self):
        return self.iterator()

    def __nonzero__(self) -> "bool":
        """__nonzero__(self) -> bool"""
        return _probt_python3.LongDoubleVector___nonzero__(self)


    def __bool__(self) -> "bool":
        """__bool__(self) -> bool"""
        return _probt_python3.LongDoubleVector___bool__(self)


    def __len__(self) -> "std::vector< long double >::size_type":
        """__len__(self) -> std::vector< long double >::size_type"""
        return _probt_python3.LongDoubleVector___len__(self)


    def __getslice__(self, i: 'std::vector< long double >::difference_type', j: 'std::vector< long double >::difference_type') -> "std::vector< long double,std::allocator< long double > > *":
        """__getslice__(self, i, j) -> LongDoubleVector"""
        return _probt_python3.LongDoubleVector___getslice__(self, i, j)


    def __setslice__(self, *args) -> "void":
        """
        __setslice__(self, i, j)
        __setslice__(self, i, j, v)
        """
        return _probt_python3.LongDoubleVector___setslice__(self, *args)


    def __delslice__(self, i: 'std::vector< long double >::difference_type', j: 'std::vector< long double >::difference_type') -> "void":
        """__delslice__(self, i, j)"""
        return _probt_python3.LongDoubleVector___delslice__(self, i, j)


    def __delitem__(self, *args) -> "void":
        """
        __delitem__(self, i)
        __delitem__(self, slice)
        """
        return _probt_python3.LongDoubleVector___delitem__(self, *args)


    def __getitem__(self, *args) -> "std::vector< long double >::value_type const &":
        """
        __getitem__(self, slice) -> LongDoubleVector
        __getitem__(self, i) -> std::vector< long double >::value_type const &
        """
        return _probt_python3.LongDoubleVector___getitem__(self, *args)


    def __setitem__(self, *args) -> "void":
        """
        __setitem__(self, slice, v)
        __setitem__(self, slice)
        __setitem__(self, i, x)
        """
        return _probt_python3.LongDoubleVector___setitem__(self, *args)


    def pop(self) -> "std::vector< long double >::value_type":
        """pop(self) -> std::vector< long double >::value_type"""
        return _probt_python3.LongDoubleVector_pop(self)


    def append(self, x: 'std::vector< long double >::value_type const &') -> "void":
        """append(self, x)"""
        return _probt_python3.LongDoubleVector_append(self, x)


    def empty(self) -> "bool":
        """empty(self) -> bool"""
        return _probt_python3.LongDoubleVector_empty(self)


    def size(self) -> "std::vector< long double >::size_type":
        """size(self) -> std::vector< long double >::size_type"""
        return _probt_python3.LongDoubleVector_size(self)


    def swap(self, v: 'LongDoubleVector') -> "void":
        """swap(self, v)"""
        return _probt_python3.LongDoubleVector_swap(self, v)


    def begin(self) -> "std::vector< long double >::iterator":
        """begin(self) -> std::vector< long double >::iterator"""
        return _probt_python3.LongDoubleVector_begin(self)


    def end(self) -> "std::vector< long double >::iterator":
        """end(self) -> std::vector< long double >::iterator"""
        return _probt_python3.LongDoubleVector_end(self)


    def rbegin(self) -> "std::vector< long double >::reverse_iterator":
        """rbegin(self) -> std::vector< long double >::reverse_iterator"""
        return _probt_python3.LongDoubleVector_rbegin(self)


    def rend(self) -> "std::vector< long double >::reverse_iterator":
        """rend(self) -> std::vector< long double >::reverse_iterator"""
        return _probt_python3.LongDoubleVector_rend(self)


    def clear(self) -> "void":
        """clear(self)"""
        return _probt_python3.LongDoubleVector_clear(self)


    def get_allocator(self) -> "std::vector< long double >::allocator_type":
        """get_allocator(self) -> std::vector< long double >::allocator_type"""
        return _probt_python3.LongDoubleVector_get_allocator(self)


    def pop_back(self) -> "void":
        """pop_back(self)"""
        return _probt_python3.LongDoubleVector_pop_back(self)


    def erase(self, *args) -> "std::vector< long double >::iterator":
        """
        erase(self, pos) -> std::vector< long double >::iterator
        erase(self, first, last) -> std::vector< long double >::iterator
        """
        return _probt_python3.LongDoubleVector_erase(self, *args)


    def __init__(self, *args):
        """
        __init__(self) -> LongDoubleVector
        __init__(self, arg2) -> LongDoubleVector
        __init__(self, size) -> LongDoubleVector
        __init__(self, size, value) -> LongDoubleVector
        """
        this = _probt_python3.new_LongDoubleVector(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def push_back(self, x: 'std::vector< long double >::value_type const &') -> "void":
        """push_back(self, x)"""
        return _probt_python3.LongDoubleVector_push_back(self, x)


    def front(self) -> "std::vector< long double >::value_type const &":
        """front(self) -> std::vector< long double >::value_type const &"""
        return _probt_python3.LongDoubleVector_front(self)


    def back(self) -> "std::vector< long double >::value_type const &":
        """back(self) -> std::vector< long double >::value_type const &"""
        return _probt_python3.LongDoubleVector_back(self)


    def assign(self, n: 'std::vector< long double >::size_type', x: 'std::vector< long double >::value_type const &') -> "void":
        """assign(self, n, x)"""
        return _probt_python3.LongDoubleVector_assign(self, n, x)


    def resize(self, *args) -> "void":
        """
        resize(self, new_size)
        resize(self, new_size, x)
        """
        return _probt_python3.LongDoubleVector_resize(self, *args)


    def insert(self, *args) -> "void":
        """
        insert(self, pos, x) -> std::vector< long double >::iterator
        insert(self, pos, n, x)
        """
        return _probt_python3.LongDoubleVector_insert(self, *args)


    def reserve(self, n: 'std::vector< long double >::size_type') -> "void":
        """reserve(self, n)"""
        return _probt_python3.LongDoubleVector_reserve(self, n)


    def capacity(self) -> "std::vector< long double >::size_type":
        """capacity(self) -> std::vector< long double >::size_type"""
        return _probt_python3.LongDoubleVector_capacity(self)

    __swig_destroy__ = _probt_python3.delete_LongDoubleVector
    __del__ = lambda self: None
LongDoubleVector_swigregister = _probt_python3.LongDoubleVector_swigregister
LongDoubleVector_swigregister(LongDoubleVector)

class LongDoubleVectorVector(_object):
    """Proxy of C++ std::vector<(std::vector<(long double)>)> class."""

    __swig_setmethods__ = {}
    __setattr__ = lambda self, name, value: _swig_setattr(self, LongDoubleVectorVector, name, value)
    __swig_getmethods__ = {}
    __getattr__ = lambda self, name: _swig_getattr(self, LongDoubleVectorVector, name)
    __repr__ = _swig_repr

    def iterator(self) -> "swig::SwigPyIterator *":
        """iterator(self) -> SwigPyIterator"""
        return _probt_python3.LongDoubleVectorVector_iterator(self)

    def __iter__(self):
        return self.iterator()

    def __nonzero__(self) -> "bool":
        """__nonzero__(self) -> bool"""
        return _probt_python3.LongDoubleVectorVector___nonzero__(self)


    def __bool__(self) -> "bool":
        """__bool__(self) -> bool"""
        return _probt_python3.LongDoubleVectorVector___bool__(self)


    def __len__(self) -> "std::vector< std::vector< long double > >::size_type":
        """__len__(self) -> std::vector< std::vector< long double > >::size_type"""
        return _probt_python3.LongDoubleVectorVector___len__(self)


    def __getslice__(self, i: 'std::vector< std::vector< long double > >::difference_type', j: 'std::vector< std::vector< long double > >::difference_type') -> "std::vector< std::vector< long double,std::allocator< long double > >,std::allocator< std::vector< long double,std::allocator< long double > > > > *":
        """__getslice__(self, i, j) -> LongDoubleVectorVector"""
        return _probt_python3.LongDoubleVectorVector___getslice__(self, i, j)


    def __setslice__(self, *args) -> "void":
        """
        __setslice__(self, i, j)
        __setslice__(self, i, j, v)
        """
        return _probt_python3.LongDoubleVectorVector___setslice__(self, *args)


    def __delslice__(self, i: 'std::vector< std::vector< long double > >::difference_type', j: 'std::vector< std::vector< long double > >::difference_type') -> "void":
        """__delslice__(self, i, j)"""
        return _probt_python3.LongDoubleVectorVector___delslice__(self, i, j)


    def __delitem__(self, *args) -> "void":
        """
        __delitem__(self, i)
        __delitem__(self, slice)
        """
        return _probt_python3.LongDoubleVectorVector___delitem__(self, *args)


    def __getitem__(self, *args) -> "std::vector< std::vector< long double > >::value_type const &":
        """
        __getitem__(self, slice) -> LongDoubleVectorVector
        __getitem__(self, i) -> LongDoubleVector
        """
        return _probt_python3.LongDoubleVectorVector___getitem__(self, *args)


    def __setitem__(self, *args) -> "void":
        """
        __setitem__(self, slice, v)
        __setitem__(self, slice)
        __setitem__(self, i, x)
        """
        return _probt_python3.LongDoubleVectorVector___setitem__(self, *args)


    def pop(self) -> "std::vector< std::vector< long double > >::value_type":
        """pop(self) -> LongDoubleVector"""
        return _probt_python3.LongDoubleVectorVector_pop(self)


    def append(self, x: 'LongDoubleVector') -> "void":
        """append(self, x)"""
        return _probt_python3.LongDoubleVectorVector_append(self, x)


    def empty(self) -> "bool":
        """empty(self) -> bool"""
        return _probt_python3.LongDoubleVectorVector_empty(self)


    def size(self) -> "std::vector< std::vector< long double > >::size_type":
        """size(self) -> std::vector< std::vector< long double > >::size_type"""
        return _probt_python3.LongDoubleVectorVector_size(self)


    def swap(self, v: 'LongDoubleVectorVector') -> "void":
        """swap(self, v)"""
        return _probt_python3.LongDoubleVectorVector_swap(self, v)


    def begin(self) -> "std::vector< std::vector< long double > >::iterator":
        """begin(self) -> std::vector< std::vector< long double > >::iterator"""
        return _probt_python3.LongDoubleVectorVector_begin(self)


    def end(self) -> "std::vector< std::vector< long double > >::iterator":
        """end(self) -> std::vector< std::vector< long double > >::iterator"""
        return _probt_python3.LongDoubleVectorVector_end(self)


    def rbegin(self) -> "std::vector< std::vector< long double > >::reverse_iterator":
        """rbegin(self) -> std::vector< std::vector< long double > >::reverse_iterator"""
        return _probt_python3.LongDoubleVectorVector_rbegin(self)


    def rend(self) -> "std::vector< std::vector< long double > >::reverse_iterator":
        """rend(self) -> std::vector< std::vector< long double > >::reverse_iterator"""
        return _probt_python3.LongDoubleVectorVector_rend(self)


    def clear(self) -> "void":
        """clear(self)"""
        return _probt_python3.LongDoubleVectorVector_clear(self)


    def get_allocator(self) -> "std::vector< std::vector< long double > >::allocator_type":
        """get_allocator(self) -> std::vector< std::vector< long double > >::allocator_type"""
        return _probt_python3.LongDoubleVectorVector_get_allocator(self)


    def pop_back(self) -> "void":
        """pop_back(self)"""
        return _probt_python3.LongDoubleVectorVector_pop_back(self)


    def erase(self, *args) -> "std::vector< std::vector< long double > >::iterator":
        """
        erase(self, pos) -> std::vector< std::vector< long double > >::iterator
        erase(self, first, last) -> std::vector< std::vector< long double > >::iterator
        """
        return _probt_python3.LongDoubleVectorVector_erase(self, *args)


    def __init__(self, *args):
        """
        __init__(self) -> LongDoubleVectorVector
        __init__(self, arg2) -> LongDoubleVectorVector
        __init__(self, size) -> LongDoubleVectorVector
        __init__(self, size, value) -> LongDoubleVectorVector
        """
        this = _probt_python3.new_LongDoubleVectorVector(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def push_back(self, x: 'LongDoubleVector') -> "void":
        """push_back(self, x)"""
        return _probt_python3.LongDoubleVectorVector_push_back(self, x)


    def front(self) -> "std::vector< std::vector< long double > >::value_type const &":
        """front(self) -> LongDoubleVector"""
        return _probt_python3.LongDoubleVectorVector_front(self)


    def back(self) -> "std::vector< std::vector< long double > >::value_type const &":
        """back(self) -> LongDoubleVector"""
        return _probt_python3.LongDoubleVectorVector_back(self)


    def assign(self, n: 'std::vector< std::vector< long double > >::size_type', x: 'LongDoubleVector') -> "void":
        """assign(self, n, x)"""
        return _probt_python3.LongDoubleVectorVector_assign(self, n, x)


    def resize(self, *args) -> "void":
        """
        resize(self, new_size)
        resize(self, new_size, x)
        """
        return _probt_python3.LongDoubleVectorVector_resize(self, *args)


    def insert(self, *args) -> "void":
        """
        insert(self, pos, x) -> std::vector< std::vector< long double > >::iterator
        insert(self, pos, n, x)
        """
        return _probt_python3.LongDoubleVectorVector_insert(self, *args)


    def reserve(self, n: 'std::vector< std::vector< long double > >::size_type') -> "void":
        """reserve(self, n)"""
        return _probt_python3.LongDoubleVectorVector_reserve(self, n)


    def capacity(self) -> "std::vector< std::vector< long double > >::size_type":
        """capacity(self) -> std::vector< std::vector< long double > >::size_type"""
        return _probt_python3.LongDoubleVectorVector_capacity(self)

    __swig_destroy__ = _probt_python3.delete_LongDoubleVectorVector
    __del__ = lambda self: None
LongDoubleVectorVector_swigregister = _probt_python3.LongDoubleVectorVector_swigregister
LongDoubleVectorVector_swigregister(LongDoubleVectorVector)

class LongDoubleVectorVectorVector(_object):
    """Proxy of C++ std::vector<(std::vector<(std::vector<(long double)>)>)> class."""

    __swig_setmethods__ = {}
    __setattr__ = lambda self, name, value: _swig_setattr(self, LongDoubleVectorVectorVector, name, value)
    __swig_getmethods__ = {}
    __getattr__ = lambda self, name: _swig_getattr(self, LongDoubleVectorVectorVector, name)
    __repr__ = _swig_repr

    def iterator(self) -> "swig::SwigPyIterator *":
        """iterator(self) -> SwigPyIterator"""
        return _probt_python3.LongDoubleVectorVectorVector_iterator(self)

    def __iter__(self):
        return self.iterator()

    def __nonzero__(self) -> "bool":
        """__nonzero__(self) -> bool"""
        return _probt_python3.LongDoubleVectorVectorVector___nonzero__(self)


    def __bool__(self) -> "bool":
        """__bool__(self) -> bool"""
        return _probt_python3.LongDoubleVectorVectorVector___bool__(self)


    def __len__(self) -> "std::vector< std::vector< std::vector< long double > > >::size_type":
        """__len__(self) -> std::vector< std::vector< std::vector< long double > > >::size_type"""
        return _probt_python3.LongDoubleVectorVectorVector___len__(self)


    def __getslice__(self, i: 'std::vector< std::vector< std::vector< long double > > >::difference_type', j: 'std::vector< std::vector< std::vector< long double > > >::difference_type') -> "std::vector< std::vector< std::vector< long double,std::allocator< long double > >,std::allocator< std::vector< long double,std::allocator< long double > > > >,std::allocator< std::vector< std::vector< long double,std::allocator< long double > >,std::allocator< std::vector< long double,std::allocator< long double > > > > > > *":
        """__getslice__(self, i, j) -> LongDoubleVectorVectorVector"""
        return _probt_python3.LongDoubleVectorVectorVector___getslice__(self, i, j)


    def __setslice__(self, *args) -> "void":
        """
        __setslice__(self, i, j)
        __setslice__(self, i, j, v)
        """
        return _probt_python3.LongDoubleVectorVectorVector___setslice__(self, *args)


    def __delslice__(self, i: 'std::vector< std::vector< std::vector< long double > > >::difference_type', j: 'std::vector< std::vector< std::vector< long double > > >::difference_type') -> "void":
        """__delslice__(self, i, j)"""
        return _probt_python3.LongDoubleVectorVectorVector___delslice__(self, i, j)


    def __delitem__(self, *args) -> "void":
        """
        __delitem__(self, i)
        __delitem__(self, slice)
        """
        return _probt_python3.LongDoubleVectorVectorVector___delitem__(self, *args)


    def __getitem__(self, *args) -> "std::vector< std::vector< std::vector< long double > > >::value_type const &":
        """
        __getitem__(self, slice) -> LongDoubleVectorVectorVector
        __getitem__(self, i) -> LongDoubleVectorVector
        """
        return _probt_python3.LongDoubleVectorVectorVector___getitem__(self, *args)


    def __setitem__(self, *args) -> "void":
        """
        __setitem__(self, slice, v)
        __setitem__(self, slice)
        __setitem__(self, i, x)
        """
        return _probt_python3.LongDoubleVectorVectorVector___setitem__(self, *args)


    def pop(self) -> "std::vector< std::vector< std::vector< long double > > >::value_type":
        """pop(self) -> LongDoubleVectorVector"""
        return _probt_python3.LongDoubleVectorVectorVector_pop(self)


    def append(self, x: 'LongDoubleVectorVector') -> "void":
        """append(self, x)"""
        return _probt_python3.LongDoubleVectorVectorVector_append(self, x)


    def empty(self) -> "bool":
        """empty(self) -> bool"""
        return _probt_python3.LongDoubleVectorVectorVector_empty(self)


    def size(self) -> "std::vector< std::vector< std::vector< long double > > >::size_type":
        """size(self) -> std::vector< std::vector< std::vector< long double > > >::size_type"""
        return _probt_python3.LongDoubleVectorVectorVector_size(self)


    def swap(self, v: 'LongDoubleVectorVectorVector') -> "void":
        """swap(self, v)"""
        return _probt_python3.LongDoubleVectorVectorVector_swap(self, v)


    def begin(self) -> "std::vector< std::vector< std::vector< long double > > >::iterator":
        """begin(self) -> std::vector< std::vector< std::vector< long double > > >::iterator"""
        return _probt_python3.LongDoubleVectorVectorVector_begin(self)


    def end(self) -> "std::vector< std::vector< std::vector< long double > > >::iterator":
        """end(self) -> std::vector< std::vector< std::vector< long double > > >::iterator"""
        return _probt_python3.LongDoubleVectorVectorVector_end(self)


    def rbegin(self) -> "std::vector< std::vector< std::vector< long double > > >::reverse_iterator":
        """rbegin(self) -> std::vector< std::vector< std::vector< long double > > >::reverse_iterator"""
        return _probt_python3.LongDoubleVectorVectorVector_rbegin(self)


    def rend(self) -> "std::vector< std::vector< std::vector< long double > > >::reverse_iterator":
        """rend(self) -> std::vector< std::vector< std::vector< long double > > >::reverse_iterator"""
        return _probt_python3.LongDoubleVectorVectorVector_rend(self)


    def clear(self) -> "void":
        """clear(self)"""
        return _probt_python3.LongDoubleVectorVectorVector_clear(self)


    def get_allocator(self) -> "std::vector< std::vector< std::vector< long double > > >::allocator_type":
        """get_allocator(self) -> std::vector< std::vector< std::vector< long double > > >::allocator_type"""
        return _probt_python3.LongDoubleVectorVectorVector_get_allocator(self)


    def pop_back(self) -> "void":
        """pop_back(self)"""
        return _probt_python3.LongDoubleVectorVectorVector_pop_back(self)


    def erase(self, *args) -> "std::vector< std::vector< std::vector< long double > > >::iterator":
        """
        erase(self, pos) -> std::vector< std::vector< std::vector< long double > > >::iterator
        erase(self, first, last) -> std::vector< std::vector< std::vector< long double > > >::iterator
        """
        return _probt_python3.LongDoubleVectorVectorVector_erase(self, *args)


    def __init__(self, *args):
        """
        __init__(self) -> LongDoubleVectorVectorVector
        __init__(self, arg2) -> LongDoubleVectorVectorVector
        __init__(self, size) -> LongDoubleVectorVectorVector
        __init__(self, size, value) -> LongDoubleVectorVectorVector
        """
        this = _probt_python3.new_LongDoubleVectorVectorVector(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def push_back(self, x: 'LongDoubleVectorVector') -> "void":
        """push_back(self, x)"""
        return _probt_python3.LongDoubleVectorVectorVector_push_back(self, x)


    def front(self) -> "std::vector< std::vector< std::vector< long double > > >::value_type const &":
        """front(self) -> LongDoubleVectorVector"""
        return _probt_python3.LongDoubleVectorVectorVector_front(self)


    def back(self) -> "std::vector< std::vector< std::vector< long double > > >::value_type const &":
        """back(self) -> LongDoubleVectorVector"""
        return _probt_python3.LongDoubleVectorVectorVector_back(self)


    def assign(self, n: 'std::vector< std::vector< std::vector< long double > > >::size_type', x: 'LongDoubleVectorVector') -> "void":
        """assign(self, n, x)"""
        return _probt_python3.LongDoubleVectorVectorVector_assign(self, n, x)


    def resize(self, *args) -> "void":
        """
        resize(self, new_size)
        resize(self, new_size, x)
        """
        return _probt_python3.LongDoubleVectorVectorVector_resize(self, *args)


    def insert(self, *args) -> "void":
        """
        insert(self, pos, x) -> std::vector< std::vector< std::vector< long double > > >::iterator
        insert(self, pos, n, x)
        """
        return _probt_python3.LongDoubleVectorVectorVector_insert(self, *args)


    def reserve(self, n: 'std::vector< std::vector< std::vector< long double > > >::size_type') -> "void":
        """reserve(self, n)"""
        return _probt_python3.LongDoubleVectorVectorVector_reserve(self, n)


    def capacity(self) -> "std::vector< std::vector< std::vector< long double > > >::size_type":
        """capacity(self) -> std::vector< std::vector< std::vector< long double > > >::size_type"""
        return _probt_python3.LongDoubleVectorVectorVector_capacity(self)

    __swig_destroy__ = _probt_python3.delete_LongDoubleVectorVectorVector
    __del__ = lambda self: None
LongDoubleVectorVectorVector_swigregister = _probt_python3.LongDoubleVectorVectorVector_swigregister
LongDoubleVectorVectorVector_swigregister(LongDoubleVectorVectorVector)

class LongIntVector(_object):
    """Proxy of C++ std::vector<(long)> class."""

    __swig_setmethods__ = {}
    __setattr__ = lambda self, name, value: _swig_setattr(self, LongIntVector, name, value)
    __swig_getmethods__ = {}
    __getattr__ = lambda self, name: _swig_getattr(self, LongIntVector, name)
    __repr__ = _swig_repr

    def iterator(self) -> "swig::SwigPyIterator *":
        """iterator(self) -> SwigPyIterator"""
        return _probt_python3.LongIntVector_iterator(self)

    def __iter__(self):
        return self.iterator()

    def __nonzero__(self) -> "bool":
        """__nonzero__(self) -> bool"""
        return _probt_python3.LongIntVector___nonzero__(self)


    def __bool__(self) -> "bool":
        """__bool__(self) -> bool"""
        return _probt_python3.LongIntVector___bool__(self)


    def __len__(self) -> "std::vector< long >::size_type":
        """__len__(self) -> std::vector< long >::size_type"""
        return _probt_python3.LongIntVector___len__(self)


    def __getslice__(self, i: 'std::vector< long >::difference_type', j: 'std::vector< long >::difference_type') -> "std::vector< long,std::allocator< long > > *":
        """__getslice__(self, i, j) -> LongIntVector"""
        return _probt_python3.LongIntVector___getslice__(self, i, j)


    def __setslice__(self, *args) -> "void":
        """
        __setslice__(self, i, j)
        __setslice__(self, i, j, v)
        """
        return _probt_python3.LongIntVector___setslice__(self, *args)


    def __delslice__(self, i: 'std::vector< long >::difference_type', j: 'std::vector< long >::difference_type') -> "void":
        """__delslice__(self, i, j)"""
        return _probt_python3.LongIntVector___delslice__(self, i, j)


    def __delitem__(self, *args) -> "void":
        """
        __delitem__(self, i)
        __delitem__(self, slice)
        """
        return _probt_python3.LongIntVector___delitem__(self, *args)


    def __getitem__(self, *args) -> "std::vector< long >::value_type const &":
        """
        __getitem__(self, slice) -> LongIntVector
        __getitem__(self, i) -> std::vector< long >::value_type const &
        """
        return _probt_python3.LongIntVector___getitem__(self, *args)


    def __setitem__(self, *args) -> "void":
        """
        __setitem__(self, slice, v)
        __setitem__(self, slice)
        __setitem__(self, i, x)
        """
        return _probt_python3.LongIntVector___setitem__(self, *args)


    def pop(self) -> "std::vector< long >::value_type":
        """pop(self) -> std::vector< long >::value_type"""
        return _probt_python3.LongIntVector_pop(self)


    def append(self, x: 'std::vector< long >::value_type const &') -> "void":
        """append(self, x)"""
        return _probt_python3.LongIntVector_append(self, x)


    def empty(self) -> "bool":
        """empty(self) -> bool"""
        return _probt_python3.LongIntVector_empty(self)


    def size(self) -> "std::vector< long >::size_type":
        """size(self) -> std::vector< long >::size_type"""
        return _probt_python3.LongIntVector_size(self)


    def swap(self, v: 'LongIntVector') -> "void":
        """swap(self, v)"""
        return _probt_python3.LongIntVector_swap(self, v)


    def begin(self) -> "std::vector< long >::iterator":
        """begin(self) -> std::vector< long >::iterator"""
        return _probt_python3.LongIntVector_begin(self)


    def end(self) -> "std::vector< long >::iterator":
        """end(self) -> std::vector< long >::iterator"""
        return _probt_python3.LongIntVector_end(self)


    def rbegin(self) -> "std::vector< long >::reverse_iterator":
        """rbegin(self) -> std::vector< long >::reverse_iterator"""
        return _probt_python3.LongIntVector_rbegin(self)


    def rend(self) -> "std::vector< long >::reverse_iterator":
        """rend(self) -> std::vector< long >::reverse_iterator"""
        return _probt_python3.LongIntVector_rend(self)


    def clear(self) -> "void":
        """clear(self)"""
        return _probt_python3.LongIntVector_clear(self)


    def get_allocator(self) -> "std::vector< long >::allocator_type":
        """get_allocator(self) -> std::vector< long >::allocator_type"""
        return _probt_python3.LongIntVector_get_allocator(self)


    def pop_back(self) -> "void":
        """pop_back(self)"""
        return _probt_python3.LongIntVector_pop_back(self)


    def erase(self, *args) -> "std::vector< long >::iterator":
        """
        erase(self, pos) -> std::vector< long >::iterator
        erase(self, first, last) -> std::vector< long >::iterator
        """
        return _probt_python3.LongIntVector_erase(self, *args)


    def __init__(self, *args):
        """
        __init__(self) -> LongIntVector
        __init__(self, arg2) -> LongIntVector
        __init__(self, size) -> LongIntVector
        __init__(self, size, value) -> LongIntVector
        """
        this = _probt_python3.new_LongIntVector(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def push_back(self, x: 'std::vector< long >::value_type const &') -> "void":
        """push_back(self, x)"""
        return _probt_python3.LongIntVector_push_back(self, x)


    def front(self) -> "std::vector< long >::value_type const &":
        """front(self) -> std::vector< long >::value_type const &"""
        return _probt_python3.LongIntVector_front(self)


    def back(self) -> "std::vector< long >::value_type const &":
        """back(self) -> std::vector< long >::value_type const &"""
        return _probt_python3.LongIntVector_back(self)


    def assign(self, n: 'std::vector< long >::size_type', x: 'std::vector< long >::value_type const &') -> "void":
        """assign(self, n, x)"""
        return _probt_python3.LongIntVector_assign(self, n, x)


    def resize(self, *args) -> "void":
        """
        resize(self, new_size)
        resize(self, new_size, x)
        """
        return _probt_python3.LongIntVector_resize(self, *args)


    def insert(self, *args) -> "void":
        """
        insert(self, pos, x) -> std::vector< long >::iterator
        insert(self, pos, n, x)
        """
        return _probt_python3.LongIntVector_insert(self, *args)


    def reserve(self, n: 'std::vector< long >::size_type') -> "void":
        """reserve(self, n)"""
        return _probt_python3.LongIntVector_reserve(self, n)


    def capacity(self) -> "std::vector< long >::size_type":
        """capacity(self) -> std::vector< long >::size_type"""
        return _probt_python3.LongIntVector_capacity(self)

    __swig_destroy__ = _probt_python3.delete_LongIntVector
    __del__ = lambda self: None
LongIntVector_swigregister = _probt_python3.LongIntVector_swigregister
LongIntVector_swigregister(LongIntVector)

class LongUnsignedIntVector(_object):
    """Proxy of C++ std::vector<(unsigned long)> class."""

    __swig_setmethods__ = {}
    __setattr__ = lambda self, name, value: _swig_setattr(self, LongUnsignedIntVector, name, value)
    __swig_getmethods__ = {}
    __getattr__ = lambda self, name: _swig_getattr(self, LongUnsignedIntVector, name)
    __repr__ = _swig_repr

    def iterator(self) -> "swig::SwigPyIterator *":
        """iterator(self) -> SwigPyIterator"""
        return _probt_python3.LongUnsignedIntVector_iterator(self)

    def __iter__(self):
        return self.iterator()

    def __nonzero__(self) -> "bool":
        """__nonzero__(self) -> bool"""
        return _probt_python3.LongUnsignedIntVector___nonzero__(self)


    def __bool__(self) -> "bool":
        """__bool__(self) -> bool"""
        return _probt_python3.LongUnsignedIntVector___bool__(self)


    def __len__(self) -> "std::vector< unsigned long >::size_type":
        """__len__(self) -> std::vector< unsigned long >::size_type"""
        return _probt_python3.LongUnsignedIntVector___len__(self)


    def __getslice__(self, i: 'std::vector< unsigned long >::difference_type', j: 'std::vector< unsigned long >::difference_type') -> "std::vector< unsigned long,std::allocator< unsigned long > > *":
        """__getslice__(self, i, j) -> LongUnsignedIntVector"""
        return _probt_python3.LongUnsignedIntVector___getslice__(self, i, j)


    def __setslice__(self, *args) -> "void":
        """
        __setslice__(self, i, j)
        __setslice__(self, i, j, v)
        """
        return _probt_python3.LongUnsignedIntVector___setslice__(self, *args)


    def __delslice__(self, i: 'std::vector< unsigned long >::difference_type', j: 'std::vector< unsigned long >::difference_type') -> "void":
        """__delslice__(self, i, j)"""
        return _probt_python3.LongUnsignedIntVector___delslice__(self, i, j)


    def __delitem__(self, *args) -> "void":
        """
        __delitem__(self, i)
        __delitem__(self, slice)
        """
        return _probt_python3.LongUnsignedIntVector___delitem__(self, *args)


    def __getitem__(self, *args) -> "std::vector< unsigned long >::value_type const &":
        """
        __getitem__(self, slice) -> LongUnsignedIntVector
        __getitem__(self, i) -> std::vector< unsigned long >::value_type const &
        """
        return _probt_python3.LongUnsignedIntVector___getitem__(self, *args)


    def __setitem__(self, *args) -> "void":
        """
        __setitem__(self, slice, v)
        __setitem__(self, slice)
        __setitem__(self, i, x)
        """
        return _probt_python3.LongUnsignedIntVector___setitem__(self, *args)


    def pop(self) -> "std::vector< unsigned long >::value_type":
        """pop(self) -> std::vector< unsigned long >::value_type"""
        return _probt_python3.LongUnsignedIntVector_pop(self)


    def append(self, x: 'std::vector< unsigned long >::value_type const &') -> "void":
        """append(self, x)"""
        return _probt_python3.LongUnsignedIntVector_append(self, x)


    def empty(self) -> "bool":
        """empty(self) -> bool"""
        return _probt_python3.LongUnsignedIntVector_empty(self)


    def size(self) -> "std::vector< unsigned long >::size_type":
        """size(self) -> std::vector< unsigned long >::size_type"""
        return _probt_python3.LongUnsignedIntVector_size(self)


    def swap(self, v: 'LongUnsignedIntVector') -> "void":
        """swap(self, v)"""
        return _probt_python3.LongUnsignedIntVector_swap(self, v)


    def begin(self) -> "std::vector< unsigned long >::iterator":
        """begin(self) -> std::vector< unsigned long >::iterator"""
        return _probt_python3.LongUnsignedIntVector_begin(self)


    def end(self) -> "std::vector< unsigned long >::iterator":
        """end(self) -> std::vector< unsigned long >::iterator"""
        return _probt_python3.LongUnsignedIntVector_end(self)


    def rbegin(self) -> "std::vector< unsigned long >::reverse_iterator":
        """rbegin(self) -> std::vector< unsigned long >::reverse_iterator"""
        return _probt_python3.LongUnsignedIntVector_rbegin(self)


    def rend(self) -> "std::vector< unsigned long >::reverse_iterator":
        """rend(self) -> std::vector< unsigned long >::reverse_iterator"""
        return _probt_python3.LongUnsignedIntVector_rend(self)


    def clear(self) -> "void":
        """clear(self)"""
        return _probt_python3.LongUnsignedIntVector_clear(self)


    def get_allocator(self) -> "std::vector< unsigned long >::allocator_type":
        """get_allocator(self) -> std::vector< unsigned long >::allocator_type"""
        return _probt_python3.LongUnsignedIntVector_get_allocator(self)


    def pop_back(self) -> "void":
        """pop_back(self)"""
        return _probt_python3.LongUnsignedIntVector_pop_back(self)


    def erase(self, *args) -> "std::vector< unsigned long >::iterator":
        """
        erase(self, pos) -> std::vector< unsigned long >::iterator
        erase(self, first, last) -> std::vector< unsigned long >::iterator
        """
        return _probt_python3.LongUnsignedIntVector_erase(self, *args)


    def __init__(self, *args):
        """
        __init__(self) -> LongUnsignedIntVector
        __init__(self, arg2) -> LongUnsignedIntVector
        __init__(self, size) -> LongUnsignedIntVector
        __init__(self, size, value) -> LongUnsignedIntVector
        """
        this = _probt_python3.new_LongUnsignedIntVector(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def push_back(self, x: 'std::vector< unsigned long >::value_type const &') -> "void":
        """push_back(self, x)"""
        return _probt_python3.LongUnsignedIntVector_push_back(self, x)


    def front(self) -> "std::vector< unsigned long >::value_type const &":
        """front(self) -> std::vector< unsigned long >::value_type const &"""
        return _probt_python3.LongUnsignedIntVector_front(self)


    def back(self) -> "std::vector< unsigned long >::value_type const &":
        """back(self) -> std::vector< unsigned long >::value_type const &"""
        return _probt_python3.LongUnsignedIntVector_back(self)


    def assign(self, n: 'std::vector< unsigned long >::size_type', x: 'std::vector< unsigned long >::value_type const &') -> "void":
        """assign(self, n, x)"""
        return _probt_python3.LongUnsignedIntVector_assign(self, n, x)


    def resize(self, *args) -> "void":
        """
        resize(self, new_size)
        resize(self, new_size, x)
        """
        return _probt_python3.LongUnsignedIntVector_resize(self, *args)


    def insert(self, *args) -> "void":
        """
        insert(self, pos, x) -> std::vector< unsigned long >::iterator
        insert(self, pos, n, x)
        """
        return _probt_python3.LongUnsignedIntVector_insert(self, *args)


    def reserve(self, n: 'std::vector< unsigned long >::size_type') -> "void":
        """reserve(self, n)"""
        return _probt_python3.LongUnsignedIntVector_reserve(self, n)


    def capacity(self) -> "std::vector< unsigned long >::size_type":
        """capacity(self) -> std::vector< unsigned long >::size_type"""
        return _probt_python3.LongUnsignedIntVector_capacity(self)

    __swig_destroy__ = _probt_python3.delete_LongUnsignedIntVector
    __del__ = lambda self: None
LongUnsignedIntVector_swigregister = _probt_python3.LongUnsignedIntVector_swigregister
LongUnsignedIntVector_swigregister(LongUnsignedIntVector)

class plVariableDiscretizerVector(_object):
    """Proxy of C++ std::vector<(p.plVariableDiscretizer)> class."""

    __swig_setmethods__ = {}
    __setattr__ = lambda self, name, value: _swig_setattr(self, plVariableDiscretizerVector, name, value)
    __swig_getmethods__ = {}
    __getattr__ = lambda self, name: _swig_getattr(self, plVariableDiscretizerVector, name)
    __repr__ = _swig_repr

    def iterator(self) -> "swig::SwigPyIterator *":
        """iterator(self) -> SwigPyIterator"""
        return _probt_python3.plVariableDiscretizerVector_iterator(self)

    def __iter__(self):
        return self.iterator()

    def __nonzero__(self) -> "bool":
        """__nonzero__(self) -> bool"""
        return _probt_python3.plVariableDiscretizerVector___nonzero__(self)


    def __bool__(self) -> "bool":
        """__bool__(self) -> bool"""
        return _probt_python3.plVariableDiscretizerVector___bool__(self)


    def __len__(self) -> "std::vector< plVariableDiscretizer * >::size_type":
        """__len__(self) -> std::vector< plVariableDiscretizer * >::size_type"""
        return _probt_python3.plVariableDiscretizerVector___len__(self)


    def __getslice__(self, i: 'std::vector< plVariableDiscretizer * >::difference_type', j: 'std::vector< plVariableDiscretizer * >::difference_type') -> "std::vector< plVariableDiscretizer *,std::allocator< plVariableDiscretizer * > > *":
        """__getslice__(self, i, j) -> plVariableDiscretizerVector"""
        return _probt_python3.plVariableDiscretizerVector___getslice__(self, i, j)


    def __setslice__(self, *args) -> "void":
        """
        __setslice__(self, i, j)
        __setslice__(self, i, j, v)
        """
        return _probt_python3.plVariableDiscretizerVector___setslice__(self, *args)


    def __delslice__(self, i: 'std::vector< plVariableDiscretizer * >::difference_type', j: 'std::vector< plVariableDiscretizer * >::difference_type') -> "void":
        """__delslice__(self, i, j)"""
        return _probt_python3.plVariableDiscretizerVector___delslice__(self, i, j)


    def __delitem__(self, *args) -> "void":
        """
        __delitem__(self, i)
        __delitem__(self, slice)
        """
        return _probt_python3.plVariableDiscretizerVector___delitem__(self, *args)


    def __getitem__(self, *args) -> "std::vector< plVariableDiscretizer * >::value_type":
        """
        __getitem__(self, slice) -> plVariableDiscretizerVector
        __getitem__(self, i) -> plVariableDiscretizer
        """
        return _probt_python3.plVariableDiscretizerVector___getitem__(self, *args)


    def __setitem__(self, *args) -> "void":
        """
        __setitem__(self, slice, v)
        __setitem__(self, slice)
        __setitem__(self, i, x)
        """
        return _probt_python3.plVariableDiscretizerVector___setitem__(self, *args)


    def pop(self) -> "std::vector< plVariableDiscretizer * >::value_type":
        """pop(self) -> plVariableDiscretizer"""
        return _probt_python3.plVariableDiscretizerVector_pop(self)


    def append(self, x: 'plVariableDiscretizer') -> "void":
        """append(self, x)"""
        return _probt_python3.plVariableDiscretizerVector_append(self, x)


    def empty(self) -> "bool":
        """empty(self) -> bool"""
        return _probt_python3.plVariableDiscretizerVector_empty(self)


    def size(self) -> "std::vector< plVariableDiscretizer * >::size_type":
        """size(self) -> std::vector< plVariableDiscretizer * >::size_type"""
        return _probt_python3.plVariableDiscretizerVector_size(self)


    def swap(self, v: 'plVariableDiscretizerVector') -> "void":
        """swap(self, v)"""
        return _probt_python3.plVariableDiscretizerVector_swap(self, v)


    def begin(self) -> "std::vector< plVariableDiscretizer * >::iterator":
        """begin(self) -> std::vector< plVariableDiscretizer * >::iterator"""
        return _probt_python3.plVariableDiscretizerVector_begin(self)


    def end(self) -> "std::vector< plVariableDiscretizer * >::iterator":
        """end(self) -> std::vector< plVariableDiscretizer * >::iterator"""
        return _probt_python3.plVariableDiscretizerVector_end(self)


    def rbegin(self) -> "std::vector< plVariableDiscretizer * >::reverse_iterator":
        """rbegin(self) -> std::vector< plVariableDiscretizer * >::reverse_iterator"""
        return _probt_python3.plVariableDiscretizerVector_rbegin(self)


    def rend(self) -> "std::vector< plVariableDiscretizer * >::reverse_iterator":
        """rend(self) -> std::vector< plVariableDiscretizer * >::reverse_iterator"""
        return _probt_python3.plVariableDiscretizerVector_rend(self)


    def clear(self) -> "void":
        """clear(self)"""
        return _probt_python3.plVariableDiscretizerVector_clear(self)


    def get_allocator(self) -> "std::vector< plVariableDiscretizer * >::allocator_type":
        """get_allocator(self) -> std::vector< plVariableDiscretizer * >::allocator_type"""
        return _probt_python3.plVariableDiscretizerVector_get_allocator(self)


    def pop_back(self) -> "void":
        """pop_back(self)"""
        return _probt_python3.plVariableDiscretizerVector_pop_back(self)


    def erase(self, *args) -> "std::vector< plVariableDiscretizer * >::iterator":
        """
        erase(self, pos) -> std::vector< plVariableDiscretizer * >::iterator
        erase(self, first, last) -> std::vector< plVariableDiscretizer * >::iterator
        """
        return _probt_python3.plVariableDiscretizerVector_erase(self, *args)


    def __init__(self, *args):
        """
        __init__(self) -> plVariableDiscretizerVector
        __init__(self, arg2) -> plVariableDiscretizerVector
        __init__(self, size) -> plVariableDiscretizerVector
        __init__(self, size, value) -> plVariableDiscretizerVector
        """
        this = _probt_python3.new_plVariableDiscretizerVector(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def push_back(self, x: 'plVariableDiscretizer') -> "void":
        """push_back(self, x)"""
        return _probt_python3.plVariableDiscretizerVector_push_back(self, x)


    def front(self) -> "std::vector< plVariableDiscretizer * >::value_type":
        """front(self) -> plVariableDiscretizer"""
        return _probt_python3.plVariableDiscretizerVector_front(self)


    def back(self) -> "std::vector< plVariableDiscretizer * >::value_type":
        """back(self) -> plVariableDiscretizer"""
        return _probt_python3.plVariableDiscretizerVector_back(self)


    def assign(self, n: 'std::vector< plVariableDiscretizer * >::size_type', x: 'plVariableDiscretizer') -> "void":
        """assign(self, n, x)"""
        return _probt_python3.plVariableDiscretizerVector_assign(self, n, x)


    def resize(self, *args) -> "void":
        """
        resize(self, new_size)
        resize(self, new_size, x)
        """
        return _probt_python3.plVariableDiscretizerVector_resize(self, *args)


    def insert(self, *args) -> "void":
        """
        insert(self, pos, x) -> std::vector< plVariableDiscretizer * >::iterator
        insert(self, pos, n, x)
        """
        return _probt_python3.plVariableDiscretizerVector_insert(self, *args)


    def reserve(self, n: 'std::vector< plVariableDiscretizer * >::size_type') -> "void":
        """reserve(self, n)"""
        return _probt_python3.plVariableDiscretizerVector_reserve(self, n)


    def capacity(self) -> "std::vector< plVariableDiscretizer * >::size_type":
        """capacity(self) -> std::vector< plVariableDiscretizer * >::size_type"""
        return _probt_python3.plVariableDiscretizerVector_capacity(self)

    __swig_destroy__ = _probt_python3.delete_plVariableDiscretizerVector
    __del__ = lambda self: None
plVariableDiscretizerVector_swigregister = _probt_python3.plVariableDiscretizerVector_swigregister
plVariableDiscretizerVector_swigregister(plVariableDiscretizerVector)

class plVariableVector(_object):
    """Proxy of C++ std::vector<(plVariable)> class."""

    __swig_setmethods__ = {}
    __setattr__ = lambda self, name, value: _swig_setattr(self, plVariableVector, name, value)
    __swig_getmethods__ = {}
    __getattr__ = lambda self, name: _swig_getattr(self, plVariableVector, name)
    __repr__ = _swig_repr

    def iterator(self) -> "swig::SwigPyIterator *":
        """iterator(self) -> SwigPyIterator"""
        return _probt_python3.plVariableVector_iterator(self)

    def __iter__(self):
        return self.iterator()

    def __nonzero__(self) -> "bool":
        """__nonzero__(self) -> bool"""
        return _probt_python3.plVariableVector___nonzero__(self)


    def __bool__(self) -> "bool":
        """__bool__(self) -> bool"""
        return _probt_python3.plVariableVector___bool__(self)


    def __len__(self) -> "std::vector< plVariable >::size_type":
        """__len__(self) -> std::vector< plVariable >::size_type"""
        return _probt_python3.plVariableVector___len__(self)


    def __getslice__(self, i: 'std::vector< plVariable >::difference_type', j: 'std::vector< plVariable >::difference_type') -> "std::vector< plVariable,std::allocator< plVariable > > *":
        """__getslice__(self, i, j) -> plVariableVector"""
        return _probt_python3.plVariableVector___getslice__(self, i, j)


    def __setslice__(self, *args) -> "void":
        """
        __setslice__(self, i, j)
        __setslice__(self, i, j, v)
        """
        return _probt_python3.plVariableVector___setslice__(self, *args)


    def __delslice__(self, i: 'std::vector< plVariable >::difference_type', j: 'std::vector< plVariable >::difference_type') -> "void":
        """__delslice__(self, i, j)"""
        return _probt_python3.plVariableVector___delslice__(self, i, j)


    def __delitem__(self, *args) -> "void":
        """
        __delitem__(self, i)
        __delitem__(self, slice)
        """
        return _probt_python3.plVariableVector___delitem__(self, *args)


    def __getitem__(self, *args) -> "std::vector< plVariable >::value_type const &":
        """
        __getitem__(self, slice) -> plVariableVector
        __getitem__(self, i) -> plVariable
        """
        return _probt_python3.plVariableVector___getitem__(self, *args)


    def __setitem__(self, *args) -> "void":
        """
        __setitem__(self, slice, v)
        __setitem__(self, slice)
        __setitem__(self, i, x)
        """
        return _probt_python3.plVariableVector___setitem__(self, *args)


    def pop(self) -> "std::vector< plVariable >::value_type":
        """pop(self) -> plVariable"""
        return _probt_python3.plVariableVector_pop(self)


    def append(self, x: 'plVariable') -> "void":
        """append(self, x)"""
        return _probt_python3.plVariableVector_append(self, x)


    def empty(self) -> "bool":
        """empty(self) -> bool"""
        return _probt_python3.plVariableVector_empty(self)


    def size(self) -> "std::vector< plVariable >::size_type":
        """size(self) -> std::vector< plVariable >::size_type"""
        return _probt_python3.plVariableVector_size(self)


    def swap(self, v: 'plVariableVector') -> "void":
        """swap(self, v)"""
        return _probt_python3.plVariableVector_swap(self, v)


    def begin(self) -> "std::vector< plVariable >::iterator":
        """begin(self) -> std::vector< plVariable >::iterator"""
        return _probt_python3.plVariableVector_begin(self)


    def end(self) -> "std::vector< plVariable >::iterator":
        """end(self) -> std::vector< plVariable >::iterator"""
        return _probt_python3.plVariableVector_end(self)


    def rbegin(self) -> "std::vector< plVariable >::reverse_iterator":
        """rbegin(self) -> std::vector< plVariable >::reverse_iterator"""
        return _probt_python3.plVariableVector_rbegin(self)


    def rend(self) -> "std::vector< plVariable >::reverse_iterator":
        """rend(self) -> std::vector< plVariable >::reverse_iterator"""
        return _probt_python3.plVariableVector_rend(self)


    def clear(self) -> "void":
        """clear(self)"""
        return _probt_python3.plVariableVector_clear(self)


    def get_allocator(self) -> "std::vector< plVariable >::allocator_type":
        """get_allocator(self) -> std::vector< plVariable >::allocator_type"""
        return _probt_python3.plVariableVector_get_allocator(self)


    def pop_back(self) -> "void":
        """pop_back(self)"""
        return _probt_python3.plVariableVector_pop_back(self)


    def erase(self, *args) -> "std::vector< plVariable >::iterator":
        """
        erase(self, pos) -> std::vector< plVariable >::iterator
        erase(self, first, last) -> std::vector< plVariable >::iterator
        """
        return _probt_python3.plVariableVector_erase(self, *args)


    def __init__(self, *args):
        """
        __init__(self) -> plVariableVector
        __init__(self, arg2) -> plVariableVector
        __init__(self, size) -> plVariableVector
        __init__(self, size, value) -> plVariableVector
        """
        this = _probt_python3.new_plVariableVector(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def push_back(self, x: 'plVariable') -> "void":
        """push_back(self, x)"""
        return _probt_python3.plVariableVector_push_back(self, x)


    def front(self) -> "std::vector< plVariable >::value_type const &":
        """front(self) -> plVariable"""
        return _probt_python3.plVariableVector_front(self)


    def back(self) -> "std::vector< plVariable >::value_type const &":
        """back(self) -> plVariable"""
        return _probt_python3.plVariableVector_back(self)


    def assign(self, n: 'std::vector< plVariable >::size_type', x: 'plVariable') -> "void":
        """assign(self, n, x)"""
        return _probt_python3.plVariableVector_assign(self, n, x)


    def resize(self, *args) -> "void":
        """
        resize(self, new_size)
        resize(self, new_size, x)
        """
        return _probt_python3.plVariableVector_resize(self, *args)


    def insert(self, *args) -> "void":
        """
        insert(self, pos, x) -> std::vector< plVariable >::iterator
        insert(self, pos, n, x)
        """
        return _probt_python3.plVariableVector_insert(self, *args)


    def reserve(self, n: 'std::vector< plVariable >::size_type') -> "void":
        """reserve(self, n)"""
        return _probt_python3.plVariableVector_reserve(self, n)


    def capacity(self) -> "std::vector< plVariable >::size_type":
        """capacity(self) -> std::vector< plVariable >::size_type"""
        return _probt_python3.plVariableVector_capacity(self)

    __swig_destroy__ = _probt_python3.delete_plVariableVector
    __del__ = lambda self: None
plVariableVector_swigregister = _probt_python3.plVariableVector_swigregister
plVariableVector_swigregister(plVariableVector)

class plVariablesConjunctionVector(_object):
    """Proxy of C++ std::vector<(plVariablesConjunction)> class."""

    __swig_setmethods__ = {}
    __setattr__ = lambda self, name, value: _swig_setattr(self, plVariablesConjunctionVector, name, value)
    __swig_getmethods__ = {}
    __getattr__ = lambda self, name: _swig_getattr(self, plVariablesConjunctionVector, name)
    __repr__ = _swig_repr

    def iterator(self) -> "swig::SwigPyIterator *":
        """iterator(self) -> SwigPyIterator"""
        return _probt_python3.plVariablesConjunctionVector_iterator(self)

    def __iter__(self):
        return self.iterator()

    def __nonzero__(self) -> "bool":
        """__nonzero__(self) -> bool"""
        return _probt_python3.plVariablesConjunctionVector___nonzero__(self)


    def __bool__(self) -> "bool":
        """__bool__(self) -> bool"""
        return _probt_python3.plVariablesConjunctionVector___bool__(self)


    def __len__(self) -> "std::vector< plVariablesConjunction >::size_type":
        """__len__(self) -> std::vector< plVariablesConjunction >::size_type"""
        return _probt_python3.plVariablesConjunctionVector___len__(self)


    def __getslice__(self, i: 'std::vector< plVariablesConjunction >::difference_type', j: 'std::vector< plVariablesConjunction >::difference_type') -> "std::vector< plVariablesConjunction,std::allocator< plVariablesConjunction > > *":
        """__getslice__(self, i, j) -> plVariablesConjunctionVector"""
        return _probt_python3.plVariablesConjunctionVector___getslice__(self, i, j)


    def __setslice__(self, *args) -> "void":
        """
        __setslice__(self, i, j)
        __setslice__(self, i, j, v)
        """
        return _probt_python3.plVariablesConjunctionVector___setslice__(self, *args)


    def __delslice__(self, i: 'std::vector< plVariablesConjunction >::difference_type', j: 'std::vector< plVariablesConjunction >::difference_type') -> "void":
        """__delslice__(self, i, j)"""
        return _probt_python3.plVariablesConjunctionVector___delslice__(self, i, j)


    def __delitem__(self, *args) -> "void":
        """
        __delitem__(self, i)
        __delitem__(self, slice)
        """
        return _probt_python3.plVariablesConjunctionVector___delitem__(self, *args)


    def __getitem__(self, *args) -> "std::vector< plVariablesConjunction >::value_type const &":
        """
        __getitem__(self, slice) -> plVariablesConjunctionVector
        __getitem__(self, i) -> plVariablesConjunction
        """
        return _probt_python3.plVariablesConjunctionVector___getitem__(self, *args)


    def __setitem__(self, *args) -> "void":
        """
        __setitem__(self, slice, v)
        __setitem__(self, slice)
        __setitem__(self, i, x)
        """
        return _probt_python3.plVariablesConjunctionVector___setitem__(self, *args)


    def pop(self) -> "std::vector< plVariablesConjunction >::value_type":
        """pop(self) -> plVariablesConjunction"""
        return _probt_python3.plVariablesConjunctionVector_pop(self)


    def append(self, x: 'plVariablesConjunction') -> "void":
        """append(self, x)"""
        return _probt_python3.plVariablesConjunctionVector_append(self, x)


    def empty(self) -> "bool":
        """empty(self) -> bool"""
        return _probt_python3.plVariablesConjunctionVector_empty(self)


    def size(self) -> "std::vector< plVariablesConjunction >::size_type":
        """size(self) -> std::vector< plVariablesConjunction >::size_type"""
        return _probt_python3.plVariablesConjunctionVector_size(self)


    def swap(self, v: 'plVariablesConjunctionVector') -> "void":
        """swap(self, v)"""
        return _probt_python3.plVariablesConjunctionVector_swap(self, v)


    def begin(self) -> "std::vector< plVariablesConjunction >::iterator":
        """begin(self) -> std::vector< plVariablesConjunction >::iterator"""
        return _probt_python3.plVariablesConjunctionVector_begin(self)


    def end(self) -> "std::vector< plVariablesConjunction >::iterator":
        """end(self) -> std::vector< plVariablesConjunction >::iterator"""
        return _probt_python3.plVariablesConjunctionVector_end(self)


    def rbegin(self) -> "std::vector< plVariablesConjunction >::reverse_iterator":
        """rbegin(self) -> std::vector< plVariablesConjunction >::reverse_iterator"""
        return _probt_python3.plVariablesConjunctionVector_rbegin(self)


    def rend(self) -> "std::vector< plVariablesConjunction >::reverse_iterator":
        """rend(self) -> std::vector< plVariablesConjunction >::reverse_iterator"""
        return _probt_python3.plVariablesConjunctionVector_rend(self)


    def clear(self) -> "void":
        """clear(self)"""
        return _probt_python3.plVariablesConjunctionVector_clear(self)


    def get_allocator(self) -> "std::vector< plVariablesConjunction >::allocator_type":
        """get_allocator(self) -> std::vector< plVariablesConjunction >::allocator_type"""
        return _probt_python3.plVariablesConjunctionVector_get_allocator(self)


    def pop_back(self) -> "void":
        """pop_back(self)"""
        return _probt_python3.plVariablesConjunctionVector_pop_back(self)


    def erase(self, *args) -> "std::vector< plVariablesConjunction >::iterator":
        """
        erase(self, pos) -> std::vector< plVariablesConjunction >::iterator
        erase(self, first, last) -> std::vector< plVariablesConjunction >::iterator
        """
        return _probt_python3.plVariablesConjunctionVector_erase(self, *args)


    def __init__(self, *args):
        """
        __init__(self) -> plVariablesConjunctionVector
        __init__(self, arg2) -> plVariablesConjunctionVector
        __init__(self, size) -> plVariablesConjunctionVector
        __init__(self, size, value) -> plVariablesConjunctionVector
        """
        this = _probt_python3.new_plVariablesConjunctionVector(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def push_back(self, x: 'plVariablesConjunction') -> "void":
        """push_back(self, x)"""
        return _probt_python3.plVariablesConjunctionVector_push_back(self, x)


    def front(self) -> "std::vector< plVariablesConjunction >::value_type const &":
        """front(self) -> plVariablesConjunction"""
        return _probt_python3.plVariablesConjunctionVector_front(self)


    def back(self) -> "std::vector< plVariablesConjunction >::value_type const &":
        """back(self) -> plVariablesConjunction"""
        return _probt_python3.plVariablesConjunctionVector_back(self)


    def assign(self, n: 'std::vector< plVariablesConjunction >::size_type', x: 'plVariablesConjunction') -> "void":
        """assign(self, n, x)"""
        return _probt_python3.plVariablesConjunctionVector_assign(self, n, x)


    def resize(self, *args) -> "void":
        """
        resize(self, new_size)
        resize(self, new_size, x)
        """
        return _probt_python3.plVariablesConjunctionVector_resize(self, *args)


    def insert(self, *args) -> "void":
        """
        insert(self, pos, x) -> std::vector< plVariablesConjunction >::iterator
        insert(self, pos, n, x)
        """
        return _probt_python3.plVariablesConjunctionVector_insert(self, *args)


    def reserve(self, n: 'std::vector< plVariablesConjunction >::size_type') -> "void":
        """reserve(self, n)"""
        return _probt_python3.plVariablesConjunctionVector_reserve(self, n)


    def capacity(self) -> "std::vector< plVariablesConjunction >::size_type":
        """capacity(self) -> std::vector< plVariablesConjunction >::size_type"""
        return _probt_python3.plVariablesConjunctionVector_capacity(self)

    __swig_destroy__ = _probt_python3.delete_plVariablesConjunctionVector
    __del__ = lambda self: None
plVariablesConjunctionVector_swigregister = _probt_python3.plVariablesConjunctionVector_swigregister
plVariablesConjunctionVector_swigregister(plVariablesConjunctionVector)

class plValuesVector(_object):
    """Proxy of C++ std::vector<(plValues)> class."""

    __swig_setmethods__ = {}
    __setattr__ = lambda self, name, value: _swig_setattr(self, plValuesVector, name, value)
    __swig_getmethods__ = {}
    __getattr__ = lambda self, name: _swig_getattr(self, plValuesVector, name)
    __repr__ = _swig_repr

    def iterator(self) -> "swig::SwigPyIterator *":
        """iterator(self) -> SwigPyIterator"""
        return _probt_python3.plValuesVector_iterator(self)

    def __iter__(self):
        return self.iterator()

    def __nonzero__(self) -> "bool":
        """__nonzero__(self) -> bool"""
        return _probt_python3.plValuesVector___nonzero__(self)


    def __bool__(self) -> "bool":
        """__bool__(self) -> bool"""
        return _probt_python3.plValuesVector___bool__(self)


    def __len__(self) -> "std::vector< plValues >::size_type":
        """__len__(self) -> std::vector< plValues >::size_type"""
        return _probt_python3.plValuesVector___len__(self)


    def __getslice__(self, i: 'std::vector< plValues >::difference_type', j: 'std::vector< plValues >::difference_type') -> "std::vector< plValues,std::allocator< plValues > > *":
        """__getslice__(self, i, j) -> plValuesVector"""
        return _probt_python3.plValuesVector___getslice__(self, i, j)


    def __setslice__(self, *args) -> "void":
        """
        __setslice__(self, i, j)
        __setslice__(self, i, j, v)
        """
        return _probt_python3.plValuesVector___setslice__(self, *args)


    def __delslice__(self, i: 'std::vector< plValues >::difference_type', j: 'std::vector< plValues >::difference_type') -> "void":
        """__delslice__(self, i, j)"""
        return _probt_python3.plValuesVector___delslice__(self, i, j)


    def __delitem__(self, *args) -> "void":
        """
        __delitem__(self, i)
        __delitem__(self, slice)
        """
        return _probt_python3.plValuesVector___delitem__(self, *args)


    def __getitem__(self, *args) -> "std::vector< plValues >::value_type const &":
        """
        __getitem__(self, slice) -> plValuesVector
        __getitem__(self, i) -> plValues
        """
        return _probt_python3.plValuesVector___getitem__(self, *args)


    def __setitem__(self, *args) -> "void":
        """
        __setitem__(self, slice, v)
        __setitem__(self, slice)
        __setitem__(self, i, x)
        """
        return _probt_python3.plValuesVector___setitem__(self, *args)


    def pop(self) -> "std::vector< plValues >::value_type":
        """pop(self) -> plValues"""
        return _probt_python3.plValuesVector_pop(self)


    def append(self, x: 'plValues') -> "void":
        """append(self, x)"""
        return _probt_python3.plValuesVector_append(self, x)


    def empty(self) -> "bool":
        """empty(self) -> bool"""
        return _probt_python3.plValuesVector_empty(self)


    def size(self) -> "std::vector< plValues >::size_type":
        """size(self) -> std::vector< plValues >::size_type"""
        return _probt_python3.plValuesVector_size(self)


    def swap(self, v: 'plValuesVector') -> "void":
        """swap(self, v)"""
        return _probt_python3.plValuesVector_swap(self, v)


    def begin(self) -> "std::vector< plValues >::iterator":
        """begin(self) -> std::vector< plValues >::iterator"""
        return _probt_python3.plValuesVector_begin(self)


    def end(self) -> "std::vector< plValues >::iterator":
        """end(self) -> std::vector< plValues >::iterator"""
        return _probt_python3.plValuesVector_end(self)


    def rbegin(self) -> "std::vector< plValues >::reverse_iterator":
        """rbegin(self) -> std::vector< plValues >::reverse_iterator"""
        return _probt_python3.plValuesVector_rbegin(self)


    def rend(self) -> "std::vector< plValues >::reverse_iterator":
        """rend(self) -> std::vector< plValues >::reverse_iterator"""
        return _probt_python3.plValuesVector_rend(self)


    def clear(self) -> "void":
        """clear(self)"""
        return _probt_python3.plValuesVector_clear(self)


    def get_allocator(self) -> "std::vector< plValues >::allocator_type":
        """get_allocator(self) -> std::vector< plValues >::allocator_type"""
        return _probt_python3.plValuesVector_get_allocator(self)


    def pop_back(self) -> "void":
        """pop_back(self)"""
        return _probt_python3.plValuesVector_pop_back(self)


    def erase(self, *args) -> "std::vector< plValues >::iterator":
        """
        erase(self, pos) -> std::vector< plValues >::iterator
        erase(self, first, last) -> std::vector< plValues >::iterator
        """
        return _probt_python3.plValuesVector_erase(self, *args)


    def __init__(self, *args):
        """
        __init__(self) -> plValuesVector
        __init__(self, arg2) -> plValuesVector
        __init__(self, size) -> plValuesVector
        __init__(self, size, value) -> plValuesVector
        """
        this = _probt_python3.new_plValuesVector(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def push_back(self, x: 'plValues') -> "void":
        """push_back(self, x)"""
        return _probt_python3.plValuesVector_push_back(self, x)


    def front(self) -> "std::vector< plValues >::value_type const &":
        """front(self) -> plValues"""
        return _probt_python3.plValuesVector_front(self)


    def back(self) -> "std::vector< plValues >::value_type const &":
        """back(self) -> plValues"""
        return _probt_python3.plValuesVector_back(self)


    def assign(self, n: 'std::vector< plValues >::size_type', x: 'plValues') -> "void":
        """assign(self, n, x)"""
        return _probt_python3.plValuesVector_assign(self, n, x)


    def resize(self, *args) -> "void":
        """
        resize(self, new_size)
        resize(self, new_size, x)
        """
        return _probt_python3.plValuesVector_resize(self, *args)


    def insert(self, *args) -> "void":
        """
        insert(self, pos, x) -> std::vector< plValues >::iterator
        insert(self, pos, n, x)
        """
        return _probt_python3.plValuesVector_insert(self, *args)


    def reserve(self, n: 'std::vector< plValues >::size_type') -> "void":
        """reserve(self, n)"""
        return _probt_python3.plValuesVector_reserve(self, n)


    def capacity(self) -> "std::vector< plValues >::size_type":
        """capacity(self) -> std::vector< plValues >::size_type"""
        return _probt_python3.plValuesVector_capacity(self)

    __swig_destroy__ = _probt_python3.delete_plValuesVector
    __del__ = lambda self: None
plValuesVector_swigregister = _probt_python3.plValuesVector_swigregister
plValuesVector_swigregister(plValuesVector)

class plFlVectorVector(_object):
    """Proxy of C++ std::vector<(plFloatVector)> class."""

    __swig_setmethods__ = {}
    __setattr__ = lambda self, name, value: _swig_setattr(self, plFlVectorVector, name, value)
    __swig_getmethods__ = {}
    __getattr__ = lambda self, name: _swig_getattr(self, plFlVectorVector, name)
    __repr__ = _swig_repr

    def iterator(self) -> "swig::SwigPyIterator *":
        """iterator(self) -> SwigPyIterator"""
        return _probt_python3.plFlVectorVector_iterator(self)

    def __iter__(self):
        return self.iterator()

    def __nonzero__(self) -> "bool":
        """__nonzero__(self) -> bool"""
        return _probt_python3.plFlVectorVector___nonzero__(self)


    def __bool__(self) -> "bool":
        """__bool__(self) -> bool"""
        return _probt_python3.plFlVectorVector___bool__(self)


    def __len__(self) -> "std::vector< plFloatVector >::size_type":
        """__len__(self) -> std::vector< plFloatVector >::size_type"""
        return _probt_python3.plFlVectorVector___len__(self)


    def __getslice__(self, i: 'std::vector< plFloatVector >::difference_type', j: 'std::vector< plFloatVector >::difference_type') -> "std::vector< plFloatVector,std::allocator< plFloatVector > > *":
        """__getslice__(self, i, j) -> plFlVectorVector"""
        return _probt_python3.plFlVectorVector___getslice__(self, i, j)


    def __setslice__(self, *args) -> "void":
        """
        __setslice__(self, i, j)
        __setslice__(self, i, j, v)
        """
        return _probt_python3.plFlVectorVector___setslice__(self, *args)


    def __delslice__(self, i: 'std::vector< plFloatVector >::difference_type', j: 'std::vector< plFloatVector >::difference_type') -> "void":
        """__delslice__(self, i, j)"""
        return _probt_python3.plFlVectorVector___delslice__(self, i, j)


    def __delitem__(self, *args) -> "void":
        """
        __delitem__(self, i)
        __delitem__(self, slice)
        """
        return _probt_python3.plFlVectorVector___delitem__(self, *args)


    def __getitem__(self, *args) -> "std::vector< plFloatVector >::value_type const &":
        """
        __getitem__(self, slice) -> plFlVectorVector
        __getitem__(self, i) -> plFloatVector
        """
        return _probt_python3.plFlVectorVector___getitem__(self, *args)


    def __setitem__(self, *args) -> "void":
        """
        __setitem__(self, slice, v)
        __setitem__(self, slice)
        __setitem__(self, i, x)
        """
        return _probt_python3.plFlVectorVector___setitem__(self, *args)


    def pop(self) -> "std::vector< plFloatVector >::value_type":
        """pop(self) -> plFloatVector"""
        return _probt_python3.plFlVectorVector_pop(self)


    def append(self, x: 'plFloatVector') -> "void":
        """append(self, x)"""
        return _probt_python3.plFlVectorVector_append(self, x)


    def empty(self) -> "bool":
        """empty(self) -> bool"""
        return _probt_python3.plFlVectorVector_empty(self)


    def size(self) -> "std::vector< plFloatVector >::size_type":
        """size(self) -> std::vector< plFloatVector >::size_type"""
        return _probt_python3.plFlVectorVector_size(self)


    def swap(self, v: 'plFlVectorVector') -> "void":
        """swap(self, v)"""
        return _probt_python3.plFlVectorVector_swap(self, v)


    def begin(self) -> "std::vector< plFloatVector >::iterator":
        """begin(self) -> std::vector< plFloatVector >::iterator"""
        return _probt_python3.plFlVectorVector_begin(self)


    def end(self) -> "std::vector< plFloatVector >::iterator":
        """end(self) -> std::vector< plFloatVector >::iterator"""
        return _probt_python3.plFlVectorVector_end(self)


    def rbegin(self) -> "std::vector< plFloatVector >::reverse_iterator":
        """rbegin(self) -> std::vector< plFloatVector >::reverse_iterator"""
        return _probt_python3.plFlVectorVector_rbegin(self)


    def rend(self) -> "std::vector< plFloatVector >::reverse_iterator":
        """rend(self) -> std::vector< plFloatVector >::reverse_iterator"""
        return _probt_python3.plFlVectorVector_rend(self)


    def clear(self) -> "void":
        """clear(self)"""
        return _probt_python3.plFlVectorVector_clear(self)


    def get_allocator(self) -> "std::vector< plFloatVector >::allocator_type":
        """get_allocator(self) -> std::vector< plFloatVector >::allocator_type"""
        return _probt_python3.plFlVectorVector_get_allocator(self)


    def pop_back(self) -> "void":
        """pop_back(self)"""
        return _probt_python3.plFlVectorVector_pop_back(self)


    def erase(self, *args) -> "std::vector< plFloatVector >::iterator":
        """
        erase(self, pos) -> std::vector< plFloatVector >::iterator
        erase(self, first, last) -> std::vector< plFloatVector >::iterator
        """
        return _probt_python3.plFlVectorVector_erase(self, *args)


    def __init__(self, *args):
        """
        __init__(self) -> plFlVectorVector
        __init__(self, arg2) -> plFlVectorVector
        __init__(self, size) -> plFlVectorVector
        __init__(self, size, value) -> plFlVectorVector
        """
        this = _probt_python3.new_plFlVectorVector(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def push_back(self, x: 'plFloatVector') -> "void":
        """push_back(self, x)"""
        return _probt_python3.plFlVectorVector_push_back(self, x)


    def front(self) -> "std::vector< plFloatVector >::value_type const &":
        """front(self) -> plFloatVector"""
        return _probt_python3.plFlVectorVector_front(self)


    def back(self) -> "std::vector< plFloatVector >::value_type const &":
        """back(self) -> plFloatVector"""
        return _probt_python3.plFlVectorVector_back(self)


    def assign(self, n: 'std::vector< plFloatVector >::size_type', x: 'plFloatVector') -> "void":
        """assign(self, n, x)"""
        return _probt_python3.plFlVectorVector_assign(self, n, x)


    def resize(self, *args) -> "void":
        """
        resize(self, new_size)
        resize(self, new_size, x)
        """
        return _probt_python3.plFlVectorVector_resize(self, *args)


    def insert(self, *args) -> "void":
        """
        insert(self, pos, x) -> std::vector< plFloatVector >::iterator
        insert(self, pos, n, x)
        """
        return _probt_python3.plFlVectorVector_insert(self, *args)


    def reserve(self, n: 'std::vector< plFloatVector >::size_type') -> "void":
        """reserve(self, n)"""
        return _probt_python3.plFlVectorVector_reserve(self, n)


    def capacity(self) -> "std::vector< plFloatVector >::size_type":
        """capacity(self) -> std::vector< plFloatVector >::size_type"""
        return _probt_python3.plFlVectorVector_capacity(self)

    __swig_destroy__ = _probt_python3.delete_plFlVectorVector
    __del__ = lambda self: None
plFlVectorVector_swigregister = _probt_python3.plFlVectorVector_swigregister
plFlVectorVector_swigregister(plFlVectorVector)

class plBnEdge(_object):
    """Proxy of C++ std::pair<(plVariable,plVariable)> class."""

    __swig_setmethods__ = {}
    __setattr__ = lambda self, name, value: _swig_setattr(self, plBnEdge, name, value)
    __swig_getmethods__ = {}
    __getattr__ = lambda self, name: _swig_getattr(self, plBnEdge, name)
    __repr__ = _swig_repr

    def __init__(self, *args):
        """
        __init__(self) -> plBnEdge
        __init__(self, first, second) -> plBnEdge
        __init__(self, p) -> plBnEdge
        """
        this = _probt_python3.new_plBnEdge(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this
    __swig_setmethods__["first"] = _probt_python3.plBnEdge_first_set
    __swig_getmethods__["first"] = _probt_python3.plBnEdge_first_get
    if _newclass:
        first = _swig_property(_probt_python3.plBnEdge_first_get, _probt_python3.plBnEdge_first_set)
    __swig_setmethods__["second"] = _probt_python3.plBnEdge_second_set
    __swig_getmethods__["second"] = _probt_python3.plBnEdge_second_get
    if _newclass:
        second = _swig_property(_probt_python3.plBnEdge_second_get, _probt_python3.plBnEdge_second_set)
    def __len__(self):
        return 2
    def __repr__(self):
        return str((self.first, self.second))
    def __getitem__(self, index): 
        if not (index % 2):
            return self.first
        else:
            return self.second
    def __setitem__(self, index, val):
        if not (index % 2):
            self.first = val
        else:
            self.second = val
    __swig_destroy__ = _probt_python3.delete_plBnEdge
    __del__ = lambda self: None
plBnEdge_swigregister = _probt_python3.plBnEdge_swigregister
plBnEdge_swigregister(plBnEdge)

class plBnEdgeList(_object):
    """Proxy of C++ std::vector<(std::pair<(plVariable,plVariable)>)> class."""

    __swig_setmethods__ = {}
    __setattr__ = lambda self, name, value: _swig_setattr(self, plBnEdgeList, name, value)
    __swig_getmethods__ = {}
    __getattr__ = lambda self, name: _swig_getattr(self, plBnEdgeList, name)
    __repr__ = _swig_repr

    def iterator(self) -> "swig::SwigPyIterator *":
        """iterator(self) -> SwigPyIterator"""
        return _probt_python3.plBnEdgeList_iterator(self)

    def __iter__(self):
        return self.iterator()

    def __nonzero__(self) -> "bool":
        """__nonzero__(self) -> bool"""
        return _probt_python3.plBnEdgeList___nonzero__(self)


    def __bool__(self) -> "bool":
        """__bool__(self) -> bool"""
        return _probt_python3.plBnEdgeList___bool__(self)


    def __len__(self) -> "std::vector< std::pair< plVariable,plVariable > >::size_type":
        """__len__(self) -> std::vector< std::pair< plVariable,plVariable > >::size_type"""
        return _probt_python3.plBnEdgeList___len__(self)


    def __getslice__(self, i: 'std::vector< std::pair< plVariable,plVariable > >::difference_type', j: 'std::vector< std::pair< plVariable,plVariable > >::difference_type') -> "std::vector< std::pair< plVariable,plVariable >,std::allocator< std::pair< plVariable,plVariable > > > *":
        """__getslice__(self, i, j) -> plBnEdgeList"""
        return _probt_python3.plBnEdgeList___getslice__(self, i, j)


    def __setslice__(self, *args) -> "void":
        """
        __setslice__(self, i, j)
        __setslice__(self, i, j, v)
        """
        return _probt_python3.plBnEdgeList___setslice__(self, *args)


    def __delslice__(self, i: 'std::vector< std::pair< plVariable,plVariable > >::difference_type', j: 'std::vector< std::pair< plVariable,plVariable > >::difference_type') -> "void":
        """__delslice__(self, i, j)"""
        return _probt_python3.plBnEdgeList___delslice__(self, i, j)


    def __delitem__(self, *args) -> "void":
        """
        __delitem__(self, i)
        __delitem__(self, slice)
        """
        return _probt_python3.plBnEdgeList___delitem__(self, *args)


    def __getitem__(self, *args) -> "std::vector< std::pair< plVariable,plVariable > >::value_type const &":
        """
        __getitem__(self, slice) -> plBnEdgeList
        __getitem__(self, i) -> plBnEdge
        """
        return _probt_python3.plBnEdgeList___getitem__(self, *args)


    def __setitem__(self, *args) -> "void":
        """
        __setitem__(self, slice, v)
        __setitem__(self, slice)
        __setitem__(self, i, x)
        """
        return _probt_python3.plBnEdgeList___setitem__(self, *args)


    def pop(self) -> "std::vector< std::pair< plVariable,plVariable > >::value_type":
        """pop(self) -> plBnEdge"""
        return _probt_python3.plBnEdgeList_pop(self)


    def append(self, x: 'plBnEdge') -> "void":
        """append(self, x)"""
        return _probt_python3.plBnEdgeList_append(self, x)


    def empty(self) -> "bool":
        """empty(self) -> bool"""
        return _probt_python3.plBnEdgeList_empty(self)


    def size(self) -> "std::vector< std::pair< plVariable,plVariable > >::size_type":
        """size(self) -> std::vector< std::pair< plVariable,plVariable > >::size_type"""
        return _probt_python3.plBnEdgeList_size(self)


    def swap(self, v: 'plBnEdgeList') -> "void":
        """swap(self, v)"""
        return _probt_python3.plBnEdgeList_swap(self, v)


    def begin(self) -> "std::vector< std::pair< plVariable,plVariable > >::iterator":
        """begin(self) -> std::vector< std::pair< plVariable,plVariable > >::iterator"""
        return _probt_python3.plBnEdgeList_begin(self)


    def end(self) -> "std::vector< std::pair< plVariable,plVariable > >::iterator":
        """end(self) -> std::vector< std::pair< plVariable,plVariable > >::iterator"""
        return _probt_python3.plBnEdgeList_end(self)


    def rbegin(self) -> "std::vector< std::pair< plVariable,plVariable > >::reverse_iterator":
        """rbegin(self) -> std::vector< std::pair< plVariable,plVariable > >::reverse_iterator"""
        return _probt_python3.plBnEdgeList_rbegin(self)


    def rend(self) -> "std::vector< std::pair< plVariable,plVariable > >::reverse_iterator":
        """rend(self) -> std::vector< std::pair< plVariable,plVariable > >::reverse_iterator"""
        return _probt_python3.plBnEdgeList_rend(self)


    def clear(self) -> "void":
        """clear(self)"""
        return _probt_python3.plBnEdgeList_clear(self)


    def get_allocator(self) -> "std::vector< std::pair< plVariable,plVariable > >::allocator_type":
        """get_allocator(self) -> std::vector< std::pair< plVariable,plVariable > >::allocator_type"""
        return _probt_python3.plBnEdgeList_get_allocator(self)


    def pop_back(self) -> "void":
        """pop_back(self)"""
        return _probt_python3.plBnEdgeList_pop_back(self)


    def erase(self, *args) -> "std::vector< std::pair< plVariable,plVariable > >::iterator":
        """
        erase(self, pos) -> std::vector< std::pair< plVariable,plVariable > >::iterator
        erase(self, first, last) -> std::vector< std::pair< plVariable,plVariable > >::iterator
        """
        return _probt_python3.plBnEdgeList_erase(self, *args)


    def __init__(self, *args):
        """
        __init__(self) -> plBnEdgeList
        __init__(self, arg2) -> plBnEdgeList
        __init__(self, size) -> plBnEdgeList
        __init__(self, size, value) -> plBnEdgeList
        """
        this = _probt_python3.new_plBnEdgeList(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def push_back(self, x: 'plBnEdge') -> "void":
        """push_back(self, x)"""
        return _probt_python3.plBnEdgeList_push_back(self, x)


    def front(self) -> "std::vector< std::pair< plVariable,plVariable > >::value_type const &":
        """front(self) -> plBnEdge"""
        return _probt_python3.plBnEdgeList_front(self)


    def back(self) -> "std::vector< std::pair< plVariable,plVariable > >::value_type const &":
        """back(self) -> plBnEdge"""
        return _probt_python3.plBnEdgeList_back(self)


    def assign(self, n: 'std::vector< std::pair< plVariable,plVariable > >::size_type', x: 'plBnEdge') -> "void":
        """assign(self, n, x)"""
        return _probt_python3.plBnEdgeList_assign(self, n, x)


    def resize(self, *args) -> "void":
        """
        resize(self, new_size)
        resize(self, new_size, x)
        """
        return _probt_python3.plBnEdgeList_resize(self, *args)


    def insert(self, *args) -> "void":
        """
        insert(self, pos, x) -> std::vector< std::pair< plVariable,plVariable > >::iterator
        insert(self, pos, n, x)
        """
        return _probt_python3.plBnEdgeList_insert(self, *args)


    def reserve(self, n: 'std::vector< std::pair< plVariable,plVariable > >::size_type') -> "void":
        """reserve(self, n)"""
        return _probt_python3.plBnEdgeList_reserve(self, n)


    def capacity(self) -> "std::vector< std::pair< plVariable,plVariable > >::size_type":
        """capacity(self) -> std::vector< std::pair< plVariable,plVariable > >::size_type"""
        return _probt_python3.plBnEdgeList_capacity(self)

    __swig_destroy__ = _probt_python3.delete_plBnEdgeList
    __del__ = lambda self: None
plBnEdgeList_swigregister = _probt_python3.plBnEdgeList_swigregister
plBnEdgeList_swigregister(plBnEdgeList)

class plTypeVector(_object):
    """Proxy of C++ std::vector<(plType)> class."""

    __swig_setmethods__ = {}
    __setattr__ = lambda self, name, value: _swig_setattr(self, plTypeVector, name, value)
    __swig_getmethods__ = {}
    __getattr__ = lambda self, name: _swig_getattr(self, plTypeVector, name)
    __repr__ = _swig_repr

    def iterator(self) -> "swig::SwigPyIterator *":
        """iterator(self) -> SwigPyIterator"""
        return _probt_python3.plTypeVector_iterator(self)

    def __iter__(self):
        return self.iterator()

    def __nonzero__(self) -> "bool":
        """__nonzero__(self) -> bool"""
        return _probt_python3.plTypeVector___nonzero__(self)


    def __bool__(self) -> "bool":
        """__bool__(self) -> bool"""
        return _probt_python3.plTypeVector___bool__(self)


    def __len__(self) -> "std::vector< plType >::size_type":
        """__len__(self) -> std::vector< plType >::size_type"""
        return _probt_python3.plTypeVector___len__(self)


    def __getslice__(self, i: 'std::vector< plType >::difference_type', j: 'std::vector< plType >::difference_type') -> "std::vector< plType,std::allocator< plType > > *":
        """__getslice__(self, i, j) -> plTypeVector"""
        return _probt_python3.plTypeVector___getslice__(self, i, j)


    def __setslice__(self, *args) -> "void":
        """
        __setslice__(self, i, j)
        __setslice__(self, i, j, v)
        """
        return _probt_python3.plTypeVector___setslice__(self, *args)


    def __delslice__(self, i: 'std::vector< plType >::difference_type', j: 'std::vector< plType >::difference_type') -> "void":
        """__delslice__(self, i, j)"""
        return _probt_python3.plTypeVector___delslice__(self, i, j)


    def __delitem__(self, *args) -> "void":
        """
        __delitem__(self, i)
        __delitem__(self, slice)
        """
        return _probt_python3.plTypeVector___delitem__(self, *args)


    def __getitem__(self, *args) -> "std::vector< plType >::value_type const &":
        """
        __getitem__(self, slice) -> plTypeVector
        __getitem__(self, i) -> plType
        """
        return _probt_python3.plTypeVector___getitem__(self, *args)


    def __setitem__(self, *args) -> "void":
        """
        __setitem__(self, slice, v)
        __setitem__(self, slice)
        __setitem__(self, i, x)
        """
        return _probt_python3.plTypeVector___setitem__(self, *args)


    def pop(self) -> "std::vector< plType >::value_type":
        """pop(self) -> plType"""
        return _probt_python3.plTypeVector_pop(self)


    def append(self, x: 'plType') -> "void":
        """append(self, x)"""
        return _probt_python3.plTypeVector_append(self, x)


    def empty(self) -> "bool":
        """empty(self) -> bool"""
        return _probt_python3.plTypeVector_empty(self)


    def size(self) -> "std::vector< plType >::size_type":
        """size(self) -> std::vector< plType >::size_type"""
        return _probt_python3.plTypeVector_size(self)


    def swap(self, v: 'plTypeVector') -> "void":
        """swap(self, v)"""
        return _probt_python3.plTypeVector_swap(self, v)


    def begin(self) -> "std::vector< plType >::iterator":
        """begin(self) -> std::vector< plType >::iterator"""
        return _probt_python3.plTypeVector_begin(self)


    def end(self) -> "std::vector< plType >::iterator":
        """end(self) -> std::vector< plType >::iterator"""
        return _probt_python3.plTypeVector_end(self)


    def rbegin(self) -> "std::vector< plType >::reverse_iterator":
        """rbegin(self) -> std::vector< plType >::reverse_iterator"""
        return _probt_python3.plTypeVector_rbegin(self)


    def rend(self) -> "std::vector< plType >::reverse_iterator":
        """rend(self) -> std::vector< plType >::reverse_iterator"""
        return _probt_python3.plTypeVector_rend(self)


    def clear(self) -> "void":
        """clear(self)"""
        return _probt_python3.plTypeVector_clear(self)


    def get_allocator(self) -> "std::vector< plType >::allocator_type":
        """get_allocator(self) -> std::vector< plType >::allocator_type"""
        return _probt_python3.plTypeVector_get_allocator(self)


    def pop_back(self) -> "void":
        """pop_back(self)"""
        return _probt_python3.plTypeVector_pop_back(self)


    def erase(self, *args) -> "std::vector< plType >::iterator":
        """
        erase(self, pos) -> std::vector< plType >::iterator
        erase(self, first, last) -> std::vector< plType >::iterator
        """
        return _probt_python3.plTypeVector_erase(self, *args)


    def __init__(self, *args):
        """
        __init__(self) -> plTypeVector
        __init__(self, arg2) -> plTypeVector
        __init__(self, size) -> plTypeVector
        __init__(self, size, value) -> plTypeVector
        """
        this = _probt_python3.new_plTypeVector(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def push_back(self, x: 'plType') -> "void":
        """push_back(self, x)"""
        return _probt_python3.plTypeVector_push_back(self, x)


    def front(self) -> "std::vector< plType >::value_type const &":
        """front(self) -> plType"""
        return _probt_python3.plTypeVector_front(self)


    def back(self) -> "std::vector< plType >::value_type const &":
        """back(self) -> plType"""
        return _probt_python3.plTypeVector_back(self)


    def assign(self, n: 'std::vector< plType >::size_type', x: 'plType') -> "void":
        """assign(self, n, x)"""
        return _probt_python3.plTypeVector_assign(self, n, x)


    def resize(self, *args) -> "void":
        """
        resize(self, new_size)
        resize(self, new_size, x)
        """
        return _probt_python3.plTypeVector_resize(self, *args)


    def insert(self, *args) -> "void":
        """
        insert(self, pos, x) -> std::vector< plType >::iterator
        insert(self, pos, n, x)
        """
        return _probt_python3.plTypeVector_insert(self, *args)


    def reserve(self, n: 'std::vector< plType >::size_type') -> "void":
        """reserve(self, n)"""
        return _probt_python3.plTypeVector_reserve(self, n)


    def capacity(self) -> "std::vector< plType >::size_type":
        """capacity(self) -> std::vector< plType >::size_type"""
        return _probt_python3.plTypeVector_capacity(self)

    __swig_destroy__ = _probt_python3.delete_plTypeVector
    __del__ = lambda self: None
plTypeVector_swigregister = _probt_python3.plTypeVector_swigregister
plTypeVector_swigregister(plTypeVector)

plProbValueVector = DoubleVector; 

stdVectorTypes = []
stdVectorTypes.append(IntVector)
stdVectorTypes.append(StringVector)
stdVectorTypes.append(UnsignedIntVector)
stdVectorTypes.append(BoolVector)
stdVectorTypes.append(FloatVector)
stdVectorTypes.append(DoubleVector)
stdVectorTypes.append(LongDoubleVector)
stdVectorTypes.append(LongIntVector)
stdVectorTypes.append(LongUnsignedIntVector)
stdVectorTypes.append(plProbValueVector)

def stdVector_display(c):
  s = "[ "
  for x in range(c.size()):
    s = s + str(c[x]) 
    if x<c.size()-1:
      s = s + ", "
  s = s +  " ]"
  return s

for t in stdVectorTypes:
  t.__str__ = stdVector_display
  t.__repr__ = t.__str__

class plObject(_object):
    """

    `plObject()`  

    Used as the base class of all ProBT API objects.  

    Constructors
    ------------
    * `plObject()`  

        Constructor.  

    C++ includes: plObject.h

    """

    __swig_setmethods__ = {}
    __setattr__ = lambda self, name, value: _swig_setattr(self, plObject, name, value)
    __swig_getmethods__ = {}
    __getattr__ = lambda self, name: _swig_getattr(self, plObject, name)

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined - class is abstract")
    __repr__ = _swig_repr
    __swig_destroy__ = _probt_python3.delete_plObject
    __del__ = lambda self: None

    def to_string(self, s: 'std::ostringstream *'=None) -> "std::string":
        """
        to_string(self, s=None) -> std::string
        to_string(self) -> std::string


        `to_string(std::ostringstream *s=0) const -> std::string`  

        Returns the object as a string.  

        If *s* in non-null, then it will be used for generating the string using "*s <<
        *this". This can be used for customizing the precision of the printing the
        numeric values for example.  

        """
        return _probt_python3.plObject_to_string(self, s)

plObject_swigregister = _probt_python3.plObject_swigregister
plObject_swigregister(plObject)

class plBuiltinModel(plObject):
    """


    A Bayesian builtin model.  

    C++ includes: plObject.h

    """

    __swig_setmethods__ = {}
    for _s in [plObject]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plBuiltinModel, name, value)
    __swig_getmethods__ = {}
    for _s in [plObject]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plBuiltinModel, name)

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined - class is abstract")
    __repr__ = _swig_repr
    __swig_destroy__ = _probt_python3.delete_plBuiltinModel
    __del__ = lambda self: None
plBuiltinModel_swigregister = _probt_python3.plBuiltinModel_swigregister
plBuiltinModel_swigregister(plBuiltinModel)

class plSampleSpaceObject(plObject):
    """


    A State Space Object.  

    C++ includes: plObject.h

    """

    __swig_setmethods__ = {}
    for _s in [plObject]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plSampleSpaceObject, name, value)
    __swig_getmethods__ = {}
    for _s in [plObject]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plSampleSpaceObject, name)

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined - class is abstract")
    __repr__ = _swig_repr
    __swig_destroy__ = _probt_python3.delete_plSampleSpaceObject
    __del__ = lambda self: None
plSampleSpaceObject_swigregister = _probt_python3.plSampleSpaceObject_swigregister
plSampleSpaceObject_swigregister(plSampleSpaceObject)

class plUserFunction(plObject):
    """


    A User Function Object.  

    C++ includes: plObject.h

    """

    __swig_setmethods__ = {}
    for _s in [plObject]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plUserFunction, name, value)
    __swig_getmethods__ = {}
    for _s in [plObject]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plUserFunction, name)

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined - class is abstract")
    __repr__ = _swig_repr
    __swig_destroy__ = _probt_python3.delete_plUserFunction
    __del__ = lambda self: None
plUserFunction_swigregister = _probt_python3.plUserFunction_swigregister
plUserFunction_swigregister(plUserFunction)

class plError(plObject, ):
    """

    `plError()`  
    `plError(unsigned int error_id)`  
    `plError(unsigned int error_id, const std::string &additional_info)`  

    A *plError* is an exception thrown when a fatal error is encountered in ProBT.  

    Every kind of *plError* has an integer code accessible with get_error_number().
    It can be output to a stream or a string by using operator<<(); in addition to
    the error code, this output contains a human-readable description of the error.  

    When thrown, a *plError* prints itself to the standard error output. This
    behaviour can be disabled globally by using plError::always_display() or for a
    given error number by using plError::ignore_this_message().  

    Constructors
    ------------
    * `plError()`  

        Default constructor.  

    * `plError(unsigned int error_id)`  

        Creates an error number *error_id* with no additional information.  

    * `plError(unsigned int error_id, const std::string &additional_info)`  

        Creates an error with number *error_id*, and additional information.  

    C++ includes: plError.h

    """

    __swig_setmethods__ = {}
    for _s in [plObject, ]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plError, name, value)
    __swig_getmethods__ = {}
    for _s in [plObject, ]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plError, name)
    __repr__ = _swig_repr

    def __init__(self, *args):
        """
        __init__(self) -> plError
        __init__(self, error_id) -> plError
        __init__(self, error_id, additional_info) -> plError


        `plError()`  
        `plError(unsigned int error_id)`  
        `plError(unsigned int error_id, const std::string &additional_info)`  

        Overloaded function
        -------------------
        * `plError()`  

            Default constructor.  

        * `plError(unsigned int error_id)`  

            Creates an error number *error_id* with no additional information.  

        * `plError(unsigned int error_id, const std::string &additional_info)`  

            Creates an error with number *error_id*, and additional information.  

        """
        this = _probt_python3.new_plError(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this
    __swig_destroy__ = _probt_python3.delete_plError
    __del__ = lambda self: None

    def what(self) -> "char const *":
        """
        what(self) -> char const *


        `what() const -> const char *`  

        Returns a human-readable string representing the error.  

        """
        return _probt_python3.plError_what(self)


    def display(self, *args) -> "void":
        """
        display(self)
        display(self)


        `display(std::ostream &out=std::cerr) const`  

        Same as Output().  

        Could probably be deprecated, and then removed.  

        """
        return _probt_python3.plError_display(self, *args)


    def get_error_number(self) -> "unsigned int":
        """
        get_error_number(self) -> unsigned int


        `get_error_number() const -> unsigned int`  

        Returns the error number.  

        """
        return _probt_python3.plError_get_error_number(self)


    def always_display(display_flag: 'bool') -> "void":
        """
        always_display(display_flag)


        `always_display(bool display_flag)`  

        Set the global display flag for errors.  

        When *true*, all errors will be displayed as soon as they are created. When
        *false*, they will not be displayed. In all cases, errors are C++ exceptions:
        you may catch them using *try* and *catch*, and inspect them using what() and
        get_error_number().  

        Parameters
        ----------
        * `display_flag` :  
            New value of the global display flag.  

        """
        return _probt_python3.plError_always_display(display_flag)

    always_display = staticmethod(always_display)

    def ignore_this_message(id_message: 'unsigned int', ignoring_state: 'bool') -> "void":
        """
        ignore_this_message(id_message, ignoring_state)


        `ignore_this_message(unsigned int id_message, bool ignoring_state)`  

        Inhibits the display of a warning or error, given its number.  

        This is useful if you are sure that a given warning is not pertinent in your
        particular setting. This function has no effect if the given message number is
        invalid.  

        Parameters
        ----------
        * `id_message` :  
            Number of the warning or error to ignore.  
        * `ignoring_state` :  
            Whether to ignore the message (*true*), or display it (*false*).  

        """
        return _probt_python3.plError_ignore_this_message(id_message, ignoring_state)

    ignore_this_message = staticmethod(ignore_this_message)

    def message_is_ignored(id_message: 'unsigned int') -> "bool":
        """
        message_is_ignored(id_message) -> bool


        `message_is_ignored(unsigned int id_message) -> bool`  

        Tells whether a warning or error is currently ignored.  

        This will return *true* unless a warning/error is specifically ignored ; calls
        to always_display_warning() and always_display() have no influence on the return
        of this function. This function returns *false* if the given message number is
        invalid.  

        Parameters
        ----------
        * `id_message` :  
            Number of the warning or error.  

        Returns
        -------
        *true* if and only if the warning is currently ignored.  

        """
        return _probt_python3.plError_message_is_ignored(id_message)

    message_is_ignored = staticmethod(message_is_ignored)

    def always_display_warning(display_flag: 'bool') -> "void":
        """
        always_display_warning(display_flag)


        `always_display_warning(bool display_flag)`  

        Inhibits the display of all warnings.  

        Parameters
        ----------
        * `display_flag` :  
            Whether to hide all warnings (*false*) or display all those that are not
            ignored (*true*).  

        """
        return _probt_python3.plError_always_display_warning(display_flag)

    always_display_warning = staticmethod(always_display_warning)

    def treat_warnings_as_errors(wie_flag: 'bool'=True) -> "void":
        """
        treat_warnings_as_errors(wie_flag=True)
        treat_warnings_as_errors()


        `treat_warnings_as_errors(bool wie_flag=true)`  

        Makes all warnings (ignored or not, displayed or not) raise an exception.  

        Parameters
        ----------
        * `wie_flag` :  
            Whether to raise an exception when the warning is raised (*true*), or just
            display it and go on with execution (*false*).  

        """
        return _probt_python3.plError_treat_warnings_as_errors(wie_flag)

    treat_warnings_as_errors = staticmethod(treat_warnings_as_errors)

    def treat_this_warning_as_error(id_warning: 'unsigned int', wae_flag: 'bool'=True) -> "void":
        """
        treat_this_warning_as_error(id_warning, wae_flag=True)
        treat_this_warning_as_error(id_warning)


        `treat_this_warning_as_error(unsigned int id_warning, bool wae_flag=true)`  

        Makes the warning with id *id_warning* (ignored or not, displayed or not) raise
        an exception.  

        Parameters
        ----------
        * `id_warning` :  
            Number of the warning.  
        * `wae_flag` :  
            Whether to raise an exception when the warning is raised (*true*), or just
            display it and go on with execution (*false*).  

        """
        return _probt_python3.plError_treat_this_warning_as_error(id_warning, wae_flag)

    treat_this_warning_as_error = staticmethod(treat_this_warning_as_error)

    def warn(*args) -> "void":
        """
        warn(error_id)
        warn(error_id, additional_info)


        `warn(unsigned int error_id)`  
        `warn(unsigned int error_id, const std::string &additional_info)`  

        Overloaded function
        -------------------
        * `warn(unsigned int error_id)`  

            Prints a ProBT warning.  

            Normally, this is not fatal. However, warnings can be made fatal globally by
            calling  

                plError::abort_in_warning(true);  

            Parameters:  
            * `error_id` :  
                Number of the warning to raise.  

        * `warn(unsigned int error_id, const std::string &additional_info)`  

            Prints a ProBT warning with additional information.  

            Normally, this is not fatal. However, *warnings* can be made fatal globally
            by calling  

                plError::abort_in_warning(true);  

            Parameters:  
            * `error_id` :  
                Number of the warning to raise.  
            * `additional_info` :  
                Additional information that details the warning.  

        """
        return _probt_python3.plError_warn(*args)

    warn = staticmethod(warn)

    def get_main_message(self) -> "std::string":
        """
        get_main_message(self) -> std::string


        `get_main_message() const -> std::string`  

        Get a human-readable description of the error.  

        """
        return _probt_python3.plError_get_main_message(self)


    def get_additional_info(self) -> "std::string const &":
        """
        get_additional_info(self) -> std::string const &


        `get_additional_info() const -> const std::string &`  

        Get a human-readable description of error's context.  

        """
        return _probt_python3.plError_get_additional_info(self)


    def set_output_stream() -> "std::ostream *":
        """
        set_output_stream()


        `set_output_stream(std::ostream *outstream)`  

        Changes the output stream in which errors and warings are displayed.  

        The default one is std::cerr.  

        """
        return _probt_python3.plError_set_output_stream()

    set_output_stream = staticmethod(set_output_stream)
plError_swigregister = _probt_python3.plError_swigregister
plError_swigregister(plError)

def plError_always_display(display_flag: 'bool') -> "void":
    """
    plError_always_display(display_flag)


    `always_display(bool display_flag)`  

    Set the global display flag for errors.  

    When *true*, all errors will be displayed as soon as they are created. When
    *false*, they will not be displayed. In all cases, errors are C++ exceptions:
    you may catch them using *try* and *catch*, and inspect them using what() and
    get_error_number().  

    Parameters
    ----------
    * `display_flag` :  
        New value of the global display flag.  

    """
    return _probt_python3.plError_always_display(display_flag)

def plError_ignore_this_message(id_message: 'unsigned int', ignoring_state: 'bool') -> "void":
    """
    plError_ignore_this_message(id_message, ignoring_state)


    `ignore_this_message(unsigned int id_message, bool ignoring_state)`  

    Inhibits the display of a warning or error, given its number.  

    This is useful if you are sure that a given warning is not pertinent in your
    particular setting. This function has no effect if the given message number is
    invalid.  

    Parameters
    ----------
    * `id_message` :  
        Number of the warning or error to ignore.  
    * `ignoring_state` :  
        Whether to ignore the message (*true*), or display it (*false*).  

    """
    return _probt_python3.plError_ignore_this_message(id_message, ignoring_state)

def plError_message_is_ignored(id_message: 'unsigned int') -> "bool":
    """
    plError_message_is_ignored(id_message) -> bool


    `message_is_ignored(unsigned int id_message) -> bool`  

    Tells whether a warning or error is currently ignored.  

    This will return *true* unless a warning/error is specifically ignored ; calls
    to always_display_warning() and always_display() have no influence on the return
    of this function. This function returns *false* if the given message number is
    invalid.  

    Parameters
    ----------
    * `id_message` :  
        Number of the warning or error.  

    Returns
    -------
    *true* if and only if the warning is currently ignored.  

    """
    return _probt_python3.plError_message_is_ignored(id_message)

def plError_always_display_warning(display_flag: 'bool') -> "void":
    """
    plError_always_display_warning(display_flag)


    `always_display_warning(bool display_flag)`  

    Inhibits the display of all warnings.  

    Parameters
    ----------
    * `display_flag` :  
        Whether to hide all warnings (*false*) or display all those that are not
        ignored (*true*).  

    """
    return _probt_python3.plError_always_display_warning(display_flag)

def plError_treat_warnings_as_errors(wie_flag: 'bool'=True) -> "void":
    """
    treat_warnings_as_errors(wie_flag=True)
    plError_treat_warnings_as_errors()


    `treat_warnings_as_errors(bool wie_flag=true)`  

    Makes all warnings (ignored or not, displayed or not) raise an exception.  

    Parameters
    ----------
    * `wie_flag` :  
        Whether to raise an exception when the warning is raised (*true*), or just
        display it and go on with execution (*false*).  

    """
    return _probt_python3.plError_treat_warnings_as_errors(wie_flag)

def plError_treat_this_warning_as_error(id_warning: 'unsigned int', wae_flag: 'bool'=True) -> "void":
    """
    treat_this_warning_as_error(id_warning, wae_flag=True)
    plError_treat_this_warning_as_error(id_warning)


    `treat_this_warning_as_error(unsigned int id_warning, bool wae_flag=true)`  

    Makes the warning with id *id_warning* (ignored or not, displayed or not) raise
    an exception.  

    Parameters
    ----------
    * `id_warning` :  
        Number of the warning.  
    * `wae_flag` :  
        Whether to raise an exception when the warning is raised (*true*), or just
        display it and go on with execution (*false*).  

    """
    return _probt_python3.plError_treat_this_warning_as_error(id_warning, wae_flag)

def plError_warn(*args) -> "void":
    """
    warn(error_id)
    plError_warn(error_id, additional_info)


    `warn(unsigned int error_id)`  
    `warn(unsigned int error_id, const std::string &additional_info)`  

    Overloaded function
    -------------------
    * `warn(unsigned int error_id)`  

        Prints a ProBT warning.  

        Normally, this is not fatal. However, warnings can be made fatal globally by
        calling  

            plError::abort_in_warning(true);  

        Parameters:  
        * `error_id` :  
            Number of the warning to raise.  

    * `warn(unsigned int error_id, const std::string &additional_info)`  

        Prints a ProBT warning with additional information.  

        Normally, this is not fatal. However, *warnings* can be made fatal globally
        by calling  

            plError::abort_in_warning(true);  

        Parameters:  
        * `error_id` :  
            Number of the warning to raise.  
        * `additional_info` :  
            Additional information that details the warning.  

    """
    return _probt_python3.plError_warn(*args)

def plError_set_output_stream() -> "std::ostream *":
    """
    plError_set_output_stream()


    `set_output_stream(std::ostream *outstream)`  

    Changes the output stream in which errors and warings are displayed.  

    The default one is std::cerr.  

    """
    return _probt_python3.plError_set_output_stream()

class plIgnoreMessage(_object):
    """

    `plIgnoreMessage(unsigned int id)`  

    Constructors
    ------------
    * `plIgnoreMessage(unsigned int id)`  

    """

    __swig_setmethods__ = {}
    __setattr__ = lambda self, name, value: _swig_setattr(self, plIgnoreMessage, name, value)
    __swig_getmethods__ = {}
    __getattr__ = lambda self, name: _swig_getattr(self, plIgnoreMessage, name)
    __repr__ = _swig_repr

    def __init__(self, id: 'unsigned int'):
        """
        __init__(self, id) -> plIgnoreMessage


        `plIgnoreMessage(unsigned int id)`  

        """
        this = _probt_python3.new_plIgnoreMessage(id)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this
    __swig_destroy__ = _probt_python3.delete_plIgnoreMessage
    __del__ = lambda self: None
plIgnoreMessage_swigregister = _probt_python3.plIgnoreMessage_swigregister
plIgnoreMessage_swigregister(plIgnoreMessage)


def get_most_derived(obj: 'plObject') -> "PyObject *":
    """get_most_derived(obj) -> PyObject *"""
    return _probt_python3.get_most_derived(obj)

def plRandomInt(max: 'unsigned int') -> "unsigned int":
    """
    plRandomInt(max) -> unsigned int


    `plRandomInt(unsigned int max) -> PL_DLL_API unsigned int`  

    Draw uniformly an integer random value in the range [0,max-1].  

    """
    return _probt_python3.plRandomInt(max)

def plRandomFloat(max: 'plFloat') -> "plFloat":
    """
    plRandomFloat(max) -> plFloat


    `plRandomFloat(plFloat max) -> PL_DLL_API plFloat`  

    Draw uniformly a floating number random value in the range [0,max[.  

    """
    return _probt_python3.plRandomFloat(max)

def plSRandom(seed: 'int') -> "void":
    """
    plSRandom(seed)


    `plSRandom(int seed) -> PL_DLL_API void`  

    Seed the random generator.  

    """
    return _probt_python3.plSRandom(seed)

def plNormalRandom(*args) -> "plFloat":
    """
    plNormalRandom(m, sd) -> plFloat
    plNormalRandom(m, sd, a, b) -> plFloat


    `plNormalRandom(plFloat m, plFloat sd) -> PL_DLL_API plFloat`  
    `plNormalRandom(plFloat m, plFloat sd, plFloat a, plFloat b) -> plFloat`  

    Overloaded function
    -------------------
    * `plNormalRandom(plFloat m, plFloat sd) -> PL_DLL_API plFloat`  

        Draw a floating number random value normally distributed widh a *m* as mean
        and *sd* as standard deviation.  

    * `plNormalRandom(plFloat m, plFloat sd, plFloat a, plFloat b) -> plFloat`  

        Draw a floating number random value normally distributed widh a *m* as mean
        and *sd* as standard deviation in the range [a,b[.  

    """
    return _probt_python3.plNormalRandom(*args)

def plNormalRandomUsingInvPhi(m: 'plFloat', sd: 'plFloat', two_inta_minus_half: 'plFloat', two_intb_minus_half: 'plFloat') -> "plFloat":
    """
    plNormalRandomUsingInvPhi(m, sd, two_inta_minus_half, two_intb_minus_half) -> plFloat


    `plNormalRandomUsingInvPhi(plFloat m, plFloat sd, plFloat two_inta_minus_half,
        plFloat two_intb_minus_half) -> plFloat`  

    """
    return _probt_python3.plNormalRandomUsingInvPhi(m, sd, two_inta_minus_half, two_intb_minus_half)
class plRandom(_object):
    """


    Basic random number generation utility functions.  

    C++ includes: plRandom.h

    """

    __swig_setmethods__ = {}
    __setattr__ = lambda self, name, value: _swig_setattr(self, plRandom, name, value)
    __swig_getmethods__ = {}
    __getattr__ = lambda self, name: _swig_getattr(self, plRandom, name)
    __repr__ = _swig_repr

    def seed(seed_value: 'int') -> "void":
        """
        seed(seed_value)


        `seed(int seed_value)`  

        Seed the random generator.  

        """
        return _probt_python3.plRandom_seed(seed_value)

    seed = staticmethod(seed)

    def uniform_integer(max: 'unsigned int') -> "unsigned int":
        """
        uniform_integer(max) -> unsigned int


        `uniform_integer(unsigned int max) -> unsigned int`  

        Draw uniformly an integer random value in the range [0,max-1].  

        It uses the MT1937 random generator.  

        """
        return _probt_python3.plRandom_uniform_integer(max)

    uniform_integer = staticmethod(uniform_integer)

    def uniform_float(max: 'plFloat') -> "plFloat":
        """
        uniform_float(max) -> plFloat


        `uniform_float(plFloat max) -> plFloat`  

        Draw uniformly a floating number random value in the range [0,max[.  

        It uses the MT1937 random generator.  

        """
        return _probt_python3.plRandom_uniform_float(max)

    uniform_float = staticmethod(uniform_float)

    def normal_float(*args) -> "plFloat":
        """
        normal_float(m, sd) -> plFloat
        normal_float(m, sd, a, b) -> plFloat


        `normal_float(plFloat m, plFloat sd) -> plFloat`  
        `normal_float(plFloat m, plFloat sd, plFloat a, plFloat b) -> plFloat`  

        Overloaded function
        -------------------
        * `normal_float(plFloat m, plFloat sd) -> plFloat`  

            Draw a floating number random value normally distributed widh *m* as mean
            and *sd* as standard deviation.  

            It uses the Box-Muller algorithm and is based on the MT1937 uniform random
            generator.  

        * `normal_float(plFloat m, plFloat sd, plFloat a, plFloat b) -> plFloat`  

            Draw a floating number random value normally distributed widh *m* as mean
            and *sd* as standard deviation in the range [a,b[.  

            It uses the Box-Muller algorithm and is based on the MT1937 uniform random
            generator.  

        """
        return _probt_python3.plRandom_normal_float(*args)

    normal_float = staticmethod(normal_float)

    def __init__(self):
        """
        __init__(self) -> plRandom



        Basic random number generation utility functions.  

        C++ includes: plRandom.h

        """
        this = _probt_python3.new_plRandom()
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this
    __swig_destroy__ = _probt_python3.delete_plRandom
    __del__ = lambda self: None
plRandom_swigregister = _probt_python3.plRandom_swigregister
plRandom_swigregister(plRandom)

def plRandom_seed(seed_value: 'int') -> "void":
    """
    plRandom_seed(seed_value)


    `seed(int seed_value)`  

    Seed the random generator.  

    """
    return _probt_python3.plRandom_seed(seed_value)

def plRandom_uniform_integer(max: 'unsigned int') -> "unsigned int":
    """
    plRandom_uniform_integer(max) -> unsigned int


    `uniform_integer(unsigned int max) -> unsigned int`  

    Draw uniformly an integer random value in the range [0,max-1].  

    It uses the MT1937 random generator.  

    """
    return _probt_python3.plRandom_uniform_integer(max)

def plRandom_uniform_float(max: 'plFloat') -> "plFloat":
    """
    plRandom_uniform_float(max) -> plFloat


    `uniform_float(plFloat max) -> plFloat`  

    Draw uniformly a floating number random value in the range [0,max[.  

    It uses the MT1937 random generator.  

    """
    return _probt_python3.plRandom_uniform_float(max)

def plRandom_normal_float(*args) -> "plFloat":
    """
    normal_float(m, sd) -> plFloat
    plRandom_normal_float(m, sd, a, b) -> plFloat


    `normal_float(plFloat m, plFloat sd) -> plFloat`  
    `normal_float(plFloat m, plFloat sd, plFloat a, plFloat b) -> plFloat`  

    Overloaded function
    -------------------
    * `normal_float(plFloat m, plFloat sd) -> plFloat`  

        Draw a floating number random value normally distributed widh *m* as mean
        and *sd* as standard deviation.  

        It uses the Box-Muller algorithm and is based on the MT1937 uniform random
        generator.  

    * `normal_float(plFloat m, plFloat sd, plFloat a, plFloat b) -> plFloat`  

        Draw a floating number random value normally distributed widh *m* as mean
        and *sd* as standard deviation in the range [a,b[.  

        It uses the Box-Muller algorithm and is based on the MT1937 uniform random
        generator.  

    """
    return _probt_python3.plRandom_normal_float(*args)

class plFloatMatrix(plObject):
    """

    `plFloatMatrix()`  
    `plFloatMatrix(size_t r, size_t c)`  
    `plFloatMatrix(size_t d)`  
    `plFloatMatrix(size_t d, const double *float_vector)`  
    `plFloatMatrix(size_t d, const float *float_vector)`  
    `plFloatMatrix(size_t d, const long double *float_vector)`  
    `plFloatMatrix(const std::vector< double > &float_vector)`  
    `plFloatMatrix(const std::vector< float > &float_vector)`  
    `plFloatMatrix(const std::vector< long double > &float_vector)`  
    `plFloatMatrix(size_t r, size_t c, const double *float_vector)`  
    `plFloatMatrix(size_t r, size_t c, const float *float_vector)`  
    `plFloatMatrix(size_t r, size_t c, const long double *float_vector)`  
    `plFloatMatrix(size_t r, size_t c, const std::vector< double > &float_vector)`  
    `plFloatMatrix(size_t r, size_t c, const std::vector< float > &float_vector)`  
    `plFloatMatrix(size_t r, size_t c, const std::vector< long double >
        &float_vector)`  
    `plFloatMatrix(const std::vector< std::vector< double > > &stl_matrix)`  
    `plFloatMatrix(const std::vector< std::vector< float > > &stl_matrix)`  
    `plFloatMatrix(const std::vector< std::vector< long double > > &stl_matrix)`  
    `plFloatMatrix(const plFloatMatrix &)`  

    A *plFloatMatrix* is an *m* x *n* matrix of elements of type *plFloat*.  

    Constructors
    ------------
    * `plFloatMatrix()`  

        Default constructor.  

    * `plFloatMatrix(size_t r, size_t c)`  

        Constructs a matrix having *r* x *c* elements.  

    * `plFloatMatrix(size_t d)`  

        Constructs a matrix having *d* x *d* elements.  

    * `plFloatMatrix(size_t d, const double *float_vector)`  

        Constructs a matrix having *d* x *d* elements and fills it using the
        *float_vector* C array of floating-point values so that *m*[i][j] =
        float_vector[i*d+j] for i, j = 0 to d-1.  

    * `plFloatMatrix(size_t d, const float *float_vector)`  

    * `plFloatMatrix(size_t d, const long double *float_vector)`  

    * `plFloatMatrix(const std::vector< double > &float_vector)`  

        Constructs a matrix having *d* x *d* elements and fills it using the
        *float_vector* STL vector of *float* values so that m[i][j] =
        float_vector[i*d+j] for i, j = 0 to d-1, where d =
        sqrt(float_vector.size()).  

    * `plFloatMatrix(const std::vector< float > &float_vector)`  

    * `plFloatMatrix(const std::vector< long double > &float_vector)`  

    * `plFloatMatrix(size_t r, size_t c, const double *float_vector)`  

        Constructs a matrix having *r* x *c* elements and fills it using the
        *float_vector* C array of floating-point values so that *m*[i][j] =
        float_vector[i*r+j] for i = 0..r-1, j = 0..c-1.  

    * `plFloatMatrix(size_t r, size_t c, const float *float_vector)`  

    * `plFloatMatrix(size_t r, size_t c, const long double *float_vector)`  

    * `plFloatMatrix(size_t r, size_t c, const std::vector< double > &float_vector)`  

        Constructs a matrix having *r* x *c* elements and fills it using the
        *float_vector* SL vector of floating-point values so that *m*[i][j] =
        float_vector[i*r+j] for i = 0..r-1, j = 0..c-1.  

    * `plFloatMatrix(size_t r, size_t c, const std::vector< float > &float_vector)`  

    * `plFloatMatrix(size_t r, size_t c, const std::vector< long double >
        &float_vector)`  

    * `plFloatMatrix(const std::vector< std::vector< double > > &stl_matrix)`  

        Conversion from an STL float matrix.  

    * `plFloatMatrix(const std::vector< std::vector< float > > &stl_matrix)`  

    * `plFloatMatrix(const std::vector< std::vector< long double > > &stl_matrix)`  

    * `plFloatMatrix(const plFloatMatrix &)`  

        Copy constructor.  

    C++ includes: plFloatMatrix.h

    """

    __swig_setmethods__ = {}
    for _s in [plObject]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plFloatMatrix, name, value)
    __swig_getmethods__ = {}
    for _s in [plObject]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plFloatMatrix, name)
    __repr__ = _swig_repr

    def __init__(self, *args):
        """
        __init__(self) -> plFloatMatrix
        __init__(self, r, c) -> plFloatMatrix
        __init__(self, d) -> plFloatMatrix
        __init__(self, d, float_vector) -> plFloatMatrix
        __init__(self, d, float_vector) -> plFloatMatrix
        __init__(self, d, float_vector) -> plFloatMatrix
        __init__(self, float_vector) -> plFloatMatrix
        __init__(self, float_vector) -> plFloatMatrix
        __init__(self, float_vector) -> plFloatMatrix
        __init__(self, r, c, float_vector) -> plFloatMatrix
        __init__(self, r, c, float_vector) -> plFloatMatrix
        __init__(self, r, c, float_vector) -> plFloatMatrix
        __init__(self, r, c, float_vector) -> plFloatMatrix
        __init__(self, r, c, float_vector) -> plFloatMatrix
        __init__(self, r, c, float_vector) -> plFloatMatrix
        __init__(self, stl_matrix) -> plFloatMatrix
        __init__(self, stl_matrix) -> plFloatMatrix
        __init__(self, stl_matrix) -> plFloatMatrix
        __init__(self, arg2) -> plFloatMatrix


        `plFloatMatrix()`  
        `plFloatMatrix(size_t r, size_t c)`  
        `plFloatMatrix(size_t d)`  
        `plFloatMatrix(size_t d, const double *float_vector)`  
        `plFloatMatrix(size_t d, const float *float_vector)`  
        `plFloatMatrix(size_t d, const long double *float_vector)`  
        `plFloatMatrix(const std::vector< double > &float_vector)`  
        `plFloatMatrix(const std::vector< float > &float_vector)`  
        `plFloatMatrix(const std::vector< long double > &float_vector)`  
        `plFloatMatrix(size_t r, size_t c, const double *float_vector)`  
        `plFloatMatrix(size_t r, size_t c, const float *float_vector)`  
        `plFloatMatrix(size_t r, size_t c, const long double *float_vector)`  
        `plFloatMatrix(size_t r, size_t c, const std::vector< double > &float_vector)`  
        `plFloatMatrix(size_t r, size_t c, const std::vector< float > &float_vector)`  
        `plFloatMatrix(size_t r, size_t c, const std::vector< long double >
            &float_vector)`  
        `plFloatMatrix(const std::vector< std::vector< double > > &stl_matrix)`  
        `plFloatMatrix(const std::vector< std::vector< float > > &stl_matrix)`  
        `plFloatMatrix(const std::vector< std::vector< long double > > &stl_matrix)`  
        `plFloatMatrix(const plFloatMatrix &)`  

        Overloaded function
        -------------------
        * `plFloatMatrix()`  

            Default constructor.  

        * `plFloatMatrix(size_t r, size_t c)`  

            Constructs a matrix having *r* x *c* elements.  

        * `plFloatMatrix(size_t d)`  

            Constructs a matrix having *d* x *d* elements.  

        * `plFloatMatrix(size_t d, const double *float_vector)`  

            Constructs a matrix having *d* x *d* elements and fills it using the
            *float_vector* C array of floating-point values so that *m*[i][j] =
            float_vector[i*d+j] for i, j = 0 to d-1.  

        * `plFloatMatrix(size_t d, const float *float_vector)`  

        * `plFloatMatrix(size_t d, const long double *float_vector)`  

        * `plFloatMatrix(const std::vector< double > &float_vector)`  

            Constructs a matrix having *d* x *d* elements and fills it using the
            *float_vector* STL vector of *float* values so that m[i][j] =
            float_vector[i*d+j] for i, j = 0 to d-1, where d =
            sqrt(float_vector.size()).  

        * `plFloatMatrix(const std::vector< float > &float_vector)`  

        * `plFloatMatrix(const std::vector< long double > &float_vector)`  

        * `plFloatMatrix(size_t r, size_t c, const double *float_vector)`  

            Constructs a matrix having *r* x *c* elements and fills it using the
            *float_vector* C array of floating-point values so that *m*[i][j] =
            float_vector[i*r+j] for i = 0..r-1, j = 0..c-1.  

        * `plFloatMatrix(size_t r, size_t c, const float *float_vector)`  

        * `plFloatMatrix(size_t r, size_t c, const long double *float_vector)`  

        * `plFloatMatrix(size_t r, size_t c, const std::vector< double > &float_vector)`  

            Constructs a matrix having *r* x *c* elements and fills it using the
            *float_vector* SL vector of floating-point values so that *m*[i][j] =
            float_vector[i*r+j] for i = 0..r-1, j = 0..c-1.  

        * `plFloatMatrix(size_t r, size_t c, const std::vector< float > &float_vector)`  

        * `plFloatMatrix(size_t r, size_t c, const std::vector< long double >
            &float_vector)`  

        * `plFloatMatrix(const std::vector< std::vector< double > > &stl_matrix)`  

            Conversion from an STL float matrix.  

        * `plFloatMatrix(const std::vector< std::vector< float > > &stl_matrix)`  

        * `plFloatMatrix(const std::vector< std::vector< long double > > &stl_matrix)`  

        * `plFloatMatrix(const plFloatMatrix &)`  

            Copy constructor.  

        """
        this = _probt_python3.new_plFloatMatrix(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def make_diagonal(self, *args) -> "void":
        """
        make_diagonal(self, diag_vector)
        make_diagonal(self, n, diag_value=1.0)
        make_diagonal(self, n)


        `make_diagonal(const plFloatVector &diag_vector)`  
        `make_diagonal(size_t n, plFloat diag_value=PL_ONE)`  

        Overloaded function
        -------------------
        * `make_diagonal(const plFloatVector &diag_vector)`  

            Constructs a diagonal square matrix having *diag_vector* as diagonal.  

            Previous content is lost.  

        * `make_diagonal(size_t n, plFloat diag_value=PL_ONE)`  

            Constructs a diagonal nxn square matrix having *diag_value* as diagonal
            value.  

            Previous content is lost.  

        """
        return _probt_python3.plFloatMatrix_make_diagonal(self, *args)


    def make_identity(self, n: 'size_t') -> "void":
        """
        make_identity(self, n)


        `make_identity(size_t n)`  

        Constructs a *n* x *n* identity matrix.  

        """
        return _probt_python3.plFloatMatrix_make_identity(self, n)


    def resize(self, *args) -> "void":
        """
        resize(self, nr, nc)
        resize(self, n)


        `resize(size_t nr, size_t nc)`  
        `resize(size_t n)`  

        Overloaded function
        -------------------
        * `resize(size_t nr, size_t nc)`  

            Sets the size of the matrix to *nr* x *nc*.  

            Note that the previous content is lost if the new size is different of the
            current one.  

        * `resize(size_t n)`  

            Sets the size of the matrix to *n* x *n*.  

            Note that the previous content is lost if the new size is different of the
            current one.  

        """
        return _probt_python3.plFloatMatrix_resize(self, *args)

    __swig_destroy__ = _probt_python3.delete_plFloatMatrix
    __del__ = lambda self: None

    def rows(self) -> "size_t":
        """
        rows(self) -> size_t


        `rows() const -> size_t`  

        Returns the number of rows.  

        """
        return _probt_python3.plFloatMatrix_rows(self)


    def cols(self) -> "size_t":
        """
        cols(self) -> size_t


        `cols() const -> size_t`  

        Returns the number of columns.  

        """
        return _probt_python3.plFloatMatrix_cols(self)


    def at(self, *args) -> "plFloat &":
        """
        at(self, r, c) -> plFloat
        at(self, r, c) -> plFloat &
        """
        return _probt_python3.plFloatMatrix_at(self, *args)


    def set_value(self, r: 'size_t const &', c: 'size_t const &', v: 'plFloat const &') -> "void":
        """
        set_value(self, r, c, v)


        `set_value(const size_t &r, const size_t &c, const plFloat &v)`  

        """
        return _probt_python3.plFloatMatrix_set_value(self, r, c, v)


    def get_value(self, r: 'size_t const &', c: 'size_t const &') -> "plFloat":
        """
        get_value(self, r, c) -> plFloat


        `get_value(const size_t &r, const size_t &c) const -> plFloat`  

        """
        return _probt_python3.plFloatMatrix_get_value(self, r, c)


    def row(self, i: 'size_t') -> "plFloatVector":
        """
        row(self, i) -> plFloatVector


        `row(size_t i) const -> plFloatVector`  

        Returns a plFloatVector containing the ith row of the matrix.  

        """
        return _probt_python3.plFloatMatrix_row(self, i)


    def column(self, j: 'size_t') -> "plFloatVector":
        """
        column(self, j) -> plFloatVector


        `column(size_t j) const -> plFloatVector`  

        Returns a plFloatVector containing the jth column of the matrix.  

        """
        return _probt_python3.plFloatMatrix_column(self, j)


    def assign_from(self, other: 'plFloatMatrix') -> "plFloatMatrix &":
        """
        assign_from(self, other) -> plFloatMatrix


        `assign_from(const plFloatMatrix &other) -> plFloatMatrix &`  

        Same as operator=()  

        """
        return _probt_python3.plFloatMatrix_assign_from(self, other)


    def __add__(self, arg2: 'plFloatMatrix') -> "plFloatMatrix":
        """__add__(self, arg2) -> plFloatMatrix"""
        return _probt_python3.plFloatMatrix___add__(self, arg2)


    def add(self, other: 'plFloatMatrix') -> "plFloatMatrix":
        """
        add(self, other) -> plFloatMatrix


        `add(const plFloatMatrix &other) const -> plFloatMatrix`  

        Addition.  

        """
        return _probt_python3.plFloatMatrix_add(self, other)


    def __iadd__(self, arg2: 'plFloatMatrix') -> "plFloatMatrix &":
        """__iadd__(self, arg2) -> plFloatMatrix"""
        return _probt_python3.plFloatMatrix___iadd__(self, arg2)


    def add_in_place(self, other: 'plFloatMatrix') -> "plFloatMatrix &":
        """
        add_in_place(self, other) -> plFloatMatrix


        `add_in_place(const plFloatMatrix &other) -> plFloatMatrix &`  

        In-place addition.  

        """
        return _probt_python3.plFloatMatrix_add_in_place(self, other)


    def __sub__(self, arg2: 'plFloatMatrix') -> "plFloatMatrix":
        """__sub__(self, arg2) -> plFloatMatrix"""
        return _probt_python3.plFloatMatrix___sub__(self, arg2)


    def subtract(self, other: 'plFloatMatrix') -> "plFloatMatrix":
        """
        subtract(self, other) -> plFloatMatrix


        `subtract(const plFloatMatrix &other) const -> plFloatMatrix`  

        Subtraction.  

        """
        return _probt_python3.plFloatMatrix_subtract(self, other)


    def __isub__(self, arg2: 'plFloatMatrix') -> "plFloatMatrix &":
        """__isub__(self, arg2) -> plFloatMatrix"""
        return _probt_python3.plFloatMatrix___isub__(self, arg2)


    def subtract_in_place(self, other: 'plFloatMatrix') -> "plFloatMatrix &":
        """
        subtract_in_place(self, other) -> plFloatMatrix


        `subtract_in_place(const plFloatMatrix &other) -> plFloatMatrix &`  

        In-place subtraction operator.  

        """
        return _probt_python3.plFloatMatrix_subtract_in_place(self, other)


    def __mul__(self, *args) -> "plFloatVector":
        """
        __mul__(self, arg2) -> plFloatMatrix
        __mul__(self, arg2) -> plFloatVector
        """
        return _probt_python3.plFloatMatrix___mul__(self, *args)


    def __eq__(self, arg2: 'plFloatMatrix') -> "bool":
        """__eq__(self, arg2) -> bool"""
        return _probt_python3.plFloatMatrix___eq__(self, arg2)


    def __ne__(self, other: 'plFloatMatrix') -> "bool":
        """__ne__(self, other) -> bool"""
        return _probt_python3.plFloatMatrix___ne__(self, other)


    def equal(self, other: 'plFloatMatrix') -> "bool":
        """
        equal(self, other) -> bool


        `equal(const plFloatMatrix &other) const -> bool`  

        Equality test.  

        """
        return _probt_python3.plFloatMatrix_equal(self, other)


    def transpose(self, *args) -> "void":
        """
        transpose(self) -> plFloatMatrix
        transpose(self, result)


        `transpose() const -> plFloatMatrix`  
        `transpose(plFloatMatrix &result) const`  

        Overloaded function
        -------------------
        * `transpose() const -> plFloatMatrix`  

            Returns the transpose of the matrix.  

        * `transpose(plFloatMatrix &result) const`  

            Returns the transpose of the matrix in the *result* matrix.  

        """
        return _probt_python3.plFloatMatrix_transpose(self, *args)


    def trace(self) -> "plFloat":
        """
        trace(self) -> plFloat


        `trace() const -> plFloat`  

        Returns the trace of the matrix (sum of the diagonal values)  

        """
        return _probt_python3.plFloatMatrix_trace(self)


    def sum(self) -> "plFloat":
        """
        sum(self) -> plFloat


        `sum() const -> plFloat`  

        Return the sum of all elements.  

        """
        return _probt_python3.plFloatMatrix_sum(self)


    def inverse_using_greville(self, *args) -> "plFloatMatrix":
        """
        inverse_using_greville(self, inverse, threshold) -> unsigned int
        inverse_using_greville(self, threshold) -> plFloatMatrix


        `inverse_using_greville(plFloatMatrix &inverse, plFloat threshold) const ->
            unsigned int`  
        `inverse_using_greville(plFloat threshold) const -> plFloatMatrix`  

        Overloaded function
        -------------------
        * `inverse_using_greville(plFloatMatrix &inverse, plFloat threshold) const ->
            unsigned int`  

            Inverses the matrix if inversible and returns the pseudoinverse if the
            matrix is not inversible.  

            Parameters:  
            * `inverse` :  
                The resulting inverse or pseudoinverse matrix  
            * `threshold` :  
                The threshold to be used by the *Greville's* algorithm.  

            Returns:
            the rank of the matrix.  

            The pseudoinverse allows computing a 'best fit' (least squares) solution to
            a system of linear equations that lacks a unique solution (over-determined
            systems: nrows > ncolmns). Another use is to find the minimum (Euclidean)
            norm solution to a system of linear equations with multiple solutions
            (under-determined systems: nrows < ncolmns).  

        * `inverse_using_greville(plFloat threshold) const -> plFloatMatrix`  

            Inverses the matrix if inversible and returns the pseudoinverse if the
            matrix is not inversible.  

            Parameters:  
            * `threshold` :  
                The threshold to be used by the *Greville's* algorithm.  

            Returns:
            The resulting inverse or pseudoinverse matrix  

            The pseudoinverse allows computing a 'best fit' (least squares) solution to
            a system of linear equations that lacks a unique solution (over-determined
            systems: nrows > ncolmns). Another use is to find the minimum (Euclidean)
            norm solution to a system of linear equations with multiple solutions
            (under-determined systems: nrows < ncolmns).  

        """
        return _probt_python3.plFloatMatrix_inverse_using_greville(self, *args)


    def inverse_using_eigen_decomposition(self, *args) -> "plFloat":
        """
        inverse_using_eigen_decomposition(self, inverse) -> plFloat
        inverse_using_eigen_decomposition(self) -> plFloatMatrix
        inverse_using_eigen_decomposition(self, inverse, mat_n_n_tmp1, mat_n_n_tmp2, vect_n_tmp) -> plFloat


        `inverse_using_eigen_decomposition(plFloatMatrix &inverse) const -> plFloat`  
        `inverse_using_eigen_decomposition() const -> plFloatMatrix`  
        `inverse_using_eigen_decomposition(plFloatMatrix &inverse, plFloatMatrix
            &mat_n_n_tmp1, plFloatMatrix &mat_n_n_tmp2, plFloatVector &vect_n_tmp) const
            -> plFloat`  

        Overloaded function
        -------------------
        * `inverse_using_eigen_decomposition(plFloatMatrix &inverse) const -> plFloat`  

            Inverses the matrix and returns the result in the *inverse* matrix using
            eigen decomposition.  

            ATTENTION: The algorithm is ONLY valid for symmetric positive definite
            matrices (such as variance/covariance matrices)  

            Returns:
            the determinant of this matrix  

        * `inverse_using_eigen_decomposition() const -> plFloatMatrix`  

            Inverses the matrix using eigen decomposition.  

            ATTENTION: The algorithm is ONLY valid for symmetric positive definite
            matrices (such as variance/covariance matrices)  

            Returns:
            The resulting inverse matrix  

        * `inverse_using_eigen_decomposition(plFloatMatrix &inverse, plFloatMatrix
            &mat_n_n_tmp1, plFloatMatrix &mat_n_n_tmp2, plFloatVector &vect_n_tmp) const
            -> plFloat`  

            Inverses the matrix and returns the result in the *inverse* matrix using
            eigen decomposition.  

            This version allows avoiding internal allocations : parameters mat_n_n_tmp1,
            mat_n_n_tmp2, and vect_n_tmp buffers will be used internally.  

            ATTENTION: The algorithm is ONLY valid for symmetric positive definite
            matrices (such as variance/covariance matrices)  

            Returns:
            the determinant of this matrix  

        """
        return _probt_python3.plFloatMatrix_inverse_using_eigen_decomposition(self, *args)


    def compute_eigen_decomposition(self, Eigen_Matrix: 'plFloatMatrix', Eigen_Vector: 'plFloatVector') -> "void":
        """
        compute_eigen_decomposition(self, Eigen_Matrix, Eigen_Vector)


        `compute_eigen_decomposition(plFloatMatrix &Eigen_Matrix, plFloatVector
            &Eigen_Vector) const`  

        Compute the eigen-decomposition the matrix and returns:  
        .  

        *   Eigen vectors in the result matrix *Eigen_Matrix*  
        *   Eigen values in the result vector *Eigen_Vector*  
            ATTENTION: The algorithm used for eigen-decomposition is ONLY valid for
            symmetric positive definite matrices (such as variance/covariance matrices)  

        """
        return _probt_python3.plFloatMatrix_compute_eigen_decomposition(self, Eigen_Matrix, Eigen_Vector)


    def cholesky_decomposition(self, *args) -> "plFloatMatrix":
        """
        cholesky_decomposition(self, L)
        cholesky_decomposition(self) -> plFloatMatrix


        `cholesky_decomposition(plFloatMatrix &L) const`  
        `cholesky_decomposition() const -> plFloatMatrix`  

        Overloaded function
        -------------------
        * `cholesky_decomposition(plFloatMatrix &L) const`  

            Compute Cholesky decomposition.  

        * `cholesky_decomposition() const -> plFloatMatrix`  

            Compute Cholesky decomposition.  

        """
        return _probt_python3.plFloatMatrix_cholesky_decomposition(self, *args)


    def reset(self, val: 'plFloat'=0.) -> "void":
        """
        reset(self, val=0.)
        reset(self)


        `reset(plFloat val=0.)`  

        Resets the matrix to val.  

        """
        return _probt_python3.plFloatMatrix_reset(self, val)


    def is_empty(self) -> "bool":
        """
        is_empty(self) -> bool


        `is_empty() const -> bool`  

        Return *true* iff it contains zero elements.  

        """
        return _probt_python3.plFloatMatrix_is_empty(self)


    def multiply_with_transpose(self, other: 'plFloatMatrix', result: 'plFloatMatrix') -> "void":
        """
        multiply_with_transpose(self, other, result)


        `multiply_with_transpose(const plFloatMatrix &other, plFloatMatrix &result)
            const`  

        Multiply this matrix with the transpose of 'other' and stores the result in
        'result'.  

        """
        return _probt_python3.plFloatMatrix_multiply_with_transpose(self, other, result)


    def multiply_with_transpose_symmetric(self, other: 'plFloatMatrix', result: 'plFloatMatrix') -> "void":
        """
        multiply_with_transpose_symmetric(self, other, result)


        `multiply_with_transpose_symmetric(const plFloatMatrix &other, plFloatMatrix
            &result) const`  

        Multiply this matrix with the transpose of 'other' and stores the result in
        'result' when the result is known to be symmetric.  

        """
        return _probt_python3.plFloatMatrix_multiply_with_transpose_symmetric(self, other, result)


    def multiply(self, *args) -> "void":
        """
        multiply(self, other, result)
        multiply(self, vect, result)


        `multiply(const plFloatMatrix &other, plFloatMatrix &result) const`  
        `multiply(const plFloatVector &vect, plFloatVector &result) const`  

        Overloaded function
        -------------------
        * `multiply(const plFloatMatrix &other, plFloatMatrix &result) const`  

            Multiply this matrix with the 'other' one and stores the result in 'result'.  

        * `multiply(const plFloatVector &vect, plFloatVector &result) const`  

            Multiply this matrix with a vector and stores the result in 'result'.  

        """
        return _probt_python3.plFloatMatrix_multiply(self, *args)


    def multiply_transpose_with(self, *args) -> "void":
        """
        multiply_transpose_with(self, other, result)
        multiply_transpose_with(self, vect, result)


        `multiply_transpose_with(const plFloatMatrix &other, plFloatMatrix &result)
            const`  
        `multiply_transpose_with(const plFloatVector &vect, plFloatVector &result)
            const`  

        Overloaded function
        -------------------
        * `multiply_transpose_with(const plFloatMatrix &other, plFloatMatrix &result)
            const`  

            Multiply the transpose of this matrix with 'other' and stores the result in
            'result'.  

        * `multiply_transpose_with(const plFloatVector &vect, plFloatVector &result)
            const`  

            Multiply the transpose of this matrix with a vector and stores the result in
            'result'.  

        """
        return _probt_python3.plFloatMatrix_multiply_transpose_with(self, *args)


    def diagonal(n: 'size_t', val: 'plFloat'=1.0) -> "plFloatMatrix":
        """
        diagonal(n, val=1.0) -> plFloatMatrix
        diagonal(n) -> plFloatMatrix


        `diagonal(size_t n, plFloat val=PL_ONE) -> plFloatMatrix`  

        Create a diagnonal matix.  

        """
        return _probt_python3.plFloatMatrix_diagonal(n, val)

    diagonal = staticmethod(diagonal)

    def as_html(self) -> "std::string":
        """
        as_html(self) -> std::string


        `as_html() const -> std::string`  

        Return the matrix as an html table.  

        """
        return _probt_python3.plFloatMatrix_as_html(self)


    def as_std_vector_vector(self) -> "std::vector< std::vector< plFloat,std::allocator< plFloat > >,std::allocator< std::vector< plFloat,std::allocator< plFloat > > > >":
        """
        as_std_vector_vector(self) -> DoubleVectorVector


        `as_std_vector_vector() const -> std::vector< std::vector< plFloat > >`  

        Return the matrix as std::vector<std::vector<double> >  

        """
        return _probt_python3.plFloatMatrix_as_std_vector_vector(self)


    def add_column_to(self, c: 'size_t', v: 'plFloatVector', f: 'plFloat'=1.0) -> "void":
        """
        add_column_to(self, c, v, f=1.0)
        add_column_to(self, c, v)


        `add_column_to(size_t c, plFloatVector &v, plFloat f=PL_ONE) const`  

        Add f*column(c) to the vector v.  

        Assumes v.size() == this->rows() and c < this->cols()  

        """
        return _probt_python3.plFloatMatrix_add_column_to(self, c, v, f)


    def set(self, r: 'unsigned int', c: 'unsigned int', value: 'plFloat') -> "void":
        """set(self, r, c, value)"""
        return _probt_python3.plFloatMatrix_set(self, r, c, value)


    def __getitem__(self, indices: 'PyObject *') -> "plFloat":
        """__getitem__(self, indices) -> plFloat"""
        return _probt_python3.plFloatMatrix___getitem__(self, indices)


    def __setitem__(self, indices: 'PyObject *', value: 'plFloat') -> "void *":
        """__setitem__(self, indices, value) -> void *"""
        return _probt_python3.plFloatMatrix___setitem__(self, indices, value)


    def __rmul__(self, *args) -> "plFloatMatrix":
        """
        __rmul__(self, f) -> plFloatMatrix
        __rmul__(self, f) -> plFloatMatrix
        """
        return _probt_python3.plFloatMatrix___rmul__(self, *args)


    def __getstate__(self) -> "std::string":
        """__getstate__(self) -> std::string"""
        return _probt_python3.plFloatMatrix___getstate__(self)


    def __setstate_internal(self, sState: 'std::string const &') -> "void":
        """__setstate_internal(self, sState)"""
        return _probt_python3.plFloatMatrix___setstate_internal(self, sState)


    def __setstate__(self, sState):
        self.__init__()
        self.__setstate_internal(sState)

plFloatMatrix_swigregister = _probt_python3.plFloatMatrix_swigregister
plFloatMatrix_swigregister(plFloatMatrix)

def plFloatMatrix_diagonal(n: 'size_t', val: 'plFloat'=1.0) -> "plFloatMatrix":
    """
    diagonal(n, val=1.0) -> plFloatMatrix
    plFloatMatrix_diagonal(n) -> plFloatMatrix


    `diagonal(size_t n, plFloat val=PL_ONE) -> plFloatMatrix`  

    Create a diagnonal matix.  

    """
    return _probt_python3.plFloatMatrix_diagonal(n, val)


def relative_difference(real: 'plFloatMatrix', estim: 'plFloatMatrix') -> "plFloatMatrix":
    """relative_difference(real, estim) -> plFloatMatrix"""
    return _probt_python3.relative_difference(real, estim)

try:
  import numpy;

  def plFloatMatrix_to_numpy( mat ):
    """
    Converts a plFloatMatrix to numpy 2D array 
    """
    npmat = numpy.zeros( (mat.rows(), mat.cols()) )
    for i in range(mat.rows()):
      for j in range(mat.cols()):
        npmat[i][j] = mat.at(i, j)
    return npmat

  plFloatMatrix.to_numpy = plFloatMatrix_to_numpy;


  def numpy_to_plFloatMatrix( a ):
    """
    Converts a numpy 2D array to plFloatMatrix
    """
    if type(a) != numpy.ndarray:
      raise TypeError(" Array is not of type numpy !")

    if a.ndim != 2:
      raise TypeError( "Array is not a 2D array ! ")

    v = plFloatMatrix( a.shape[0], a.shape[1]) 
    for i in range(a.shape[0]):
      for j in range(a.shape[1]):
        v.set( i, j, a[i][j] )
    return v

except ImportError:
  pass


class plFloatVector(plObject):
    """

    `plFloatVector()`  
    `plFloatVector(size_t r, double val)`  
    `plFloatVector(size_t r, float val)`  
    `plFloatVector(size_t r, long double val)`  
    `plFloatVector(size_t r)`  
    `plFloatVector(size_t r, const double *float_vector)`  
    `plFloatVector(size_t r, const float *float_vector)`  
    `plFloatVector(size_t r, const long double *float_vector)`  
    `plFloatVector(const std::vector< double > &float_vector)`  
    `plFloatVector(const std::vector< float > &float_vector)`  
    `plFloatVector(const std::vector< long double > &float_vector)`  
    `plFloatVector(const plDataValues &values)`  
    `plFloatVector(const plFloatVector &v2)`  

    A *plFloatVector* is a vector of *n* elements of type *plFloat*.  

    Constructors
    ------------
    * `plFloatVector()`  

        Default void constructor.  

    * `plFloatVector(size_t r, double val)`  

        Constructs a vector having *r* elements initialized to *val*.  

    * `plFloatVector(size_t r, float val)`  

        Constructs a vector having *r* elements initialized to *val*.  

    * `plFloatVector(size_t r, long double val)`  

        Constructs a vector having *r* elements initialized to *val*.  

    * `plFloatVector(size_t r)`  

        Constructs a vector having *r* elements.  

    * `plFloatVector(size_t r, const double *float_vector)`  

        Constructs a vector having *r* elements and fills it using the
        *float_vector* C array of values.  

    * `plFloatVector(size_t r, const float *float_vector)`  

    * `plFloatVector(size_t r, const long double *float_vector)`  

    * `plFloatVector(const std::vector< double > &float_vector)`  

        Constructs a vector and fills it using the *float_vector* STL vector of
        values.  

    * `plFloatVector(const std::vector< float > &float_vector)`  

    * `plFloatVector(const std::vector< long double > &float_vector)`  

    * `plFloatVector(const plDataValues &values)`  

        Constructs a vector and fills it using the data values.  

    * `plFloatVector(const plFloatVector &v2)`  

        Copy constructor.  

    C++ includes: plFloatVector.h

    """

    __swig_setmethods__ = {}
    for _s in [plObject]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plFloatVector, name, value)
    __swig_getmethods__ = {}
    for _s in [plObject]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plFloatVector, name)
    __repr__ = _swig_repr

    def size(self) -> "size_t":
        """
        size(self) -> size_t


        `size() const -> size_t`  

        Returns vector's size.  

        """
        return _probt_python3.plFloatVector_size(self)


    def __init__(self, *args):
        """
        __init__(self) -> plFloatVector
        __init__(self, r, val) -> plFloatVector
        __init__(self, r, val) -> plFloatVector
        __init__(self, r, val) -> plFloatVector
        __init__(self, r) -> plFloatVector
        __init__(self, r, float_vector) -> plFloatVector
        __init__(self, r, float_vector) -> plFloatVector
        __init__(self, r, float_vector) -> plFloatVector
        __init__(self, float_vector) -> plFloatVector
        __init__(self, float_vector) -> plFloatVector
        __init__(self, float_vector) -> plFloatVector
        __init__(self, values) -> plFloatVector
        __init__(self, v2) -> plFloatVector


        `plFloatVector()`  
        `plFloatVector(size_t r, double val)`  
        `plFloatVector(size_t r, float val)`  
        `plFloatVector(size_t r, long double val)`  
        `plFloatVector(size_t r)`  
        `plFloatVector(size_t r, const double *float_vector)`  
        `plFloatVector(size_t r, const float *float_vector)`  
        `plFloatVector(size_t r, const long double *float_vector)`  
        `plFloatVector(const std::vector< double > &float_vector)`  
        `plFloatVector(const std::vector< float > &float_vector)`  
        `plFloatVector(const std::vector< long double > &float_vector)`  
        `plFloatVector(const plDataValues &values)`  
        `plFloatVector(const plFloatVector &v2)`  

        Overloaded function
        -------------------
        * `plFloatVector()`  

            Default void constructor.  

        * `plFloatVector(size_t r, double val)`  

            Constructs a vector having *r* elements initialized to *val*.  

        * `plFloatVector(size_t r, float val)`  

            Constructs a vector having *r* elements initialized to *val*.  

        * `plFloatVector(size_t r, long double val)`  

            Constructs a vector having *r* elements initialized to *val*.  

        * `plFloatVector(size_t r)`  

            Constructs a vector having *r* elements.  

        * `plFloatVector(size_t r, const double *float_vector)`  

            Constructs a vector having *r* elements and fills it using the
            *float_vector* C array of values.  

        * `plFloatVector(size_t r, const float *float_vector)`  

        * `plFloatVector(size_t r, const long double *float_vector)`  

        * `plFloatVector(const std::vector< double > &float_vector)`  

            Constructs a vector and fills it using the *float_vector* STL vector of
            values.  

        * `plFloatVector(const std::vector< float > &float_vector)`  

        * `plFloatVector(const std::vector< long double > &float_vector)`  

        * `plFloatVector(const plDataValues &values)`  

            Constructs a vector and fills it using the data values.  

        * `plFloatVector(const plFloatVector &v2)`  

            Copy constructor.  

        """
        this = _probt_python3.new_plFloatVector(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this
    __swig_destroy__ = _probt_python3.delete_plFloatVector
    __del__ = lambda self: None

    def resize(self, r: 'size_t') -> "void":
        """
        resize(self, r)


        `resize(size_t r)`  

        Sets the size of the vector to *r*.  

        Note that the previous content is lost.  

        """
        return _probt_python3.plFloatVector_resize(self, r)


    def assign_from(self, other: 'plFloatVector') -> "plFloatVector &":
        """
        assign_from(self, other) -> plFloatVector


        `assign_from(const plFloatVector &other) -> plFloatVector &`  

        Same as operator=()  

        """
        return _probt_python3.plFloatVector_assign_from(self, other)


    def __add__(self, arg2: 'plFloatVector') -> "plFloatVector":
        """__add__(self, arg2) -> plFloatVector"""
        return _probt_python3.plFloatVector___add__(self, arg2)


    def add(self, other: 'plFloatVector') -> "plFloatVector":
        """
        add(self, other) -> plFloatVector


        `add(const plFloatVector &other) const -> plFloatVector`  

        Addition.  

        """
        return _probt_python3.plFloatVector_add(self, other)


    def __iadd__(self, arg2: 'plFloatVector') -> "plFloatVector &":
        """__iadd__(self, arg2) -> plFloatVector"""
        return _probt_python3.plFloatVector___iadd__(self, arg2)


    def add_in_place(self, other: 'plFloatVector') -> "plFloatVector &":
        """
        add_in_place(self, other) -> plFloatVector


        `add_in_place(const plFloatVector &other) -> plFloatVector &`  

        In-place Addition.  

        """
        return _probt_python3.plFloatVector_add_in_place(self, other)


    def __sub__(self, arg2: 'plFloatVector') -> "plFloatVector":
        """__sub__(self, arg2) -> plFloatVector"""
        return _probt_python3.plFloatVector___sub__(self, arg2)


    def subtract(self, other: 'plFloatVector') -> "plFloatVector":
        """
        subtract(self, other) -> plFloatVector


        `subtract(const plFloatVector &other) const -> plFloatVector`  

        Subtraction.  

        """
        return _probt_python3.plFloatVector_subtract(self, other)


    def __isub__(self, arg2: 'plFloatVector') -> "plFloatVector &":
        """__isub__(self, arg2) -> plFloatVector"""
        return _probt_python3.plFloatVector___isub__(self, arg2)


    def subtract_in_place(self, other: 'plFloatVector') -> "plFloatVector &":
        """
        subtract_in_place(self, other) -> plFloatVector


        `subtract_in_place(const plFloatVector &other) -> plFloatVector &`  

        In-place subtraction.  

        """
        return _probt_python3.plFloatVector_subtract_in_place(self, other)


    def __mul__(self, f: 'plFloat') -> "plFloatVector":
        """__mul__(self, f) -> plFloatVector"""
        return _probt_python3.plFloatVector___mul__(self, f)


    def multiply(self, f: 'plFloat') -> "plFloatVector":
        """
        multiply(self, f) -> plFloatVector


        `multiply(plFloat f) const -> plFloatVector`  

        Multiplication with a scalar.  

        """
        return _probt_python3.plFloatVector_multiply(self, f)


    def __imul__(self, f: 'plFloat') -> "plFloatVector &":
        """__imul__(self, f) -> plFloatVector"""
        return _probt_python3.plFloatVector___imul__(self, f)


    def multiply_in_place(self, f: 'plFloat') -> "plFloatVector &":
        """
        multiply_in_place(self, f) -> plFloatVector


        `multiply_in_place(plFloat f) -> plFloatVector &`  

        In-place multiplication with a scalar.  

        """
        return _probt_python3.plFloatVector_multiply_in_place(self, f)


    def __truediv__(self, *args):
        return _probt_python3.plFloatVector___truediv__(self, *args)
    __div__ = __truediv__



    def divide(self, f: 'plFloat') -> "plFloatVector":
        """
        divide(self, f) -> plFloatVector


        `divide(plFloat f) const -> plFloatVector`  

        Division with a scalar.  

        """
        return _probt_python3.plFloatVector_divide(self, f)


    def __itruediv__(self, *args):
        return _probt_python3.plFloatVector___itruediv__(self, *args)
    __idiv__ = __itruediv__



    def divide_in_place(self, f: 'plFloat') -> "plFloatVector &":
        """
        divide_in_place(self, f) -> plFloatVector


        `divide_in_place(plFloat f) -> plFloatVector &`  

        In-place division with a scalar.  

        """
        return _probt_python3.plFloatVector_divide_in_place(self, f)


    def at(self, *args) -> "plFloat &":
        """
        at(self, i) -> plFloat const
        at(self, i) -> plFloat &


        `at(size_t i) const -> const plFloat &`  
        `at(size_t i) -> plFloat &`  

        Overloaded function
        -------------------
        * `at(size_t i) const -> const plFloat &`  

            Return the ith element.  

            Raises an exception unless 0 <= i < size().  

        * `at(size_t i) -> plFloat &`  

            Return a reference to the ith element.  

            Raises an exception unless 0 <= i < size().  

        """
        return _probt_python3.plFloatVector_at(self, *args)


    def set_value(self, i: 'size_t const &', val: 'plFloat const &') -> "void":
        """
        set_value(self, i, val)


        `set_value(const size_t &i, const plFloat &val)`  

        Sets the value at position i.  

        """
        return _probt_python3.plFloatVector_set_value(self, i, val)


    def get_value(self, i: 'size_t') -> "plFloat":
        """
        get_value(self, i) -> plFloat


        `get_value(size_t i) const -> plFloat`  

        Returns the ith element if *i* is less than vector's size.  

        Generates an error otherwise  

        """
        return _probt_python3.plFloatVector_get_value(self, i)


    def __eq__(self, arg2: 'plFloatVector') -> "bool":
        """__eq__(self, arg2) -> bool"""
        return _probt_python3.plFloatVector___eq__(self, arg2)


    def __ne__(self, other: 'plFloatVector') -> "bool":
        """__ne__(self, other) -> bool"""
        return _probt_python3.plFloatVector___ne__(self, other)


    def equal(self, other: 'plFloatVector') -> "bool":
        """
        equal(self, other) -> bool


        `equal(const plFloatVector &other) const -> bool`  

        Equality test.  

        """
        return _probt_python3.plFloatVector_equal(self, other)


    def dot_product(self, a: 'plFloatVector') -> "plFloat":
        """
        dot_product(self, a) -> plFloat


        `dot_product(const plFloatVector &a) const -> plFloat`  

        Computes the dot (inner) product of two vectors.  

        """
        return _probt_python3.plFloatVector_dot_product(self, a)


    def cross_product(self, a: 'plFloatVector') -> "plFloatVector":
        """
        cross_product(self, a) -> plFloatVector


        `cross_product(const plFloatVector &a) const -> plFloatVector`  

        Computes the cross product of two vectors.  

        This method is only allowed for 3-dimensional vectors  

        """
        return _probt_python3.plFloatVector_cross_product(self, a)


    def normalize(self, result: 'plFloatVector') -> "plFloat":
        """
        normalize(self, result) -> plFloat


        `normalize(plFloatVector &result) const -> plFloat`  

        Normalizes the vector, stores the result in *result* vector and returns the norm
        of the vector.  

        """
        return _probt_python3.plFloatVector_normalize(self, result)


    def product(self) -> "plFloat":
        """
        product(self) -> plFloat


        `product() const -> plFloat`  

        Returns the product of all elements.  

        """
        return _probt_python3.plFloatVector_product(self)


    def reset(self, val: 'plFloat'=0.) -> "void":
        """
        reset(self, val=0.)
        reset(self)


        `reset(plFloat val=0.)`  

        Resets the vector to val (0 by default).  

        """
        return _probt_python3.plFloatVector_reset(self, val)


    def is_empty(self) -> "bool":
        """
        is_empty(self) -> bool


        `is_empty() const -> bool`  

        Return *true* iff it contains zero elements.  

        """
        return _probt_python3.plFloatVector_is_empty(self)


    def data(self) -> "std::vector< plFloat,std::allocator< plFloat > > const &":
        """
        data(self) -> DoubleVector


        `data() const -> const std::vector< plFloat > &`  

        Return a const reference to the raw data vector.  

        """
        return _probt_python3.plFloatVector_data(self)


    def outer_product(self, *args) -> "plFloatMatrix":
        """
        outer_product(self, other, result)
        outer_product(self, other) -> plFloatMatrix
        outer_product(self, result)
        outer_product(self) -> plFloatMatrix


        `outer_product(const plFloatVector &other, plFloatMatrix &result) const`  
        `outer_product(const plFloatVector &other) const -> plFloatMatrix`  
        `outer_product(plFloatMatrix &result) const`  
        `outer_product() const -> plFloatMatrix`  

        Overloaded function
        -------------------
        * `outer_product(const plFloatVector &other, plFloatMatrix &result) const`  

            Outer product.  

        * `outer_product(const plFloatVector &other) const -> plFloatMatrix`  

            Outer product.  

        * `outer_product(plFloatMatrix &result) const`  

            Outer product with self.  

        * `outer_product() const -> plFloatMatrix`  

            Outer product with self.  

        """
        return _probt_python3.plFloatVector_outer_product(self, *args)


    def plLogSum(self) -> "plFloat":
        """
        plLogSum(self) -> plFloat


        `plLogSum() const -> plFloat`  

        Robust computation of the log of a sum of a vector of exponentials.  

        Returns
        -------
        log ( Sum_i exp( this_vector[i] ) )  

        """
        return _probt_python3.plFloatVector_plLogSum(self)


    def set(self, i: 'unsigned int', value: 'plFloat') -> "void":
        """set(self, i, value)"""
        return _probt_python3.plFloatVector_set(self, i, value)


    def __setitem__(self, i: 'int', value: 'plFloat') -> "void *":
        """__setitem__(self, i, value) -> void *"""
        return _probt_python3.plFloatVector___setitem__(self, i, value)


    def __len__(self) -> "int":
        """__len__(self) -> int"""
        return _probt_python3.plFloatVector___len__(self)


    def __rmul__(self, *args) -> "plFloatVector":
        """
        __rmul__(self, f) -> plFloatVector
        __rmul__(self, f) -> plFloatVector
        """
        return _probt_python3.plFloatVector___rmul__(self, *args)


    def __getstate__(self) -> "std::string":
        """__getstate__(self) -> std::string"""
        return _probt_python3.plFloatVector___getstate__(self)


    def __setstate_internal(self, sState: 'std::string const &') -> "void":
        """__setstate_internal(self, sState)"""
        return _probt_python3.plFloatVector___setstate_internal(self, sState)


    def __setstate__(self, sState):
        self.__init__()
        self.__setstate_internal(sState)

plFloatVector_swigregister = _probt_python3.plFloatVector_swigregister
plFloatVector_swigregister(plFloatVector)


def plLogSum(logs: 'plFloatVector') -> "plFloat":
    """
    plLogSum(logs) -> plFloat


    `plLogSum(const LogType *logs, const unsigned int len) -> LogType`  
    `plLogSum(const std::vector< LogType > &logs) -> LogType`  

    Overloaded function
    -------------------
    * `plLogSum(const LogType *logs, const unsigned int len) -> LogType`  

        Robust computation of the log of a sum of a vector of exponentials.  

        It's based on the formula: \begin{eqnarray*} ln(x+y) &=& \ln(x) +
        \ln(x+y) - \ln(x) \\ &=& \ln(x) + \ln\left(\frac{x+y}{x}\right)
        \\ &=& \ln(x) + \ln\left(1 + \frac{y}{x}\right) \\ &=& \ln(x) +
        \ln\left(1 + e^{ \ln(\frac{y}{x})}\right) \\ &=& \ln(x) +
        \ln\left(1 + e^{ \ln(y) - \ln(x)}\right) \\ \end{eqnarray*}  

        For numerical stability, it's important to use this formula with $x$ larger
        than $y$. Indeed, it's important to check the size of the logarithms of the
        summands, because the numerical stability of this computation depends on
        small values of the exponential term in log(1 + exp(log(y)-log(x))). Small
        values can be ensured by always subtracting the larger argument from the
        smaller argument so that the sign of the difference of logarithms is
        negative. For example, consider the case where the summands are exp(60) and
        exp(-10). When considering decimal logarithms and exponentials for
        simplification, the logarithms of the summands are 60 and -10, and the
        logarithm of the sum can be computed either as log(exp(60)) + log(1 +
        exp(-70)), or as log(exp(-10)) + log(1 + exp(70)). In the first alternative,
        the quantity exp(-70) gets underflowed to zero, and the result is 60, which
        is as accurate as most machine precisions will allow. In the second
        alternative, exp(70) will evaluate to inf, the floating point constant used
        to represent a number to large to be represented in the machine precision,
        and the numerical value of the computation will be lost. When computing the
        logarithm of the sum of two numbers that have substantially different
        magnitudes, the exact form of the computation employed can make the
        difference between a usable result and an overflow error.  

        Parameters:  
        * `logs` :  
            an array of logarithm values  
        * `len` :  
            the length of 'logs' array  

        Returns:
        log ( Sum_i exp( logs[i] ) )  

    * `plLogSum(const std::vector< LogType > &logs) -> LogType`  

        Robust computation of the log of a sum of a vector of exponentials.  

        Parameters:  
        * `logs` :  
            a vector of logarithm values  

        Returns:
        log ( Sum_i exp( logs[i] ) )  

    """
    return _probt_python3.plLogSum(logs)

def log(*args) -> "plFloatVector":
    """
    log(arg1) -> plFloatMatrix
    log(arg1) -> plFloatVector


    `log(const plFloatMatrix &) -> PL_DLL_API plFloatMatrix`  
    `log(const plFloatVector &) -> PL_DLL_API plFloatVector`  
    `log(const plProbability &pr) -> double`  

    Overloaded function
    -------------------
    * `log(const plFloatMatrix &) -> PL_DLL_API plFloatMatrix`  

        Natural logarithm function.  

    * `log(const plFloatVector &) -> PL_DLL_API plFloatVector`  

        Natural logarithm function.  

    * `log(const plProbability &pr) -> double`  

        Natural logarithm function.  

    """
    return _probt_python3.log(*args)

def exp(*args) -> "plFloatVector":
    """
    exp(arg1) -> plFloatMatrix
    exp(arg1) -> plFloatVector


    `exp(const plFloatMatrix &) -> PL_DLL_API plFloatMatrix`  
    `exp(const plFloatVector &) -> PL_DLL_API plFloatVector`  

    Overloaded function
    -------------------
    * `exp(const plFloatMatrix &) -> PL_DLL_API plFloatMatrix`  

        Natural exponential function.  

    * `exp(const plFloatVector &) -> PL_DLL_API plFloatVector`  

        Natural exponential function.  

    """
    return _probt_python3.exp(*args)

  # The original plFloatVector.at() is not suitable since it prints the plError in addition to raising it.
def plFloatVector_getitem(self, i):
    if i < 0 or i >= self.size():
        raise IndexError(i)
    return self.at(i)

plFloatVector.__getitem__ = plFloatVector_getitem

try:

  def plFloatVector_to_numpy( vec ):
    """
    Converts a plFloatVector to a numpy 1D array 
    """
    n = numpy.zeros(vec.size())
    for i in range(vec.size()):
      n[i] = vec[i]
    return n;

  def numpy_to_plFloatVector( a ):
    """ Converts a numpy array to plFloatVector """
    if type(a) != numpy.ndarray:
      raise TypeError( "Array is not of type numpy !" )

    if a.ndim != 1:
      raise TypeError( "Array is not a one dimensional vector !")

    v = plFloatVector( a.size )
    for i in range(a.size):
      v[i] = a[i]
    return v;

  plFloatVector.to_numpy = plFloatVector_to_numpy;

except ImportError:
  pass


PL_INTEGER = _probt_python3.PL_INTEGER
PL_REAL = _probt_python3.PL_REAL
PL_CONTINUOUS_INTERVAL = _probt_python3.PL_CONTINUOUS_INTERVAL
PL_DISCRETE_INTERVAL = _probt_python3.PL_DISCRETE_INTERVAL
PL_LABEL = _probt_python3.PL_LABEL
PL_UNKNOWN_TYPE = _probt_python3.PL_UNKNOWN_TYPE
class plData(_object):
    """

    `plData()`  
    `plData(plData::plData_type type)`  
    `plData(const plData &other)`  

    Constructors
    ------------
    * `plData()`  

        Creates a void plData.  

    * `plData(plData::plData_type type)`  

        Creates a plData with a given type.  

    * `plData(const plData &other)`  

        Copy constructor.  

    Attributes
    ----------
    * `int_value_` : `long int`  

    * `float_value_` : `plFloat`  

    """

    __swig_setmethods__ = {}
    __setattr__ = lambda self, name, value: _swig_setattr(self, plData, name, value)
    __swig_getmethods__ = {}
    __getattr__ = lambda self, name: _swig_getattr(self, plData, name)
    __repr__ = _swig_repr
    kplNIL = _probt_python3.plData_kplNIL
    kplINTEGER = _probt_python3.plData_kplINTEGER
    kplFLOAT = _probt_python3.plData_kplFLOAT
    INT_INT = _probt_python3.plData_INT_INT
    INT_FLOAT = _probt_python3.plData_INT_FLOAT
    FLOAT_INT = _probt_python3.plData_FLOAT_INT
    FLOAT_FLOAT = _probt_python3.plData_FLOAT_FLOAT

    def __init__(self, *args):
        """
        __init__(self) -> plData
        __init__(self, type) -> plData
        __init__(self, other) -> plData


        `plData()`  
        `plData(plData::plData_type type)`  
        `plData(const plData &other)`  

        Overloaded function
        -------------------
        * `plData()`  

            Creates a void plData.  

        * `plData(plData::plData_type type)`  

            Creates a plData with a given type.  

        * `plData(const plData &other)`  

            Copy constructor.  

        """
        this = _probt_python3.new_plData(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this
    __swig_destroy__ = _probt_python3.delete_plData
    __del__ = lambda self: None

    def set(self, other: 'plData') -> "void":
        """
        set(self, other)


        `set(const plData &other)`  

        Sets the content to *other*.  

        This could change the internal type of this data.  

        """
        return _probt_python3.plData_set(self, other)


    def equal(self, data: 'plData') -> "bool":
        """
        equal(self, data) -> bool


        `equal(const plData &data) const -> bool`  

        "Equal to" another plData  

        """
        return _probt_python3.plData_equal(self, data)


    def not_equal(self, data: 'plData') -> "bool":
        """
        not_equal(self, data) -> bool


        `not_equal(const plData &data) const -> bool`  

        "Different from" another plData  

        """
        return _probt_python3.plData_not_equal(self, data)


    def greater(self, data: 'plData') -> "bool":
        """
        greater(self, data) -> bool


        `greater(const plData &data) const -> bool`  

        "Greater than" another plData  

        """
        return _probt_python3.plData_greater(self, data)


    def less_or_equal(self, data: 'plData') -> "bool":
        """
        less_or_equal(self, data) -> bool


        `less_or_equal(const plData &data) const -> bool`  

        "Less than or equal"  

        """
        return _probt_python3.plData_less_or_equal(self, data)


    def less(self, data: 'plData') -> "bool":
        """
        less(self, data) -> bool


        `less(const plData &data) const -> bool`  

        "Less than" another plData  

        """
        return _probt_python3.plData_less(self, data)


    def greater_or_equal(self, other: 'plData') -> "bool":
        """
        greater_or_equal(self, other) -> bool


        `greater_or_equal(const plData &other) const -> bool`  

        "Greater than or equal"  

        """
        return _probt_python3.plData_greater_or_equal(self, other)


    def __sub__(self, data: 'plData') -> "plData":
        """__sub__(self, data) -> plData"""
        return _probt_python3.plData___sub__(self, data)


    def to_double(self) -> "double":
        """to_double(self) -> double"""
        return _probt_python3.plData_to_double(self)


    def to_long_double(self) -> "long double":
        """to_long_double(self) -> long double"""
        return _probt_python3.plData_to_long_double(self)


    def __nonzero__(self):
        return _probt_python3.plData_to_bool(self)
    __bool__ = __nonzero__



    def to_int(self) -> "int":
        """to_int(self) -> int"""
        return _probt_python3.plData_to_int(self)


    def to_unsigned_int(self) -> "unsigned int":
        """to_unsigned_int(self) -> unsigned int"""
        return _probt_python3.plData_to_unsigned_int(self)


    def to_long_int(self) -> "long":
        """to_long_int(self) -> long"""
        return _probt_python3.plData_to_long_int(self)


    def to_long_unsigned_int(self) -> "unsigned long":
        """to_long_unsigned_int(self) -> unsigned long"""
        return _probt_python3.plData_to_long_unsigned_int(self)


    def input(self, arg2: 'std::istream &') -> "void":
        """
        input(self, arg2)


        `input(std::istream &in)`  

        Conversion to size_t.  

        Read the data from an input stream  

        """
        return _probt_python3.plData_input(self, arg2)


    def output(self) -> "void":
        """
        output(self)


        `output(std::ostream &out) const`  

        Write the data to an output stream.  

        """
        return _probt_python3.plData_output(self)


    def to_string(self) -> "std::string":
        """
        to_string(self) -> std::string


        `to_string() const -> std::string`  

        """
        return _probt_python3.plData_to_string(self)


    def is_label(self) -> "bool":
        """
        is_label(self) -> bool


        `is_label() const -> bool`  

        """
        return _probt_python3.plData_is_label(self)


    def get_data_type(self) -> "plData::plData_type":
        """
        get_data_type(self) -> plData::plData_type


        `get_data_type() const -> plData_type`  

        Needed by the Python bindings, but not part of the user API.  

        Please do not use.  

        """
        return _probt_python3.plData_get_data_type(self)


    def as_int(self) -> "int":
        """
        as_int(self) -> int


        `as_int() const -> int`  

        Get the value as int.  

        """
        return _probt_python3.plData_as_int(self)


    def as_double(self) -> "double":
        """
        as_double(self) -> double


        `as_double() const -> double`  

        Get the value as double.  

        """
        return _probt_python3.plData_as_double(self)


    def as_label(self) -> "std::string":
        """
        as_label(self) -> std::string


        `as_label() const -> std::string`  

        Get the value as a label string Throw an exception if the data is not of
        plLabelType.  

        """
        return _probt_python3.plData_as_label(self)


    def maybe_set_label_type(self, var: 'plVariable') -> "void":
        """
        maybe_set_label_type(self, var)


        `maybe_set_label_type(const plVariable &var)`  

        """
        return _probt_python3.plData_maybe_set_label_type(self, var)


    def set_data(self, *args) -> "plData &":
        """
        set_data(self, data) -> plData
        set_data(self, label) -> plData
        set_data(self, label) -> plData
        set_data(self, number) -> plData
        set_data(self, number) -> plData
        set_data(self, number) -> plData
        """
        return _probt_python3.plData_set_data(self, *args)


    def __add__(self, *args) -> "plData":
        """
        __add__(self, data) -> plData
        __add__(self, number) -> plData
        __add__(self, number) -> plData
        """
        return _probt_python3.plData___add__(self, *args)


    def __mul__(self, *args) -> "plData":
        """
        __mul__(self, data) -> plData
        __mul__(self, number) -> plData
        __mul__(self, number) -> plData
        """
        return _probt_python3.plData___mul__(self, *args)


    def __truediv__(self, *args):
        return _probt_python3.plData___truediv__(self, *args)
    __div__ = __truediv__



    def __mod__(self, int_number: 'int const &') -> "long":
        """__mod__(self, int_number) -> long"""
        return _probt_python3.plData___mod__(self, int_number)


    def __gt__(self, *args) -> "bool":
        """
        __gt__(self, data) -> bool
        __gt__(self, number) -> bool
        __gt__(self, number) -> bool
        """
        return _probt_python3.plData___gt__(self, *args)


    def __lt__(self, *args) -> "bool":
        """
        __lt__(self, data) -> bool
        __lt__(self, number) -> bool
        __lt__(self, number) -> bool
        """
        return _probt_python3.plData___lt__(self, *args)


    def __eq__(self, *args) -> "bool":
        """
        __eq__(self, data) -> bool
        __eq__(self, number) -> bool
        __eq__(self, number) -> bool
        """
        return _probt_python3.plData___eq__(self, *args)


    def __ne__(self, *args) -> "bool":
        """
        __ne__(self, other) -> bool
        __ne__(self, other) -> bool
        """
        return _probt_python3.plData___ne__(self, *args)


    def __le__(self, *args) -> "bool":
        """
        __le__(self, data) -> bool
        __le__(self, data) -> bool
        """
        return _probt_python3.plData___le__(self, *args)


    def __ge__(self, *args) -> "bool":
        """
        __ge__(self, other) -> bool
        __ge__(self, other) -> bool
        """
        return _probt_python3.plData___ge__(self, *args)


    def __neg__(self) -> "plData":
        """__neg__(self) -> plData"""
        return _probt_python3.plData___neg__(self)


    def __rmul__(self, *args) -> "plData":
        """
        __rmul__(self, input) -> plData
        __rmul__(self, input) -> plData
        """
        return _probt_python3.plData___rmul__(self, *args)


    def __radd__(self, *args) -> "plData":
        """
        __radd__(self, input) -> plData
        __radd__(self, input) -> plData
        """
        return _probt_python3.plData___radd__(self, *args)


    def __rdiv__(self, *args) -> "plData":
        """
        __rdiv__(self, input) -> plData
        __rdiv__(self, input) -> plData
        """
        return _probt_python3.plData___rdiv__(self, *args)


    def __rsub__(self, *args) -> "plData":
        """
        __rsub__(self, input) -> plData
        __rsub__(self, input) -> plData
        """
        return _probt_python3.plData___rsub__(self, *args)


    def __str__(self) -> "std::string":
        """__str__(self) -> std::string"""
        return _probt_python3.plData___str__(self)


    def __float__(self) -> "double":
        """__float__(self) -> double"""
        return _probt_python3.plData___float__(self)


    def __int__(self) -> "int":
        """__int__(self) -> int"""
        return _probt_python3.plData___int__(self)


    def to_float(self, *args) -> "double":
        """
        to_float(self) -> float
        to_float(self) -> double
        """
        return _probt_python3.plData_to_float(self, *args)

plData_swigregister = _probt_python3.plData_swigregister
plData_swigregister(plData)


plData.__repr__ = plData.__str__; 

class plType(plSampleSpaceObject):
    """

    `plType()`  
    `plType(const plType &other)`  

    *plType* is the base class of all ProBT types.  

    Constructors
    ------------
    * `plType()`  

        Constructor.  

    * `plType(const plType &other)`  

        Copy constructor.  

    C++ includes: plType.h

    """

    __swig_setmethods__ = {}
    for _s in [plSampleSpaceObject]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plType, name, value)
    __swig_getmethods__ = {}
    for _s in [plSampleSpaceObject]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plType, name)
    __repr__ = _swig_repr

    def __init__(self, *args):
        """
        __init__(self) -> plType
        __init__(self, other) -> plType


        `plType()`  
        `plType(const plType &other)`  

        Overloaded function
        -------------------
        * `plType()`  

            Constructor.  

        * `plType(const plType &other)`  

            Copy constructor.  

        """
        this = _probt_python3.new_plType(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this
    __swig_destroy__ = _probt_python3.delete_plType
    __del__ = lambda self: None

    def assign_from(self, other: 'plType') -> "plType &":
        """
        assign_from(self, other) -> plType


        `assign_from(const plType &other) -> plType &`  

        Same as operator=()  

        """
        return _probt_python3.plType_assign_from(self, other)


    def first_value(self) -> "plData const &":
        """
        first_value(self) -> plData


        `first_value() const -> const plData &`  

        Returns the start value of the type.  

        """
        return _probt_python3.plType_first_value(self)


    def get_min(self) -> "plData const &":
        """
        get_min(self) -> plData


        `get_min() const -> const plData &`  

        Returns the minimum value of the type.  

        """
        return _probt_python3.plType_get_min(self)


    def get_max(self) -> "plData const &":
        """
        get_max(self) -> plData


        `get_max() const -> const plData &`  

        Returns the maximum value of the type.  

        """
        return _probt_python3.plType_get_max(self)


    def next_value(self, *args) -> "bool":
        """
        next_value(self, v) -> bool
        next_value(self, v) -> bool
        next_value(self) -> bool
        next_value(self, v) -> bool
        next_value(self, v) -> bool


        `next_value(plData &v) const -> bool`  
        `next_value(float &v) const -> bool`  
        `next_value(double &v) const -> bool`  
        `next_value(long double &v) const -> bool`  
        `next_value(int &v) const -> bool`  

        Overloaded function
        -------------------
        * `next_value(plData &v) const -> bool`  

            Returns *true* if *v* has a successor and sets *v* to the successor
            otherwise it return *false*.  

        * `next_value(float &v) const -> bool`  

            Returns *true* if *v* has a successor and sets *v* to the successor
            otherwise it return *false*.  

        * `next_value(double &v) const -> bool`  

            Returns *true* if *v* has a successor and sets *v* to the successor
            otherwise it return *false*.  

        * `next_value(long double &v) const -> bool`  

            Returns *true* if *v* has a successor and sets *v* to the successor
            otherwise it return *false*.  

        * `next_value(int &v) const -> bool`  

            Returns *true* if *v* has a successor and sets *v* to the successor
            otherwise it return *false*.  

        """
        return _probt_python3.plType_next_value(self, *args)


    def cardinality(self) -> "unsigned int":
        """
        cardinality(self) -> unsigned int


        `cardinality() const -> unsigned int`  

        Get the type cardinality.  

        """
        return _probt_python3.plType_cardinality(self)


    def get_var_type(self) -> "plVariableType":
        """
        get_var_type(self) -> plVariableType


        `get_var_type() const -> plVariableType`  

        Get the variable type as a value from enum {PL_INTEGER, PL_REAL,
        PL_CONTINUOUS_INTERVAL, PL_DISCRETE_INTERVAL, PL_LABEL, PL_UNKNOWN_TYPE}.  

        """
        return _probt_python3.plType_get_var_type(self)


    def value_is_valid(self, v: 'plData') -> "bool":
        """
        value_is_valid(self, v) -> bool


        `value_is_valid(const plData &v) const -> bool`  

        Return true if the value is valid for this type.  

        """
        return _probt_python3.plType_value_is_valid(self, v)


    def is_empty(self) -> "bool":
        """
        is_empty(self) -> bool


        `is_empty() const -> bool`  

        Return true if the object is default-constructed (as opposed to fully
        initialized).  

        In that case, it is invalid for the creation of plVariables.  

        """
        return _probt_python3.plType_is_empty(self)


    def get_value_from_index(self, index: 'unsigned int') -> "bool":
        """
        get_value_from_index(self, index) -> bool


        `get_value_from_index(plData &result, unsigned int index) const -> bool`  

        For discretized types, get as result the center of the interval represented by
        the given index.  

        Throws if the type is not discretized. Return false if the index is out-of-
        bounds, true otherwise.  

        """
        return _probt_python3.plType_get_value_from_index(self, index)


    def get_random_value_from_index(self, index: 'unsigned int') -> "bool":
        """
        get_random_value_from_index(self, index) -> bool


        `get_random_value_from_index(plData &result, unsigned int index) const -> bool`  

        For discretized types, draws a value from the interval represented by the given
        index.  

        Throws if the type is not discretized. Return false if the index is out-of-
        bounds, true otherwise.  

        """
        return _probt_python3.plType_get_random_value_from_index(self, index)


    def get_value_index(self, *args) -> "bool":
        """
        get_value_index(self, result, value) -> bool
        get_value_index(self, result, value) -> bool
        get_value_index(self, result, value) -> bool
        get_value_index(self, result, value) -> bool
        get_value_index(self, result, value) -> bool
        get_value_index(self, result, value) -> bool
        get_value_index(self, result, value) -> bool
        get_value_index(self, result, value) -> bool


        `get_value_index(unsigned int &result, const plData &value) const -> bool`  
        `get_value_index(unsigned int &result, const int &value) const -> bool`  
        `get_value_index(unsigned int &result, const unsigned int &value) const -> bool`  
        `get_value_index(unsigned int &result, const long int &value) const -> bool`  
        `get_value_index(unsigned int &result, const unsigned long int &value) const ->
            bool`  
        `get_value_index(unsigned int &result, const float &value) const -> bool`  
        `get_value_index(unsigned int &result, const double &value) const -> bool`  
        `get_value_index(unsigned int &result, const long double &value) const -> bool`  

        Overloaded function
        -------------------
        * `get_value_index(unsigned int &result, const plData &value) const -> bool`  

            For discretized types, get the index representing the given value.  

            Throws if the type is not discretized. Return false if the value is invalid,
            true otherwise.  

        * `get_value_index(unsigned int &result, const int &value) const -> bool`  

            For discretized types, get the index representing the given value.  

            Throws if the type is not discretized. Return false if the value is invalid,
            true otherwise.  

        * `get_value_index(unsigned int &result, const unsigned int &value) const ->
            bool`  

            For discretized types, get the index representing the given value.  

            Throws if the type is not discretized. Return false if the value is invalid,
            true otherwise.  

        * `get_value_index(unsigned int &result, const long int &value) const -> bool`  

            For discretized types, get the index representing the given value.  

            Throws if the type is not discretized. Return false if the value is invalid,
            true otherwise.  

        * `get_value_index(unsigned int &result, const unsigned long int &value) const
            -> bool`  

            For discretized types, get the index representing the given value.  

            Throws if the type is not discretized. Return false if the value is invalid,
            true otherwise.  

        * `get_value_index(unsigned int &result, const float &value) const -> bool`  

            For discretized types, get the index representing the given value.  

            Throws if the type is not discretized. Return false if the value is invalid,
            true otherwise.  

        * `get_value_index(unsigned int &result, const double &value) const -> bool`  

            For discretized types, get the index representing the given value.  

            Throws if the type is not discretized. Return false if the value is invalid,
            true otherwise.  

        * `get_value_index(unsigned int &result, const long double &value) const ->
            bool`  

            For discretized types, get the index representing the given value.  

            Throws if the type is not discretized. Return false if the value is invalid,
            true otherwise.  

        """
        return _probt_python3.plType_get_value_index(self, *args)


    def get_values_as_strings(self) -> "std::vector< std::string,std::allocator< std::string > >":
        """
        get_values_as_strings(self) -> StringVector


        `get_values_as_strings() const -> std::vector< std::string >`  

        Get the values of the type as strings.  

        """
        return _probt_python3.plType_get_values_as_strings(self)


    def __eq__(self, other: 'plType') -> "bool":
        """__eq__(self, other) -> bool"""
        return _probt_python3.plType___eq__(self, other)


    def equal(self, other: 'plType') -> "bool":
        """
        equal(self, other) -> bool


        `equal(const plType &other) const -> bool`  

        Equality.  

        """
        return _probt_python3.plType_equal(self, other)


    def __ne__(self, other: 'plType') -> "bool":
        """__ne__(self, other) -> bool"""
        return _probt_python3.plType___ne__(self, other)


    def not_equal(self, other: 'plType') -> "bool":
        """
        not_equal(self, other) -> bool


        `not_equal(const plType &other) const -> bool`  

        Inequality.  

        """
        return _probt_python3.plType_not_equal(self, other)

plType_swigregister = _probt_python3.plType_swigregister
plType_swigregister(plType)

class plDiscreteType(plType):
    """

    `plDiscreteType()`  
    `plDiscreteType(const plType &other)`  

    *plDiscreteType* is the base class of all ProBT discrete types.  

    Constructors
    ------------
    * `plDiscreteType()`  

        Default constructor.  

    * `plDiscreteType(const plType &other)`  

        Promote from a plType.  

        This makes sense because all the information is actually in parent class
        plType. If the object being copied is actually of the wrong type, an
        exception is raised.  

    C++ includes: plType.h

    """

    __swig_setmethods__ = {}
    for _s in [plType]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plDiscreteType, name, value)
    __swig_getmethods__ = {}
    for _s in [plType]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plDiscreteType, name)
    __repr__ = _swig_repr

    def __init__(self, *args):
        """
        __init__(self) -> plDiscreteType
        __init__(self, other) -> plDiscreteType


        `plDiscreteType()`  
        `plDiscreteType(const plType &other)`  

        Overloaded function
        -------------------
        * `plDiscreteType()`  

            Default constructor.  

        * `plDiscreteType(const plType &other)`  

            Promote from a plType.  

            This makes sense because all the information is actually in parent class
            plType. If the object being copied is actually of the wrong type, an
            exception is raised.  

        """
        this = _probt_python3.new_plDiscreteType(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this
    __swig_destroy__ = _probt_python3.delete_plDiscreteType
    __del__ = lambda self: None
plDiscreteType_swigregister = _probt_python3.plDiscreteType_swigregister
plDiscreteType_swigregister(plDiscreteType)

class plContinuousType(plType):
    """

    `plContinuousType()`  
    `plContinuousType(const plType &other)`  

    *plContinuousType* is the base class of all ProBT continuous types.  

    Constructors
    ------------
    * `plContinuousType()`  

        Default constructor.  

    * `plContinuousType(const plType &other)`  

        Promote from a plType.  

        This makes sense because all the information is actually in parent class
        plType. If the object being copied is actually of the wrong type, an
        exception is raised.  

    C++ includes: plType.h

    """

    __swig_setmethods__ = {}
    for _s in [plType]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plContinuousType, name, value)
    __swig_getmethods__ = {}
    for _s in [plType]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plContinuousType, name)
    __repr__ = _swig_repr

    def __init__(self, *args):
        """
        __init__(self) -> plContinuousType
        __init__(self, other) -> plContinuousType


        `plContinuousType()`  
        `plContinuousType(const plType &other)`  

        Overloaded function
        -------------------
        * `plContinuousType()`  

            Default constructor.  

        * `plContinuousType(const plType &other)`  

            Promote from a plType.  

            This makes sense because all the information is actually in parent class
            plType. If the object being copied is actually of the wrong type, an
            exception is raised.  

        """
        this = _probt_python3.new_plContinuousType(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this
    __swig_destroy__ = _probt_python3.delete_plContinuousType
    __del__ = lambda self: None
plContinuousType_swigregister = _probt_python3.plContinuousType_swigregister
plContinuousType_swigregister(plContinuousType)



def plType_iter( s  ):
  val = s.first_value()
  yield val

  while s.next_value( val ):
    yield val

plType.iterator = plType_iter


class plLabelType(plDiscreteType):
    """

    `plLabelType()`  
    `plLabelType(const std::vector< std::string > &vals)`  
    `plLabelType(const plType &)`  

    The *plLabelType* class is used to create label types taking there values in a
    set of textual labels.  

    e.g. {"TRUE", "FALSE"}, {"BLUE", "RED", "YELLOW"}  

    Constructors
    ------------
    * `plLabelType()`  

        Default constructor.  

    * `plLabelType(const std::vector< std::string > &vals)`  

        Creates a label type taking its values in the set *vals*.  

    * `plLabelType(const plType &)`  

        Promote from a plType.  

        This makes sense because all the information is actually in parent class
        plType. If the object being copied is actually of the wrong type, an
        exception is raised.  

    C++ includes: plLabelType.h

    """

    __swig_setmethods__ = {}
    for _s in [plDiscreteType]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plLabelType, name, value)
    __swig_getmethods__ = {}
    for _s in [plDiscreteType]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plLabelType, name)
    __repr__ = _swig_repr

    def add_label(self, label: 'std::string const &') -> "void":
        """
        add_label(self, label)


        `add_label(const std::string &label)`  

        Insert a new label.  

        """
        return _probt_python3.plLabelType_add_label(self, label)

    __swig_destroy__ = _probt_python3.delete_plLabelType
    __del__ = lambda self: None

    def __init__(self, *args):
        """
        __init__(self) -> plLabelType
        __init__(self, vals) -> plLabelType
        __init__(self, arg2) -> plLabelType


        `plLabelType()`  
        `plLabelType(const std::vector< std::string > &vals)`  
        `plLabelType(const plType &)`  

        Overloaded function
        -------------------
        * `plLabelType()`  

            Default constructor.  

        * `plLabelType(const std::vector< std::string > &vals)`  

            Creates a label type taking its values in the set *vals*.  

        * `plLabelType(const plType &)`  

            Promote from a plType.  

            This makes sense because all the information is actually in parent class
            plType. If the object being copied is actually of the wrong type, an
            exception is raised.  

        """
        this = _probt_python3.new_plLabelType(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def get_values(self) -> "std::vector< std::string,std::allocator< std::string > > const &":
        """
        get_values(self) -> StringVector


        `get_values() const -> const std::vector< std::string > &`  

        Get the set of values.  

        """
        return _probt_python3.plLabelType_get_values(self)


    def get_label_max_size(self) -> "size_t":
        """
        get_label_max_size(self) -> size_t


        `get_label_max_size() const -> size_t`  

        Get the max size of the allowed labels.  

        """
        return _probt_python3.plLabelType_get_label_max_size(self)


    def label_to_index(self, label: 'std::string const &') -> "unsigned int":
        """
        label_to_index(self, label) -> unsigned int


        `label_to_index(const std::string &label) const -> unsigned int`  

        Get the index corresponding to a given label if exists.  

        Throws an exception otherwise.  

        """
        return _probt_python3.plLabelType_label_to_index(self, label)


    def __getstate__(self) -> "std::string":
        """__getstate__(self) -> std::string"""
        return _probt_python3.plLabelType___getstate__(self)


    def __setstate_internal(self, sState: 'std::string const &') -> "void":
        """__setstate_internal(self, sState)"""
        return _probt_python3.plLabelType___setstate_internal(self, sState)


    def __setstate__(self, sState):
        self.__init__()
        self.__setstate_internal(sState)

plLabelType_swigregister = _probt_python3.plLabelType_swigregister
plLabelType_swigregister(plLabelType)

class plRealType(plContinuousType):
    """

    `plRealType()`  
    `plRealType(plFloat min, plFloat max, unsigned int n_intervals)`  
    `plRealType(plFloat min, plFloat max)`  
    `plRealType(const plType &)`  

    The *plRealType* is used to create real types with a particular interval
    **[min,max[.  

    Constructors
    ------------
    * `plRealType()`  

        Default constructor, needed by the serialization code.  

    * `plRealType(plFloat min, plFloat max, unsigned int n_intervals)`  

        Creates a discretized real type with interval **[min,max[.  

        The interval **[min,max[ is dicretized into *n_intervals* intervals.
        Distributions containing only discretized real or integer variables can use
        tabulation methods such as *tablulate* and *compile*. ATTENTION: this is an
        obsolete constructor. Use
        plContinuousIntervalType::plContinuousIntervalType(plFloat min, plFloat max,
        unsigned int n_intervals) instead.  

    * `plRealType(plFloat min, plFloat max)`  

        Creates a non-discretized real type with interval **[min,max[.  

        No tabulation methods (e.g. *tablulate* and *compile*) are allowed for
        distributions containing non-discretized real variables.  

    * `plRealType(const plType &)`  

        Promote from a plType.  

        This makes sense because all the information is actually in parent class
        plType. If the object being copied is actually of the wrong type, an
        exception is raised.  

    C++ includes: plRealType.h

    """

    __swig_setmethods__ = {}
    for _s in [plContinuousType]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plRealType, name, value)
    __swig_getmethods__ = {}
    for _s in [plContinuousType]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plRealType, name)
    __repr__ = _swig_repr
    __swig_destroy__ = _probt_python3.delete_plRealType
    __del__ = lambda self: None

    def __init__(self, *args):
        """
        __init__(self) -> plRealType
        __init__(self, min, max, n_intervals) -> plRealType
        __init__(self, min, max) -> plRealType
        __init__(self, arg2) -> plRealType


        `plRealType()`  
        `plRealType(plFloat min, plFloat max, unsigned int n_intervals)`  
        `plRealType(plFloat min, plFloat max)`  
        `plRealType(const plType &)`  

        Overloaded function
        -------------------
        * `plRealType()`  

            Default constructor, needed by the serialization code.  

        * `plRealType(plFloat min, plFloat max, unsigned int n_intervals)`  

            Creates a discretized real type with interval **[min,max[.  

            The interval **[min,max[ is dicretized into *n_intervals* intervals.
            Distributions containing only discretized real or integer variables can use
            tabulation methods such as *tablulate* and *compile*. ATTENTION: this is an
            obsolete constructor. Use
            plContinuousIntervalType::plContinuousIntervalType(plFloat min, plFloat max,
            unsigned int n_intervals) instead.  

        * `plRealType(plFloat min, plFloat max)`  

            Creates a non-discretized real type with interval **[min,max[.  

            No tabulation methods (e.g. *tablulate* and *compile*) are allowed for
            distributions containing non-discretized real variables.  

        * `plRealType(const plType &)`  

            Promote from a plType.  

            This makes sense because all the information is actually in parent class
            plType. If the object being copied is actually of the wrong type, an
            exception is raised.  

        """
        this = _probt_python3.new_plRealType(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def __getstate__(self) -> "std::string":
        """__getstate__(self) -> std::string"""
        return _probt_python3.plRealType___getstate__(self)


    def __setstate_internal(self, sState: 'std::string const &') -> "void":
        """__setstate_internal(self, sState)"""
        return _probt_python3.plRealType___setstate_internal(self, sState)


    def __setstate__(self, sState):
        self.__init__()
        self.__setstate_internal(sState)

plRealType_swigregister = _probt_python3.plRealType_swigregister
plRealType_swigregister(plRealType)

class plContinuousIntervalType(plContinuousType):
    """

    `plContinuousIntervalType()`  
    `plContinuousIntervalType(const std::vector< double > &interval_values)`  
    `plContinuousIntervalType(const std::vector< float > &interval_values)`  
    `plContinuousIntervalType(const std::vector< long double > &interval_values)`  
    `plContinuousIntervalType(unsigned int n_plus_one, const double
        *interval_values)`  
    `plContinuousIntervalType(unsigned int n_plus_one, const float
        *interval_values)`  
    `plContinuousIntervalType(unsigned int n_plus_one, const long double
        *interval_values)`  
    `plContinuousIntervalType(plFloat min, plFloat max, unsigned int n_intervals)`  
    `plContinuousIntervalType(const plType &)`  

    This class implements continuous types defined as intervals.  

    Constructors
    ------------
    * `plContinuousIntervalType()`  

        Default constructor, needed by the serialization code.  

    * `plContinuousIntervalType(const std::vector< double > &interval_values)`  

        Constructor using the min/max values of the intervals.  

        A set of n intervals is defined using (n+1)-length interval_values as
        follows: { [interval_values(0), interval_values(1) [, [interval_values(1),
        interval_values(2) [, ..., [interval_values(n-1), interval_values(n) [ }.  

    * `plContinuousIntervalType(const std::vector< float > &interval_values)`  

    * `plContinuousIntervalType(const std::vector< long double > &interval_values)`  

    * `plContinuousIntervalType(unsigned int n_plus_one, const double
        *interval_values)`  

        Constructor using the min/max values of the intervals.  

        A set of n intervals is defined using (n+1)-length interval_values as
        follows: { [interval_values(0), interval_values(1) [, [interval_values(1),
        interval_values(2) [, ..., [interval_values(n-1), interval_values(n) [ }.  

    * `plContinuousIntervalType(unsigned int n_plus_one, const float
        *interval_values)`  

    * `plContinuousIntervalType(unsigned int n_plus_one, const long double
        *interval_values)`  

    * `plContinuousIntervalType(plFloat min, plFloat max, unsigned int n_intervals)`  

        Creates a continuous-by-interval type.  

        The interval **[min,max[ is dicretized into *n_intervals* subintervals.  

    * `plContinuousIntervalType(const plType &)`  

        Promote from a plType.  

        This makes sense because all the information is actually in parent class
        plType. If the object being copied is actually of the wrong type, an
        exception is raised.  

    C++ includes: plContinuousIntervalType.h

    """

    __swig_setmethods__ = {}
    for _s in [plContinuousType]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plContinuousIntervalType, name, value)
    __swig_getmethods__ = {}
    for _s in [plContinuousType]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plContinuousIntervalType, name)
    __repr__ = _swig_repr

    def add_interval_point(self, *args) -> "void":
        """
        add_interval_point(self, point)
        add_interval_point(self, point)
        add_interval_point(self, point)


        `add_interval_point(long double point)`  
        `add_interval_point(double point)`  
        `add_interval_point(float point)`  

        Overloaded function
        -------------------
        * `add_interval_point(long double point)`  

            Add a new internal point.  

        * `add_interval_point(double point)`  

        * `add_interval_point(float point)`  

        """
        return _probt_python3.plContinuousIntervalType_add_interval_point(self, *args)

    __swig_destroy__ = _probt_python3.delete_plContinuousIntervalType
    __del__ = lambda self: None

    def get_interval_number(self, val: 'plFloat') -> "int":
        """
        get_interval_number(self, val) -> int


        `get_interval_number(plFloat val) const -> int`  

        Returns the number (begining from zero) of the interval corresponding to the
        value 'val'.  

        Returns -1 when 'val' is greater or equal to the maximum value.  

        """
        return _probt_python3.plContinuousIntervalType_get_interval_number(self, val)


    def __init__(self, *args):
        """
        __init__(self) -> plContinuousIntervalType
        __init__(self, interval_values) -> plContinuousIntervalType
        __init__(self, interval_values) -> plContinuousIntervalType
        __init__(self, interval_values) -> plContinuousIntervalType
        __init__(self, n_plus_one, interval_values) -> plContinuousIntervalType
        __init__(self, n_plus_one, interval_values) -> plContinuousIntervalType
        __init__(self, n_plus_one, interval_values) -> plContinuousIntervalType
        __init__(self, min, max, n_intervals) -> plContinuousIntervalType
        __init__(self, arg2) -> plContinuousIntervalType


        `plContinuousIntervalType()`  
        `plContinuousIntervalType(const std::vector< double > &interval_values)`  
        `plContinuousIntervalType(const std::vector< float > &interval_values)`  
        `plContinuousIntervalType(const std::vector< long double > &interval_values)`  
        `plContinuousIntervalType(unsigned int n_plus_one, const double
            *interval_values)`  
        `plContinuousIntervalType(unsigned int n_plus_one, const float
            *interval_values)`  
        `plContinuousIntervalType(unsigned int n_plus_one, const long double
            *interval_values)`  
        `plContinuousIntervalType(plFloat min, plFloat max, unsigned int n_intervals)`  
        `plContinuousIntervalType(const plType &)`  

        Overloaded function
        -------------------
        * `plContinuousIntervalType()`  

            Default constructor, needed by the serialization code.  

        * `plContinuousIntervalType(const std::vector< double > &interval_values)`  

            Constructor using the min/max values of the intervals.  

            A set of n intervals is defined using (n+1)-length interval_values as
            follows: { [interval_values(0), interval_values(1) [, [interval_values(1),
            interval_values(2) [, ..., [interval_values(n-1), interval_values(n) [ }.  

        * `plContinuousIntervalType(const std::vector< float > &interval_values)`  

        * `plContinuousIntervalType(const std::vector< long double > &interval_values)`  

        * `plContinuousIntervalType(unsigned int n_plus_one, const double
            *interval_values)`  

            Constructor using the min/max values of the intervals.  

            A set of n intervals is defined using (n+1)-length interval_values as
            follows: { [interval_values(0), interval_values(1) [, [interval_values(1),
            interval_values(2) [, ..., [interval_values(n-1), interval_values(n) [ }.  

        * `plContinuousIntervalType(unsigned int n_plus_one, const float
            *interval_values)`  

        * `plContinuousIntervalType(unsigned int n_plus_one, const long double
            *interval_values)`  

        * `plContinuousIntervalType(plFloat min, plFloat max, unsigned int n_intervals)`  

            Creates a continuous-by-interval type.  

            The interval **[min,max[ is dicretized into *n_intervals* subintervals.  

        * `plContinuousIntervalType(const plType &)`  

            Promote from a plType.  

            This makes sense because all the information is actually in parent class
            plType. If the object being copied is actually of the wrong type, an
            exception is raised.  

        """
        this = _probt_python3.new_plContinuousIntervalType(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def get_values(self) -> "std::vector< plFloat,std::allocator< plFloat > >":
        """
        get_values(self) -> DoubleVector


        `get_values() const -> std::vector< plFloat >`  

        Get the interval boundaries.  

        """
        return _probt_python3.plContinuousIntervalType_get_values(self)


    def __getstate__(self) -> "std::string":
        """__getstate__(self) -> std::string"""
        return _probt_python3.plContinuousIntervalType___getstate__(self)


    def __setstate_internal(self, sState: 'std::string const &') -> "void":
        """__setstate_internal(self, sState)"""
        return _probt_python3.plContinuousIntervalType___setstate_internal(self, sState)


    def __setstate__(self, sState):
        self.__init__()
        self.__setstate_internal(sState)

plContinuousIntervalType_swigregister = _probt_python3.plContinuousIntervalType_swigregister
plContinuousIntervalType_swigregister(plContinuousIntervalType)

class plDiscreteIntervalType(plDiscreteType):
    """

    `plDiscreteIntervalType()`  
    `plDiscreteIntervalType(const std::vector< double > &interval_values)`  
    `plDiscreteIntervalType(const std::vector< float > &interval_values)`  
    `plDiscreteIntervalType(const std::vector< long double > &interval_values)`  
    `plDiscreteIntervalType(unsigned int n_plus_one, const double *interval_values)`  
    `plDiscreteIntervalType(unsigned int n_plus_one, const float *interval_values)`  
    `plDiscreteIntervalType(unsigned int n_plus_one, const long double
        *interval_values)`  
    `plDiscreteIntervalType(plFloat min, plFloat max, unsigned int n_intervals)`  
    `plDiscreteIntervalType(const plType &)`  

    This class implements discretized continuous types defined as intervals.  

    Calculation using this type assumes that the variable is discrete taking a
    finite set of values corresponding to the middle of the provided intervals.
    Thus, tabulation and marginalization over this variable will be exact
    (exhaustive) by using this finite set of values. If you need to assume that the
    variable is continuous by interval then consider using the type
    *plContinuousIntervalType*.  

    See also: plContinuousIntervalType  

    Constructors
    ------------
    * `plDiscreteIntervalType()`  

        Default constructor, needed by the serialization code.  

    * `plDiscreteIntervalType(const std::vector< double > &interval_values)`  

        Constructor using the min/max values of the intervals.  

        A set of n intervals is defined using (n+1)-length interval_values as
        follows: { [interval_values(0), interval_values(1) [, [interval_values(1),
        interval_values(2) [, ..., [interval_values(n-1), interval_values(n) [ }.  

    * `plDiscreteIntervalType(const std::vector< float > &interval_values)`  

    * `plDiscreteIntervalType(const std::vector< long double > &interval_values)`  

    * `plDiscreteIntervalType(unsigned int n_plus_one, const double
        *interval_values)`  

        Constructor using the min/max values of the intervals.  

        A set of n intervals is defined using (n+1)-length interval_values as
        follows: { [interval_values(0), interval_values(1) [, [interval_values(1),
        interval_values(2) [, ..., [interval_values(n-1), interval_values(n) [ }.  

    * `plDiscreteIntervalType(unsigned int n_plus_one, const float
        *interval_values)`  

    * `plDiscreteIntervalType(unsigned int n_plus_one, const long double
        *interval_values)`  

    * `plDiscreteIntervalType(plFloat min, plFloat max, unsigned int n_intervals)`  

        Creates a continuous-by-interval type.  

        The interval **[min,max[ is dicretized into *n_intervals* subintervals.  

    * `plDiscreteIntervalType(const plType &)`  

        Promote from a plType.  

        This makes sense because all the information is actually in parent class
        plType. If the object being copied is actually of the wrong type, an
        exception is raised.  

    C++ includes: plDiscreteIntervalType.h

    """

    __swig_setmethods__ = {}
    for _s in [plDiscreteType]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plDiscreteIntervalType, name, value)
    __swig_getmethods__ = {}
    for _s in [plDiscreteType]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plDiscreteIntervalType, name)
    __repr__ = _swig_repr

    def add_interval_point(self, *args) -> "void":
        """
        add_interval_point(self, point)
        add_interval_point(self, point)
        add_interval_point(self, point)


        `add_interval_point(long double point)`  
        `add_interval_point(double point)`  
        `add_interval_point(float point)`  

        Overloaded function
        -------------------
        * `add_interval_point(long double point)`  

            Add a new internal point.  

        * `add_interval_point(double point)`  

        * `add_interval_point(float point)`  

        """
        return _probt_python3.plDiscreteIntervalType_add_interval_point(self, *args)

    __swig_destroy__ = _probt_python3.delete_plDiscreteIntervalType
    __del__ = lambda self: None

    def get_interval_number(self, val: 'plFloat') -> "int":
        """
        get_interval_number(self, val) -> int


        `get_interval_number(plFloat val) const -> int`  

        Returns the number (begining from zero) of the interval corresponding to the
        value 'val'.  

        Returns -1 when 'val' is greater or equal to the maximum value.  

        """
        return _probt_python3.plDiscreteIntervalType_get_interval_number(self, val)


    def __init__(self, *args):
        """
        __init__(self) -> plDiscreteIntervalType
        __init__(self, interval_values) -> plDiscreteIntervalType
        __init__(self, interval_values) -> plDiscreteIntervalType
        __init__(self, interval_values) -> plDiscreteIntervalType
        __init__(self, n_plus_one, interval_values) -> plDiscreteIntervalType
        __init__(self, n_plus_one, interval_values) -> plDiscreteIntervalType
        __init__(self, n_plus_one, interval_values) -> plDiscreteIntervalType
        __init__(self, min, max, n_intervals) -> plDiscreteIntervalType
        __init__(self, arg2) -> plDiscreteIntervalType


        `plDiscreteIntervalType()`  
        `plDiscreteIntervalType(const std::vector< double > &interval_values)`  
        `plDiscreteIntervalType(const std::vector< float > &interval_values)`  
        `plDiscreteIntervalType(const std::vector< long double > &interval_values)`  
        `plDiscreteIntervalType(unsigned int n_plus_one, const double *interval_values)`  
        `plDiscreteIntervalType(unsigned int n_plus_one, const float *interval_values)`  
        `plDiscreteIntervalType(unsigned int n_plus_one, const long double
            *interval_values)`  
        `plDiscreteIntervalType(plFloat min, plFloat max, unsigned int n_intervals)`  
        `plDiscreteIntervalType(const plType &)`  

        Overloaded function
        -------------------
        * `plDiscreteIntervalType()`  

            Default constructor, needed by the serialization code.  

        * `plDiscreteIntervalType(const std::vector< double > &interval_values)`  

            Constructor using the min/max values of the intervals.  

            A set of n intervals is defined using (n+1)-length interval_values as
            follows: { [interval_values(0), interval_values(1) [, [interval_values(1),
            interval_values(2) [, ..., [interval_values(n-1), interval_values(n) [ }.  

        * `plDiscreteIntervalType(const std::vector< float > &interval_values)`  

        * `plDiscreteIntervalType(const std::vector< long double > &interval_values)`  

        * `plDiscreteIntervalType(unsigned int n_plus_one, const double
            *interval_values)`  

            Constructor using the min/max values of the intervals.  

            A set of n intervals is defined using (n+1)-length interval_values as
            follows: { [interval_values(0), interval_values(1) [, [interval_values(1),
            interval_values(2) [, ..., [interval_values(n-1), interval_values(n) [ }.  

        * `plDiscreteIntervalType(unsigned int n_plus_one, const float
            *interval_values)`  

        * `plDiscreteIntervalType(unsigned int n_plus_one, const long double
            *interval_values)`  

        * `plDiscreteIntervalType(plFloat min, plFloat max, unsigned int n_intervals)`  

            Creates a continuous-by-interval type.  

            The interval **[min,max[ is dicretized into *n_intervals* subintervals.  

        * `plDiscreteIntervalType(const plType &)`  

            Promote from a plType.  

            This makes sense because all the information is actually in parent class
            plType. If the object being copied is actually of the wrong type, an
            exception is raised.  

        """
        this = _probt_python3.new_plDiscreteIntervalType(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def get_values(self) -> "std::vector< plFloat,std::allocator< plFloat > >":
        """
        get_values(self) -> DoubleVector


        `get_values() const -> std::vector< plFloat >`  

        Get the interval boundaries.  

        """
        return _probt_python3.plDiscreteIntervalType_get_values(self)


    def __getstate__(self) -> "std::string":
        """__getstate__(self) -> std::string"""
        return _probt_python3.plDiscreteIntervalType___getstate__(self)


    def __setstate_internal(self, sState: 'std::string const &') -> "void":
        """__setstate_internal(self, sState)"""
        return _probt_python3.plDiscreteIntervalType___setstate_internal(self, sState)


    def __setstate__(self, sState):
        self.__init__()
        self.__setstate_internal(sState)

plDiscreteIntervalType_swigregister = _probt_python3.plDiscreteIntervalType_swigregister
plDiscreteIntervalType_swigregister(plDiscreteIntervalType)

class plIntegerType(plDiscreteType):
    """

    `plIntegerType()`  
    `plIntegerType(int min, int max)`  
    `plIntegerType(const plType &)`  

    The *plIntegerType* class is used to create integer types with particular
    interval [min,max].  

    Constructors
    ------------
    * `plIntegerType()`  

        Default constructor, needed by the serialization code.  

    * `plIntegerType(int min, int max)`  

        Creates an integer type with interval [min,max].  

    * `plIntegerType(const plType &)`  

        Promote from a plType.  

        This makes sense because all the information is actually in parent class
        plType. If the object being copied is actually of the wrong type, an
        exception is raised.  

    C++ includes: plIntegerType.h

    """

    __swig_setmethods__ = {}
    for _s in [plDiscreteType]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plIntegerType, name, value)
    __swig_getmethods__ = {}
    for _s in [plDiscreteType]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plIntegerType, name)
    __repr__ = _swig_repr
    __swig_destroy__ = _probt_python3.delete_plIntegerType
    __del__ = lambda self: None

    def __init__(self, *args):
        """
        __init__(self) -> plIntegerType
        __init__(self, min, max) -> plIntegerType
        __init__(self, arg2) -> plIntegerType


        `plIntegerType()`  
        `plIntegerType(int min, int max)`  
        `plIntegerType(const plType &)`  

        Overloaded function
        -------------------
        * `plIntegerType()`  

            Default constructor, needed by the serialization code.  

        * `plIntegerType(int min, int max)`  

            Creates an integer type with interval [min,max].  

        * `plIntegerType(const plType &)`  

            Promote from a plType.  

            This makes sense because all the information is actually in parent class
            plType. If the object being copied is actually of the wrong type, an
            exception is raised.  

        """
        this = _probt_python3.new_plIntegerType(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def __getstate__(self) -> "std::string":
        """__getstate__(self) -> std::string"""
        return _probt_python3.plIntegerType___getstate__(self)


    def __setstate_internal(self, sState: 'std::string const &') -> "void":
        """__setstate_internal(self, sState)"""
        return _probt_python3.plIntegerType___setstate_internal(self, sState)


    def __setstate__(self, sState):
        self.__init__()
        self.__setstate_internal(sState)

plIntegerType_swigregister = _probt_python3.plIntegerType_swigregister
plIntegerType_swigregister(plIntegerType)

PL_BINARY_TYPE=plIntegerType(0, 1)

class plVariablesConjunction(plSampleSpaceObject):
    """

    `plVariablesConjunction()`  
    `plVariablesConjunction(const std::vector< plVariable > &variables)`  
    `plVariablesConjunction(plVariablesConjunction::const_iterator b,
        plVariablesConjunction::const_iterator e)`  
    `plVariablesConjunction(const plVariablesConjunction &other)`  

    The *plVariablesConjunction* class implements the conjunction of a set of
    variables.  

    Constructors
    ------------
    * `plVariablesConjunction()`  

        Default constructor, creates an empty variable conjuction.  

    * `plVariablesConjunction(const std::vector< plVariable > &variables)`  

        Constructor using a set of plVariables.  

        Assumes that each plVariable is found only once.  

    * `plVariablesConjunction(plVariablesConjunction::const_iterator b,
        plVariablesConjunction::const_iterator e)`  

        Constructor using begin and end iterators.  

    * `plVariablesConjunction(const plVariablesConjunction &other)`  

        Copy constructor.  

    C++ includes: plVariablesConjunction.h

    """

    __swig_setmethods__ = {}
    for _s in [plSampleSpaceObject]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plVariablesConjunction, name, value)
    __swig_getmethods__ = {}
    for _s in [plSampleSpaceObject]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plVariablesConjunction, name)
    __repr__ = _swig_repr

    def get_variable_list(self) -> "kplVariableList const &":
        """
        get_variable_list(self) -> kplVariableList const &


        `get_variable_list() const -> const kplVariableList &`  

        """
        return _probt_python3.plVariablesConjunction_get_variable_list(self)

    __swig_destroy__ = _probt_python3.delete_plVariablesConjunction
    __del__ = lambda self: None

    def __xor__(self, variable: 'plVariablesConjunction') -> "plVariablesConjunction":
        """__xor__(self, variable) -> plVariablesConjunction"""
        return _probt_python3.plVariablesConjunction___xor__(self, variable)


    def concatenate(self, variable: 'plVariablesConjunction', warn_on_duplicated: 'bool'=True) -> "plVariablesConjunction":
        """
        concatenate(self, variable, warn_on_duplicated=True) -> plVariablesConjunction
        concatenate(self, variable) -> plVariablesConjunction


        `concatenate(const plVariablesConjunction &variable, bool
            warn_on_duplicated=true) const -> plVariablesConjunction`  

        Return the concatenation of the variable *var* (at right side of the operator)
        with the variable at left side.  

        If a variable is found twice, only the first occurrence will be kept and a
        warning 62 will be raised.  

        """
        return _probt_python3.plVariablesConjunction_concatenate(self, variable, warn_on_duplicated)


    def is_discretized(self) -> "bool":
        """
        is_discretized(self) -> bool


        `is_discretized() const -> bool`  

        Returns true if the conjunction contains only discretizable variables (ie, all
        types excluding non-discretized plRealType), false otherwise.  

        """
        return _probt_python3.plVariablesConjunction_is_discretized(self)


    def is_discrete(self) -> "bool":
        """
        is_discrete(self) -> bool


        `is_discrete() const -> bool`  

        Returns true if the conjunction contains only discrete variables, false
        otherwise.  

        """
        return _probt_python3.plVariablesConjunction_is_discrete(self)


    def is_continuous(self) -> "bool":
        """
        is_continuous(self) -> bool


        `is_continuous() const -> bool`  

        Returns true if the conjunction contains only continuous variables (ie,
        plRealType or plContinuousIntervalType), false otherwise.  

        """
        return _probt_python3.plVariablesConjunction_is_continuous(self)


    def dim(self) -> "size_t":
        """
        dim(self) -> size_t


        `dim() const -> size_t`  

        Returns the number of variables in the conjunction.  

        """
        return _probt_python3.plVariablesConjunction_dim(self)


    def size(self) -> "size_t":
        """
        size(self) -> size_t


        `size() const -> size_t`  

        Returns the number of variables in the conjunction.  

        """
        return _probt_python3.plVariablesConjunction_size(self)


    def is_empty(self) -> "bool":
        """
        is_empty(self) -> bool


        `is_empty() const -> bool`  

        Returns true if the conjunction is empty.  

        """
        return _probt_python3.plVariablesConjunction_is_empty(self)


    def get_var_type(self) -> "plVariableType":
        """
        get_var_type(self) -> plVariableType


        `get_var_type() const -> plVariableType`  

        Returns the variable's type as a 'plVariableType' value, where plVariableType is
        defined as an enum: enum {PL_INTEGER, PL_REAL, PL_CONINUOUS_INTERVAL,
        PL_DISCRETE_INTERVAL, PL_LABEL, PL_UNKNOWN_TYPE}.  

        In the case of a multi-dimensional conjunction, the type of the first variable
        is returned.  

        """
        return _probt_python3.plVariablesConjunction_get_var_type(self)


    def get_type(self) -> "plType":
        """
        get_type(self) -> plType


        `get_type() const -> plType`  

        Returns the variable's type as a 'plType' object.  

        In the case of a conjunction, the type of the first variable is returned. The
        returned object can in turn be converted into the appropriate derived class
        (plIntegerType, plRealType, plContinuousIntervalType, ...) so you can use its
        specialized methods and query its characteristics. In order to know into which
        class the object has to be converted, use the get_var_type() method.  

        """
        return _probt_python3.plVariablesConjunction_get_type(self)


    def get_types(self) -> "std::vector< plType,std::allocator< plType > >":
        """
        get_types(self) -> plTypeVector


        `get_types() const -> std::vector< plType >`  

        Returns the variable types.  

        """
        return _probt_python3.plVariablesConjunction_get_types(self)


    def name(self) -> "std::string":
        """
        name(self) -> std::string


        `name() const -> std::string`  

        Gets the variable name, given by the user.  

        In the case of a conjunction, the name of the first variable is returned.  

        """
        return _probt_python3.plVariablesConjunction_name(self)


    def get_names(self) -> "std::vector< std::string,std::allocator< std::string > >":
        """
        get_names(self) -> StringVector


        `get_names() const -> std::vector< std::string >`  

        Get the names of all the variables in the conjunction.  

        """
        return _probt_python3.plVariablesConjunction_get_names(self)


    def begin(self) -> "plVariablesConjunction::const_iterator":
        """
        begin(self) -> plVariablesConjunction::const_iterator


        `begin() const -> const_iterator`  

        Returns a const_iterator to the first variable in this conjunction.  

        """
        return _probt_python3.plVariablesConjunction_begin(self)


    def end(self) -> "plVariablesConjunction::const_iterator":
        """
        end(self) -> plVariablesConjunction::const_iterator


        `end() const -> const_iterator`  

        Returns a const_iterator pointing one item after the last variable in this
        conjunction.  

        """
        return _probt_python3.plVariablesConjunction_end(self)


    def contains(self, other: 'plVariablesConjunction') -> "bool":
        """
        contains(self, other) -> bool


        `contains(const plVariablesConjunction &other) const -> bool`  

        Tests if this conjunction is a superset of 'other'.  

        (a ^ b).contains(a) == true (a ^ b).contains(b) == true (a ^ b).contains(c) ==
        false (a ^ b ^ c).contains(a ^ b) == true (a ^ b ^ c).contains(a ^ b ^ d) ==
        false  

        """
        return _probt_python3.plVariablesConjunction_contains(self, other)


    def has_same_variables_as(self, other: 'plVariablesConjunction') -> "bool":
        """
        has_same_variables_as(self, other) -> bool


        `has_same_variables_as(const plVariablesConjunction &other) const -> bool`  

        Tests if this conjunction has the same variables as 'other'.  

        (a ^ b).has_same_variables_as(b ^ a) == true; (a ^ b).has_same_variables_as(b ^
        a ^ c) == false; (a ^ b).has_same_variables_as(b) == false;  

        """
        return _probt_python3.plVariablesConjunction_has_same_variables_as(self, other)


    def intersects(self, other: 'plVariablesConjunction') -> "bool":
        """
        intersects(self, other) -> bool


        `intersects(const plVariablesConjunction &other) const -> bool`  

        Test intersection with another conjunction.  

        """
        return _probt_python3.plVariablesConjunction_intersects(self, other)


    def get_intersection(self, other: 'plVariablesConjunction') -> "plVariablesConjunction":
        """
        get_intersection(self, other) -> plVariablesConjunction


        `get_intersection(const plVariablesConjunction &other) const ->
            plVariablesConjunction`  

        Get the intersection with another conjunction.  

        """
        return _probt_python3.plVariablesConjunction_get_intersection(self, other)


    def assign_from(self, other: 'plVariablesConjunction') -> "plVariablesConjunction &":
        """
        assign_from(self, other) -> plVariablesConjunction


        `assign_from(const plVariablesConjunction &other) -> plVariablesConjunction &`  

        Same as operator=()  

        """
        return _probt_python3.plVariablesConjunction_assign_from(self, other)


    def __init__(self, *args):
        """
        __init__(self) -> plVariablesConjunction
        __init__(self, variables) -> plVariablesConjunction
        __init__(self, b, e) -> plVariablesConjunction
        __init__(self, other) -> plVariablesConjunction


        `plVariablesConjunction()`  
        `plVariablesConjunction(const std::vector< plVariable > &variables)`  
        `plVariablesConjunction(plVariablesConjunction::const_iterator b,
            plVariablesConjunction::const_iterator e)`  
        `plVariablesConjunction(const plVariablesConjunction &other)`  

        Overloaded function
        -------------------
        * `plVariablesConjunction()`  

            Default constructor, creates an empty variable conjuction.  

        * `plVariablesConjunction(const std::vector< plVariable > &variables)`  

            Constructor using a set of plVariables.  

            Assumes that each plVariable is found only once.  

        * `plVariablesConjunction(plVariablesConjunction::const_iterator b,
            plVariablesConjunction::const_iterator e)`  

            Constructor using begin and end iterators.  

        * `plVariablesConjunction(const plVariablesConjunction &other)`  

            Copy constructor.  

        """
        this = _probt_python3.new_plVariablesConjunction(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def get_all_variables(self, variables: 'plVariableVector') -> "void":
        """
        get_all_variables(self, variables)


        `get_all_variables(std::vector< plVariable > &variables) const`  

        Convert the plVariablesConjunction into a vector of plVariable objects.  

        """
        return _probt_python3.plVariablesConjunction_get_all_variables(self, variables)


    def as_variable_vector(self) -> "std::vector< plVariable,std::allocator< plVariable > >":
        """
        as_variable_vector(self) -> plVariableVector


        `as_variable_vector() const -> std::vector< plVariable >`  

        Same as get_all_variables() but returns the vector by value.  

        """
        return _probt_python3.plVariablesConjunction_as_variable_vector(self)


    def at(self, n: 'size_t') -> "plVariable":
        """
        at(self, n) -> plVariable


        `at(size_t n) const -> plVariable`  

        Get the n^th variable of the conjunction.  

        """
        return _probt_python3.plVariablesConjunction_at(self, n)


    def __eq__(self, other: 'plVariablesConjunction') -> "bool":
        """__eq__(self, other) -> bool"""
        return _probt_python3.plVariablesConjunction___eq__(self, other)


    def equal(self, other: 'plVariablesConjunction') -> "bool":
        """
        equal(self, other) -> bool


        `equal(const plVariablesConjunction &other) const -> bool`  

        Return true if this and the other object are the same.  

        """
        return _probt_python3.plVariablesConjunction_equal(self, other)


    def __ne__(self, other: 'plVariablesConjunction') -> "bool":
        """__ne__(self, other) -> bool"""
        return _probt_python3.plVariablesConjunction___ne__(self, other)


    def not_equal(self, other: 'plVariablesConjunction') -> "bool":
        """
        not_equal(self, other) -> bool


        `not_equal(const plVariablesConjunction &other) const -> bool`  

        Return true if this and the other object are not the same.  

        """
        return _probt_python3.plVariablesConjunction_not_equal(self, other)


    def empty() -> "plVariablesConjunction const &":
        """
        empty() -> plVariablesConjunction


        `empty() -> const plVariablesConjunction &`  

        Return the empty variable conjunction.  

        """
        return _probt_python3.plVariablesConjunction_empty()

    empty = staticmethod(empty)

    def get_variable_position(self, *args) -> "int":
        """
        get_variable_position(self, variable) -> int
        get_variable_position(self, name) -> int


        `get_variable_position(const plVariable &variable) const -> int`  
        `get_variable_position(const std::string &name) const -> int`  

        Overloaded function
        -------------------
        * `get_variable_position(const plVariable &variable) const -> int`  

            Return the position of a given variable in the conjunction.  

            Return -1 if the variable is not found.  

        * `get_variable_position(const std::string &name) const -> int`  

            Return the position of a given variable in the conjunction.  

            Return -1 if the variable is not found.  

        """
        return _probt_python3.plVariablesConjunction_get_variable_position(self, *args)


    def replace_type(self, name: 'std::string const &', new_type: 'plType') -> "plVariablesConjunction":
        """
        replace_type(self, name, new_type) -> plVariablesConjunction


        `replace_type(const std::string &name, const plType &new_type) ->
            plVariablesConjunction`  

        Replace the variable with name 'name' with a new variable having the same name
        and the new provided type.  

        """
        return _probt_python3.plVariablesConjunction_replace_type(self, name, new_type)


    def __ixor__(self, var: 'plVariablesConjunction') -> "plVariablesConjunction &":
        """__ixor__(self, var) -> plVariablesConjunction"""
        return _probt_python3.plVariablesConjunction___ixor__(self, var)


    def push_back(self, var: 'plVariablesConjunction', warn_duplicated: 'bool'=True) -> "plVariablesConjunction &":
        """
        push_back(self, var, warn_duplicated=True) -> plVariablesConjunction
        push_back(self, var) -> plVariablesConjunction


        `push_back(const plVariablesConjunction &var, bool warn_duplicated=true) ->
            plVariablesConjunction &`  

        In place concatenation of the variable *var* (at right side of the operator)
        with the variable at left side.  

        If a variable is found twice, only the first occurrence will be kept and a
        warning 62 will be raised.  

        WARNING: This operator has effect only on base plVariablesConjunction objects.
        For all subclasses this operator does not have any effect (e.g. You can't use a
        plVariable at the left side of the operator).  

        """
        return _probt_python3.plVariablesConjunction_push_back(self, var, warn_duplicated)


    def remove(self, *args) -> "plVariablesConjunction &":
        """
        remove(self, variable) -> plVariablesConjunction
        remove(self, variable_name) -> plVariablesConjunction


        `remove(const plVariable &variable) -> plVariablesConjunction &`  
        `remove(const std::string &variable_name) -> plVariablesConjunction &`  

        Overloaded function
        -------------------
        * `remove(const plVariable &variable) -> plVariablesConjunction &`  

            Remove one variable from the variable conjunction and return a reference to
            the conjunction.  

        * `remove(const std::string &variable_name) -> plVariablesConjunction &`  

            Remove one variable from the variable conjunction and return a reference to
            the conjunction.  

        """
        return _probt_python3.plVariablesConjunction_remove(self, *args)


    def clear(self) -> "void":
        """
        clear(self)


        `clear()`  

        Clear the conjunction.  

        """
        return _probt_python3.plVariablesConjunction_clear(self)


    def get_variable_with_name(self, name: 'std::string const &') -> "plVariable":
        """
        get_variable_with_name(self, name) -> plVariable


        `get_variable_with_name(const std::string &name) const -> plVariable`  

        Returns the first variable having *name* as print name.  

        Raises an exception if no variable with this print name is found.  

        """
        return _probt_python3.plVariablesConjunction_get_variable_with_name(self, name)


    def get_variables_with_names(self, names: 'StringVector') -> "plVariablesConjunction":
        """
        get_variables_with_names(self, names) -> plVariablesConjunction


        `get_variables_with_names(const std::vector< std::string > &names) const ->
            plVariablesConjunction`  

        Returns the first variable having *names*.  

        The returned conjunction keeps the order of this conjunction Example: {Z, Y,
        X}.get_variables_with_name( ["X", "Y"] ) will return the {Y, X} conjunction  

        """
        return _probt_python3.plVariablesConjunction_get_variables_with_names(self, names)


    def __sub__(self, other: 'plVariablesConjunction') -> "plVariablesConjunction":
        """__sub__(self, other) -> plVariablesConjunction"""
        return _probt_python3.plVariablesConjunction___sub__(self, other)


    def subtract(self, other: 'plVariablesConjunction') -> "plVariablesConjunction":
        """
        subtract(self, other) -> plVariablesConjunction


        `subtract(const plVariablesConjunction &other) const -> plVariablesConjunction`  

        Difference.  

        """
        return _probt_python3.plVariablesConjunction_subtract(self, other)


    def sort_by_name(self) -> "plVariablesConjunction":
        """
        sort_by_name(self) -> plVariablesConjunction


        `sort_by_name() const -> plVariablesConjunction`  

        Get a sorted-by-name copy of the conjunction.  

        """
        return _probt_python3.plVariablesConjunction_sort_by_name(self)


    def get_discrete_variables(self) -> "plVariablesConjunction":
        """
        get_discrete_variables(self) -> plVariablesConjunction


        `get_discrete_variables() const -> plVariablesConjunction`  

        Get the discrete variables of the conjunction.  

        """
        return _probt_python3.plVariablesConjunction_get_discrete_variables(self)


    def __lt__(self, other: 'plVariablesConjunction') -> "bool":
        """__lt__(self, other) -> bool"""
        return _probt_python3.plVariablesConjunction___lt__(self, other)


    def less(self, other: 'plVariablesConjunction') -> "bool":
        """
        less(self, other) -> bool


        `less(const plVariablesConjunction &other) const -> bool`  

        "Less than"  

        """
        return _probt_python3.plVariablesConjunction_less(self, other)


    def discretize_and_replace(self, variables_to_replace: 'StringVector', discretization_bins: 'UnsignedIntVector', data: 'plDataDescriptor') -> "plVariablesConjunction":
        """
        discretize_and_replace(self, variables_to_replace, discretization_bins, data) -> plVariablesConjunction


        `discretize_and_replace(const std::vector< std::string > &variables_to_replace,
            const std::vector< unsigned int > &discretization_bins, plDataDescriptor
            &data) const -> plVariablesConjunction`  

        Discretize a subset of variables using plEqualFrequenciesVariableDiscretizer and
        replace them in the returned new conjunction.  

        The other variables are returned unchanged  

        """
        return _probt_python3.plVariablesConjunction_discretize_and_replace(self, variables_to_replace, discretization_bins, data)


    def create_variables(variable_names: 'StringVector', variable_is_continuous: 'BoolVector', variable_min: 'DoubleVector', variable_max: 'DoubleVector') -> "plVariablesConjunction":
        """
        create_variables(variable_names, variable_is_continuous, variable_min, variable_max) -> plVariablesConjunction


        `create_variables(const std::vector< std::string > &variable_names, const
            std::vector< bool > &variable_is_continuous, const std::vector< plFloat >
            &variable_min, const std::vector< plFloat > &variable_max) ->
            plVariablesConjunction`  

        Create a variable conjunction from variable names, types (continuous or
        integer), and min/max values.  

        Parameters
        ----------
        * `variable_names` :  
            The names of the variables  
        * `variable_is_continuous` :  
            For each variable in the list above, True if the variable is continuous,
            False otherwise  
        * `variable_min` :  
            For each variable in the list above, the min value for the range (inclusive)  
        * `variable_max` :  
            For each variable in the list above, the max value for the range (inclusive
            for discrete variables and exclusive for continuous ones)  

        """
        return _probt_python3.plVariablesConjunction_create_variables(variable_names, variable_is_continuous, variable_min, variable_max)

    create_variables = staticmethod(create_variables)

    def __getitem__(self, n: 'int') -> "plVariable":
        """__getitem__(self, n) -> plVariable"""
        return _probt_python3.plVariablesConjunction___getitem__(self, n)


    def get_cardinality(self) -> "double":
        """get_cardinality(self) -> double"""
        return _probt_python3.plVariablesConjunction_get_cardinality(self)


    def __len__(self) -> "int":
        """__len__(self) -> int"""
        return _probt_python3.plVariablesConjunction___len__(self)


    def __getstate__(self) -> "std::string":
        """__getstate__(self) -> std::string"""
        return _probt_python3.plVariablesConjunction___getstate__(self)


    def __setstate_internal(self, sState: 'std::string const &') -> "void":
        """__setstate_internal(self, sState)"""
        return _probt_python3.plVariablesConjunction___setstate_internal(self, sState)


    def __setstate__(self, sState):
        self.__init__()
        self.__setstate_internal(sState)

plVariablesConjunction_swigregister = _probt_python3.plVariablesConjunction_swigregister
plVariablesConjunction_swigregister(plVariablesConjunction)

def plVariablesConjunction_empty() -> "plVariablesConjunction const &":
    """
    plVariablesConjunction_empty() -> plVariablesConjunction


    `empty() -> const plVariablesConjunction &`  

    Return the empty variable conjunction.  

    """
    return _probt_python3.plVariablesConjunction_empty()

def plVariablesConjunction_create_variables(variable_names: 'StringVector', variable_is_continuous: 'BoolVector', variable_min: 'DoubleVector', variable_max: 'DoubleVector') -> "plVariablesConjunction":
    """
    plVariablesConjunction_create_variables(variable_names, variable_is_continuous, variable_min, variable_max) -> plVariablesConjunction


    `create_variables(const std::vector< std::string > &variable_names, const
        std::vector< bool > &variable_is_continuous, const std::vector< plFloat >
        &variable_min, const std::vector< plFloat > &variable_max) ->
        plVariablesConjunction`  

    Create a variable conjunction from variable names, types (continuous or
    integer), and min/max values.  

    Parameters
    ----------
    * `variable_names` :  
        The names of the variables  
    * `variable_is_continuous` :  
        For each variable in the list above, True if the variable is continuous,
        False otherwise  
    * `variable_min` :  
        For each variable in the list above, the min value for the range (inclusive)  
    * `variable_max` :  
        For each variable in the list above, the max value for the range (inclusive
        for discrete variables and exclusive for continuous ones)  

    """
    return _probt_python3.plVariablesConjunction_create_variables(variable_names, variable_is_continuous, variable_min, variable_max)


def plVariablesConjunction_iter(self):
  for i in range(self.dim()):
    yield self[i]

plVariablesConjunction.__iter__ = plVariablesConjunction_iter

def plVariablesConjunction_hash(self):
  return hash(tuple( [v for v in self] ))

plVariablesConjunction.__hash__ = plVariablesConjunction_hash

class plVariable(plVariablesConjunction):
    """

    `plVariable(const std::string &print_name, const plType &variable_type)`  
    `plVariable(const std::string &print_name, const plVariable &variable)`  
    `plVariable()`  
    `plVariable(const plVariablesConjunction &)`  

    A *plVariable* is a set containing one and only one unidimensional variable.  

    Constructors
    ------------
    * `plVariable(const std::string &print_name, const plType &variable_type)`  

        Constructor from a *print_name* as a *string*, selected by the user, and a
        previously defined *variable_type*.  

    * `plVariable(const std::string &print_name, const plVariable &variable)`  

        Constructor from a *print_name* as a *string*, selected by the user, and a
        previously defined *variable*.  

    * `plVariable()`  

        Default empty plVariable constructor.  

    * `plVariable(const plVariablesConjunction &)`  

        Promote from a plVariablesConjunction.  

        If the object being copied contains more than one variable, an exception is
        raised.  

    C++ includes: plVariable.h

    """

    __swig_setmethods__ = {}
    for _s in [plVariablesConjunction]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plVariable, name, value)
    __swig_getmethods__ = {}
    for _s in [plVariablesConjunction]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plVariable, name)
    __repr__ = _swig_repr
    __swig_destroy__ = _probt_python3.delete_plVariable
    __del__ = lambda self: None

    def __init__(self, *args):
        """
        __init__(self, print_name, variable_type) -> plVariable
        __init__(self, print_name, variable) -> plVariable
        __init__(self) -> plVariable
        __init__(self, arg2) -> plVariable


        `plVariable(const std::string &print_name, const plType &variable_type)`  
        `plVariable(const std::string &print_name, const plVariable &variable)`  
        `plVariable()`  
        `plVariable(const plVariablesConjunction &)`  

        Overloaded function
        -------------------
        * `plVariable(const std::string &print_name, const plType &variable_type)`  

            Constructor from a *print_name* as a *string*, selected by the user, and a
            previously defined *variable_type*.  

        * `plVariable(const std::string &print_name, const plVariable &variable)`  

            Constructor from a *print_name* as a *string*, selected by the user, and a
            previously defined *variable*.  

        * `plVariable()`  

            Default empty plVariable constructor.  

        * `plVariable(const plVariablesConjunction &)`  

            Promote from a plVariablesConjunction.  

            If the object being copied contains more than one variable, an exception is
            raised.  

        """
        this = _probt_python3.new_plVariable(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def __hash__(self) -> "int_fast64_t":
        """
        __hash__(self) -> int_fast64_t


        `id() const -> int_fast64_t`  

        Return an identifier for this variable.  

        Two copies of the same variable are guaranteed to have the same identifier. This
        value is not guaranteed to be stable accross runs or serializations.  

        """
        return _probt_python3.plVariable___hash__(self)


    def __getstate__(self) -> "std::string":
        """__getstate__(self) -> std::string"""
        return _probt_python3.plVariable___getstate__(self)


    def __setstate_internal(self, sState: 'std::string const &') -> "void":
        """__setstate_internal(self, sState)"""
        return _probt_python3.plVariable___setstate_internal(self, sState)


    def __setstate__(self, sState):
        self.__init__()
        self.__setstate_internal(sState)

plVariable_swigregister = _probt_python3.plVariable_swigregister
plVariable_swigregister(plVariable)

class plVariableCollection(plVariablesConjunction):
    """

    `plVariableCollection(const std::string &print_name, const plType
        &variable_type, int tab_dim,...)`  
    `plVariableCollection()`  
    `plVariableCollection(const plVariableCollection &array)`  

    Implements single-type multidimensional variable arrays.  

    For example, to construct a 3-dimentional array of type PL_BINARY_TYPE, with *n*
    entries for the first dimension, *m* entries for the second dimension, and *p*
    for the third one, you can write:  

        plVariableCollection my_variableCollection("3DVariableArray",
    PL_BINARY_TYPE, 3, n, m, p);  

    See also: pl1DVariableCollection  

    See also: pl2DVariableCollection  

    Constructors
    ------------
    * `plVariableCollection(const std::string &print_name, const plType
        &variable_type, int tab_dim,...)`  

        Constructs a single-type multidimensional variable array.  

        The variableCollection named *print_name* contains variables of type
        *variable_type*, has dimensions *tab_dim*. The other parameters
        *first_dimension*,... are the sizes for each dimension. Example :  

            plVariableCollection t("matrix",t1,2,3,4)
         creates a table named *matrix* with variables of type *t1* and of size (2
        dimensions) *3x4*.  

    * `plVariableCollection()`  

        Default constructor.  

    * `plVariableCollection(const plVariableCollection &array)`  

        Copy constructor.  

    C++ includes: plVariableCollection.h

    """

    __swig_setmethods__ = {}
    for _s in [plVariablesConjunction]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plVariableCollection, name, value)
    __swig_getmethods__ = {}
    for _s in [plVariablesConjunction]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plVariableCollection, name)
    __repr__ = _swig_repr

    def __init__(self, *args):
        """
        __init__(self, print_name, variable_type, tab_dim, arg5=0, arg6=0, arg7=0, arg8=0) -> plVariableCollection
        __init__(self, print_name, variable_type, tab_dim, arg5=0, arg6=0, arg7=0) -> plVariableCollection
        __init__(self, print_name, variable_type, tab_dim, arg5=0, arg6=0) -> plVariableCollection
        __init__(self, print_name, variable_type, tab_dim, arg5=0) -> plVariableCollection
        __init__(self, print_name, variable_type, tab_dim) -> plVariableCollection
        __init__(self) -> plVariableCollection
        __init__(self, array) -> plVariableCollection


        `plVariableCollection(const std::string &print_name, const plType
            &variable_type, int tab_dim,...)`  
        `plVariableCollection()`  
        `plVariableCollection(const plVariableCollection &array)`  

        Overloaded function
        -------------------
        * `plVariableCollection(const std::string &print_name, const plType
            &variable_type, int tab_dim,...)`  

            Constructs a single-type multidimensional variable array.  

            The variableCollection named *print_name* contains variables of type
            *variable_type*, has dimensions *tab_dim*. The other parameters
            *first_dimension*,... are the sizes for each dimension. Example :  

                plVariableCollection t("matrix",t1,2,3,4)
             creates a table named *matrix* with variables of type *t1* and of size (2
            dimensions) *3x4*.  

        * `plVariableCollection()`  

            Default constructor.  

        * `plVariableCollection(const plVariableCollection &array)`  

            Copy constructor.  

        """
        this = _probt_python3.new_plVariableCollection(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this
    __swig_destroy__ = _probt_python3.delete_plVariableCollection
    __del__ = lambda self: None

    def at(self, first_index: 'int', arg3: 'int'=0, arg4: 'int'=0, arg5: 'int'=0, arg6: 'int'=0) -> "plVariable":
        """
        at(self, first_index, arg3=0, arg4=0, arg5=0, arg6=0) -> plVariable
        at(self, first_index, arg3=0, arg4=0, arg5=0) -> plVariable
        at(self, first_index, arg3=0, arg4=0) -> plVariable
        at(self, first_index, arg3=0) -> plVariable
        at(self, first_index) -> plVariable
        """
        return _probt_python3.plVariableCollection_at(self, first_index, arg3, arg4, arg5, arg6)


    def name(self) -> "std::string":
        """
        name(self) -> std::string


        `name() const -> std::string`  

        Gets the array name, given by the user.  

        """
        return _probt_python3.plVariableCollection_name(self)


    def __getstate__(self) -> "std::string":
        """__getstate__(self) -> std::string"""
        return _probt_python3.plVariableCollection___getstate__(self)


    def __setstate_internal(self, sState: 'std::string const &') -> "void":
        """__setstate_internal(self, sState)"""
        return _probt_python3.plVariableCollection___setstate_internal(self, sState)


    def __setstate__(self, sState):
        self.__init__()
        self.__setstate_internal(sState)

plVariableCollection_swigregister = _probt_python3.plVariableCollection_swigregister
plVariableCollection_swigregister(plVariableCollection)

class pl1DVariableCollection(plVariableCollection):
    """

    `pl1DVariableCollection(const std::string &print_name, const plType
        &variable_type, unsigned int n)`  
    `pl1DVariableCollection()`  

    Implements single-type one-dimensional variable arrays.  

    For example, to construct a one-dimentional array of type PL_BINARY_TYPE, with
    *n* elements, you can write:  

        pl1DVariableCollection my_1d_array("1DVariableArray", PL_BINARY_TYPE, n);  

    See also: plVariableCollection  

    See also: pl2DVariableCollection  

    Constructors
    ------------
    * `pl1DVariableCollection(const std::string &print_name, const plType
        &variable_type, unsigned int n)`  

        Constructs a Variable Set.  

    * `pl1DVariableCollection()`  

        Default constructor.  

    C++ includes: plVariableCollection.h

    """

    __swig_setmethods__ = {}
    for _s in [plVariableCollection]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, pl1DVariableCollection, name, value)
    __swig_getmethods__ = {}
    for _s in [plVariableCollection]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, pl1DVariableCollection, name)
    __repr__ = _swig_repr

    def __init__(self, *args):
        """
        __init__(self, print_name, variable_type, n) -> pl1DVariableCollection
        __init__(self) -> pl1DVariableCollection


        `pl1DVariableCollection(const std::string &print_name, const plType
            &variable_type, unsigned int n)`  
        `pl1DVariableCollection()`  

        Overloaded function
        -------------------
        * `pl1DVariableCollection(const std::string &print_name, const plType
            &variable_type, unsigned int n)`  

            Constructs a Variable Set.  

        * `pl1DVariableCollection()`  

            Default constructor.  

        """
        this = _probt_python3.new_pl1DVariableCollection(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def at(self, index: 'int') -> "plVariable":
        """at(self, index) -> plVariable"""
        return _probt_python3.pl1DVariableCollection_at(self, index)


    def __getstate__(self) -> "std::string":
        """__getstate__(self) -> std::string"""
        return _probt_python3.pl1DVariableCollection___getstate__(self)


    def __setstate_internal(self, sState: 'std::string const &') -> "void":
        """__setstate_internal(self, sState)"""
        return _probt_python3.pl1DVariableCollection___setstate_internal(self, sState)


    def __setstate__(self, sState):
        self.__init__()
        self.__setstate_internal(sState)

    __swig_destroy__ = _probt_python3.delete_pl1DVariableCollection
    __del__ = lambda self: None
pl1DVariableCollection_swigregister = _probt_python3.pl1DVariableCollection_swigregister
pl1DVariableCollection_swigregister(pl1DVariableCollection)

class pl2DVariableCollection(plVariableCollection):
    """

    `pl2DVariableCollection(const std::string &print_name, const plType
        &variable_type, unsigned int n, unsigned int m)`  
    `pl2DVariableCollection()`  

    Implements single-type two-dimensional variable arrays.  

    For example, to construct *nxm* two-dimentional array (matrix) of type
    PL_BINARY_TYPE, you can write:  

        pl2DVariableCollection my_2d_array("2DVariableArray", PL_BINARY_TYPE, n,
    m);  

    See also: plVariableCollection  

    See also: pl1DVariableCollection  

    Constructors
    ------------
    * `pl2DVariableCollection(const std::string &print_name, const plType
        &variable_type, unsigned int n, unsigned int m)`  

        Constructs a Variable Set.  

    * `pl2DVariableCollection()`  

        Default constructor.  

    C++ includes: plVariableCollection.h

    """

    __swig_setmethods__ = {}
    for _s in [plVariableCollection]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, pl2DVariableCollection, name, value)
    __swig_getmethods__ = {}
    for _s in [plVariableCollection]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, pl2DVariableCollection, name)
    __repr__ = _swig_repr

    def __init__(self, *args):
        """
        __init__(self, print_name, variable_type, n, m) -> pl2DVariableCollection
        __init__(self) -> pl2DVariableCollection


        `pl2DVariableCollection(const std::string &print_name, const plType
            &variable_type, unsigned int n, unsigned int m)`  
        `pl2DVariableCollection()`  

        Overloaded function
        -------------------
        * `pl2DVariableCollection(const std::string &print_name, const plType
            &variable_type, unsigned int n, unsigned int m)`  

            Constructs a Variable Set.  

        * `pl2DVariableCollection()`  

            Default constructor.  

        """
        this = _probt_python3.new_pl2DVariableCollection(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def at(self, index1: 'int', index2: 'int') -> "plVariable":
        """
        at(self, index1, index2) -> plVariable


        `at(int index1, int index2) const -> plVariable`  

        Same as operator()(int index1, int index2)  

        """
        return _probt_python3.pl2DVariableCollection_at(self, index1, index2)


    def __getitem__(self, indices: 'PyObject *') -> "plVariable":
        """__getitem__(self, indices) -> plVariable"""
        return _probt_python3.pl2DVariableCollection___getitem__(self, indices)


    def __getstate__(self) -> "std::string":
        """__getstate__(self) -> std::string"""
        return _probt_python3.pl2DVariableCollection___getstate__(self)


    def __setstate_internal(self, sState: 'std::string const &') -> "void":
        """__setstate_internal(self, sState)"""
        return _probt_python3.pl2DVariableCollection___setstate_internal(self, sState)


    def __setstate__(self, sState):
        self.__init__()
        self.__setstate_internal(sState)

    __swig_destroy__ = _probt_python3.delete_pl2DVariableCollection
    __del__ = lambda self: None
pl2DVariableCollection_swigregister = _probt_python3.pl2DVariableCollection_swigregister
pl2DVariableCollection_swigregister(pl2DVariableCollection)

class plValues(plSampleSpaceObject):
    """

    `plValues()`  
    `plValues(const plValues &val)`  
    `plValues(const plVariablesConjunction &variables)`  
    `plValues(const kplVariableList &vars)`  
    `plValues(const kplVariableList &vars, const plDataValues &val)`  

    A plValues is an object storing the values of a set of variables.  

    Constructors
    ------------
    * `plValues()`  

        Default constructor.  

    * `plValues(const plValues &val)`  

        Copy constructor.  

    * `plValues(const plVariablesConjunction &variables)`  

        Create a plValues allowing to store the values of the variable conjunction
        *variable* and initialize its value to the first value of the conjunction.  

    * `plValues(const kplVariableList &vars)`  

    * `plValues(const kplVariableList &vars, const plDataValues &val)`  

    C++ includes: plValues.h

    """

    __swig_setmethods__ = {}
    for _s in [plSampleSpaceObject]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plValues, name, value)
    __swig_getmethods__ = {}
    for _s in [plSampleSpaceObject]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plValues, name)
    __repr__ = _swig_repr

    def __init__(self, *args):
        """
        __init__(self) -> plValues
        __init__(self, val) -> plValues
        __init__(self, variables) -> plValues
        __init__(self, vars) -> plValues
        __init__(self, vars, val) -> plValues


        `plValues()`  
        `plValues(const plValues &val)`  
        `plValues(const plVariablesConjunction &variables)`  
        `plValues(const kplVariableList &vars)`  
        `plValues(const kplVariableList &vars, const plDataValues &val)`  

        Overloaded function
        -------------------
        * `plValues()`  

            Default constructor.  

        * `plValues(const plValues &val)`  

            Copy constructor.  

        * `plValues(const plVariablesConjunction &variables)`  

            Create a plValues allowing to store the values of the variable conjunction
            *variable* and initialize its value to the first value of the conjunction.  

        * `plValues(const kplVariableList &vars)`  

        * `plValues(const kplVariableList &vars, const plDataValues &val)`  

        """
        this = _probt_python3.new_plValues(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this
    __swig_destroy__ = _probt_python3.delete_plValues
    __del__ = lambda self: None

    def is_empty(self) -> "bool":
        """
        is_empty(self) -> bool


        `is_empty() const -> bool`  

        Return true if default-constructed.  

        """
        return _probt_python3.plValues_is_empty(self)


    def is_valid(self, *args) -> "bool":
        """
        is_valid(self) -> bool
        is_valid(self, check_variable) -> bool


        `is_valid() const -> bool`  
        `is_valid(const std::vector< bool > &check_variable) const -> bool`  

        Overloaded function
        -------------------
        * `is_valid() const -> bool`  

            Return *true* iff the object is fully initialized (non-empty) or the current
            values are compatible with the types of the variable conjunction.  

        * `is_valid(const std::vector< bool > &check_variable) const -> bool`  

            Return *true* iff the object is fully initialized (non-empty) or the current
            values are compatible with the types of the variable conjunction for which
            *check_variable* is *true*.  

        """
        return _probt_python3.plValues_is_valid(self, *args)


    def size(self) -> "size_t":
        """
        size(self) -> size_t


        `size() const -> size_t`  

        Returns the number of the stored variables.  

        """
        return _probt_python3.plValues_size(self)


    def reset(self, *args) -> "void":
        """
        reset(self)
        reset(self, variables)


        `reset()`  
        `reset(const plVariablesConjunction &variables)`  

        Overloaded function
        -------------------
        * `reset()`  

            Resets all variable values to their initial values.  

        * `reset(const plVariablesConjunction &variables)`  

            Resets particular variables values to their initial values.  

        """
        return _probt_python3.plValues_reset(self, *args)


    def next(self, *args) -> "bool":
        """
        next(self) -> bool
        next(self, variable) -> bool


        `next() -> bool`  
        `next(const plVariablesConjunction &variable) -> bool`  

        Overloaded function
        -------------------
        * `next() -> bool`  

            Makes an increment iteration of all variables.  

        * `next(const plVariablesConjunction &variable) -> bool`  

            Makes an increment iteration of a set of particular variables.  

        """
        return _probt_python3.plValues_next(self, *args)


    def get_variables(self) -> "plVariablesConjunction":
        """
        get_variables(self) -> plVariablesConjunction


        `get_variables() const -> plVariablesConjunction`  

        Returns the corresponding variable conjunction.  

        """
        return _probt_python3.plValues_get_variables(self)


    def assign_from(self, other: 'plValues') -> "plValues &":
        """
        assign_from(self, other) -> plValues


        `assign_from(const plValues &other) -> plValues &`  

        Same as operator=()  

        """
        return _probt_python3.plValues_assign_from(self, other)


    def __eq__(self, v: 'plValues') -> "bool":
        """__eq__(self, v) -> bool"""
        return _probt_python3.plValues___eq__(self, v)


    def equal(self, v: 'plValues') -> "bool":
        """
        equal(self, v) -> bool


        `equal(const plValues &v) const -> bool`  

        Equality.  

        """
        return _probt_python3.plValues_equal(self, v)


    def __ne__(self, v: 'plValues') -> "bool":
        """__ne__(self, v) -> bool"""
        return _probt_python3.plValues___ne__(self, v)


    def not_equal(self, v: 'plValues') -> "bool":
        """
        not_equal(self, v) -> bool


        `not_equal(const plValues &v) const -> bool`  

        Non equality.  

        """
        return _probt_python3.plValues_not_equal(self, v)


    def __lt__(self, v: 'plValues') -> "bool":
        """__lt__(self, v) -> bool"""
        return _probt_python3.plValues___lt__(self, v)


    def less(self, v: 'plValues') -> "bool":
        """
        less(self, v) -> bool


        `less(const plValues &v) const -> bool`  

        "Less than"  

        """
        return _probt_python3.plValues_less(self, v)


    def __ge__(self, v: 'plValues') -> "bool":
        """__ge__(self, v) -> bool"""
        return _probt_python3.plValues___ge__(self, v)


    def greater_or_equal(self, v: 'plValues') -> "bool":
        """
        greater_or_equal(self, v) -> bool


        `greater_or_equal(const plValues &v) const -> bool`  

        "Greater than or equal"  

        """
        return _probt_python3.plValues_greater_or_equal(self, v)


    def __gt__(self, v: 'plValues') -> "bool":
        """__gt__(self, v) -> bool"""
        return _probt_python3.plValues___gt__(self, v)


    def greater(self, v: 'plValues') -> "bool":
        """
        greater(self, v) -> bool


        `greater(const plValues &v) const -> bool`  

        "Greater than"  

        """
        return _probt_python3.plValues_greater(self, v)


    def __le__(self, v: 'plValues') -> "bool":
        """__le__(self, v) -> bool"""
        return _probt_python3.plValues___le__(self, v)


    def less_or_equal(self, v: 'plValues') -> "bool":
        """
        less_or_equal(self, v) -> bool


        `less_or_equal(const plValues &v) const -> bool`  

        "Less than or equal"  

        """
        return _probt_python3.plValues_less_or_equal(self, v)


    def add(self, *args) -> "plValues":
        """
        add(self, variable, value) -> plValues
        add(self, variable, value) -> plValues
        add(self, variable, value) -> plValues
        add(self, variable, value) -> plValues
        add(self, variable, value) -> plValues


        `add(const plVariable &variable, const plData &value) const -> plValues`  
        `add(const plVariable &variable, const int &value) const -> plValues`  
        `add(const plVariable &variable, const unsigned int &value) const -> plValues`  
        `add(const plVariable &variable, const float &value) const -> plValues`  
        `add(const plVariable &variable, const double &value) const -> plValues`  
        `add(const plVariable &variable, const std::string &value) const -> plValues`  

        Overloaded function
        -------------------
        * `add(const plVariable &variable, const plData &value) const -> plValues`  

            Creates a new plValues object identical to this one, except that it binds a
            variable to a value.  

            The variable does not need to be already bound in the original object.  

            This is useful to build plValues objects inline. For example:  

                std::cout << question.instantiate(plValues().add(a, 42).add(b,
            66)).compile() << std::endl;


        * `add(const plVariable &variable, const int &value) const -> plValues`  

        * `add(const plVariable &variable, const unsigned int &value) const -> plValues`  

        * `add(const plVariable &variable, const float &value) const -> plValues`  

        * `add(const plVariable &variable, const double &value) const -> plValues`  

        * `add(const plVariable &variable, const std::string &value) const -> plValues`  

        """
        return _probt_python3.plValues_add(self, *args)


    def remove(self, *args) -> "plValues":
        """
        remove(self, variables) -> plValues
        remove(self, variable_name) -> plValues


        `remove(const plVariablesConjunction &variables) const -> plValues`  
        `remove(const std::string &variable_name) const -> plValues`  

        Overloaded function
        -------------------
        * `remove(const plVariablesConjunction &variables) const -> plValues`  

            Creates a new plValues object identical to this one, except that the values
            corresponding to *variables* are removed.  

        * `remove(const std::string &variable_name) const -> plValues`  

            Creates a new plValues object identical to this one, except that the values
            corresponding to the variable with name *name* is removed.  

        """
        return _probt_python3.plValues_remove(self, *args)


    def rename(self, new_variable: 'plVariablesConjunction') -> "void":
        """
        rename(self, new_variable)


        `rename(const plVariablesConjunction &new_variable)`  

        Renames the variables assuming that the old and the new variables have the same
        number and same types.  

        """
        return _probt_python3.plValues_rename(self, new_variable)


    def set_partially(self, partial_value: 'plValues') -> "void":
        """
        set_partially(self, partial_value)


        `set_partially(const plValues &partial_value)`  

        Set partially the value.  

        *partial_value* variables are assumed to be a subset of this value variables  

        """
        return _probt_python3.plValues_set_partially(self, partial_value)


    def set_from(self, other_value: 'plValues') -> "void":
        """
        set_from(self, other_value)


        `set_from(const plValues &other_value)`  

        Set the value from another value Same as set_partially(), however the variables
        of *set_partially* are not assued to be a subset of this value variables.  

        """
        return _probt_python3.plValues_set_from(self, other_value)


    def __xor__(self, other: 'plValues') -> "plValues":
        """__xor__(self, other) -> plValues"""
        return _probt_python3.plValues___xor__(self, other)


    def concatenate(self, other: 'plValues') -> "plValues":
        """
        concatenate(self, other) -> plValues


        `concatenate(plValues const &other) const -> plValues`  

        Same as operator^() above.  

        """
        return _probt_python3.plValues_concatenate(self, other)


    def __ixor__(self, other: 'plValues') -> "plValues &":
        """__ixor__(self, other) -> plValues"""
        return _probt_python3.plValues___ixor__(self, other)


    def push_back(self, other: 'plValues') -> "plValues &":
        """
        push_back(self, other) -> plValues


        `push_back(plValues const &other) -> plValues &`  

        Same as operator^=() above.  

        """
        return _probt_python3.plValues_push_back(self, other)


    def support_area(self) -> "plFloat":
        """
        support_area(self) -> plFloat


        `support_area() const -> plFloat`  

        Returns the support area of this value.  

        The support area for an interval variable is the size of the current interval.
        For any value of any other variable, the support area is always 1. For a
        conjunction of variables, the support area is the product of support areas for
        each variable in the conjunction.  

        """
        return _probt_python3.plValues_support_area(self)


    def set_values_address(self, val: 'plDataValues') -> "void":
        """
        set_values_address(self, val)


        `set_values_address(plDataValues *val)`  

        """
        return _probt_python3.plValues_set_values_address(self, val)


    def values(self, *args) -> "plDataValues const &":
        """
        values(self) -> plDataValues
        values(self) -> plDataValues


        `values() -> plDataValues &`  
        `values() const -> const plDataValues &`  

        Overloaded function
        -------------------
        * `values() -> plDataValues &`  

        * `values() const -> const plDataValues &`  

        """
        return _probt_python3.plValues_values(self, *args)


    def to_data_values(self, *args) -> "void":
        """
        to_data_values(self, variable, ptr, definition)
        to_data_values(self, variable, ptr)


        `to_data_values(const kplVariableList &variable, plDataValues *ptr, std::vector<
            bool > &definition) const`  
        `to_data_values(const kplVariableList &variable, plDataValues *ptr) const`  

        Overloaded function
        -------------------
        * `to_data_values(const kplVariableList &variable, plDataValues *ptr,
            std::vector< bool > &definition) const`  

        * `to_data_values(const kplVariableList &variable, plDataValues *ptr) const`  

        """
        return _probt_python3.plValues_to_data_values(self, *args)


    def set_variable_value(self, variable: 'kplVariable const *', value: 'plData') -> "bool":
        """
        set_variable_value(self, variable, value) -> bool


        `set_variable_value(const kplVariable *variable, const plData &value) -> bool`  

        """
        return _probt_python3.plValues_set_variable_value(self, variable, value)


    def get_value(self, *args) -> "plData const &":
        """
        get_value(self, s) -> plData
        get_value(self, i) -> plData
        get_value(self, name) -> plData


        `get_value(const plVariable &s) const -> const plData &`  
        `get_value(size_t i) const -> const plData &`  
        `get_value(const std::string &name) const -> const plData &`  

        Overloaded function
        -------------------
        * `get_value(const plVariable &s) const -> const plData &`  

            Get value for a given variable.  

        * `get_value(size_t i) const -> const plData &`  

            Get value at a given position.  

        * `get_value(const std::string &name) const -> const plData &`  

            Get value from a variable name.  

        """
        return _probt_python3.plValues_get_value(self, *args)


    def get_value_as_int(self, *args) -> "int":
        """
        get_value_as_int(self, s) -> int
        get_value_as_int(self, i) -> int


        `get_value_as_int(const plVariable &s) const -> int`  
        `get_value_as_int(size_t i) const -> int`  

        Overloaded function
        -------------------
        * `get_value_as_int(const plVariable &s) const -> int`  

            Get value for a given variable as int.  

        * `get_value_as_int(size_t i) const -> int`  

            Get value at a given position as int.  

        """
        return _probt_python3.plValues_get_value_as_int(self, *args)


    def get_value_as_double(self, *args) -> "double":
        """
        get_value_as_double(self, s) -> double
        get_value_as_double(self, i) -> double


        `get_value_as_double(const plVariable &s) const -> double`  
        `get_value_as_double(size_t i) const -> double`  

        Overloaded function
        -------------------
        * `get_value_as_double(const plVariable &s) const -> double`  

            Get value for a given variable as double.  

        * `get_value_as_double(size_t i) const -> double`  

            Get value at a given position as double.  

        """
        return _probt_python3.plValues_get_value_as_double(self, *args)


    def get_value_as_label(self, *args) -> "std::string":
        """
        get_value_as_label(self, s) -> std::string
        get_value_as_label(self, i) -> std::string


        `get_value_as_label(const plVariable &s) const -> std::string`  
        `get_value_as_label(size_t i) const -> std::string`  

        Overloaded function
        -------------------
        * `get_value_as_label(const plVariable &s) const -> std::string`  

            Get value for a given variable as string label.  

        * `get_value_as_label(size_t i) const -> std::string`  

            Get value at a given position as string label.  

        """
        return _probt_python3.plValues_get_value_as_label(self, *args)


    def set_value(self, *args) -> "void":
        """
        set_value(self, s, data)
        set_value(self, i, data)
        set_value(self, name, data)
        set_value(self, s, data)
        set_value(self, i, data)
        set_value(self, name, data)
        set_value(self, s, data)
        set_value(self, i, data)
        set_value(self, name, data)
        set_value(self, s, data)
        set_value(self, i, data)
        set_value(self, name, data)
        set_value(self, s, data)
        set_value(self, i, data)
        set_value(self, name, data)


        `set_value(const plVariable &s, const plData &data)`  
        `set_value(size_t i, const plData &data)`  
        `set_value(const std::string &name, const plData &data)`  
        `set_value(const plVariable &s, int data)`  
        `set_value(size_t i, int data)`  
        `set_value(const std::string &name, int data)`  
        `set_value(const plVariable &s, unsigned int data)`  
        `set_value(size_t i, unsigned int data)`  
        `set_value(const std::string &name, unsigned int data)`  
        `set_value(const plVariable &s, double data)`  
        `set_value(size_t i, double data)`  
        `set_value(const std::string &name, double data)`  
        `set_value(const plVariable &s, float data)`  
        `set_value(size_t i, float data)`  
        `set_value(const std::string &name, float data)`  
        `set_value(const plVariable &s, const std::string &data)`  
        `set_value(size_t i, const std::string &data)`  
        `set_value(const std::string &name, const std::string &data)`  

        Overloaded function
        -------------------
        * `set_value(const plVariable &s, const plData &data)`  

            Set value for a given variable.  

        * `set_value(size_t i, const plData &data)`  

            Set value for a given position.  

        * `set_value(const std::string &name, const plData &data)`  

            Set value for a given variable name.  

        * `set_value(const plVariable &s, int data)`  

            Set value for a given variable.  

        * `set_value(size_t i, int data)`  

            Set value for a given position.  

        * `set_value(const std::string &name, int data)`  

            Set value for a given variable name.  

        * `set_value(const plVariable &s, unsigned int data)`  

            Set value for a given variable.  

        * `set_value(size_t i, unsigned int data)`  

            Set value for a given position.  

        * `set_value(const std::string &name, unsigned int data)`  

            Set value for a given variable name.  

        * `set_value(const plVariable &s, double data)`  

            Set value for a given variable.  

        * `set_value(size_t i, double data)`  

            Set value for a given position.  

        * `set_value(const std::string &name, double data)`  

            Set value for a given variable name.  

        * `set_value(const plVariable &s, float data)`  

            Set value for a given variable.  

        * `set_value(size_t i, float data)`  

            Set value for a given position.  

        * `set_value(const std::string &name, float data)`  

            Set value for a given variable name.  

        * `set_value(const plVariable &s, const std::string &data)`  

            Set value for a given variable.  

        * `set_value(size_t i, const std::string &data)`  

            Set value for a given position.  

        * `set_value(const std::string &name, const std::string &data)`  

            Set value for a given variable name.  

        """
        return _probt_python3.plValues_set_value(self, *args)


    def get_defined(self, defined: 'BoolVector') -> "plValues":
        """
        get_defined(self, defined) -> plValues


        `get_defined(const std::vector< bool > &defined) const -> plValues`  

        Returns the values for which 'defined' is true.  

        """
        return _probt_python3.plValues_get_defined(self, defined)


    def set_to_random(self) -> "void":
        """
        set_to_random(self)


        `set_to_random()`  

        Set at a random value in variable ranges.  

        """
        return _probt_python3.plValues_set_to_random(self)


    def has_same_variables_as(self, other: 'plValues') -> "bool":
        """
        has_same_variables_as(self, other) -> bool


        `has_same_variables_as(const plValues &other) const -> bool`  

        Return true iff this value and the other value have the same variables in the
        same order.  

        """
        return _probt_python3.plValues_has_same_variables_as(self, other)


    def copy_defined_values(defined_value: 'plValues', vals: 'plValues', arg3: 'BoolVector') -> "void":
        """
        copy_defined_values(defined_value, vals, arg3)


        `copy_defined_values(plValues &defined_value, const plValues &vals, const
            std::vector< bool > &def)`  

        """
        return _probt_python3.plValues_copy_defined_values(defined_value, vals, arg3)

    copy_defined_values = staticmethod(copy_defined_values)

    def __getitem__(self, *args) -> "plData":
        """
        __getitem__(self, index) -> plData
        __getitem__(self, var) -> plData
        __getitem__(self, name) -> plData
        """
        return _probt_python3.plValues___getitem__(self, *args)


    def __setitem__(self, *args) -> "void":
        """
        __setitem__(self, index, value)
        __setitem__(self, index, value)
        __setitem__(self, index, value)
        __setitem__(self, index, value)
        __setitem__(self, index, value)
        __setitem__(self, index, value)
        __setitem__(self, index, value)
        __setitem__(self, index, value)
        __setitem__(self, index, value)
        __setitem__(self, index, value)
        __setitem__(self, index, value)
        __setitem__(self, index, value)
        """
        return _probt_python3.plValues___setitem__(self, *args)


    def __getstate__(self) -> "std::string":
        """__getstate__(self) -> std::string"""
        return _probt_python3.plValues___getstate__(self)


    def __setstate_internal(self, sState: 'std::string const &') -> "void":
        """__setstate_internal(self, sState)"""
        return _probt_python3.plValues___setstate_internal(self, sState)


    def __setstate__(self, sState):
        self.__init__()
        self.__setstate_internal(sState)

plValues_swigregister = _probt_python3.plValues_swigregister
plValues_swigregister(plValues)

def plValues_copy_defined_values(defined_value: 'plValues', vals: 'plValues', arg4: 'BoolVector') -> "void":
    """
    plValues_copy_defined_values(defined_value, vals, arg4)


    `copy_defined_values(plValues &defined_value, const plValues &vals, const
        std::vector< bool > &def)`  

    """
    return _probt_python3.plValues_copy_defined_values(defined_value, vals, arg4)



def plValues_all(self):
  """Iterate over all possible values of the variables covered by this object.
  """
  import sys
  copy = plValues(self)
  copy.reset()
  while 1:
    yield copy
    if not copy.next():
      if sys.version_info.major > 3 or (sys.version_info.major == 3 and sys.version_info.minor > 5):
        return
      else:
        raise StopIteration

plValues.all = plValues_all

def plValues_iter(self):
  """Iterate over (variable, value) pairs.
  """
  for v in self.get_variables():
    yield v, self[v]

plValues.__iter__ = plValues_iter

plValues.__len__ = plValues.size

class plPredictionPerformanceReport(plObject):
    """

    `plPredictionPerformanceReport()`  
    `plPredictionPerformanceReport(const plVariablesConjunction &target_vars)`  
    `plPredictionPerformanceReport(const std::vector< plValues > &actual_values,
        const std::vector< plValues > &predicted_values)`  
    `plPredictionPerformanceReport(const std::vector< unsigned int > &actual_values,
        const std::vector< unsigned int > &predicted_values)`  
    `plPredictionPerformanceReport(const std::vector< long int > &actual_values,
        const std::vector< long int > &predicted_values)`  
    `plPredictionPerformanceReport(const std::vector< std::string > &actual_values,
        const std::vector< std::string > &predicted_values)`  
    `plPredictionPerformanceReport(const std::vector< plFloat > &actual_values,
        const std::vector< plFloat > &predicted_values, const std::string
        &variable_name="X")`  
    `plPredictionPerformanceReport(const std::vector< std::string > &class_names)`  

    Prediction Performance Report.  

    It provides confusion matrix information (accuracy, precision, recall,...) in
    case of classification, and R2, RMSE, SSE, MBE, MAE, MRE in case of regression.
    It's used in model evaluation functions such as
    plBayesianNetwork::validate_prediction(),
    plCndDistribution::validate_prediction(),
    plConcurrentHmmSet::evaluate_online_classification(), and
    plConcurrentHmmSet::evaluate_offline_classification().  

    Constructors
    ------------
    * `plPredictionPerformanceReport()`  

        Default constructor, for the benefit of Python wrappers.  

    * `plPredictionPerformanceReport(const plVariablesConjunction &target_vars)`  

        Construction for a given target.  

    * `plPredictionPerformanceReport(const std::vector< plValues > &actual_values,
        const std::vector< plValues > &predicted_values)`  

        Construction using a vector of real values and a vector of predicted ones.  

    * `plPredictionPerformanceReport(const std::vector< unsigned int >
        &actual_values, const std::vector< unsigned int > &predicted_values)`  

        Construction for classification using a vector of real values and a vector
        of predicted ones.  

    * `plPredictionPerformanceReport(const std::vector< long int > &actual_values,
        const std::vector< long int > &predicted_values)`  

        Construction for classification using a vector of real values and a vector
        of predicted ones.  

    * `plPredictionPerformanceReport(const std::vector< std::string >
        &actual_values, const std::vector< std::string > &predicted_values)`  

        Construction for classification using a vector of real values and a vector
        of predicted ones.  

    * `plPredictionPerformanceReport(const std::vector< plFloat > &actual_values,
        const std::vector< plFloat > &predicted_values, const std::string
        &variable_name="X")`  

        Construction for regression using a vector of real values and a vector of
        predicted ones.  

    * `plPredictionPerformanceReport(const std::vector< std::string > &class_names)`  

        Construction for classification.  

        To be used with function update_classification(unsigned int actual_index,
        unsigned int inferred_index, int data_row_number)  

    C++ includes: plPredictionPerformanceReport.h

    """

    __swig_setmethods__ = {}
    for _s in [plObject]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plPredictionPerformanceReport, name, value)
    __swig_getmethods__ = {}
    for _s in [plObject]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plPredictionPerformanceReport, name)
    __repr__ = _swig_repr

    def __init__(self, *args):
        """
        __init__(self) -> plPredictionPerformanceReport
        __init__(self, target_vars) -> plPredictionPerformanceReport
        __init__(self, actual_values, predicted_values) -> plPredictionPerformanceReport
        __init__(self, actual_values, predicted_values) -> plPredictionPerformanceReport
        __init__(self, actual_values, predicted_values) -> plPredictionPerformanceReport
        __init__(self, actual_values, predicted_values) -> plPredictionPerformanceReport
        __init__(self, actual_values, predicted_values, variable_name) -> plPredictionPerformanceReport
        __init__(self, actual_values, predicted_values) -> plPredictionPerformanceReport
        __init__(self, class_names) -> plPredictionPerformanceReport


        `plPredictionPerformanceReport()`  
        `plPredictionPerformanceReport(const plVariablesConjunction &target_vars)`  
        `plPredictionPerformanceReport(const std::vector< plValues > &actual_values,
            const std::vector< plValues > &predicted_values)`  
        `plPredictionPerformanceReport(const std::vector< unsigned int > &actual_values,
            const std::vector< unsigned int > &predicted_values)`  
        `plPredictionPerformanceReport(const std::vector< long int > &actual_values,
            const std::vector< long int > &predicted_values)`  
        `plPredictionPerformanceReport(const std::vector< std::string > &actual_values,
            const std::vector< std::string > &predicted_values)`  
        `plPredictionPerformanceReport(const std::vector< plFloat > &actual_values,
            const std::vector< plFloat > &predicted_values, const std::string
            &variable_name="X")`  
        `plPredictionPerformanceReport(const std::vector< std::string > &class_names)`  

        Overloaded function
        -------------------
        * `plPredictionPerformanceReport()`  

            Default constructor, for the benefit of Python wrappers.  

        * `plPredictionPerformanceReport(const plVariablesConjunction &target_vars)`  

            Construction for a given target.  

        * `plPredictionPerformanceReport(const std::vector< plValues > &actual_values,
            const std::vector< plValues > &predicted_values)`  

            Construction using a vector of real values and a vector of predicted ones.  

        * `plPredictionPerformanceReport(const std::vector< unsigned int >
            &actual_values, const std::vector< unsigned int > &predicted_values)`  

            Construction for classification using a vector of real values and a vector
            of predicted ones.  

        * `plPredictionPerformanceReport(const std::vector< long int > &actual_values,
            const std::vector< long int > &predicted_values)`  

            Construction for classification using a vector of real values and a vector
            of predicted ones.  

        * `plPredictionPerformanceReport(const std::vector< std::string >
            &actual_values, const std::vector< std::string > &predicted_values)`  

            Construction for classification using a vector of real values and a vector
            of predicted ones.  

        * `plPredictionPerformanceReport(const std::vector< plFloat > &actual_values,
            const std::vector< plFloat > &predicted_values, const std::string
            &variable_name="X")`  

            Construction for regression using a vector of real values and a vector of
            predicted ones.  

        * `plPredictionPerformanceReport(const std::vector< std::string > &class_names)`  

            Construction for classification.  

            To be used with function update_classification(unsigned int actual_index,
            unsigned int inferred_index, int data_row_number)  

        """
        this = _probt_python3.new_plPredictionPerformanceReport(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this
    __swig_destroy__ = _probt_python3.delete_plPredictionPerformanceReport
    __del__ = lambda self: None

    def update(self, actual_value: 'plValues', predicted_value: 'plValues', data_row_number: 'int'=-1) -> "void":
        """
        update(self, actual_value, predicted_value, data_row_number=-1)
        update(self, actual_value, predicted_value)


        `update(const plValues &actual_value, const plValues &predicted_value, int
            data_row_number=-1)`  

        Update prediction statistics.  

        Parameters
        ----------
        * `actual_value` :  
            The real target value  
        * `predicted_value` :  
            The inferred target value  
        * `data_row_number` :  
            The data row number to be used for keeping classification errors row lines
            when calling get_classification_error_row_numbers(). -1 is used when one
            does not need to keep error information  

        """
        return _probt_python3.plPredictionPerformanceReport_update(self, actual_value, predicted_value, data_row_number)


    def update_classification(self, actual_index: 'unsigned int', predicted_index: 'unsigned int', data_row_number: 'int') -> "void":
        """
        update_classification(self, actual_index, predicted_index, data_row_number)


        `update_classification(unsigned int actual_index, unsigned int predicted_index,
            int data_row_number)`  

        Update prediction statistics for classification.  

        Parameters
        ----------
        * `actual_index` :  
            The real target value index  
        * `predicted_index` :  
            The inferred target value index  
        * `data_row_number` :  
            The data row number to be used for keeping classification errors row lines
            when calling get_classification_error_row_numbers(). -1 is used when one
            does not need to keep error information  

        """
        return _probt_python3.plPredictionPerformanceReport_update_classification(self, actual_index, predicted_index, data_row_number)


    def get_n(self) -> "unsigned int":
        """
        get_n(self) -> unsigned int


        `get_n() const -> unsigned int`  

        Get the number of validation examples.  

        """
        return _probt_python3.plPredictionPerformanceReport_get_n(self)


    def is_classification(self) -> "bool":
        """
        is_classification(self) -> bool


        `is_classification() const -> bool`  

        Return True is classification results and False if regression.  

        """
        return _probt_python3.plPredictionPerformanceReport_is_classification(self)


    def add(self, other: 'plPredictionPerformanceReport') -> "void":
        """
        add(self, other)


        `add(const plPredictionPerformanceReport &other)`  

        Add another report to this.  

        """
        return _probt_python3.plPredictionPerformanceReport_add(self, other)


    def __add__(self, other: 'plPredictionPerformanceReport') -> "plPredictionPerformanceReport":
        """__add__(self, other) -> plPredictionPerformanceReport"""
        return _probt_python3.plPredictionPerformanceReport___add__(self, other)


    def get_confusion_matrix_element(self, real: 'size_t', predicted: 'size_t') -> "unsigned int":
        """
        get_confusion_matrix_element(self, real, predicted) -> unsigned int


        `get_confusion_matrix_element(size_t real, size_t predicted) const -> unsigned
            int`  

        Get a given entry of the confusion matrix.  

        Applicable only for classification  

        """
        return _probt_python3.plPredictionPerformanceReport_get_confusion_matrix_element(self, real, predicted)


    def get_n_real(self, class_index: 'size_t') -> "unsigned int":
        """
        get_n_real(self, class_index) -> unsigned int


        `get_n_real(size_t class_index) const -> unsigned int`  

        Get the number of real validation examples for a given class index.  

        Applicable only for classification  

        """
        return _probt_python3.plPredictionPerformanceReport_get_n_real(self, class_index)


    def get_n_predicted(self, class_index: 'size_t') -> "unsigned int":
        """
        get_n_predicted(self, class_index) -> unsigned int


        `get_n_predicted(size_t class_index) const -> unsigned int`  

        Get the number of prediction validation examples for a given class index.  

        Applicable only for classification  

        """
        return _probt_python3.plPredictionPerformanceReport_get_n_predicted(self, class_index)


    def get_precision(self, class_index: 'size_t') -> "plFloat":
        """
        get_precision(self, class_index) -> plFloat


        `get_precision(size_t class_index) const -> plFloat`  

        Get the precision for a given class.  

        Applicable only for classification  

        """
        return _probt_python3.plPredictionPerformanceReport_get_precision(self, class_index)


    def get_recall(self, class_index: 'size_t') -> "plFloat":
        """
        get_recall(self, class_index) -> plFloat


        `get_recall(size_t class_index) const -> plFloat`  

        Get the recall for a given class.  

        Applicable only for classification  

        """
        return _probt_python3.plPredictionPerformanceReport_get_recall(self, class_index)


    def get_accuracy(self) -> "plFloat":
        """
        get_accuracy(self) -> plFloat


        `get_accuracy() const -> plFloat`  

        Get classification accuray.  

        Applicable only for classification  

        """
        return _probt_python3.plPredictionPerformanceReport_get_accuracy(self)


    def get_n_classification_errors(self) -> "unsigned int":
        """
        get_n_classification_errors(self) -> unsigned int


        `get_n_classification_errors() const -> unsigned int`  

        Get the number of classification errors.  

        Applicable only for classification  

        """
        return _probt_python3.plPredictionPerformanceReport_get_n_classification_errors(self)


    def get_n_good_classifications(self) -> "unsigned int":
        """
        get_n_good_classifications(self) -> unsigned int


        `get_n_good_classifications() const -> unsigned int`  

        Get the number of good classification responses.  

        Applicable only for classification  

        """
        return _probt_python3.plPredictionPerformanceReport_get_n_good_classifications(self)


    def variable_indexer(self) -> "plVariableIndexer const &":
        """
        variable_indexer(self) -> plVariableIndexer


        `variable_indexer() const -> const plVariableIndexer &`  

        """
        return _probt_python3.plPredictionPerformanceReport_variable_indexer(self)


    def get_r2(self, dim: 'size_t'=0) -> "plFloat":
        """
        get_r2(self, dim=0) -> plFloat
        get_r2(self) -> plFloat


        `get_r2(size_t dim=0) const -> plFloat`  

        Get the R-squared score for a given dimension.  

        Applicable only for regression  

        """
        return _probt_python3.plPredictionPerformanceReport_get_r2(self, dim)


    def get_rmse(self, dim: 'size_t'=0) -> "plFloat":
        """
        get_rmse(self, dim=0) -> plFloat
        get_rmse(self) -> plFloat


        `get_rmse(size_t dim=0) const -> plFloat`  

        Get the Root Mean Squared Error for a given dimension.  

        Applicable only for regression  

        """
        return _probt_python3.plPredictionPerformanceReport_get_rmse(self, dim)


    def get_sse(self, dim: 'size_t'=0) -> "plFloat":
        """
        get_sse(self, dim=0) -> plFloat
        get_sse(self) -> plFloat


        `get_sse(size_t dim=0) const -> plFloat`  

        Get the Sum of Squared Error for a given dimension.  

        Applicable only for regression  

        """
        return _probt_python3.plPredictionPerformanceReport_get_sse(self, dim)


    def get_mbe(self, dim: 'size_t'=0) -> "plFloat":
        """
        get_mbe(self, dim=0) -> plFloat
        get_mbe(self) -> plFloat


        `get_mbe(size_t dim=0) const -> plFloat`  

        Get the Mean Bias Error for a given dimension.  

        Applicable only for regression  

        """
        return _probt_python3.plPredictionPerformanceReport_get_mbe(self, dim)


    def get_mae(self, dim: 'size_t'=0) -> "plFloat":
        """
        get_mae(self, dim=0) -> plFloat
        get_mae(self) -> plFloat


        `get_mae(size_t dim=0) const -> plFloat`  

        Get the Mean Absolute Error for a given dimension.  

        Applicable only for regression  

        """
        return _probt_python3.plPredictionPerformanceReport_get_mae(self, dim)


    def get_mre(self, dim: 'size_t'=0) -> "plFloat":
        """
        get_mre(self, dim=0) -> plFloat
        get_mre(self) -> plFloat


        `get_mre(size_t dim=0) const -> plFloat`  

        Get the Mean Relative Error for a given dimension.  

        Applicable only for regression  

        """
        return _probt_python3.plPredictionPerformanceReport_get_mre(self, dim)


    def get_classification_error_row_numbers(self) -> "std::vector< std::pair< unsigned int,unsigned int >,std::allocator< std::pair< unsigned int,unsigned int > > >":
        """
        get_classification_error_row_numbers(self) -> PairUiVector


        `get_classification_error_row_numbers() const -> std::vector< std::pair<
            unsigned int, unsigned int > >`  

        Return the row numbers corresponding to classification errors.  

        This corresponds to the wrong classified row numbers passed to the function
        update() as parameter, and the errornous predicted class index  

        """
        return _probt_python3.plPredictionPerformanceReport_get_classification_error_row_numbers(self)


    def get_class_names(self) -> "std::vector< std::string,std::allocator< std::string > >":
        """
        get_class_names(self) -> StringVector


        `get_class_names() const -> std::vector< std::string >`  

        Get the set of values of the target Applicable only for classification.  

        """
        return _probt_python3.plPredictionPerformanceReport_get_class_names(self)


    def get_target_names(self) -> "std::vector< std::string,std::allocator< std::string > >":
        """
        get_target_names(self) -> StringVector


        `get_target_names() const -> std::vector< std::string >`  

        Get the names of the target variables.  

        """
        return _probt_python3.plPredictionPerformanceReport_get_target_names(self)


    def to_html(self) -> "std::string":
        """
        to_html(self) -> std::string


        `to_html() const -> std::string`  

        Get the corresponding html code.  

        """
        return _probt_python3.plPredictionPerformanceReport_to_html(self)


    def __getstate__(self) -> "std::string":
        """__getstate__(self) -> std::string"""
        return _probt_python3.plPredictionPerformanceReport___getstate__(self)


    def __setstate_internal(self, sState: 'std::string const &') -> "void":
        """__setstate_internal(self, sState)"""
        return _probt_python3.plPredictionPerformanceReport___setstate_internal(self, sState)


    def __setstate__(self, sState):
        self.__init__()
        self.__setstate_internal(sState)

plPredictionPerformanceReport_swigregister = _probt_python3.plPredictionPerformanceReport_swigregister
plPredictionPerformanceReport_swigregister(plPredictionPerformanceReport)


plPredictionPerformanceReport._repr_html_ = plPredictionPerformanceReport.to_html

def plPredictionPerformanceReport_get_classification_errors(self, test_df, class_names=None):
  """
  Get the real and predicted values for classification errors
# Arguments
        test_df: The Pandas dataframe used for generating this report and having columns with the real values of the target
        class_names: The names of target columns in test_df
# Returns
        A Pandas dataframe with target's real and predicted values for classification errors
  """
  import pandas as pd
  if class_names is None:
    class_names = list(self.get_target_names())
  class_names_predicted = [n+'_predicted' for n in class_names]
  error_rows = self.get_classification_error_row_numbers()
  error_idx = [err[0] for err in error_rows]
  error_cls = [err[1] for err in error_rows]
  indexer = self.variable_indexer()
  val = plValues()
  errors = []
  for e in error_cls:
    indexer.get_value_from_index(e, val)
    err = [val[j] for j in range(len(val))]
    errors.append(err)
  test_data = test_df.iloc[error_idx,:]
  err_data = pd.DataFrame(errors, columns=class_names_predicted)
  err_data.index = test_data.index
  result_df = pd.concat([test_data, err_data], axis=1)
  return result_df
plPredictionPerformanceReport.python_get_classification_errors = plPredictionPerformanceReport_get_classification_errors

PLCndNormal = _probt_python3.PLCndNormal
PLComputableObject = _probt_python3.PLComputableObject
PLCndDistribution = _probt_python3.PLCndDistribution
PLCndUnknown = _probt_python3.PLCndUnknown
PLJointDistribution = _probt_python3.PLJointDistribution
PLDeterministic = _probt_python3.PLDeterministic
PLCndDeterministic = _probt_python3.PLCndDeterministic
PLGamma = _probt_python3.PLGamma
PLNormal = _probt_python3.PLNormal
PLDistribution = _probt_python3.PLDistribution
PLDistributionTable = _probt_python3.PLDistributionTable
PLPoisson = _probt_python3.PLPoisson
PLProbTable = _probt_python3.PLProbTable
PLUniform = _probt_python3.PLUniform
PLUnknown = _probt_python3.PLUnknown
PLAnonymousDistribution = _probt_python3.PLAnonymousDistribution
PLCndAnonymousDistribution = _probt_python3.PLCndAnonymousDistribution
PLIneqConstraint = _probt_python3.PLIneqConstraint
PLLogNormal = _probt_python3.PLLogNormal
PLCndLogNormal = _probt_python3.PLCndLogNormal
PLExponential = _probt_python3.PLExponential
PLBeta = _probt_python3.PLBeta
PLBinomial = _probt_python3.PLBinomial
PLDirichlet = _probt_python3.PLDirichlet
PLCndUniform = _probt_python3.PLCndUniform
PLCndPoisson = _probt_python3.PLCndPoisson
PLJtDistribution = _probt_python3.PLJtDistribution
PLCndJtDistribution = _probt_python3.PLCndJtDistribution
PLCndBinomial = _probt_python3.PLCndBinomial
PLWeibull = _probt_python3.PLWeibull
PLNoisyOR = _probt_python3.PLNoisyOR
PLLinearRegression = _probt_python3.PLLinearRegression
PLSoftmax = _probt_python3.PLSoftmax
PLCndBeta = _probt_python3.PLCndBeta
PLCndExponential = _probt_python3.PLCndExponential
PLCndGamma = _probt_python3.PLCndGamma
PLCndWeibull = _probt_python3.PLCndWeibull
PLVonMises = _probt_python3.PLVonMises
PLCndVonMises = _probt_python3.PLCndVonMises
NUMBER_OF_PL_COMPUTABLE_OBJECTS = _probt_python3.NUMBER_OF_PL_COMPUTABLE_OBJECTS

def pl_get_computable_object_type_name(arg1: 'plComputableObjectType') -> "std::string":
    """
    pl_get_computable_object_type_name(arg1) -> std::string


    `pl_get_computable_object_type_name(plComputableObjectType) -> PL_DLL_API
        std::string`  

    Get the printable name of a plComputableObjectType.  

    """
    return _probt_python3.pl_get_computable_object_type_name(arg1)

def pl_get_computable_object_type(*args) -> "plComputableObjectType":
    """
    pl_get_computable_object_type(name) -> plComputableObjectType
    pl_get_computable_object_type(signature) -> plComputableObjectType


    `pl_get_computable_object_type(const std::string &name) -> PL_DLL_API
        plComputableObjectType`  
    `pl_get_computable_object_type(const plSignature &signature) -> PL_DLL_API
        plComputableObjectType`  

    Overloaded function
    -------------------
    * `pl_get_computable_object_type(const std::string &name) -> PL_DLL_API
        plComputableObjectType`  

        Get a plComputableObjectType value from its printable name.  

    * `pl_get_computable_object_type(const plSignature &signature) -> PL_DLL_API
        plComputableObjectType`  

        Get the actual (most-derived) type of a plComputableObject given its
        signature.  

    """
    return _probt_python3.pl_get_computable_object_type(*args)
class plComputableObjectList(plObject):
    """

    `plComputableObjectList()`  
    `plComputableObjectList(const plComputableObject &obj)`  
    `plComputableObjectList(const plComputableObjectList &l)`  

    A *plComputableObjectList* is an STL-like list of *plComputableObjects*.  

    It's provided with iterators and concatenation operators (*, *=). A
    plComputableObjectList is especially used to concatenate a set of
    plComputableObjects (to be used when creating a *plJointDistribution* for
    example).  

    Constructors
    ------------
    * `plComputableObjectList()`  

        Default constructor.  

    * `plComputableObjectList(const plComputableObject &obj)`  

        Constructor using a single computable object.  

    * `plComputableObjectList(const plComputableObjectList &l)`  

        Copy constructor.  

    C++ includes: plComputableObject.h

    """

    __swig_setmethods__ = {}
    for _s in [plObject]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plComputableObjectList, name, value)
    __swig_getmethods__ = {}
    for _s in [plObject]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plComputableObjectList, name)
    __repr__ = _swig_repr

    def __init__(self, *args):
        """
        __init__(self) -> plComputableObjectList
        __init__(self, obj) -> plComputableObjectList
        __init__(self, l) -> plComputableObjectList


        `plComputableObjectList()`  
        `plComputableObjectList(const plComputableObject &obj)`  
        `plComputableObjectList(const plComputableObjectList &l)`  

        Overloaded function
        -------------------
        * `plComputableObjectList()`  

            Default constructor.  

        * `plComputableObjectList(const plComputableObject &obj)`  

            Constructor using a single computable object.  

        * `plComputableObjectList(const plComputableObjectList &l)`  

            Copy constructor.  

        """
        this = _probt_python3.new_plComputableObjectList(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this
    __swig_destroy__ = _probt_python3.delete_plComputableObjectList
    __del__ = lambda self: None

    def assign_from(self, l: 'plComputableObjectList') -> "plComputableObjectList &":
        """
        assign_from(self, l) -> plComputableObjectList


        `assign_from(const plComputableObjectList &l) -> plComputableObjectList &`  

        Same as operator=()  

        """
        return _probt_python3.plComputableObjectList_assign_from(self, l)


    def __mul__(self, *args) -> "plComputableObjectList":
        """
        __mul__(self, f1) -> plComputableObjectList
        __mul__(self, r_list) -> plComputableObjectList
        """
        return _probt_python3.plComputableObjectList___mul__(self, *args)


    def concatenate(self, *args) -> "plComputableObjectList":
        """
        concatenate(self, f1) -> plComputableObjectList
        concatenate(self, r_list) -> plComputableObjectList


        `concatenate(const plComputableObject &f1) const -> plComputableObjectList`  
        `concatenate(const plComputableObjectList &r_list) const ->
            plComputableObjectList`  

        Overloaded function
        -------------------
        * `concatenate(const plComputableObject &f1) const -> plComputableObjectList`  

            Concatenation with a single computable object operator.  

        * `concatenate(const plComputableObjectList &r_list) const ->
            plComputableObjectList`  

            Concatenation with another computable objects list operator.  

        """
        return _probt_python3.plComputableObjectList_concatenate(self, *args)


    def __imul__(self, *args) -> "plComputableObjectList const &":
        """
        __imul__(self, f1) -> plComputableObjectList
        __imul__(self, r_list) -> plComputableObjectList
        """
        return _probt_python3.plComputableObjectList___imul__(self, *args)


    def push_back(self, *args) -> "plComputableObjectList const &":
        """
        push_back(self, f1) -> plComputableObjectList
        push_back(self, r_list) -> plComputableObjectList


        `push_back(const plComputableObject &f1) -> const plComputableObjectList &`  
        `push_back(const plComputableObjectList &r_list) -> const plComputableObjectList
            &`  

        Overloaded function
        -------------------
        * `push_back(const plComputableObject &f1) -> const plComputableObjectList &`  

            In-place concatenation with a single computable object.  

        * `push_back(const plComputableObjectList &r_list) -> const
            plComputableObjectList &`  

            In-place concatenation with another computable objects list.  

        """
        return _probt_python3.plComputableObjectList_push_back(self, *args)


    def clear(self) -> "void":
        """
        clear(self)


        `clear()`  

        Clear the list.  

        """
        return _probt_python3.plComputableObjectList_clear(self)


    def size(self) -> "size_t":
        """
        size(self) -> size_t


        `size() const -> size_t`  

        Return the number of computable objects in the list.  

        """
        return _probt_python3.plComputableObjectList_size(self)


    def __getitem__(self, i: 'size_t') -> "plComputableObject":
        """__getitem__(self, i) -> plComputableObject"""
        return _probt_python3.plComputableObjectList___getitem__(self, i)


    def at(self, i: 'size_t') -> "plComputableObject":
        """
        at(self, i) -> plComputableObject


        `at(size_t i) const -> plComputableObject`  

        Access the i-th element as a plComputableObject.  

        """
        return _probt_python3.plComputableObjectList_at(self, i)


    def empty(self) -> "bool":
        """
        empty(self) -> bool


        `empty() const -> bool`  

        Return *true* if and only if the list contains zero elements.  

        """
        return _probt_python3.plComputableObjectList_empty(self)


    def begin(self) -> "plComputableObjectList::const_iterator":
        """
        begin(self) -> plComputableObjectList::const_iterator


        `begin() const -> const_iterator`  

        Returns a const_iterator to the first object in this list.  

        """
        return _probt_python3.plComputableObjectList_begin(self)


    def end(self) -> "plComputableObjectList::const_iterator":
        """
        end(self) -> plComputableObjectList::const_iterator


        `end() const -> const_iterator`  

        Returns a const_iterator pointing one item after the last object in this list.  

        """
        return _probt_python3.plComputableObjectList_end(self)


    def get_distribution_over(self, variable: 'plVariablesConjunction') -> "plComputableObject":
        """
        get_distribution_over(self, variable) -> plComputableObject


        `get_distribution_over(const plVariablesConjunction &variable) const ->
            plComputableObject`  

        Returns the first distribution over (i.e., having as left variable) the variable
        *variable* if any.  

        Raises an exception if no distribution over *variable* is found  

        """
        return _probt_python3.plComputableObjectList_get_distribution_over(self, variable)


    def ancestral_order_distributions(self) -> "plComputableObjectList":
        """
        ancestral_order_distributions(self) -> plComputableObjectList


        `ancestral_order_distributions() const -> plComputableObjectList`  

        Get an ancestral ordering of the distributions.  

        """
        return _probt_python3.plComputableObjectList_ancestral_order_distributions(self)


    def ancestral_order_variables(self) -> "plVariablesConjunction":
        """
        ancestral_order_variables(self) -> plVariablesConjunction


        `ancestral_order_variables() const -> plVariablesConjunction`  

        Get an ancestral ordering of the variables.  

        """
        return _probt_python3.plComputableObjectList_ancestral_order_variables(self)


    def remove(self, *args) -> "plComputableObjectList":
        """
        remove(self, left_variable, right_variable) -> plComputableObjectList
        remove(self, left_variable) -> plComputableObjectList


        `remove(const plVariablesConjunction &left_variable, const
            plVariablesConjunction &right_variable) -> plComputableObjectList`  
        `remove(const plVariablesConjunction &left_variable) -> plComputableObjectList`  

        Overloaded function
        -------------------
        * `remove(const plVariablesConjunction &left_variable, const
            plVariablesConjunction &right_variable) -> plComputableObjectList`  

            Remove an element having the passed variable signature.  

        * `remove(const plVariablesConjunction &left_variable) ->
            plComputableObjectList`  

            Remove an element having the passed variable signature.  

        """
        return _probt_python3.plComputableObjectList_remove(self, *args)


    def __getstate__(self) -> "std::string":
        """__getstate__(self) -> std::string"""
        return _probt_python3.plComputableObjectList___getstate__(self)


    def __setstate_internal(self, sState: 'std::string const &') -> "void":
        """__setstate_internal(self, sState)"""
        return _probt_python3.plComputableObjectList___setstate_internal(self, sState)


    def __setstate__(self, sState):
        self.__init__()
        self.__setstate_internal(sState)

plComputableObjectList_swigregister = _probt_python3.plComputableObjectList_swigregister
plComputableObjectList_swigregister(plComputableObjectList)

class plComputableObject(plObject):
    """

    `plComputableObject()`  
    `plComputableObject(const plComputableObjectList &func_lis)`  
    `plComputableObject(const plComputableObjectList &func_lis, const
        plVariablesConjunction &left_variables, const plVariablesConjunction
        &right_variables)`  
    `plComputableObject(const plComputableObject &)`  

    A *computable* *object* on $ \omega $ is defined as an abstract object provided
    with a probability measure function *compute*( $ \omega $).  

    Constructors
    ------------
    * `plComputableObject()`  

        Empty constructor.  

        The resulting object is invalid for most operations, except for being
        assigned to, or used as a return value.  

    * `plComputableObject(const plComputableObjectList &func_lis)`  

        Creates a conditional or non conditional distribution as a product of a
        conditional and non conditional distributions.  

        The left variables of the constructed computable object are the
        concatenation (in the same order) of the left variables of all the terms of
        the list. Its right variables are the concatenation of the right variables
        of all the terms and that are not in left one above.  

    * `plComputableObject(const plComputableObjectList &func_lis, const
        plVariablesConjunction &left_variables, const plVariablesConjunction
        &right_variables)`  

    * `plComputableObject(const plComputableObject &)`  

        Copy constructor.  

    C++ includes: plComputableObject.h

    """

    __swig_setmethods__ = {}
    for _s in [plObject]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plComputableObject, name, value)
    __swig_getmethods__ = {}
    for _s in [plObject]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plComputableObject, name)
    __repr__ = _swig_repr
    __swig_destroy__ = _probt_python3.delete_plComputableObject
    __del__ = lambda self: None

    def __init__(self, *args):
        """
        __init__(self) -> plComputableObject
        __init__(self, func_lis) -> plComputableObject
        __init__(self, func_lis, left_variables, right_variables) -> plComputableObject
        __init__(self, arg2) -> plComputableObject


        `plComputableObject()`  
        `plComputableObject(const plComputableObjectList &func_lis)`  
        `plComputableObject(const plComputableObjectList &func_lis, const
            plVariablesConjunction &left_variables, const plVariablesConjunction
            &right_variables)`  
        `plComputableObject(const plComputableObject &)`  

        Overloaded function
        -------------------
        * `plComputableObject()`  

            Empty constructor.  

            The resulting object is invalid for most operations, except for being
            assigned to, or used as a return value.  

        * `plComputableObject(const plComputableObjectList &func_lis)`  

            Creates a conditional or non conditional distribution as a product of a
            conditional and non conditional distributions.  

            The left variables of the constructed computable object are the
            concatenation (in the same order) of the left variables of all the terms of
            the list. Its right variables are the concatenation of the right variables
            of all the terms and that are not in left one above.  

        * `plComputableObject(const plComputableObjectList &func_lis, const
            plVariablesConjunction &left_variables, const plVariablesConjunction
            &right_variables)`  

        * `plComputableObject(const plComputableObject &)`  

            Copy constructor.  

        """
        this = _probt_python3.new_plComputableObject(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def assign_from(self, other: 'plComputableObject') -> "plComputableObject &":
        """
        assign_from(self, other) -> plComputableObject


        `assign_from(const plComputableObject &other) -> plComputableObject &`  

        Same as operator=()  

        """
        return _probt_python3.plComputableObject_assign_from(self, other)


    def get_print_name(self) -> "std::string":
        """
        get_print_name(self) -> std::string


        `get_print_name() const -> std::string`  

        Return the distribution print name.  

        """
        return _probt_python3.plComputableObject_get_print_name(self)


    def isObject(self, type: 'plComputableObjectType const &') -> "bool":
        """
        isObject(self, type) -> bool


        `is(const plComputableObjectType &type) const -> bool`  

        Returns *true* if the plComputableObject is of type *type*.  

        """
        return _probt_python3.plComputableObject_isObject(self, type)


    def is_some_on_signature(self, prototype_signature: 'plSignature const &') -> "bool":
        """
        is_some_on_signature(self, prototype_signature) -> bool


        `is_some_on_signature(const plSignature &prototype_signature) const -> bool`  

        Returns *true* if the plComputableObjectType is at least one of the types
        described by *prototype_signature*.  

        """
        return _probt_python3.plComputableObject_is_some_on_signature(self, prototype_signature)


    def is_conditional(self) -> "bool":
        """
        is_conditional(self) -> bool


        `is_conditional() const -> bool`  

        Returns true if the distribution really is conditional.  

        """
        return _probt_python3.plComputableObject_is_conditional(self)


    def is_empty(self) -> "bool":
        """
        is_empty(self) -> bool


        `is_empty() const -> bool`  

        Return true if the object is default-constructed (as opposed to full-
        initialized).  

        """
        return _probt_python3.plComputableObject_is_empty(self)


    def get_signature(self) -> "plSignature const &":
        """
        get_signature(self) -> plSignature const &


        `get_signature() const -> const plSignature &`  

        Get the object full signature (e.g its actual type and parent classes)  

        """
        return _probt_python3.plComputableObject_get_signature(self)


    def get_computable_object_type(self) -> "plComputableObjectType":
        """
        get_computable_object_type(self) -> plComputableObjectType


        `get_computable_object_type() const -> plComputableObjectType`  

        Get the object actual (most derived) type.  

        See also: get_signature()  

        """
        return _probt_python3.plComputableObject_get_computable_object_type(self)


    def get_variables(self) -> "plVariablesConjunction":
        """
        get_variables(self) -> plVariablesConjunction


        `get_variables() const -> plVariablesConjunction`  

        Returns all the variables (left and right) of the computable object.  

        This is equivalent to get_left_variables() ^ get_right_variables().  

        """
        return _probt_python3.plComputableObject_get_variables(self)


    def get_left_variables(self) -> "plVariablesConjunction":
        """
        get_left_variables(self) -> plVariablesConjunction


        `get_left_variables() const -> plVariablesConjunction`  

        Returns the left variables of the computable object.  

        For instance, for a distribution representing P(A B | C D), this would return A
        B.  

        """
        return _probt_python3.plComputableObject_get_left_variables(self)


    def get_right_variables(self) -> "plVariablesConjunction":
        """
        get_right_variables(self) -> plVariablesConjunction


        `get_right_variables() const -> plVariablesConjunction`  

        Returns the right variables of the computable object.  

        For instance, for a conditional distribution representing P(A B | C D), this
        would return C D. This returns an empty plVariablesConjunction for a non-
        conditional distribution.  

        """
        return _probt_python3.plComputableObject_get_right_variables(self)


    def compute(self, *args) -> "plProbValue":
        """
        compute(self, values) -> plProbValue
        compute(self, values) -> plProbValue
        compute(self, values) -> plProbValue
        compute(self, values) -> plProbValue
        compute(self, values) -> plProbValue
        compute(self, values) -> plProbValue
        compute(self, parameter) -> plProbValue
        compute(self, parameter) -> plProbValue
        compute(self, parameter) -> plProbValue
        compute(self, parameter) -> plProbValue
        compute(self, parameter) -> plProbValue


        `compute(const plValues &values) const -> plProbValue`  
        `compute(const int *values) const -> plProbValue`  
        `compute(const unsigned int *values) const -> plProbValue`  
        `compute(const float *values) const -> plProbValue`  
        `compute(const double *values) const -> plProbValue`  
        `compute(const long double *values) const -> plProbValue`  
        `compute(const std::vector< int > &parameter) const -> plProbValue`  
        `compute(const std::vector< unsigned int > &parameter) const -> plProbValue`  
        `compute(const std::vector< float > &parameter) const -> plProbValue`  
        `compute(const std::vector< double > &parameter) const -> plProbValue`  
        `compute(const std::vector< long double > &parameter) const -> plProbValue`  

        Overloaded function
        -------------------
        * `compute(const plValues &values) const -> plProbValue`  

            Computes the value of the function for the input parameter *values*.  

            ATTENTION: the returned value is guaranteed to be NORMALIZED for and only
            for:  

            *   builtin distributions (basic distributions provided directly by ProBT),  
            *   compiled distributions (obtained by using the compile() method).  
            *   distributions obtained with *instantiate* called with parameter
                *ensure_normalization_on_compute* = *true*.  

            Calling compute() on distributions resulting from the ask and/or instantiate
            methods is not guaranteed to return a normalized value unless the
            instantiate method is called with parameter
            *ensure_normalization_on_compute* = *true*. To be sure to obtain normalized
            values, consider compiling these distributions using compile().  

            However, this method is useful if you just want to compare the relative
            magnitudes of several probability values.  

        * `compute(const int *values) const -> plProbValue`  

            Computes the value of the function for the array input parameter *values*.  

            ATTENTION: the returned value is guaranteed to be NORMALIZED for and only
            for:  

            *   builtin distributions (basic distributions provided by ProBT),  
            *   compiled distributions (obtained by using the *compile* method).  
            *   distributions obtained with *instantiate* called with parameter
                *ensure_normalization_on_compute* = *true*.  

            Calling compute() on distributions resulting from the ask and/or instantiate
            methods is not guaranteed to return a normalized value unless the
            instantiate method is called with parameter
            *ensure_normalization_on_compute* = true. To be sure to obtain normalized
            values, consider compiling these distributions using compile().  

        * `compute(const unsigned int *values) const -> plProbValue`  

            Computes the value of the function for the array input parameter *values*.  

            ATTENTION: the returned value is guaranteed to be NORMALIZED for and only
            for:  

            *   builtin distributions (basic distributions provided by ProBT),  
            *   compiled distributions (obtained by using the *compile* method).  
            *   distributions obtained with *instantiate* called with parameter
                *ensure_normalization_on_compute* = *true*.  

            Calling compute() on distributions resulting from the ask and/or instantiate
            methods is not guaranteed to return a normalized value unless the
            instantiate method is called with parameter
            *ensure_normalization_on_compute* = true. To be sure to obtain normalized
            values, consider compiling these distributions using compile().  

        * `compute(const float *values) const -> plProbValue`  

            Computes the value of the function for the array input parameter *values*.  

            ATTENTION: the returned value is guaranteed to be NORMALIZED for and only
            for:  

            *   builtin distributions (basic distributions provided by ProBT),  
            *   compiled distributions (obtained by using the *compile* method).  
            *   distributions obtained with *instantiate* called with parameter
                *ensure_normalization_on_compute* = *true*.  

            Calling compute() on distributions resulting from the ask and/or instantiate
            methods is not guaranteed to return a normalized value unless the
            instantiate method is called with parameter
            *ensure_normalization_on_compute* = true. To be sure to obtain normalized
            values, consider compiling these distributions using compile().  

        * `compute(const double *values) const -> plProbValue`  

            Computes the value of the function for the array input parameter *values*.  

            ATTENTION: the returned value is guaranteed to be NORMALIZED for and only
            for:  

            *   builtin distributions (basic distributions provided by ProBT),  
            *   compiled distributions (obtained by using the *compile* method).  
            *   distributions obtained with *instantiate* called with parameter
                *ensure_normalization_on_compute* = *true*.  

            Calling compute() on distributions resulting from the ask and/or instantiate
            methods is not guaranteed to return a normalized value unless the
            instantiate method is called with parameter
            *ensure_normalization_on_compute* = true. To be sure to obtain normalized
            values, consider compiling these distributions using compile().  

        * `compute(const long double *values) const -> plProbValue`  

        * `compute(const std::vector< int > &parameter) const -> plProbValue`  

            Computes the value of the function for the STL vector input parameter
            'values'.  

            ATTENTION: the returned value is guaranteed to be NORMALIZED for and only
            for:  

            *   builtin distributions (basic distributions provided by ProBT),  
            *   compiled distributions (obtained by using the *compile* method).  
            *   distributions obtained with *instantiate* called with parameter
                *ensure_normalization_on_compute* = true.  

            Calling compute() on distributions resulting from the ask and/or instantiate
            methods is not guaranteed to return a normalized value unless the
            instantiate method is called with parameter
            *ensure_normalization_on_compute* = *true*. To be sure to obtain normalized
            values, consider compiling these distributions using the *compile* method.  

        * `compute(const std::vector< unsigned int > &parameter) const -> plProbValue`  

            Computes the value of the function for the STL vector input parameter
            'values'.  

            ATTENTION: the returned value is guaranteed to be NORMALIZED for and only
            for:  

            *   builtin distributions (basic distributions provided by ProBT),  
            *   compiled distributions (obtained by using the *compile* method).  
            *   distributions obtained with *instantiate* called with parameter
                *ensure_normalization_on_compute* = true.  

            Calling compute() on distributions resulting from the ask and/or instantiate
            methods is not guaranteed to return a normalized value unless the
            instantiate method is called with parameter
            *ensure_normalization_on_compute* = *true*. To be sure to obtain normalized
            values, consider compiling these distributions using the *compile* method.  

        * `compute(const std::vector< float > &parameter) const -> plProbValue`  

            Computes the value of the function for the STL vector input parameter
            'values'.  

            ATTENTION: the returned value is guaranteed to be NORMALIZED for and only
            for:  

            *   builtin distributions (basic distributions provided by ProBT),  
            *   compiled distributions (obtained by using the *compile* method).  
            *   distributions obtained with *instantiate* called with parameter
                *ensure_normalization_on_compute* = true.  

            Calling compute() on distributions resulting from the ask and/or instantiate
            methods is not guaranteed to return a normalized value unless the
            instantiate method is called with parameter
            *ensure_normalization_on_compute* = *true*. To be sure to obtain normalized
            values, consider compiling these distributions using the *compile* method.  

        * `compute(const std::vector< double > &parameter) const -> plProbValue`  

            Computes the value of the function for the STL vector input parameter
            'values'.  

            ATTENTION: the returned value is guaranteed to be NORMALIZED for and only
            for:  

            *   builtin distributions (basic distributions provided by ProBT),  
            *   compiled distributions (obtained by using the *compile* method).  
            *   distributions obtained with *instantiate* called with parameter
                *ensure_normalization_on_compute* = true.  

            Calling compute() on distributions resulting from the ask and/or instantiate
            methods is not guaranteed to return a normalized value unless the
            instantiate method is called with parameter
            *ensure_normalization_on_compute* = *true*. To be sure to obtain normalized
            values, consider compiling these distributions using the *compile* method.  

        * `compute(const std::vector< long double > &parameter) const -> plProbValue`  

        """
        return _probt_python3.plComputableObject_compute(self, *args)


    def compute_log(self, *args) -> "plFloat":
        """
        compute_log(self, values) -> plFloat
        compute_log(self, values) -> plFloat
        compute_log(self, values) -> plFloat
        compute_log(self, values) -> plFloat
        compute_log(self, values) -> plFloat
        compute_log(self, values) -> plFloat
        compute_log(self, parameter) -> plFloat
        compute_log(self, parameter) -> plFloat
        compute_log(self, parameter) -> plFloat
        compute_log(self, parameter) -> plFloat
        compute_log(self, parameter) -> plFloat


        `compute_log(const plValues &values) const -> plFloat`  
        `compute_log(const int *values) const -> plFloat`  
        `compute_log(const unsigned int *values) const -> plFloat`  
        `compute_log(const float *values) const -> plFloat`  
        `compute_log(const double *values) const -> plFloat`  
        `compute_log(const long double *values) const -> plFloat`  
        `compute_log(const std::vector< int > &parameter) const -> plFloat`  
        `compute_log(const std::vector< unsigned int > &parameter) const -> plFloat`  
        `compute_log(const std::vector< float > &parameter) const -> plFloat`  
        `compute_log(const std::vector< double > &parameter) const -> plFloat`  
        `compute_log(const std::vector< long double > &parameter) const -> plFloat`  

        Overloaded function
        -------------------
        * `compute_log(const plValues &values) const -> plFloat`  

            Computes the logarithm value of the function for the input parameter
            *values*.  

        * `compute_log(const int *values) const -> plFloat`  

            Computes the logarithm value of the function for the input parameter
            *values*.  

        * `compute_log(const unsigned int *values) const -> plFloat`  

            Computes the logarithm value of the function for the input parameter
            *values*.  

        * `compute_log(const float *values) const -> plFloat`  

            Computes the logarithm value of the function for the input parameter
            *values*.  

        * `compute_log(const double *values) const -> plFloat`  

            Computes the logarithm value of the function for the input parameter
            *values*.  

        * `compute_log(const long double *values) const -> plFloat`  

        * `compute_log(const std::vector< int > &parameter) const -> plFloat`  

            Computes the logarithm value of the function for the input parameter
            *values*.  

        * `compute_log(const std::vector< unsigned int > &parameter) const -> plFloat`  

            Computes the logarithm value of the function for the input parameter
            *values*.  

        * `compute_log(const std::vector< float > &parameter) const -> plFloat`  

            Computes the logarithm value of the function for the input parameter
            *values*.  

        * `compute_log(const std::vector< double > &parameter) const -> plFloat`  

            Computes the logarithm value of the function for the input parameter
            *values*.  

        * `compute_log(const std::vector< long double > &parameter) const -> plFloat`  

        """
        return _probt_python3.plComputableObject_compute_log(self, *args)


    def rename(self, new_variables: 'plVariablesConjunction') -> "plComputableObject &":
        """
        rename(self, new_variables) -> plComputableObject


        `rename(const plVariablesConjunction &new_variables) -> plComputableObject &`  

        Renames the head variables of a function and returns a reference to it .  

        """
        return _probt_python3.plComputableObject_rename(self, new_variables)


    def write_head(self, *args) -> "std::ostream &":
        """
        write_head(self) -> std::ostream
        write_head(self) -> std::ostream &


        `write_head(std::ostream &out=std::cout) const -> std::ostream &`  

        Writes the the distribution head at the output stream *out*.  

        """
        return _probt_python3.plComputableObject_write_head(self, *args)


    def get_head_string(self) -> "std::string":
        """
        get_head_string(self) -> std::string


        `get_head_string() const -> std::string`  

        Get the distribution head as a string.  

        """
        return _probt_python3.plComputableObject_get_head_string(self)


    def write_body(self, *args) -> "std::ostream &":
        """
        write_body(self) -> std::ostream
        write_body(self) -> std::ostream &


        `write_body(std::ostream &out=std::cout) const -> std::ostream &`  

        Writes the distribution body at the output stream *out*.  

        """
        return _probt_python3.plComputableObject_write_body(self, *args)


    def get_body_string(self) -> "std::string":
        """
        get_body_string(self) -> std::string


        `get_body_string() const -> std::string`  

        Get the distribution body as a string.  

        """
        return _probt_python3.plComputableObject_get_body_string(self)


    def __mul__(self, *args) -> "plComputableObjectList":
        """
        __mul__(self, f2) -> plComputableObjectList
        __mul__(self, v_list) -> plComputableObjectList
        """
        return _probt_python3.plComputableObject___mul__(self, *args)


    def concatenate(self, *args) -> "plComputableObjectList":
        """
        concatenate(self, f2) -> plComputableObjectList
        concatenate(self, v_list) -> plComputableObjectList


        `concatenate(const plComputableObject &f2) const -> plComputableObjectList`  
        `concatenate(const plComputableObjectList &v_list) const ->
            plComputableObjectList`  

        Overloaded function
        -------------------
        * `concatenate(const plComputableObject &f2) const -> plComputableObjectList`  

            Concatenation with another computable object operator.  

        * `concatenate(const plComputableObjectList &v_list) const ->
            plComputableObjectList`  

            Concatenation with a computable objects list operator.  

        """
        return _probt_python3.plComputableObject_concatenate(self, *args)


    def replace(self, *args) -> "void":
        """
        replace(self, left_vars, right_vars, new_co)
        replace(self, left_vars, new_distribution)


        `replace(const plVariablesConjunction &left_vars, const plVariablesConjunction
            &right_vars, const plComputableObject &new_co)`  
        `replace(const plVariablesConjunction &left_vars, const plDistribution
            &new_distribution)`  

        Overloaded function
        -------------------
        * `replace(const plVariablesConjunction &left_vars, const plVariablesConjunction
            &right_vars, const plComputableObject &new_co)`  

            Replace the referenced distribution P(left_vars | right_vars) by another
            distribution *new_co*.  

            *new_cnd_distribution* must have the same left and right variables.  

            This method is intended to be used especially on non-compiled computable
            objects such as:  

            *   Expressions obtained using the *ask* method (see *plJointDistribution*
                class) and non-conditional expressions obtained using the *instantiate*
                method on the conditional expressions above.  
            *   Joint distribution objects (*plJointDistribution*).  

            Using *replace* affects only the computable object on which is called. To
            get a global effect, use *mutate* instead.  

            See also: plMutableComputableObject::mutate  

        * `replace(const plVariablesConjunction &left_vars, const plDistribution
            &new_distribution)`  

            Replace the distribution P(left_vars ) by another distribution
            *new_distribution*.  

            *new_distribution* must have the same left variables.  

            This method is intended to be used especially on non-compiled computable
            objects such as:  

            *   Expressions obtained using the *ask* method (see *plJointDistribution*
                class) and non-conditional expressions obtained using the *instantiate*
                method on the conditional expressions above.  
            *   Joint distribution objects (*plJointDistribution*).  

            Using *replace* affects only the computable object on which is called. To
            get a global effect, use *mutate* instead.  

            See also: plMutableComputableObject::mutate  

        """
        return _probt_python3.plComputableObject_replace(self, *args)


    def __eq__(self, other: 'plComputableObject') -> "bool":
        """__eq__(self, other) -> bool"""
        return _probt_python3.plComputableObject___eq__(self, other)


    def equal(self, other: 'plComputableObject') -> "bool":
        """
        equal(self, other) -> bool


        `equal(const plComputableObject &other) const -> bool`  

        Return *true* if this and the other object are the same.  

        """
        return _probt_python3.plComputableObject_equal(self, other)


    def __ne__(self, other: 'plComputableObject') -> "bool":
        """__ne__(self, other) -> bool"""
        return _probt_python3.plComputableObject___ne__(self, other)


    def not_equal(self, other: 'plComputableObject') -> "bool":
        """
        not_equal(self, other) -> bool


        `not_equal(const plComputableObject &other) const -> bool`  

        Return *true* if this and the other object are not the same.  

        """
        return _probt_python3.plComputableObject_not_equal(self, other)


    def is_builtin(self) -> "bool":
        """
        is_builtin(self) -> bool


        `is_builtin() const -> bool`  

        Returns *true* if and only if the computable object is a ProBT builtin one.  

        """
        return _probt_python3.plComputableObject_is_builtin(self)


    def print_evaluation_tree_infos(self) -> "std::ostream &":
        """
        print_evaluation_tree_infos(self) -> std::ostream &


        `print_evaluation_tree_infos(std::ostream &out) const -> std::ostream &`  

        Displays the evaluation tree corresponding to the computable object.  

        See also: get_exhaustive_compilation_complexity()  

        See also: get_exhaustive_update_complexity  

        """
        return _probt_python3.plComputableObject_print_evaluation_tree_infos(self)


    def get_exhaustive_compilation_complexity(self) -> "long double":
        """
        get_exhaustive_compilation_complexity(self) -> long double


        `get_exhaustive_compilation_complexity() const -> long double`  

        Get the sum of the number of sums and the number of products required to compile
        the corresponding expression.  

        See also: get_exhaustive_update_complexity()  

        See also: print_evaluation_tree_infos()  

        """
        return _probt_python3.plComputableObject_get_exhaustive_compilation_complexity(self)


    def get_exhaustive_update_complexity(self) -> "long double":
        """
        get_exhaustive_update_complexity(self) -> long double


        `get_exhaustive_update_complexity() const -> long double`  

        Get the sum of the number of sums and the number of products required to update
        the corresponding expression for a new given evidence value.  

        See also: get_exhaustive_compilation_complexity()  

        See also: print_evaluation_tree_infos  

        """
        return _probt_python3.plComputableObject_get_exhaustive_update_complexity(self)


    def is_mutable(self) -> "bool":
        """
        is_mutable(self) -> bool


        `is_mutable() const -> bool`  

        Get the mutability property.  

        Returns
        -------
        'true' if the computable object is mutable.  

        """
        return _probt_python3.plComputableObject_is_mutable(self)


    def tabulate(self, output: 'DoubleVector') -> "void":
        """
        tabulate(self, output)


        `tabulate(std::vector< plProbValue > &output) const`  

        Tabulates the computable object in the 'output' vector.  

        The value $ P(X) $ is computed for each possible value of the $ X $ variables
        and stored in the output vector 'output. Calling this method on computable
        objects with non-discretized continuous variables throws a plError(27)
        exception.  

        In multi-dimensional cases $ X = X_1 X_2 $, where $ X_1 $ and $ X_2 $ can take,
        for example, $ 1 \cdots n_1 $ and $ 1 \cdots n_2 $ values respectively, it
        constructs the probability table on $ P(X)$ as follows:  

        *   output[0] = $ P([X_1=1, X_2=1]) $  
        *   output[1] = $ P([X_1=1, X_2=2]) $  
            .  
             .  
             .  
        *   output[ $ n_2-1$] = $ P([X_1=1, X_2=n_2]) $  
        *   output[ $ n_2 $] = $ P([X_1=2, X_2=1]) $  
        *   output[ $ n_2+1 $] = $ P([X_1=2, X_2=2]) $  
             .  
             .  
             .  
        *   output[ $ 2 n_2 - 1 $] = $ P([X_1=2, X_2=n_2]) $  
             .  
             .  
             .  
        *   output[ $ n_1 n_2-1 $] = $ P([X_1=n_1, X_2=n_2]) $  
             The same tabulation scheme is used for conditional distributions (eg., $
            P(X_1 X_2 | Y_1 Y_2)$).  

        """
        return _probt_python3.plComputableObject_tabulate(self, output)


    def n_tabulate(self, output: 'DoubleVector', n: 'unsigned long') -> "void":
        """
        n_tabulate(self, output, n)


        `n_tabulate(std::vector< plProbValue > &output, long unsigned int n) const`  

        Same as tabulate(vector <plProbValue> &output) but using limited sampling
        iterations *n*.  

        """
        return _probt_python3.plComputableObject_n_tabulate(self, output, n)


    def time_tabulate(self, output: 'DoubleVector', time_in_seconds: 'double') -> "void":
        """
        time_tabulate(self, output, time_in_seconds)


        `time_tabulate(std::vector< plProbValue > &output, double time_in_seconds)
            const`  

        Same as tabulate(vector <plProbValue> &output) but using limited sampling time
        *time_in_seconds*.  

        """
        return _probt_python3.plComputableObject_time_tabulate(self, output, time_in_seconds)


    def get_factors(self) -> "plComputableObjectList":
        """
        get_factors(self) -> plComputableObjectList


        `get_factors() const -> plComputableObjectList`  

        Get the independant factors of a product computable object.  

        """
        return _probt_python3.plComputableObject_get_factors(self)


    def get_children(self) -> "plComputableObjectList":
        """
        get_children(self) -> plComputableObjectList


        `get_children() const -> plComputableObjectList`  

        Get expression children.  

        """
        return _probt_python3.plComputableObject_get_children(self)


    def get_marginalized_variables(self) -> "plVariablesConjunction":
        """
        get_marginalized_variables(self) -> plVariablesConjunction


        `get_marginalized_variables() const -> plVariablesConjunction`  

        Get expression marginalized variables.  

        """
        return _probt_python3.plComputableObject_get_marginalized_variables(self)


    def left_variable_dim(self) -> "size_t":
        """
        left_variable_dim(self) -> size_t


        `left_variable_dim() const -> size_t`  

        Get the dimension of the left variables.  

        """
        return _probt_python3.plComputableObject_left_variable_dim(self)


    def right_variable_dim(self) -> "size_t":
        """
        right_variable_dim(self) -> size_t


        `right_variable_dim() const -> size_t`  

        Get the dimension of the right variables.  

        """
        return _probt_python3.plComputableObject_right_variable_dim(self)


    def python_plot(self) -> "void":
        """
        python_plot(self)


        `python_plot()`  

        Only for Python: Plot the distribution.  

        """
        return _probt_python3.plComputableObject_python_plot(self)


    def __getstate__(self) -> "std::string":
        """__getstate__(self) -> std::string"""
        return _probt_python3.plComputableObject___getstate__(self)


    def __setstate_internal(self, sState: 'std::string const &') -> "void":
        """__setstate_internal(self, sState)"""
        return _probt_python3.plComputableObject___setstate_internal(self, sState)


    def __setstate__(self, sState):
        self.__init__()
        self.__setstate_internal(sState)

plComputableObject_swigregister = _probt_python3.plComputableObject_swigregister
plComputableObject_swigregister(plComputableObject)



def plComputableObjectList_str( cls ):
  s = "[ "
  for i in range(cls.size()):
    s += cls[i].to_string()
    if i!=cls.size()-1:
      s += ", "
  s += " ]"
  return s;

def plComputableObjectList_iter ( cls ):
  cls.index = -1
  return cls;

def plComputableObjectList_next( cls ):
  cls.index = cls.index + 1
  if cls.index<cls.size():
    return cls[cls.index]
  else:
    raise StopIteration

# done in pypl.i
#plComputableObjectList.__str__ = plComputableObjectList_str
#plComputableObjectList.__repr__ = plComputableObjectList.__str__

plComputableObjectList.__iter__ = plComputableObjectList_iter
plComputableObjectList.next = plComputableObjectList_next
plComputableObjectList.__next__ = plComputableObjectList_next
plComputableObjectList.__len__ = plComputableObjectList.size



class plDistribution(plComputableObject):
    """

    `plDistribution()`  
    `plDistribution(const plVariablesConjunction &variables, const plProbValue
        *table, bool already_normalized=false)`  
    `plDistribution(const plVariablesConjunction &variables, const std::vector<
        plProbValue > &table, bool already_normalized=false)`  
    `plDistribution(const plVariablesConjunction &variables)`  
    `plDistribution(const plVariablesConjunction &variables, const
        plComputableObjectType &sig)`  
    `plDistribution(const plDistribution &)`  
    `plDistribution(const plComputableObject &)`  
    `plDistribution(const plCndDistribution &)`  
    `plDistribution(const plComputableObjectList &)`  
    `plDistribution(const plComputableObjectList &fun_list, const
        plVariablesConjunction &variables)`  

    The *plDistribution* class is the base class of all non-conditional probability
    (and density) distributions.  

    Constructors
    ------------
    * `plDistribution()`  

        Empty constructor.  

        The resulting object is invalid for most operations, except for being
        assigned to, or used as a return value.  

    * `plDistribution(const plVariablesConjunction &variables, const plProbValue
        *table, bool already_normalized=false)`  

        Construct a plDistribution with an array of plProbValues implicitly defining
        a set of plProbTable.  

        ATTENTION: This constructor is reserved for discrete/discretized variables.  

        See also: plProbTable  

    * `plDistribution(const plVariablesConjunction &variables, const std::vector<
        plProbValue > &table, bool already_normalized=false)`  

        Construct a variables with a vector of plProbValues implicitly defining a
        set of plProbTable.  

        ATTENTION: This constructor is reserved for discrete variables.  

        See also: plProbTable  

    * `plDistribution(const plVariablesConjunction &variables)`  

        Construct a plDistribution (actually a plProbTable) containing random
        probability table.  

        See also: plProbTable  

    * `plDistribution(const plVariablesConjunction &variables, const
        plComputableObjectType &sig)`  

        Constructor with a set of variables and the signature.  

    * `plDistribution(const plDistribution &)`  

        Constructs a Distribution from another Distribution.  

    * `plDistribution(const plComputableObject &)`  

        Constructs from a plComputableObject.  

        The object transmitted as parameter has to actually point to a non-
        conditional distribution, else a plError is raised.  

    * `plDistribution(const plCndDistribution &)`  

        Construct from a plCndDistribution that has an empty list of known
        variables.  

    * `plDistribution(const plComputableObjectList &)`  

        Creates a non-conditional distribution as a product of a conditional and non
        conditional distributions.  

        Throws an exception if the result of the product is not actually a non-
        conditional distribution. The variables of the constructed distribution are
        the concatenation (in the same order) of the left variables of all the terms
        of the list.  

    * `plDistribution(const plComputableObjectList &fun_list, const
        plVariablesConjunction &variables)`  

        Creates a non-conditional distribution as a product of a conditional and non
        conditional distributions.  

        Throws an exception if the result of the product is not actually a non-
        conditional distribution. This constructor explicits the variables of the
        constructed distribution.  

    C++ includes: plDistribution.h

    """

    __swig_setmethods__ = {}
    for _s in [plComputableObject]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plDistribution, name, value)
    __swig_getmethods__ = {}
    for _s in [plComputableObject]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plDistribution, name)
    __repr__ = _swig_repr

    def __init__(self, *args):
        """
        __init__(self) -> plDistribution
        __init__(self, variables, table, already_normalized=False) -> plDistribution
        __init__(self, variables, table) -> plDistribution
        __init__(self, variables) -> plDistribution
        __init__(self, variables, sig) -> plDistribution
        __init__(self, arg2) -> plDistribution
        __init__(self, arg2) -> plDistribution
        __init__(self, arg2) -> plDistribution
        __init__(self, arg2) -> plDistribution
        __init__(self, fun_list, variables) -> plDistribution


        `plDistribution()`  
        `plDistribution(const plVariablesConjunction &variables, const plProbValue
            *table, bool already_normalized=false)`  
        `plDistribution(const plVariablesConjunction &variables, const std::vector<
            plProbValue > &table, bool already_normalized=false)`  
        `plDistribution(const plVariablesConjunction &variables)`  
        `plDistribution(const plVariablesConjunction &variables, const
            plComputableObjectType &sig)`  
        `plDistribution(const plDistribution &)`  
        `plDistribution(const plComputableObject &)`  
        `plDistribution(const plCndDistribution &)`  
        `plDistribution(const plComputableObjectList &)`  
        `plDistribution(const plComputableObjectList &fun_list, const
            plVariablesConjunction &variables)`  

        Overloaded function
        -------------------
        * `plDistribution()`  

            Empty constructor.  

            The resulting object is invalid for most operations, except for being
            assigned to, or used as a return value.  

        * `plDistribution(const plVariablesConjunction &variables, const plProbValue
            *table, bool already_normalized=false)`  

            Construct a plDistribution with an array of plProbValues implicitly defining
            a set of plProbTable.  

            ATTENTION: This constructor is reserved for discrete/discretized variables.  

            See also: plProbTable  

        * `plDistribution(const plVariablesConjunction &variables, const std::vector<
            plProbValue > &table, bool already_normalized=false)`  

            Construct a variables with a vector of plProbValues implicitly defining a
            set of plProbTable.  

            ATTENTION: This constructor is reserved for discrete variables.  

            See also: plProbTable  

        * `plDistribution(const plVariablesConjunction &variables)`  

            Construct a plDistribution (actually a plProbTable) containing random
            probability table.  

            See also: plProbTable  

        * `plDistribution(const plVariablesConjunction &variables, const
            plComputableObjectType &sig)`  

            Constructor with a set of variables and the signature.  

        * `plDistribution(const plDistribution &)`  

            Constructs a Distribution from another Distribution.  

        * `plDistribution(const plComputableObject &)`  

            Constructs from a plComputableObject.  

            The object transmitted as parameter has to actually point to a non-
            conditional distribution, else a plError is raised.  

        * `plDistribution(const plCndDistribution &)`  

            Construct from a plCndDistribution that has an empty list of known
            variables.  

        * `plDistribution(const plComputableObjectList &)`  

            Creates a non-conditional distribution as a product of a conditional and non
            conditional distributions.  

            Throws an exception if the result of the product is not actually a non-
            conditional distribution. The variables of the constructed distribution are
            the concatenation (in the same order) of the left variables of all the terms
            of the list.  

        * `plDistribution(const plComputableObjectList &fun_list, const
            plVariablesConjunction &variables)`  

            Creates a non-conditional distribution as a product of a conditional and non
            conditional distributions.  

            Throws an exception if the result of the product is not actually a non-
            conditional distribution. This constructor explicits the variables of the
            constructed distribution.  

        """
        this = _probt_python3.new_plDistribution(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this
    __swig_destroy__ = _probt_python3.delete_plDistribution
    __del__ = lambda self: None

    def draw_vector(self) -> "plFloatVector":
        """
        draw_vector(self) -> plFloatVector


        `draw_vector() const -> plFloatVector`  

        Get a sample as a plFloatVector.  

        """
        return _probt_python3.plDistribution_draw_vector(self)


    def n_compile(self, *args) -> "plDistribution":
        """
        n_compile(self, result, n, generator_type=PL_CHOOSE_GENERATOR_FOR_ME, compiled_distrib_type=PL_CHOOSE_COMP_TYPE_FOR_ME)
        n_compile(self, result, n, generator_type=PL_CHOOSE_GENERATOR_FOR_ME)
        n_compile(self, result, n)
        n_compile(self, n, generator_type=PL_CHOOSE_GENERATOR_FOR_ME, compiled_distrib_type=PL_CHOOSE_COMP_TYPE_FOR_ME) -> plDistribution
        n_compile(self, n, generator_type=PL_CHOOSE_GENERATOR_FOR_ME) -> plDistribution
        n_compile(self, n) -> plDistribution


        `n_compile(plDistribution &result, unsigned int n, plGeneratorType
            generator_type=PL_CHOOSE_GENERATOR_FOR_ME, plCompiledDistributionType
            compiled_distrib_type=PL_CHOOSE_COMP_TYPE_FOR_ME) const`  
        `n_compile(unsigned int n, plGeneratorType
            generator_type=PL_CHOOSE_GENERATOR_FOR_ME, plCompiledDistributionType
            compiled_distrib_type=PL_CHOOSE_COMP_TYPE_FOR_ME) const -> plDistribution`  

        Overloaded function
        -------------------
        * `n_compile(plDistribution &result, unsigned int n, plGeneratorType
            generator_type=PL_CHOOSE_GENERATOR_FOR_ME, plCompiledDistributionType
            compiled_distrib_type=PL_CHOOSE_COMP_TYPE_FOR_ME) const`  

            Compiles the distribution using an approximation, hopefully faster than the
            plain compile().  

            This approximation is performed by sampling the distribution. This function
            uses the number of sampling points as stop criterion.  

            Parameters:  
            * `result` :  
                The resulting compiled distribution  
            * `n` :  
                The number of sample points to be used  
            * `generator_type` :  
                The method to be used for generating the sample points. The allowed
                values are:  
                1) PL_EXHAUSTIVE_GENERATOR: Use all points of the discrete or
                discretized variables space (exhaustive exploration)  
                2) PL_RANDOM_GENERATOR: Uniform random exploration of the variable
                space.  
                3) PL_MC_GENERATOR: Random (non uniform) exploration of the variable
                space by drawing according to the sampled distribution.  
                4) PL_GA_GENERATOR: Exploration of the variable space using a genetic
                algorithm.  
                5) PL_CHOOSE_GENERATOR_FOR_ME: Let ProBT choose the most appropriate
                generation method (default value).  
            * `compiled_distrib_type` :  
                The internal data structure to be used for storing the resulting
                distribution. The allowed values are:  
                1) PL_TABLE: a probability table.  
                2) PL_MRBT: a Multi-Resolution Binary Tree representation.  
                3) PL_MAP: a map for non-null values.  
                4) PL_CHOOSE_COMP_TYPE_FOR_ME: Let ProBT choose the most appropriate
                structure (default value).  

            See also: time_compile()  

        * `n_compile(unsigned int n, plGeneratorType
            generator_type=PL_CHOOSE_GENERATOR_FOR_ME, plCompiledDistributionType
            compiled_distrib_type=PL_CHOOSE_COMP_TYPE_FOR_ME) const -> plDistribution`  

            Does a n_compile(), and returns the compiled distribution.  

            See n_compile() above for details. Note that this method returns a freshly
            created object. If you are calling it in a loop, consider using the version
            that modifies an existing object instead.  

        """
        return _probt_python3.plDistribution_n_compile(self, *args)


    def time_compile(self, *args) -> "plDistribution":
        """
        time_compile(self, result, time_in_seconds, generator_type=PL_CHOOSE_GENERATOR_FOR_ME, compiled_distrib_type=PL_CHOOSE_COMP_TYPE_FOR_ME)
        time_compile(self, result, time_in_seconds, generator_type=PL_CHOOSE_GENERATOR_FOR_ME)
        time_compile(self, result, time_in_seconds)
        time_compile(self, time_in_seconds, generator_type=PL_CHOOSE_GENERATOR_FOR_ME, compliled_distrib_type=PL_CHOOSE_COMP_TYPE_FOR_ME) -> plDistribution
        time_compile(self, time_in_seconds, generator_type=PL_CHOOSE_GENERATOR_FOR_ME) -> plDistribution
        time_compile(self, time_in_seconds) -> plDistribution


        `time_compile(plDistribution &result, double time_in_seconds, plGeneratorType
            generator_type=PL_CHOOSE_GENERATOR_FOR_ME, plCompiledDistributionType
            compiled_distrib_type=PL_CHOOSE_COMP_TYPE_FOR_ME) const`  
        `time_compile(double time_in_seconds, plGeneratorType
            generator_type=PL_CHOOSE_GENERATOR_FOR_ME, plCompiledDistributionType
            compliled_distrib_type=PL_CHOOSE_COMP_TYPE_FOR_ME) const -> plDistribution`  

        Overloaded function
        -------------------
        * `time_compile(plDistribution &result, double time_in_seconds, plGeneratorType
            generator_type=PL_CHOOSE_GENERATOR_FOR_ME, plCompiledDistributionType
            compiled_distrib_type=PL_CHOOSE_COMP_TYPE_FOR_ME) const`  

            Compiles the distribution using an approximation, hopefully faster than the
            plain compile().  

            This approximation is performed by sampling the distribution. This function
            uses the running time as stop criterion.  

            Parameters:  
            * `result` :  
                The resulting compiled distribution  
            * `time_in_seconds` :  
                The time (in seconds) to be spent in generating sample points.  
            * `generator_type` :  
                The method to be used for generating the sample points. The allowed
                values are:  
                1) PL_EXHAUSTIVE_GENERATOR: Use all points of the discrete or
                discretized variables space (exhaustive exploration)  
                2) PL_RANDOM_GENERATOR: Uniform random exploration of the variable
                space.  
                3) PL_MC_GENERATOR: Random (non uniform) exploration of the variable
                space by drawing according to the sampled distribution.  
                4) PL_GA_GENERATOR: Exploration of the variable space using a genetic
                algorithm.  
                5) PL_CHOOSE_GENERATOR_FOR_ME: Let ProBT choose the most appropriate
                generation method (default value).  
            * `compiled_distrib_type` :  
                The internal data structure to be used for storing the resulting
                distribution. The allowed values are:  
                1) PL_TABLE: a probability table.  
                2) PL_MRBT: a Multi-Resolution Binary Tree representation.  
                3) PL_MAP: a map for non-null values.  
                4) PL_CHOOSE_COMP_TYPE_FOR_ME: Let ProBT choose the most appropriate
                structure (default value).  

            See also: n_compile()  

        * `time_compile(double time_in_seconds, plGeneratorType
            generator_type=PL_CHOOSE_GENERATOR_FOR_ME, plCompiledDistributionType
            compliled_distrib_type=PL_CHOOSE_COMP_TYPE_FOR_ME) const -> plDistribution`  

            Does a time_compile(), and returns the compiled distribution.  

            See time_compile() above for details. Note that this method returns a
            freshly created object. If you are calling it in a loop, consider using the
            version that modifies an existing object instead.  

        """
        return _probt_python3.plDistribution_time_compile(self, *args)


    def compile_low_memory_use(self, result: 'plDistribution') -> "void":
        """
        compile_low_memory_use(self, result)


        `compile_low_memory_use(plDistribution &result) const`  

        Compiles the distribution using an exhaustive generator
        (PL_EXHAUSTIVE_GENERATOR) (i.e.  

        by generating all points of the discrete or discretized variables space) and
        stores the result as a table (PL_TABLE)  

        """
        return _probt_python3.plDistribution_compile_low_memory_use(self, result)


    def compile(self, *args) -> "void":
        """
        compile(self, result)
        compile(self) -> plDistribution
        compile(self, result, compiled_distrib_type)


        `compile(plDistribution &result) const`  
        `compile() const -> plDistribution`  
        `compile(plDistribution &result, plCompiledDistributionType
            compiled_distrib_type) const`  

        Overloaded function
        -------------------
        * `compile(plDistribution &result) const`  

            Compiles the distribution using an exhaustive generator
            (PL_EXHAUSTIVE_GENERATOR) (i.e.  

            by generating all points of the discrete or discretized variables space) and
            stores the result as a table (PL_TABLE)  

        * `compile() const -> plDistribution`  

            Compiles the distribution using an exhaustive generator
            (PL_EXHAUSTIVE_GENERATOR) (i.e.  

            by generating all points of the discrete or discretized variables space) and
            stores the result as a table (PL_TABLE). Note that this method returns a
            freshly created object. If you are calling it in a loop, consider using the
            version that modifies an existing object instead.  

        * `compile(plDistribution &result, plCompiledDistributionType
            compiled_distrib_type) const`  

            Compiles the distribution using an exhaustive generator
            (PL_EXHAUSTIVE_GENERATOR) (i.e.  

            by generating all points of the discrete or discretized variables space) and
            stores the result as a *compiled_distrib_type*  

        """
        return _probt_python3.plDistribution_compile(self, *args)


    def incremental_n_compile(self, result: 'plDistribution', n_iterations: 'unsigned int', generatorType: 'plGeneratorType'=PL_CHOOSE_GENERATOR_FOR_ME, distrib_type: 'plCompiledDistributionType'=PL_CHOOSE_COMP_TYPE_FOR_ME) -> "void":
        """
        incremental_n_compile(self, result, n_iterations, generatorType=PL_CHOOSE_GENERATOR_FOR_ME, distrib_type=PL_CHOOSE_COMP_TYPE_FOR_ME)
        incremental_n_compile(self, result, n_iterations, generatorType=PL_CHOOSE_GENERATOR_FOR_ME)
        incremental_n_compile(self, result, n_iterations)


        `incremental_n_compile(plDistribution &result, unsigned int n_iterations,
            plGeneratorType generatorType=PL_CHOOSE_GENERATOR_FOR_ME,
            plCompiledDistributionType distrib_type=PL_CHOOSE_COMP_TYPE_FOR_ME) const`  

        Like n_compile() with the possibility to incrementally compile the distribution.  

        It assumes to be called on the same result distribution "result" to update it.
        It also assumes that this result distribution is empty for the first call. The
        first call is equivalent to a call to n_compile(). The parameters
        "generatorType" and "distrib_type" are taken into account only in the first
        call.  

        """
        return _probt_python3.plDistribution_incremental_n_compile(self, result, n_iterations, generatorType, distrib_type)


    def incremental_time_compile(self, result: 'plDistribution', time_in_seconds: 'double', generatorType: 'plGeneratorType'=PL_CHOOSE_GENERATOR_FOR_ME, distrib_type: 'plCompiledDistributionType'=PL_CHOOSE_COMP_TYPE_FOR_ME) -> "void":
        """
        incremental_time_compile(self, result, time_in_seconds, generatorType=PL_CHOOSE_GENERATOR_FOR_ME, distrib_type=PL_CHOOSE_COMP_TYPE_FOR_ME)
        incremental_time_compile(self, result, time_in_seconds, generatorType=PL_CHOOSE_GENERATOR_FOR_ME)
        incremental_time_compile(self, result, time_in_seconds)


        `incremental_time_compile(plDistribution &result, double time_in_seconds,
            plGeneratorType generatorType=PL_CHOOSE_GENERATOR_FOR_ME,
            plCompiledDistributionType distrib_type=PL_CHOOSE_COMP_TYPE_FOR_ME) const`  

        Like time_compile() with the possibility to incrementally compile the
        distribution.  

        It assumes to be called on the same result distribution "result" to update it.
        It also assumes that this result distribution is empty for the first call. The
        first call is equivalent to a call to time_compile(). The parameters
        "generatorType" and "distrib_type" are taken into account only in the first
        call.  

        """
        return _probt_python3.plDistribution_incremental_time_compile(self, result, time_in_seconds, generatorType, distrib_type)


    def tabulate(self, *args) -> "void":
        """
        tabulate(self, output)
        tabulate(self)


        `tabulate(std::ostream &out=std::cout, bool print_on_zero=true) const`  
        `tabulate(std::vector< plValues > &values, std::vector< plProbValue >
            &probabilities) const`  

        Overloaded function
        -------------------
        * `tabulate(std::ostream &out=std::cout, bool print_on_zero=true) const`  

            Tabulates the distribution in "out" stream.  

            Each of the possible values of the distribution variables set are printed
            together with the result of "compute". Function not allowed for non-
            discretized continuous variables.  
             If the parameter *print_on_zero* is set to *false*, cases having O as
            probability value are not written  

        * `tabulate(std::vector< plValues > &values, std::vector< plProbValue >
            &probabilities) const`  

            Tabulates the distribution in "output" plProbValue vector and fills the
            "values" with the corresponding variable values.  

            The value P(X) is computed for each possible value of the distribution
            variables and put in the output vector "output". Function not allowed for
            distributions with non-discretized continuous variables.  
             Same as the method above for multi-dimensional cases.  

            For Python, the signature of this function is changed to return its results.
            It can be used as follows:  

                distribution = ...
                values, probabilities = distribution.tabulate()


        """
        return _probt_python3.plDistribution_tabulate(self, *args)


    def sorted_tabulate(self, output: 'PairVPVVector') -> "void":
        """
        sorted_tabulate(self, output)


        `sorted_tabulate(std::vector< std::pair< plValues, plProbValue > > &output)
            const`  

        Tabulates the distribution in "output" vector <pair <plDataValues,
        plProbValue> >.  

        The The value P(X) is computed for each possible value of the distribution
        variables and put, sorted by probability in the output map "output". Function
        not allowed for Distributions with non-discretized continuous variables.  

        """
        return _probt_python3.plDistribution_sorted_tabulate(self, output)


    def plot(self, *args) -> "void":
        """
        plot(self, file_name, plottype=PL_DEFAULT_PLOT, n_samples=100)
        plot(self, file_name, plottype=PL_DEFAULT_PLOT)
        plot(self, file_name)
        plot(self, file_name, plottype=PL_DEFAULT_PLOT, n_samples=100)


        `plot(const std::string &file_name, plPlotType plottype=PL_DEFAULT_PLOT, int
            n_samples=100) const`  
        `plot(const char *file_name, plPlotType plottype=PL_DEFAULT_PLOT, int
            n_samples=100) const`  

        Overloaded function
        -------------------
        * `plot(const std::string &file_name, plPlotType plottype=PL_DEFAULT_PLOT, int
            n_samples=100) const`  

            Generates a set of gnuplot instructions allowing to plot this distribution.  

            This function is allowed for 1D and 2D distributions only.  

            Parameters:  
            * `file_name` :  
                The name of the gnuplot instructions file to be generated  
            * `plottype` :  
                The 'terminal' type to be used by gnuplot (see plPlotType definition)  
            * `n_samples` :  
                The 'samples' parameter to be used by gnuplot (only used for continuous
                distributions)  

            ATTENTION: The function does not call the 'gnuplot' command directly. You
            have to call the 'gnuplot' command using the generated file in order to get
            the plot (on your screen or in a image file according to the value of the
            parameter 'plottype').  

        * `plot(const char *file_name, plPlotType plottype=PL_DEFAULT_PLOT, int
            n_samples=100) const`  

        """
        return _probt_python3.plDistribution_plot(self, *args)


    def time_best(self, *args) -> "plValues":
        """
        time_best(self, result, time_in_seconds)
        time_best(self, result, time_in_seconds)
        time_best(self, result, time_in_seconds)
        time_best(self, result, time_in_seconds)
        time_best(self, result, time_in_seconds)
        time_best(self, result, time_in_seconds)
        time_best(self, result, time_in_seconds)
        time_best(self, result, time_in_seconds)
        time_best(self, result, time_in_seconds)
        time_best(self, result, time_in_seconds)
        time_best(self, result, time_in_seconds)
        time_best(self, result, time_in_seconds)
        time_best(self, result, time_in_seconds)
        time_best(self, result, time_in_seconds)
        time_best(self, result, time_in_seconds)
        time_best(self, res, time_in_seconds)
        time_best(self, time_in_seconds) -> plValues


        `time_best(int *result, double time_in_seconds) const`  
        `time_best(unsigned int *result, double time_in_seconds) const`  
        `time_best(float *result, double time_in_seconds) const`  
        `time_best(double *result, double time_in_seconds) const`  
        `time_best(long double *result, double time_in_seconds) const`  
        `time_best(int &result, double time_in_seconds) const`  
        `time_best(unsigned int &result, double time_in_seconds) const`  
        `time_best(float &result, double time_in_seconds) const`  
        `time_best(double &result, double time_in_seconds) const`  
        `time_best(long double &result, double time_in_seconds) const`  
        `time_best(std::vector< int > &result, double time_in_seconds) const`  
        `time_best(std::vector< unsigned int > &result, double time_in_seconds) const`  
        `time_best(std::vector< float > &result, double time_in_seconds) const`  
        `time_best(std::vector< double > &result, double time_in_seconds) const`  
        `time_best(std::vector< long double > &result, double time_in_seconds) const`  
        `time_best(plValues &res, double time_in_seconds) const`  
        `time_best(double time_in_seconds) const -> plValues`  

        Overloaded function
        -------------------
        * `time_best(int *result, double time_in_seconds) const`  

            Optimizes the function by running an optimization algorithm for
            *time_in_seconds* seconds and returns the function variables values that
            executes that optimization in an array.  

            The size of *parameter* must be at least the number of parameters.
            Implemented for int, unsigned int, float, and double types.  

        * `time_best(unsigned int *result, double time_in_seconds) const`  

        * `time_best(float *result, double time_in_seconds) const`  

        * `time_best(double *result, double time_in_seconds) const`  

        * `time_best(long double *result, double time_in_seconds) const`  

        * `time_best(int &result, double time_in_seconds) const`  

            Optimizes the function by running an optimization algorithm for
            *time_in_seconds* seconds and returns the function variables values that
            executes that optimization in a scalar variable.  

            Attention mainly used with one variable distributions. For two or more
            variables distributions the first variable value will be copied at
            *parameter* while the others will be ignored. Implemented for int, unsigned
            int, float, and double types.  

        * `time_best(unsigned int &result, double time_in_seconds) const`  

        * `time_best(float &result, double time_in_seconds) const`  

        * `time_best(double &result, double time_in_seconds) const`  

        * `time_best(long double &result, double time_in_seconds) const`  

        * `time_best(std::vector< int > &result, double time_in_seconds) const`  

            Optimizes the function by running an optimization algorithm for
            *time_in_seconds* seconds and returns the function variables values that
            executes that optimization in an STL vector Attention mainly used with one
            variable distributions.  

            For two or more variables distributions the first variable value will be
            copied at *parameter* while the others will be ignored. Implemented for int,
            unsigned int, float, and double types.  

        * `time_best(std::vector< unsigned int > &result, double time_in_seconds) const`  

        * `time_best(std::vector< float > &result, double time_in_seconds) const`  

        * `time_best(std::vector< double > &result, double time_in_seconds) const`  

        * `time_best(std::vector< long double > &result, double time_in_seconds) const`  

        * `time_best(plValues &res, double time_in_seconds) const`  

            Optimizes the function by running an optimization algorithm for
            *time_in_seconds* seconds and returns the function variables values that
            executes that optimization in a plValues.  

        * `time_best(double time_in_seconds) const -> plValues`  

            Optimizes the function.  

            Note that this method returns a freshly created object. If you are calling
            it in a loop, consider using the version that modifies an existing object
            instead.  

        """
        return _probt_python3.plDistribution_time_best(self, *args)


    def n_best(self, *args) -> "void":
        """
        n_best(self, res, n)
        n_best(self, n) -> plValues
        n_best(self, result, n)
        n_best(self, result, n)
        n_best(self, result, n)
        n_best(self, result, n)
        n_best(self, result, n)
        n_best(self, result, n)
        n_best(self, result, n)
        n_best(self, result, n)
        n_best(self, result, n)
        n_best(self, result, n)
        n_best(self, parameter, n)
        n_best(self, parameter, n)
        n_best(self, parameter, n)
        n_best(self, parameter, n)
        n_best(self, parameter, n)


        `n_best(plValues &res, unsigned int n) const`  
        `n_best(unsigned int n) const -> plValues`  
        `n_best(int *result, unsigned int n) const`  
        `n_best(unsigned int *result, unsigned int n) const`  
        `n_best(float *result, unsigned int n) const`  
        `n_best(double *result, unsigned int n) const`  
        `n_best(long double *result, unsigned int n) const`  
        `n_best(int &result, unsigned int n) const`  
        `n_best(unsigned int &result, unsigned int n) const`  
        `n_best(float &result, unsigned int n) const`  
        `n_best(double &result, unsigned int n) const`  
        `n_best(long double &result, unsigned int n) const`  
        `n_best(std::vector< int > &parameter, unsigned int n) const`  
        `n_best(std::vector< unsigned int > &parameter, unsigned int n) const`  
        `n_best(std::vector< float > &parameter, unsigned int n) const`  
        `n_best(std::vector< double > &parameter, unsigned int n) const`  
        `n_best(std::vector< long double > &parameter, unsigned int n) const`  

        Overloaded function
        -------------------
        * `n_best(plValues &res, unsigned int n) const`  

            Optimizes the function by running an optimization algorithm for *ns*
            iterations and returns the function variables values that executes that
            optimization in a plValues.  

        * `n_best(unsigned int n) const -> plValues`  

            Optimizes the function.  

            Note that this method returns a freshly created object. If you are calling
            it in a loop, consider using the version that modifies an existing object
            instead.  

        * `n_best(int *result, unsigned int n) const`  

            Optimizes the function by running an optimization algorithm for *n*
            iterations and returns the function variables values that executes that
            optimization in an array.  

            The size of *parameter* must be at least the number of parameters.
            Implemented for int, unsigned int, float, and double types.  

        * `n_best(unsigned int *result, unsigned int n) const`  

        * `n_best(float *result, unsigned int n) const`  

        * `n_best(double *result, unsigned int n) const`  

        * `n_best(long double *result, unsigned int n) const`  

        * `n_best(int &result, unsigned int n) const`  

            Optimizes the function by running an optimization algorithm for *n*
            iterations and returns the function variables values that executes that
            optimization in a scalar variable.  

            Attention mainly used with one variable distributions. For two or more
            variables distributions the first variable value will be copied at
            *parameter* while the others will be ignored. Implemented for int, unsigned
            int, float, and double types.  

        * `n_best(unsigned int &result, unsigned int n) const`  

        * `n_best(float &result, unsigned int n) const`  

        * `n_best(double &result, unsigned int n) const`  

        * `n_best(long double &result, unsigned int n) const`  

        * `n_best(std::vector< int > &parameter, unsigned int n) const`  

            Optimizes the function by running an optimization algorithm for *n*
            iterations and returns the function variables values that executes that
            optimization in an STL vector Attention mainly used with one variable
            distributions.  

            For two or more variables distributions the first variable value will be
            copied at *parameter* while the others will be ignored. Implemented for int,
            unsigned int, float, and double types.  

        * `n_best(std::vector< unsigned int > &parameter, unsigned int n) const`  

        * `n_best(std::vector< float > &parameter, unsigned int n) const`  

        * `n_best(std::vector< double > &parameter, unsigned int n) const`  

        * `n_best(std::vector< long double > &parameter, unsigned int n) const`  

        """
        return _probt_python3.plDistribution_n_best(self, *args)


    def draw(self, *args) -> "void":
        """
        draw(self, res)
        draw(self) -> plValues
        draw(self, resuls)
        draw(self, resuls)
        draw(self, resuls)
        draw(self, resuls)
        draw(self, resuls)
        draw(self, result)
        draw(self, result)
        draw(self, result)
        draw(self, result)
        draw(self, result)
        draw(self, result)
        draw(self, result)
        draw(self, result)
        draw(self, result)
        draw(self, result)
        draw(self, res, initial_state, proposal_standard_deviation, n, probability_log)
        draw(self, parameter, initial_state, proposal_standard_deviation, n, probability_log)
        draw(self, parameter, initial_state, proposal_standard_deviation, n, probability_log)
        draw(self, parameter, initial_state, proposal_standard_deviation, n, probability_log)
        draw(self, parameter, initial_state, proposal_standard_deviation, n, probability_log)
        draw(self, parameter, initial_state, proposal_standard_deviation, n, probability_log)
        draw(self, parameter, initial_state, proposal_standard_deviation, n, probability_log)
        draw(self, parameter, initial_state, proposal_standard_deviation, n, probability_log)
        draw(self, parameter, initial_state, proposal_standard_deviation, n, probability_log)
        draw(self, parameter, initial_state, proposal_standard_deviation, n, probability_log)
        draw(self, parameter, initial_state, proposal_standard_deviation, n, probability_log)
        draw(self, parameter, initial_state, proposal_standard_deviation, n, probability_log)
        draw(self, parameter, initial_state, proposal_standard_deviation, n, probability_log)
        draw(self, parameter, initial_state, proposal_standard_deviation, n, probability_log)
        draw(self, parameter, initial_state, proposal_standard_deviation, n, probability_log)
        draw(self, parameter, initial_state, proposal_standard_deviation, n, probability_log)


        `draw(plValues &res) const`  
        `draw() const -> plValues`  
        `draw(int *resuls) const`  
        `draw(unsigned int *resuls) const`  
        `draw(float *resuls) const`  
        `draw(double *resuls) const`  
        `draw(long double *resuls) const`  
        `draw(int &result) const`  
        `draw(unsigned int &result) const`  
        `draw(float &result) const`  
        `draw(double &result) const`  
        `draw(long double &result) const`  
        `draw(std::vector< int > &result) const`  
        `draw(std::vector< unsigned int > &result) const`  
        `draw(std::vector< float > &result) const`  
        `draw(std::vector< double > &result) const`  
        `draw(std::vector< long double > &result) const`  
        `draw(plValues &res, const plValues &initial_state, const std::vector< plFloat >
            &proposal_standard_deviation, unsigned int n, plFloat &probability_log)
            const`  
        `draw(int *parameter, const plValues &initial_state, const std::vector< plFloat
            > &proposal_standard_deviation, unsigned int n, plFloat &probability_log)
            const`  
        `draw(unsigned int *parameter, const plValues &initial_state, const std::vector<
            plFloat > &proposal_standard_deviation, unsigned int n, plFloat
            &probability_log) const`  
        `draw(float *parameter, const plValues &initial_state, const std::vector<
            plFloat > &proposal_standard_deviation, unsigned int n, plFloat
            &probability_log) const`  
        `draw(double *parameter, const plValues &initial_state, const std::vector<
            plFloat > &proposal_standard_deviation, unsigned int n, plFloat
            &probability_log) const`  
        `draw(long double *parameter, const plValues &initial_state, const std::vector<
            plFloat > &proposal_standard_deviation, unsigned int n, plFloat
            &probability_log) const`  
        `draw(int &parameter, const plValues &initial_state, const std::vector< plFloat
            > &proposal_standard_deviation, unsigned int n, plFloat &probability_log)
            const`  
        `draw(unsigned int &parameter, const plValues &initial_state, const std::vector<
            plFloat > &proposal_standard_deviation, unsigned int n, plFloat
            &probability_log) const`  
        `draw(float &parameter, const plValues &initial_state, const std::vector<
            plFloat > &proposal_standard_deviation, unsigned int n, plFloat
            &probability_log) const`  
        `draw(double &parameter, const plValues &initial_state, const std::vector<
            plFloat > &proposal_standard_deviation, unsigned int n, plFloat
            &probability_log) const`  
        `draw(long double &parameter, const plValues &initial_state, const std::vector<
            plFloat > &proposal_standard_deviation, unsigned int n, plFloat
            &probability_log) const`  
        `draw(std::vector< int > &parameter, const plValues &initial_state, const
            std::vector< plFloat > &proposal_standard_deviation, unsigned int n, plFloat
            &probability_log) const`  
        `draw(std::vector< unsigned int > &parameter, const plValues &initial_state,
            const std::vector< plFloat > &proposal_standard_deviation, unsigned int n,
            plFloat &probability_log) const`  
        `draw(std::vector< float > &parameter, const plValues &initial_state, const
            std::vector< plFloat > &proposal_standard_deviation, unsigned int n, plFloat
            &probability_log) const`  
        `draw(std::vector< double > &parameter, const plValues &initial_state, const
            std::vector< plFloat > &proposal_standard_deviation, unsigned int n, plFloat
            &probability_log) const`  
        `draw(std::vector< long double > &parameter, const plValues &initial_state,
            const std::vector< plFloat > &proposal_standard_deviation, unsigned int n,
            plFloat &probability_log) const`  

        Overloaded function
        -------------------
        * `draw(plValues &res) const`  

            Draw a set of function variables values, according to the function
            distribution and depose them in a plValues.  

        * `draw() const -> plValues`  

            Draw a set of function variables values, according to the function
            distribution and depose them in a plValues.  

            Note that this method returns a freshly created object. If you are calling
            it in a loop, consider using the version that modifies an existing object
            instead.  

        * `draw(int *resuls) const`  

            Draw a set of function variables values, according to the function
            distribution and depose them in an array.  

            Implemented for int, unsigned int, float, and double types.  

        * `draw(unsigned int *resuls) const`  

        * `draw(float *resuls) const`  

        * `draw(double *resuls) const`  

        * `draw(long double *resuls) const`  

        * `draw(int &result) const`  

            Draw a set of function variables values, according to the function
            distribution and depose them in the parameter.  

            Attention mainly used with one variable distributions. For two or more
            variables distributions the first variable value will be copied at
            *parameter* while the others will be ignored. Implemented for int, unsigned
            int, float, and double types.  

        * `draw(unsigned int &result) const`  

        * `draw(float &result) const`  

        * `draw(double &result) const`  

        * `draw(long double &result) const`  

        * `draw(std::vector< int > &result) const`  

            Draw a set of function variables values, according to the function
            distribution and depose them in an STL vector.  

            Implemented for int, unsigned int, float, and double types.  

        * `draw(std::vector< unsigned int > &result) const`  

        * `draw(std::vector< float > &result) const`  

        * `draw(std::vector< double > &result) const`  

        * `draw(std::vector< long double > &result) const`  

        * `draw(plValues &res, const plValues &initial_state, const std::vector< plFloat
            > &proposal_standard_deviation, unsigned int n, plFloat &probability_log)
            const`  

            Draw a set of function variables values, according to the function
            distribution and depose them in a plValues.  

            Parameters "initial_state", "proposal_standard_deviation", and "n" are
            only used when drawing non-compiled distribution (i.e. using Metropolis
            algorithm). They represent:  

            *   initial_state: the initial point from which the Metropolis sampler will
                start.  
            *   proposal_standard_deviation: The standard deviations of the normals that
                will be used when generating Metropolis candidate points.  
            *   n: the number of steps that the Metropolis sampler will run before
                returning a drawn point.  
            *   probability_log: the log-probability (or density value) of the returned
                point.  

        * `draw(int *parameter, const plValues &initial_state, const std::vector<
            plFloat > &proposal_standard_deviation, unsigned int n, plFloat
            &probability_log) const`  

            Draw a set of function variables values, according to the function
            distribution and depose them in a scalar array.  

            Parameters "initial_state", "proposal_standard_deviation", and "n" are
            only used when drawing non-compiled distribution (i.e. using Metropolis
            algorithm). They represent:  

            *   initial_state: the initial point from which the Metropolis sampler will
                start.  
            *   proposal_standard_deviation: The standard deviations of the normals that
                will be used when generating Metropolis candidate points.  
            *   n: the number of steps that the Metropolis sampler will run before
                returning a drawn point.  
            *   probability_log: the log-probability (or density value) of the returned
                point. Implemented for int, unsigned int, float, and double types.  

        * `draw(unsigned int *parameter, const plValues &initial_state, const
            std::vector< plFloat > &proposal_standard_deviation, unsigned int n, plFloat
            &probability_log) const`  

        * `draw(float *parameter, const plValues &initial_state, const std::vector<
            plFloat > &proposal_standard_deviation, unsigned int n, plFloat
            &probability_log) const`  

        * `draw(double *parameter, const plValues &initial_state, const std::vector<
            plFloat > &proposal_standard_deviation, unsigned int n, plFloat
            &probability_log) const`  

        * `draw(long double *parameter, const plValues &initial_state, const
            std::vector< plFloat > &proposal_standard_deviation, unsigned int n, plFloat
            &probability_log) const`  

        * `draw(int &parameter, const plValues &initial_state, const std::vector<
            plFloat > &proposal_standard_deviation, unsigned int n, plFloat
            &probability_log) const`  

            Draw a set of function variables values, according to the function
            distribution and depose them in a scalar variable.  

            Attention mainly used with one variable distributions. For two or more
            variables distributions the first variable value will be copied at
            *parameter* while the others will be ignored. Parameters "initial_state",
            "proposal_standard_deviation", and "n" are only used when drawing non-
            compiled distribution (i.e. using Metropolis algorithm). They represent:  

            *   initial_state: the initial point from which the Metropolis sampler will
                start.  
            *   proposal_standard_deviation: The standard deviations of the normals that
                will be used when generating Metropolis candidate points.  
            *   n: the number of steps that the Metropolis sampler will run before
                returning a drawn point.  
            *   probability_log: the log-probability (or density value) of the returned
                point. Implemented for int, unsigned int, float, and double types.  

        * `draw(unsigned int &parameter, const plValues &initial_state, const
            std::vector< plFloat > &proposal_standard_deviation, unsigned int n, plFloat
            &probability_log) const`  

        * `draw(float &parameter, const plValues &initial_state, const std::vector<
            plFloat > &proposal_standard_deviation, unsigned int n, plFloat
            &probability_log) const`  

        * `draw(double &parameter, const plValues &initial_state, const std::vector<
            plFloat > &proposal_standard_deviation, unsigned int n, plFloat
            &probability_log) const`  

        * `draw(long double &parameter, const plValues &initial_state, const
            std::vector< plFloat > &proposal_standard_deviation, unsigned int n, plFloat
            &probability_log) const`  

        * `draw(std::vector< int > &parameter, const plValues &initial_state, const
            std::vector< plFloat > &proposal_standard_deviation, unsigned int n, plFloat
            &probability_log) const`  

            Draw a set of function variables values, according to the function
            distribution and depose them in an STL scalar vector.  

            Parameters "initial_state", "proposal_standard_deviation", and "n" are
            only used when drawing non-compiled distribution (i.e. using Metropolis
            algorithm). They represent:  

            *   initial_state: the initial point from which the Metropolis sampler will
                start.  
            *   proposal_standard_deviation: The standard deviations of the normals that
                will be used when generating Metropolis candidate points.  
            *   n: the number of steps that the Metropolis sampler will run before
                returning a drawn point.  
            *   probability_log: the log-probability (or density value) of the returned
                point. Implemented for int, unsigned int, float, and double types.  

        * `draw(std::vector< unsigned int > &parameter, const plValues &initial_state,
            const std::vector< plFloat > &proposal_standard_deviation, unsigned int n,
            plFloat &probability_log) const`  

        * `draw(std::vector< float > &parameter, const plValues &initial_state, const
            std::vector< plFloat > &proposal_standard_deviation, unsigned int n, plFloat
            &probability_log) const`  

        * `draw(std::vector< double > &parameter, const plValues &initial_state, const
            std::vector< plFloat > &proposal_standard_deviation, unsigned int n, plFloat
            &probability_log) const`  

        * `draw(std::vector< long double > &parameter, const plValues &initial_state,
            const std::vector< plFloat > &proposal_standard_deviation, unsigned int n,
            plFloat &probability_log) const`  

        """
        return _probt_python3.plDistribution_draw(self, *args)


    def best(self, *args) -> "void":
        """
        best(self, res)
        best(self) -> plValues
        best(self, result)
        best(self, result)
        best(self, result)
        best(self, result)
        best(self, result)
        best(self, result)
        best(self, result)
        best(self, result)
        best(self, result)
        best(self, result)
        best(self, result)
        best(self, result)
        best(self, result)
        best(self, result)
        best(self, result)
        best(self, res, initial_state, proposal_standard_deviation, n, probability_log)
        best(self, parameter, initial_state, proposal_standard_deviation, n, probability_log)
        best(self, parameter, initial_state, proposal_standard_deviation, n, probability_log)
        best(self, parameter, initial_state, proposal_standard_deviation, n, probability_log)
        best(self, parameter, initial_state, proposal_standard_deviation, n, probability_log)
        best(self, parameter, initial_state, proposal_standard_deviation, n, probability_log)
        best(self, parameter, initial_state, proposal_standard_deviation, n, probability_log)
        best(self, parameter, initial_state, proposal_standard_deviation, n, probability_log)
        best(self, parameter, initial_state, proposal_standard_deviation, n, probability_log)
        best(self, parameter, initial_state, proposal_standard_deviation, n, probability_log)
        best(self, parameter, initial_state, proposal_standard_deviation, n, probability_log)
        best(self, parameter, initial_state, proposal_standard_deviation, n, probability_log)
        best(self, parameter, initial_state, proposal_standard_deviation, n, probability_log)
        best(self, parameter, initial_state, proposal_standard_deviation, n, probability_log)
        best(self, parameter, initial_state, proposal_standard_deviation, n, probability_log)
        best(self, parameter, initial_state, proposal_standard_deviation, n, probability_log)


        `best(plValues &res) const`  
        `best() const -> plValues`  
        `best(int *result) const`  
        `best(unsigned int *result) const`  
        `best(float *result) const`  
        `best(double *result) const`  
        `best(long double *result) const`  
        `best(int &result) const`  
        `best(unsigned int &result) const`  
        `best(float &result) const`  
        `best(double &result) const`  
        `best(long double &result) const`  
        `best(std::vector< int > &result) const`  
        `best(std::vector< unsigned int > &result) const`  
        `best(std::vector< float > &result) const`  
        `best(std::vector< double > &result) const`  
        `best(std::vector< long double > &result) const`  
        `best(plValues &res, const plValues &initial_state, const std::vector< plFloat >
            &proposal_standard_deviation, unsigned int n, plFloat &probability_log)
            const`  
        `best(int *parameter, const plValues &initial_state, const std::vector< plFloat
            > &proposal_standard_deviation, unsigned int n, plFloat &probability_log)
            const`  
        `best(unsigned int *parameter, const plValues &initial_state, const std::vector<
            plFloat > &proposal_standard_deviation, unsigned int n, plFloat
            &probability_log) const`  
        `best(float *parameter, const plValues &initial_state, const std::vector<
            plFloat > &proposal_standard_deviation, unsigned int n, plFloat
            &probability_log) const`  
        `best(double *parameter, const plValues &initial_state, const std::vector<
            plFloat > &proposal_standard_deviation, unsigned int n, plFloat
            &probability_log) const`  
        `best(long double *parameter, const plValues &initial_state, const std::vector<
            plFloat > &proposal_standard_deviation, unsigned int n, plFloat
            &probability_log) const`  
        `best(int &parameter, const plValues &initial_state, const std::vector< plFloat
            > &proposal_standard_deviation, unsigned int n, plFloat &probability_log)
            const`  
        `best(unsigned int &parameter, const plValues &initial_state, const std::vector<
            plFloat > &proposal_standard_deviation, unsigned int n, plFloat
            &probability_log) const`  
        `best(float &parameter, const plValues &initial_state, const std::vector<
            plFloat > &proposal_standard_deviation, unsigned int n, plFloat
            &probability_log) const`  
        `best(double &parameter, const plValues &initial_state, const std::vector<
            plFloat > &proposal_standard_deviation, unsigned int n, plFloat
            &probability_log) const`  
        `best(long double &parameter, const plValues &initial_state, const std::vector<
            plFloat > &proposal_standard_deviation, unsigned int n, plFloat
            &probability_log) const`  
        `best(std::vector< int > &parameter, const plValues &initial_state, const
            std::vector< plFloat > &proposal_standard_deviation, unsigned int n, plFloat
            &probability_log) const`  
        `best(std::vector< unsigned int > &parameter, const plValues &initial_state,
            const std::vector< plFloat > &proposal_standard_deviation, unsigned int n,
            plFloat &probability_log) const`  
        `best(std::vector< float > &parameter, const plValues &initial_state, const
            std::vector< plFloat > &proposal_standard_deviation, unsigned int n, plFloat
            &probability_log) const`  
        `best(std::vector< double > &parameter, const plValues &initial_state, const
            std::vector< plFloat > &proposal_standard_deviation, unsigned int n, plFloat
            &probability_log) const`  
        `best(std::vector< long double > &parameter, const plValues &initial_state,
            const std::vector< plFloat > &proposal_standard_deviation, unsigned int n,
            plFloat &probability_log) const`  

        Overloaded function
        -------------------
        * `best(plValues &res) const`  

            Optimize the function and returns the function variables values that
            executes that optimization in a plValues.  

        * `best() const -> plValues`  

            Optimize the function and returns the function variables values that
            executes that optimization in a plValues.  

            Note that this method returns a freshly created object. If you are calling
            it in a loop, consider using the version that modifies an existing object
            instead.  

        * `best(int *result) const`  

            Optimize the function and returns the function variables values that
            executes that optimization in a array.  

            The size of *parameter* must be at least the number of parameters.
            Implemented for int, unsigned int, float, and double types.  

        * `best(unsigned int *result) const`  

        * `best(float *result) const`  

        * `best(double *result) const`  

        * `best(long double *result) const`  

        * `best(int &result) const`  

            Optimize the function and returns the function variables values that
            executes that optimization in a scalar variable.  

            This function is mainly used with one variable distributions. For two or
            more variables distributions the first variable value will be copied at
            *parameter* while the others will be ignored. Implemented for int, unsigned
            int, float, and double types.  

        * `best(unsigned int &result) const`  

        * `best(float &result) const`  

        * `best(double &result) const`  

        * `best(long double &result) const`  

        * `best(std::vector< int > &result) const`  

            Optimize the function and returns the function variables values that
            executes that optimization in an STL vector.  

            Implemented for int, unsigned int, float, and double types.  

        * `best(std::vector< unsigned int > &result) const`  

        * `best(std::vector< float > &result) const`  

        * `best(std::vector< double > &result) const`  

        * `best(std::vector< long double > &result) const`  

        * `best(plValues &res, const plValues &initial_state, const std::vector< plFloat
            > &proposal_standard_deviation, unsigned int n, plFloat &probability_log)
            const`  

        * `best(int *parameter, const plValues &initial_state, const std::vector<
            plFloat > &proposal_standard_deviation, unsigned int n, plFloat
            &probability_log) const`  

            Implemented for int, unsigned int, float, and double types.  

        * `best(unsigned int *parameter, const plValues &initial_state, const
            std::vector< plFloat > &proposal_standard_deviation, unsigned int n, plFloat
            &probability_log) const`  

        * `best(float *parameter, const plValues &initial_state, const std::vector<
            plFloat > &proposal_standard_deviation, unsigned int n, plFloat
            &probability_log) const`  

        * `best(double *parameter, const plValues &initial_state, const std::vector<
            plFloat > &proposal_standard_deviation, unsigned int n, plFloat
            &probability_log) const`  

        * `best(long double *parameter, const plValues &initial_state, const
            std::vector< plFloat > &proposal_standard_deviation, unsigned int n, plFloat
            &probability_log) const`  

        * `best(int &parameter, const plValues &initial_state, const std::vector<
            plFloat > &proposal_standard_deviation, unsigned int n, plFloat
            &probability_log) const`  

            Implemented for int, unsigned int, long int, float, double and long double
            value-types.  

        * `best(unsigned int &parameter, const plValues &initial_state, const
            std::vector< plFloat > &proposal_standard_deviation, unsigned int n, plFloat
            &probability_log) const`  

        * `best(float &parameter, const plValues &initial_state, const std::vector<
            plFloat > &proposal_standard_deviation, unsigned int n, plFloat
            &probability_log) const`  

        * `best(double &parameter, const plValues &initial_state, const std::vector<
            plFloat > &proposal_standard_deviation, unsigned int n, plFloat
            &probability_log) const`  

        * `best(long double &parameter, const plValues &initial_state, const
            std::vector< plFloat > &proposal_standard_deviation, unsigned int n, plFloat
            &probability_log) const`  

        * `best(std::vector< int > &parameter, const plValues &initial_state, const
            std::vector< plFloat > &proposal_standard_deviation, unsigned int n, plFloat
            &probability_log) const`  

            Implemented for int, unsigned int, float, and double types.  

        * `best(std::vector< unsigned int > &parameter, const plValues &initial_state,
            const std::vector< plFloat > &proposal_standard_deviation, unsigned int n,
            plFloat &probability_log) const`  

        * `best(std::vector< float > &parameter, const plValues &initial_state, const
            std::vector< plFloat > &proposal_standard_deviation, unsigned int n, plFloat
            &probability_log) const`  

        * `best(std::vector< double > &parameter, const plValues &initial_state, const
            std::vector< plFloat > &proposal_standard_deviation, unsigned int n, plFloat
            &probability_log) const`  

        * `best(std::vector< long double > &parameter, const plValues &initial_state,
            const std::vector< plFloat > &proposal_standard_deviation, unsigned int n,
            plFloat &probability_log) const`  

        """
        return _probt_python3.plDistribution_best(self, *args)


    def compute_shannon_entropy(self) -> "plFloat":
        """
        compute_shannon_entropy(self) -> plFloat


        `compute_shannon_entropy() const -> plFloat`  

        Compute Shannon's entropy of the distribution.  

        """
        return _probt_python3.plDistribution_compute_shannon_entropy(self)


    def kullback_leibler_divergence_to(self, q: 'plDistribution') -> "plFloat":
        """
        kullback_leibler_divergence_to(self, q) -> plFloat


        `kullback_leibler_divergence_to(plDistribution const &q) const -> plFloat`  

        Computes the Kullback-Leibler divergence from this distribution to distribution
        q, using a natural logarithm.  

        The two distributions must have the same cardinality.  

        The divergence from p to q Dkl(p,q) is a measure of dissimilarity between two
        distributions. It has the following properties:  

        *   non-negative  
        *   null if and only if p = q  
        *   infinity iff there exists x such that p(X=x)!=0 and q(X=x)==0  
        *   NOT symmetric  
        *   does NOT satisfy triangle inequality.  

        """
        return _probt_python3.plDistribution_kullback_leibler_divergence_to(self, q)


    def is_null(self) -> "bool":
        """
        is_null(self) -> bool


        `is_null() const -> bool`  

        Return 'true' if the distribution has all its probability values to zero.  

        """
        return _probt_python3.plDistribution_is_null(self)


    def as_builtin(k: 'plDistribution') -> "plDistribution":
        """
        as_builtin(k) -> plDistribution


        `as_builtin(const plDistribution &k) -> plDistribution`  

        """
        return _probt_python3.plDistribution_as_builtin(k)

    as_builtin = staticmethod(as_builtin)

    def compute(self, *args) -> "plProbValue":
        """
        compute(self, values) -> plProbValue
        compute(self, values) -> plProbValue
        compute(self, values) -> plProbValue
        compute(self, values) -> plProbValue
        compute(self, values) -> plProbValue
        compute(self, values) -> plProbValue
        compute(self, parameter) -> plProbValue
        compute(self, parameter) -> plProbValue
        compute(self, parameter) -> plProbValue
        compute(self, parameter) -> plProbValue
        compute(self, parameter) -> plProbValue
        compute(self, value) -> plProbValue
        compute(self, value) -> plProbValue
        compute(self, value) -> plProbValue
        compute(self, value) -> plProbValue
        compute(self, value) -> plProbValue
        compute(self, value) -> plProbValue


        `compute(int value) const -> plProbValue`  
        `compute(unsigned int value) const -> plProbValue`  
        `compute(float value) const -> plProbValue`  
        `compute(double value) const -> plProbValue`  
        `compute(long double value) const -> plProbValue`  
        `compute(const std::string &value) const -> plProbValue`  

        Overloaded function
        -------------------
        * `compute(int value) const -> plProbValue`  

            Computes the value of the function for the one-dimensional input parameter
            *value*.  

            ATTENTION: the returned value is guaranteed to be NORMALIZED for and only
            for:  

            *   builtin distributions (basics distributions provided by ProBT),  
            *   compiled distributions (obtained by using the *compile* method).  
            *   distributions obtained with *instantiate* called with parameter
                *ensure_normalization_on_compute* = *true*.  

            Calling the *compute* method on distributions resulting from the ask and/or
            instantiate methods is not guaranteed to return a normalized value unless
            the instantiate method is called with parameter
            *ensure_normalization_on_compute* = *true*. To be sure to obtain normalized
            values, consider compiling these distributions using the *compile* method.  

        * `compute(unsigned int value) const -> plProbValue`  

            Computes the value of the function for the one-dimensional input parameter
            *value*.  

            ATTENTION: the returned value is guaranteed to be NORMALIZED for and only
            for:  

            *   builtin distributions (basics distributions provided by ProBT),  
            *   compiled distributions (obtained by using the *compile* method).  
            *   distributions obtained with *instantiate* called with parameter
                *ensure_normalization_on_compute* = *true*.  

            Calling the *compute* method on distributions resulting from the ask and/or
            instantiate methods is not guaranteed to return a normalized value unless
            the instantiate method is called with parameter
            *ensure_normalization_on_compute* = *true*. To be sure to obtain normalized
            values, consider compiling these distributions using the *compile* method.  

        * `compute(float value) const -> plProbValue`  

            Computes the value of the function for the one-dimensional input parameter
            *value*.  

            ATTENTION: the returned value is guaranteed to be NORMALIZED for and only
            for:  

            *   builtin distributions (basics distributions provided by ProBT),  
            *   compiled distributions (obtained by using the *compile* method).  
            *   distributions obtained with *instantiate* called with parameter
                *ensure_normalization_on_compute* = *true*.  

            Calling the *compute* method on distributions resulting from the ask and/or
            instantiate methods is not guaranteed to return a normalized value unless
            the instantiate method is called with parameter
            *ensure_normalization_on_compute* = *true*. To be sure to obtain normalized
            values, consider compiling these distributions using the *compile* method.  

        * `compute(double value) const -> plProbValue`  

            Computes the value of the function for the one-dimensional input parameter
            *value*.  

            ATTENTION: the returned value is guaranteed to be NORMALIZED for and only
            for:  

            *   builtin distributions (basics distributions provided by ProBT),  
            *   compiled distributions (obtained by using the *compile* method).  
            *   distributions obtained with *instantiate* called with parameter
                *ensure_normalization_on_compute* = *true*.  

            Calling the *compute* method on distributions resulting from the ask and/or
            instantiate methods is not guaranteed to return a normalized value unless
            the instantiate method is called with parameter
            *ensure_normalization_on_compute* = *true*. To be sure to obtain normalized
            values, consider compiling these distributions using the *compile* method.  

        * `compute(long double value) const -> plProbValue`  

        * `compute(const std::string &value) const -> plProbValue`  

            Computes the value of the function for the one-dimensional input parameter
            *value*.  

            ATTENTION: the returned value is guaranteed to be NORMALIZED for and only
            for:  

            *   builtin distributions (basics distributions provided by ProBT),  
            *   compiled distributions (obtained by using the *compile* method).  
            *   distributions obtained with *instantiate* called with parameter
                *ensure_normalization_on_compute* = *true*.  

            Calling the *compute* method on distributions resulting from the ask and/or
            instantiate methods is not guaranteed to return a normalized value unless
            the instantiate method is called with parameter
            *ensure_normalization_on_compute* = *true*. To be sure to obtain normalized
            values, consider compiling these distributions using the *compile* method.  

        """
        return _probt_python3.plDistribution_compute(self, *args)


    def compute_log(self, *args) -> "plFloat":
        """
        compute_log(self, values) -> plFloat
        compute_log(self, values) -> plFloat
        compute_log(self, values) -> plFloat
        compute_log(self, values) -> plFloat
        compute_log(self, values) -> plFloat
        compute_log(self, values) -> plFloat
        compute_log(self, parameter) -> plFloat
        compute_log(self, parameter) -> plFloat
        compute_log(self, parameter) -> plFloat
        compute_log(self, parameter) -> plFloat
        compute_log(self, parameter) -> plFloat
        compute_log(self, value) -> plFloat
        compute_log(self, value) -> plFloat
        compute_log(self, value) -> plFloat
        compute_log(self, value) -> plFloat
        compute_log(self, value) -> plFloat
        compute_log(self, value) -> plFloat


        `compute_log(int value) const -> plFloat`  
        `compute_log(unsigned int value) const -> plFloat`  
        `compute_log(float value) const -> plFloat`  
        `compute_log(double value) const -> plFloat`  
        `compute_log(long double value) const -> plFloat`  
        `compute_log(const std::string &value) const -> plFloat`  

        Overloaded function
        -------------------
        * `compute_log(int value) const -> plFloat`  

            Computes the logarithm value of the function for the input parameter
            *values*.  

        * `compute_log(unsigned int value) const -> plFloat`  

            Computes the logarithm value of the function for the input parameter
            *values*.  

        * `compute_log(float value) const -> plFloat`  

            Computes the logarithm value of the function for the input parameter
            *values*.  

        * `compute_log(double value) const -> plFloat`  

            Computes the logarithm value of the function for the input parameter
            *values*.  

        * `compute_log(long double value) const -> plFloat`  

        * `compute_log(const std::string &value) const -> plFloat`  

        """
        return _probt_python3.plDistribution_compute_log(self, *args)


    def set_soft_evidence(self, soft_evidence: 'plDistribution') -> "void":
        """
        set_soft_evidence(self, soft_evidence)


        `set_soft_evidence(const plDistribution &soft_evidence)`  

        Set a soft evidence on the expression.  

        ATTENTION: after this call, the values provided by compute() functions is no
        longer normalized. Compile you distribution to get normalized values  

        """
        return _probt_python3.plDistribution_set_soft_evidence(self, soft_evidence)


    def set_soft_evidences(self, soft_evidences: 'plComputableObjectList') -> "void":
        """
        set_soft_evidences(self, soft_evidences)


        `set_soft_evidences(const plComputableObjectList &soft_evidences)`  

        Set a set of soft evidences on the expression.  

        ATTENTION: after this call, the values provided by compute() functions is no
        longer normalized. Compile you distribution to get normalized values  

        """
        return _probt_python3.plDistribution_set_soft_evidences(self, soft_evidences)


    def remove_soft_evidence(self, variable: 'plVariablesConjunction') -> "void":
        """
        remove_soft_evidence(self, variable)


        `remove_soft_evidence(const plVariablesConjunction &variable)`  

        Remove soft evidence on a given variable.  

        """
        return _probt_python3.plDistribution_remove_soft_evidence(self, variable)


    def clear_soft_evidences(self) -> "void":
        """
        clear_soft_evidences(self)


        `clear_soft_evidences()`  

        Remove all soft evidences.  

        """
        return _probt_python3.plDistribution_clear_soft_evidences(self)


    def sample(self, nsamples: 'unsigned int') -> "std::vector< plValues,std::allocator< plValues > >":
        """
        sample(self, nsamples) -> plValuesVector


        `sample(unsigned int nsamples) const -> std::vector< plValues >`  

        Return *nsamples* data samples according to the distribution.  

        """
        return _probt_python3.plDistribution_sample(self, nsamples)


    def compute_expectation(self, *args) -> "plValues":
        """
        compute_expectation(self, res)
        compute_expectation(self, res)
        compute_expectation(self) -> plValues


        `compute_expectation(plValues &res) const`  
        `compute_expectation(std::vector< plFloat > &res) const`  

        Overloaded function
        -------------------
        * `compute_expectation(plValues &res) const`  

            Compute the expectation of the distribution.  

            ATTENTION: as plValues are typed (integer, float,...), using this function
            could truncate the result. For example, the following code will truncate the
            mean value of *PX* by returning 50 instead of 50.5:  

                plVariable X("X", plIntegerType(0, 100) );
                plNormal PX(X, 50.5, 2.0);
                plValues X_val(X);
                PX.compute_expectation(X_val);
                std::cout << X_val << std::endl;


        * `compute_expectation(std::vector< plFloat > &res) const`  

            Compute the expectation of the distribution.  

        """
        return _probt_python3.plDistribution_compute_expectation(self, *args)


    def __getstate__(self) -> "std::string":
        """__getstate__(self) -> std::string"""
        return _probt_python3.plDistribution___getstate__(self)


    def __setstate_internal(self, sState: 'std::string const &') -> "void":
        """__setstate_internal(self, sState)"""
        return _probt_python3.plDistribution___setstate_internal(self, sState)


    def __setstate__(self, sState):
        self.__init__()
        self.__setstate_internal(sState)

plDistribution_swigregister = _probt_python3.plDistribution_swigregister
plDistribution_swigregister(plDistribution)

def plDistribution_as_builtin(k: 'plDistribution') -> "plDistribution":
    """
    plDistribution_as_builtin(k) -> plDistribution


    `as_builtin(const plDistribution &k) -> plDistribution`  

    """
    return _probt_python3.plDistribution_as_builtin(k)


def plDistribution_as_dataframe(self):
    """ Return the distribution as a Pandas dataframe
    """
    vals, probs = self.tabulate()
    ret = dataframe_of_values(vals)
    index_columns = list(ret.columns)
    ret["probability"] = probs
    ret.set_index(index_columns, inplace=True)
    return ret
plDistribution.as_dataframe = plDistribution_as_dataframe

class plAnonymousDistribution(plDistribution):
    """

    `plAnonymousDistribution()`  
    `plAnonymousDistribution(const plVariablesConjunction &variable, const
        plExternalProbFunction &function)`  
    `plAnonymousDistribution(const plExternalProbFunction &function)`  
    `plAnonymousDistribution(const plDistribution &)`  

    The *plAnonymousDistribution* class implements a distribution having the user
    external function *function* as *compute* method.  

    The only information we have is a way to compute the probability (or probability
    density) for a given value of the variables *variable*.  

    Constructors
    ------------
    * `plAnonymousDistribution()`  

        Default constructor, needed by the serialization code.  

    * `plAnonymousDistribution(const plVariablesConjunction &variable, const
        plExternalProbFunction &function)`  

        Constructs an Anonymous Distribution with external function *function*.  

         Suppose one wants two define a custom density function P(dist) over a given
        "dist" variable:  

            const plVariable dist("distance", plRealType(0.0, 10.0) );  

        An example showing the 3 ways allowing creating and using
        plExternalProbFunction for defining a custom P(dist) is as follows:  

        1) Using a non-member function:  

            plProbValue laplace(const plValues &distance_val)
            {
             const double B = 0.6;
             const double MU = 3.0;

             const double x = distance_val[0];

             return 1.0/(2.0*B)*std::exp(-std::abs(x-MU)/B);
            }

            plExternalProbFunction distance_density_func(dist, &laplace);

            plAnonymousDistribution P_distance(dist, distance_density_func);  

        2) Using a member function:  

            class MyLaplaceClass
            {
            public:
             MyLaplaceClass(double B, double MU)
             : B_(B)
             , MU_(MU)
             {}

             plProbValue laplace(const plValues &distance_val)const
             {
              const double x = distance_val[0];

              return 1.0/(2.0*B_)*std::exp(-std::abs(x-MU_)/B_);
             }

            private:
             double B_;
             double MU_;
            };

            MyLaplaceClass *my_laplace_obj_ptr = new MyLaplaceClass(0.6, 3.0);
            plExternalProbFunction distance_density_func(dist, my_laplace_obj_ptr,
        &MyLaplaceClass::laplace);

            plAnonymousDistribution P_distance(dist, distance_density_func);  

        3) Using a C source code function:  

            const std::string laplace_C_code = "result =
        1.0/(2.0*0.6)*exp(-fabs(dist-3.0)/0.6);";

            plExternalProbFunction distance_density_func =
                      createExternalProbFunctionFromC(dist,
        laplace_C_code,"laplace_func");

            plAnonymousDistribution P_distance(dist, distance_density_func);  

        ATTENTION: for performance reasons, using this constructor requires that the
        passed variables have the same order as the function's variables. You can
        also use the constructor plAnonymousDistribution(const
        plExternalProbFunction& ) below.  

    * `plAnonymousDistribution(const plExternalProbFunction &function)`  

        Same as the constructr above however the variables are assumed to be the
        same as the ones provided by the passed function.  

    * `plAnonymousDistribution(const plDistribution &)`  

        Promote from a plDistribution.  

        If the object being copied is actually of the wrong type, an exception is
        raised.  

    C++ includes: plAnonymousDistribution.h

    """

    __swig_setmethods__ = {}
    for _s in [plDistribution]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plAnonymousDistribution, name, value)
    __swig_getmethods__ = {}
    for _s in [plDistribution]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plAnonymousDistribution, name)
    __repr__ = _swig_repr
    __swig_destroy__ = _probt_python3.delete_plAnonymousDistribution
    __del__ = lambda self: None

    def __init__(self, *args):
        """
        __init__(self) -> plAnonymousDistribution
        __init__(self, variable, function) -> plAnonymousDistribution
        __init__(self, function) -> plAnonymousDistribution
        __init__(self, arg2) -> plAnonymousDistribution


        `plAnonymousDistribution()`  
        `plAnonymousDistribution(const plVariablesConjunction &variable, const
            plExternalProbFunction &function)`  
        `plAnonymousDistribution(const plExternalProbFunction &function)`  
        `plAnonymousDistribution(const plDistribution &)`  

        Overloaded function
        -------------------
        * `plAnonymousDistribution()`  

            Default constructor, needed by the serialization code.  

        * `plAnonymousDistribution(const plVariablesConjunction &variable, const
            plExternalProbFunction &function)`  

            Constructs an Anonymous Distribution with external function *function*.  

             Suppose one wants two define a custom density function P(dist) over a given
            "dist" variable:  

                const plVariable dist("distance", plRealType(0.0, 10.0) );  

            An example showing the 3 ways allowing creating and using
            plExternalProbFunction for defining a custom P(dist) is as follows:  

            1) Using a non-member function:  

                plProbValue laplace(const plValues &distance_val)
                {
                 const double B = 0.6;
                 const double MU = 3.0;

                 const double x = distance_val[0];

                 return 1.0/(2.0*B)*std::exp(-std::abs(x-MU)/B);
                }

                plExternalProbFunction distance_density_func(dist, &laplace);

                plAnonymousDistribution P_distance(dist, distance_density_func);  

            2) Using a member function:  

                class MyLaplaceClass
                {
                public:
                 MyLaplaceClass(double B, double MU)
                 : B_(B)
                 , MU_(MU)
                 {}

                 plProbValue laplace(const plValues &distance_val)const
                 {
                  const double x = distance_val[0];

                  return 1.0/(2.0*B_)*std::exp(-std::abs(x-MU_)/B_);
                 }

                private:
                 double B_;
                 double MU_;
                };

                MyLaplaceClass *my_laplace_obj_ptr = new MyLaplaceClass(0.6, 3.0);
                plExternalProbFunction distance_density_func(dist, my_laplace_obj_ptr,
            &MyLaplaceClass::laplace);

                plAnonymousDistribution P_distance(dist, distance_density_func);  

            3) Using a C source code function:  

                const std::string laplace_C_code = "result =
            1.0/(2.0*0.6)*exp(-fabs(dist-3.0)/0.6);";

                plExternalProbFunction distance_density_func =
                          createExternalProbFunctionFromC(dist,
            laplace_C_code,"laplace_func");

                plAnonymousDistribution P_distance(dist, distance_density_func);  

            ATTENTION: for performance reasons, using this constructor requires that the
            passed variables have the same order as the function's variables. You can
            also use the constructor plAnonymousDistribution(const
            plExternalProbFunction& ) below.  

        * `plAnonymousDistribution(const plExternalProbFunction &function)`  

            Same as the constructr above however the variables are assumed to be the
            same as the ones provided by the passed function.  

        * `plAnonymousDistribution(const plDistribution &)`  

            Promote from a plDistribution.  

            If the object being copied is actually of the wrong type, an exception is
            raised.  

        """
        this = _probt_python3.new_plAnonymousDistribution(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def get_prob_function(self) -> "plExternalProbFunction":
        """
        get_prob_function(self) -> plExternalProbFunction


        `get_prob_function() const -> plExternalProbFunction`  

        Get the external function used to construct this object.  

        """
        return _probt_python3.plAnonymousDistribution_get_prob_function(self)


    def is_base_class(self) -> "bool":
        """
        is_base_class(self) -> bool


        `is_base_class() const -> bool`  

        """
        return _probt_python3.plAnonymousDistribution_is_base_class(self)


    def __getstate__(self) -> "std::string":
        """__getstate__(self) -> std::string"""
        return _probt_python3.plAnonymousDistribution___getstate__(self)


    def __setstate_internal(self, sState: 'std::string const &') -> "void":
        """__setstate_internal(self, sState)"""
        return _probt_python3.plAnonymousDistribution___setstate_internal(self, sState)


    def __setstate__(self, sState):
        self.__init__()
        self.__setstate_internal(sState)

plAnonymousDistribution_swigregister = _probt_python3.plAnonymousDistribution_swigregister
plAnonymousDistribution_swigregister(plAnonymousDistribution)

class plBeta(plDistribution):
    """

    `plBeta()`  
    `plBeta(const plVariable &V, plFloat p, plFloat q, plFloat a=PL_ZERO, plFloat
        b=PL_ONE)`  
    `plBeta(const plDistribution &)`  

    This class implements the Beta distribution.  

    A Beta distribution over variable *x*, with parameters *p* and *q*, has as
    density function (using the *Beta* function *B*): \[ p(x) = \frac{(x-a)^{p-1}
    (b-x)^{q-1}}{B(p, q) (b - a)^{p+q-1}} \]  

    *   *p* and *q* are the shape parameters. They must be strictly positive.  
    *   *a* and *b* are the bounds of the distribution: it is defined on $ [a; b] $.
        We must have $ a < b$.  
    *   *a* is also called the location parameter.  
    *   *b-a* is called the scale parameter.  

    Keeping a = 0, b = 1 gives the standard Beta distribution.  

    Constructors
    ------------
    * `plBeta()`  

        Default constructor, needed by the serialization code.  

    * `plBeta(const plVariable &V, plFloat p, plFloat q, plFloat a=PL_ZERO, plFloat
        b=PL_ONE)`  

        Constructs a Beta distribution.  

        Parameters:  
        * `V` :  
            variable over which to build the distribution.  
        * `p` :  
            p shape parameter  
        * `q` :  
            q shape parameter  
        * `a` :  
            Lower bound  
        * `b` :  
            Higher bound  

    * `plBeta(const plDistribution &)`  

        Promote from a plDistribution.  

        This makes sense because all the information is actually in parent class
        plDistribution. If the object being copied is actually of the wrong type, an
        exception is raised.  

    C++ includes: plBeta.h

    """

    __swig_setmethods__ = {}
    for _s in [plDistribution]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plBeta, name, value)
    __swig_getmethods__ = {}
    for _s in [plDistribution]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plBeta, name)
    __repr__ = _swig_repr
    __swig_destroy__ = _probt_python3.delete_plBeta
    __del__ = lambda self: None

    def get_parameters(self) -> "void":
        """
        get_parameters(self)


        `get_parameters(plFloat &p, plFloat &q, plFloat &a, plFloat &b) const`  

        Get the parameters used for constructing this object.  

        """
        return _probt_python3.plBeta_get_parameters(self)


    def __init__(self, *args):
        """
        __init__(self) -> plBeta
        __init__(self, V, p, q, a=0.0, b=1.0) -> plBeta
        __init__(self, V, p, q, a=0.0) -> plBeta
        __init__(self, V, p, q) -> plBeta
        __init__(self, arg2) -> plBeta


        `plBeta()`  
        `plBeta(const plVariable &V, plFloat p, plFloat q, plFloat a=PL_ZERO, plFloat
            b=PL_ONE)`  
        `plBeta(const plDistribution &)`  

        Overloaded function
        -------------------
        * `plBeta()`  

            Default constructor, needed by the serialization code.  

        * `plBeta(const plVariable &V, plFloat p, plFloat q, plFloat a=PL_ZERO, plFloat
            b=PL_ONE)`  

            Constructs a Beta distribution.  

            Parameters:  
            * `V` :  
                variable over which to build the distribution.  
            * `p` :  
                p shape parameter  
            * `q` :  
                q shape parameter  
            * `a` :  
                Lower bound  
            * `b` :  
                Higher bound  

        * `plBeta(const plDistribution &)`  

            Promote from a plDistribution.  

            This makes sense because all the information is actually in parent class
            plDistribution. If the object being copied is actually of the wrong type, an
            exception is raised.  

        """
        this = _probt_python3.new_plBeta(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def is_base_class(self) -> "bool":
        """
        is_base_class(self) -> bool


        `is_base_class() const -> bool`  

        """
        return _probt_python3.plBeta_is_base_class(self)


    def __getstate__(self) -> "std::string":
        """__getstate__(self) -> std::string"""
        return _probt_python3.plBeta___getstate__(self)


    def __setstate_internal(self, sState: 'std::string const &') -> "void":
        """__setstate_internal(self, sState)"""
        return _probt_python3.plBeta___setstate_internal(self, sState)


    def __setstate__(self, sState):
        self.__init__()
        self.__setstate_internal(sState)

plBeta_swigregister = _probt_python3.plBeta_swigregister
plBeta_swigregister(plBeta)

class plDirichlet(plDistribution):
    """

    `plDirichlet()`  
    `plDirichlet(const plVariablesConjunction &variables, const std::vector< plFloat
        > &alpha)`  
    `plDirichlet(const plDistribution &)`  

    The Dirichlet distribution.  

    Constructors
    ------------
    * `plDirichlet()`  

        Construct an empty Dirichlet distribution.  

    * `plDirichlet(const plVariablesConjunction &variables, const std::vector<
        plFloat > &alpha)`  

        Construct a Dirichlet distribution.  

        Parameters:  
        * `variables` :  
            The N-dimensional variable on which the distribution is defined.  
        * `alpha` :  
            The N-dimensional vector of effectives corresponding to each variable in
            *variables*  

        The Dirichlet distribution has the following density function: \[ p(x;
        \alpha) = \frac{1}{\beta(\alpha)} \prod_{i=1}^{N} x_i^{\alpha_i-1}\]  

    * `plDirichlet(const plDistribution &)`  

        Promote from a plDistribution.  

        If the object being copied is actually of the wrong type, an exception is
        raised.  

    C++ includes: plDirichlet.h

    """

    __swig_setmethods__ = {}
    for _s in [plDistribution]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plDirichlet, name, value)
    __swig_getmethods__ = {}
    for _s in [plDistribution]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plDirichlet, name)
    __repr__ = _swig_repr
    __swig_destroy__ = _probt_python3.delete_plDirichlet
    __del__ = lambda self: None

    def get_parameters(self, alpha: 'DoubleVector') -> "void":
        """
        get_parameters(self, alpha)


        `get_parameters(std::vector< plFloat > &alpha) const`  

        Get the parameters used for constructing this object.  

        """
        return _probt_python3.plDirichlet_get_parameters(self, alpha)


    def __init__(self, *args):
        """
        __init__(self) -> plDirichlet
        __init__(self, variables, alpha) -> plDirichlet
        __init__(self, arg2) -> plDirichlet


        `plDirichlet()`  
        `plDirichlet(const plVariablesConjunction &variables, const std::vector< plFloat
            > &alpha)`  
        `plDirichlet(const plDistribution &)`  

        Overloaded function
        -------------------
        * `plDirichlet()`  

            Construct an empty Dirichlet distribution.  

        * `plDirichlet(const plVariablesConjunction &variables, const std::vector<
            plFloat > &alpha)`  

            Construct a Dirichlet distribution.  

            Parameters:  
            * `variables` :  
                The N-dimensional variable on which the distribution is defined.  
            * `alpha` :  
                The N-dimensional vector of effectives corresponding to each variable in
                *variables*  

            The Dirichlet distribution has the following density function: \[ p(x;
            \alpha) = \frac{1}{\beta(\alpha)} \prod_{i=1}^{N} x_i^{\alpha_i-1}\]  

        * `plDirichlet(const plDistribution &)`  

            Promote from a plDistribution.  

            If the object being copied is actually of the wrong type, an exception is
            raised.  

        """
        this = _probt_python3.new_plDirichlet(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def is_base_class(self) -> "bool":
        """
        is_base_class(self) -> bool


        `is_base_class() const -> bool`  

        """
        return _probt_python3.plDirichlet_is_base_class(self)


    def __getstate__(self) -> "std::string":
        """__getstate__(self) -> std::string"""
        return _probt_python3.plDirichlet___getstate__(self)


    def __setstate_internal(self, sState: 'std::string const &') -> "void":
        """__setstate_internal(self, sState)"""
        return _probt_python3.plDirichlet___setstate_internal(self, sState)


    def __setstate__(self, sState):
        self.__init__()
        self.__setstate_internal(sState)

plDirichlet_swigregister = _probt_python3.plDirichlet_swigregister
plDirichlet_swigregister(plDirichlet)

class plExponential(plDistribution):
    """

    `plExponential()`  
    `plExponential(const plVariable &V, plFloat beta, plFloat mu=PL_ZERO)`  
    `plExponential(const plDistribution &)`  

    This class implements the Exponential distribution.  

    The Exponential distribution with parameters *beta* and *mu* follows the
    following probability density function (for x > mu): \[ p(x) =
    \frac{1}{\beta} \exp\left( -\frac{x-\mu}{\beta}\right) \]  

    Constructors
    ------------
    * `plExponential()`  

        Default constructor, needed by the serialization code.  

    * `plExponential(const plVariable &V, plFloat beta, plFloat mu=PL_ZERO)`  

        Constructs a Exponential distribution on the domain of *V*.  

        Parameters:  
        * `V` :  
            Variable over which the distribution is built. It must be continuous.  
        * `beta` :  
            Scale parameter and must be > 0.  
        * `mu` :  
            Location parameter. Zero by default. The inferior bound of *variable*
            must be superior or equal to *mu*.  

        The Exponential distribution with parameters *beta* and *and* *mu* follows
        the following probability density function (for x > mu): \[ p(x) =
        \frac{1}{\beta} \exp\left( -\frac{x-\mu}{\beta}\right) \]  

    * `plExponential(const plDistribution &)`  

        Promote from a plDistribution.  

        If the object being copied is actually of the wrong type, an exception is
        raised.  

    C++ includes: plExponential.h

    """

    __swig_setmethods__ = {}
    for _s in [plDistribution]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plExponential, name, value)
    __swig_getmethods__ = {}
    for _s in [plDistribution]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plExponential, name)
    __repr__ = _swig_repr
    __swig_destroy__ = _probt_python3.delete_plExponential
    __del__ = lambda self: None

    def get_parameters(self) -> "void":
        """
        get_parameters(self)


        `get_parameters(plFloat &beta, plFloat &mu) const`  

        Get the parameters used for constructing this object.  

        """
        return _probt_python3.plExponential_get_parameters(self)


    def __init__(self, *args):
        """
        __init__(self) -> plExponential
        __init__(self, V, beta, mu=0.0) -> plExponential
        __init__(self, V, beta) -> plExponential
        __init__(self, arg2) -> plExponential


        `plExponential()`  
        `plExponential(const plVariable &V, plFloat beta, plFloat mu=PL_ZERO)`  
        `plExponential(const plDistribution &)`  

        Overloaded function
        -------------------
        * `plExponential()`  

            Default constructor, needed by the serialization code.  

        * `plExponential(const plVariable &V, plFloat beta, plFloat mu=PL_ZERO)`  

            Constructs a Exponential distribution on the domain of *V*.  

            Parameters:  
            * `V` :  
                Variable over which the distribution is built. It must be continuous.  
            * `beta` :  
                Scale parameter and must be > 0.  
            * `mu` :  
                Location parameter. Zero by default. The inferior bound of *variable*
                must be superior or equal to *mu*.  

            The Exponential distribution with parameters *beta* and *and* *mu* follows
            the following probability density function (for x > mu): \[ p(x) =
            \frac{1}{\beta} \exp\left( -\frac{x-\mu}{\beta}\right) \]  

        * `plExponential(const plDistribution &)`  

            Promote from a plDistribution.  

            If the object being copied is actually of the wrong type, an exception is
            raised.  

        """
        this = _probt_python3.new_plExponential(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def is_base_class(self) -> "bool":
        """
        is_base_class(self) -> bool


        `is_base_class() const -> bool`  

        """
        return _probt_python3.plExponential_is_base_class(self)


    def __getstate__(self) -> "std::string":
        """__getstate__(self) -> std::string"""
        return _probt_python3.plExponential___getstate__(self)


    def __setstate_internal(self, sState: 'std::string const &') -> "void":
        """__setstate_internal(self, sState)"""
        return _probt_python3.plExponential___setstate_internal(self, sState)


    def __setstate__(self, sState):
        self.__init__()
        self.__setstate_internal(sState)

plExponential_swigregister = _probt_python3.plExponential_swigregister
plExponential_swigregister(plExponential)

class plGamma(plDistribution):
    """

    `plGamma()`  
    `plGamma(const plVariable &variable, plFloat alpha, plFloat theta, plFloat
        mu=PL_ZERO)`  
    `plGamma(const plDistribution &)`  

    This class implements the Gamma distribution.  

    The Gamma distribution with parameters *alpha*, *theta*, and *mu* follows the
    following probability density function (for x > mu): \[ p(x) = (x -
    \mu)^{\alpha - 1} \frac{e^{-\frac{x - \mu}{\theta}}}{\theta^{\alpha}
    \Gamma(\alpha)} \]  

    Constructors
    ------------
    * `plGamma()`  

        Default constructor.  

    * `plGamma(const plVariable &variable, plFloat alpha, plFloat theta, plFloat
        mu=PL_ZERO)`  

        Constructs a Gamma distribution on the domain of *variable*.  

        Parameters:  
        * `variable` :  
            Variable over which the distribution is built.  
        * `alpha` :  
            Shape parameter (also known as *gamma* or *k*) and must be > 0.  
        * `theta` :  
            Scale parameter (also known as 1/beta, where *beta* is called the *rate*
            parameter) and must be > 0.  
        * `mu` :  
            Location parameter. Zero by default. The inferior bound of *variable*
            must be be greater than or equal to $ \mu $.  

    * `plGamma(const plDistribution &)`  

        Promote from a plDistribution.  

        If the object being copied is actually of the wrong type, an exception is
        raised.  

    C++ includes: plGamma.h

    """

    __swig_setmethods__ = {}
    for _s in [plDistribution]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plGamma, name, value)
    __swig_getmethods__ = {}
    for _s in [plDistribution]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plGamma, name)
    __repr__ = _swig_repr
    __swig_destroy__ = _probt_python3.delete_plGamma
    __del__ = lambda self: None

    def get_parameters(self) -> "void":
        """
        get_parameters(self)


        `get_parameters(plFloat &alpha, plFloat &theta, plFloat &mu) const`  

        Get the parameters used for constructing this object.  

        """
        return _probt_python3.plGamma_get_parameters(self)


    def __init__(self, *args):
        """
        __init__(self) -> plGamma
        __init__(self, variable, alpha, theta, mu=0.0) -> plGamma
        __init__(self, variable, alpha, theta) -> plGamma
        __init__(self, arg2) -> plGamma


        `plGamma()`  
        `plGamma(const plVariable &variable, plFloat alpha, plFloat theta, plFloat
            mu=PL_ZERO)`  
        `plGamma(const plDistribution &)`  

        Overloaded function
        -------------------
        * `plGamma()`  

            Default constructor.  

        * `plGamma(const plVariable &variable, plFloat alpha, plFloat theta, plFloat
            mu=PL_ZERO)`  

            Constructs a Gamma distribution on the domain of *variable*.  

            Parameters:  
            * `variable` :  
                Variable over which the distribution is built.  
            * `alpha` :  
                Shape parameter (also known as *gamma* or *k*) and must be > 0.  
            * `theta` :  
                Scale parameter (also known as 1/beta, where *beta* is called the *rate*
                parameter) and must be > 0.  
            * `mu` :  
                Location parameter. Zero by default. The inferior bound of *variable*
                must be be greater than or equal to $ \mu $.  

        * `plGamma(const plDistribution &)`  

            Promote from a plDistribution.  

            If the object being copied is actually of the wrong type, an exception is
            raised.  

        """
        this = _probt_python3.new_plGamma(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def is_base_class(self) -> "bool":
        """
        is_base_class(self) -> bool


        `is_base_class() const -> bool`  

        """
        return _probt_python3.plGamma_is_base_class(self)


    def __getstate__(self) -> "std::string":
        """__getstate__(self) -> std::string"""
        return _probt_python3.plGamma___getstate__(self)


    def __setstate_internal(self, sState: 'std::string const &') -> "void":
        """__setstate_internal(self, sState)"""
        return _probt_python3.plGamma___setstate_internal(self, sState)


    def __setstate__(self, sState):
        self.__init__()
        self.__setstate_internal(sState)

plGamma_swigregister = _probt_python3.plGamma_swigregister
plGamma_swigregister(plGamma)


def plLgamma(x: 'plFloat') -> "plFloat":
    """
    plLgamma(x) -> plFloat


    `plLgamma(plFloat x) -> PL_DLL_API plFloat`  

    Log-Gamma function.  

    """
    return _probt_python3.plLgamma(x)

def plGammaFunc(x: 'plFloat') -> "plFloat":
    """
    plGammaFunc(x) -> plFloat


    `plGammaFunc(plFloat x) -> plFloat`  

    Gamma function.  

    """
    return _probt_python3.plGammaFunc(x)

def plIncompleteGammaFunc(a: 'plFloat', x: 'plFloat') -> "plFloat":
    """
    plIncompleteGammaFunc(a, x) -> plFloat


    `plIncompleteGammaFunc(plFloat a, plFloat x) -> PL_DLL_API plFloat`  

    Incomplete Gamma integral.  

    The function is defined by: \[ igamma(a, x) = \frac {1} {\Gamma(a)} \int_0^x
    e^{-t} t^{a-1} dt. \]  

    See also: plIncompleteGammaCFunc  

    """
    return _probt_python3.plIncompleteGammaFunc(a, x)

def plIncompleteGammaCFunc(a: 'plFloat', x: 'plFloat') -> "plFloat":
    """
    plIncompleteGammaCFunc(a, x) -> plFloat


    `plIncompleteGammaCFunc(plFloat a, plFloat x) -> PL_DLL_API plFloat`  

    Complemented incomplete Gamma integral.  

    The function is defined by: \[ igammac(a, x) = 1 - igamma(a, x) = \frac {1}
    {\Gamma(a)} \int_x^{\infty} e^{-t} t^{a-1} dt. \]  

    See also: plIncompleteGammaFunc  

    """
    return _probt_python3.plIncompleteGammaCFunc(a, x)
class plLogNormal(plDistribution):
    """

    `plLogNormal()`  
    `plLogNormal(const plVariable &V, plFloat sigma, plFloat m=PL_ONE, plFloat
        theta=PL_ZERO)`  
    `plLogNormal(const plDistribution &)`  

    A plLogNormal is a one-dimensional probability distribution on a single
    continuous variable.  

    A variable X is said to be lognormally distributed if $ Y = ln(X) $ is normally
    distributed with *ln* denoting the natural logarithm. The general formula for
    the probability density function of the lognormal distribution is:  

    \[ p(x) = \frac {\exp (- (\ln( (x-\theta)/m) )^2/(2 \sigma^2))} { (x -
    \theta) \sigma \sqrt{2 \pi}} \hspace{2cm} x \geq \theta; m, \sigma > 0
    \]  

    $ \sigma $ is the shape parameter, $ \theta $ is the location parameter, and
    *m* is the scale parameter. The case where $ \theta = 0 $ and *m* = 1 is called
    the standard lognormal distribution. The case where $ \theta = 0 $ is called
    the 2-parameter lognormal distribution.  

    There are several common parameterizations of the lognormal distribution. The
    form given here is from: Evans, Hastings, and Peacock (2000), Statistical
    Distributions, 3rd. Ed., John Wiley and Sons.  

    In this parametrization, *X* is is said to be lognormally distributed with
    parameters $ \sigma $, $ \theta $, and *m* if $ Y = LN( (X - \theta)/m ) $ is
    normally distributed with 0 as mean and $ \sigma $ as standard deviation.  

    Constructors
    ------------
    * `plLogNormal()`  

        Default constructor, needed by the serialization code.  

    * `plLogNormal(const plVariable &V, plFloat sigma, plFloat m=PL_ONE, plFloat
        theta=PL_ZERO)`  

        Constructs a *plLogNormal* on the Variable *V*, where $ \sigma $ is the
        shape parameter, *m* is the scale parameter and $ \theta $ the location
        parameter.  

        The case where $ \theta = 0 $ and *m* = 1 is called the standard lognormal
        distribution. The case where $ \theta = 0 $ is called the 2-parameter
        lognormal distribution.  

    * `plLogNormal(const plDistribution &)`  

        Promote from a plDistribution.  

        If the object being copied is actually of the wrong type, an exception is
        raised.  

    C++ includes: plLogNormal.h

    """

    __swig_setmethods__ = {}
    for _s in [plDistribution]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plLogNormal, name, value)
    __swig_getmethods__ = {}
    for _s in [plDistribution]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plLogNormal, name)
    __repr__ = _swig_repr
    __swig_destroy__ = _probt_python3.delete_plLogNormal
    __del__ = lambda self: None

    def get_parameters(self, sigma: 'plFloat &', m: 'plFloat &', theta: 'plFloat &') -> "void":
        """
        get_parameters(self, sigma, m, theta)


        `get_parameters(plFloat &sigma, plFloat &m, plFloat &theta) const`  

        Get the parameters used for constructing this object.  

        """
        return _probt_python3.plLogNormal_get_parameters(self, sigma, m, theta)


    def __init__(self, *args):
        """
        __init__(self) -> plLogNormal
        __init__(self, V, sigma, m=1.0, theta=0.0) -> plLogNormal
        __init__(self, V, sigma, m=1.0) -> plLogNormal
        __init__(self, V, sigma) -> plLogNormal
        __init__(self, arg2) -> plLogNormal


        `plLogNormal()`  
        `plLogNormal(const plVariable &V, plFloat sigma, plFloat m=PL_ONE, plFloat
            theta=PL_ZERO)`  
        `plLogNormal(const plDistribution &)`  

        Overloaded function
        -------------------
        * `plLogNormal()`  

            Default constructor, needed by the serialization code.  

        * `plLogNormal(const plVariable &V, plFloat sigma, plFloat m=PL_ONE, plFloat
            theta=PL_ZERO)`  

            Constructs a *plLogNormal* on the Variable *V*, where $ \sigma $ is the
            shape parameter, *m* is the scale parameter and $ \theta $ the location
            parameter.  

            The case where $ \theta = 0 $ and *m* = 1 is called the standard lognormal
            distribution. The case where $ \theta = 0 $ is called the 2-parameter
            lognormal distribution.  

        * `plLogNormal(const plDistribution &)`  

            Promote from a plDistribution.  

            If the object being copied is actually of the wrong type, an exception is
            raised.  

        """
        this = _probt_python3.new_plLogNormal(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def is_base_class(self) -> "bool":
        """
        is_base_class(self) -> bool


        `is_base_class() const -> bool`  

        """
        return _probt_python3.plLogNormal_is_base_class(self)


    def __getstate__(self) -> "std::string":
        """__getstate__(self) -> std::string"""
        return _probt_python3.plLogNormal___getstate__(self)


    def __setstate_internal(self, sState: 'std::string const &') -> "void":
        """__setstate_internal(self, sState)"""
        return _probt_python3.plLogNormal___setstate_internal(self, sState)


    def __setstate__(self, sState):
        self.__init__()
        self.__setstate_internal(sState)

plLogNormal_swigregister = _probt_python3.plLogNormal_swigregister
plLogNormal_swigregister(plLogNormal)

class plWeibull(plDistribution):
    """

    `plWeibull()`  
    `plWeibull(const plVariable &variable, plFloat gamma, plFloat alpha=PL_ONE,
        plFloat mu=PL_ZERO)`  
    `plWeibull(const plDistribution &)`  

    This class implements the Weibull distribution.  

    The Weibull distribution with parameters $ \gamma $, $ \alpha $, and $ \mu $
    follows the following probability density function (for $ x > \mu $): \[ p(x)
    = \frac{\gamma}{\alpha} \left( \frac{x-\mu}{\alpha}
    \right)^{\gamma-1}\exp\left( -\left(\frac{x-\mu}{\alpha}
    \right)^\gamma \right) \]  

    The case where $ \mu = 0 $ and $ \alpha = 1 $ is called the standard Weibull
    distribution. The case where $ \mu = 0 $ is called the 2-parameter Weibull
    distribution.  

    Constructors
    ------------
    * `plWeibull()`  

        Default constructor.  

    * `plWeibull(const plVariable &variable, plFloat gamma, plFloat alpha=PL_ONE,
        plFloat mu=PL_ZERO)`  

        Constructs a Weibull distribution on the domain of *variable*.  

        Parameters:  
        * `variable` :  
            Variable over which the distribution is built. It must be continuous.  
        * `gamma` :  
            Shape parameter (also known as *k*) and must be > 0.  
        * `alpha` :  
            Scale parameter (also known as $ \lambda $) and must be > 0.  
        * `mu` :  
            Location parameter. Zero by default. The inferior bound of *variable*
            must be greater than or equal to $ \mu $.  

    * `plWeibull(const plDistribution &)`  

        Promote from a plDistribution.  

        If the object being copied is actually of the wrong type, an exception is
        raised.  

    C++ includes: plWeibull.h

    """

    __swig_setmethods__ = {}
    for _s in [plDistribution]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plWeibull, name, value)
    __swig_getmethods__ = {}
    for _s in [plDistribution]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plWeibull, name)
    __repr__ = _swig_repr
    __swig_destroy__ = _probt_python3.delete_plWeibull
    __del__ = lambda self: None

    def get_parameters(self, gamma: 'plFloat &', alpha: 'plFloat &', mu: 'plFloat &') -> "void":
        """
        get_parameters(self, gamma, alpha, mu)


        `get_parameters(plFloat &gamma, plFloat &alpha, plFloat &mu) const`  

        Get the parameters used for constructing this object.  

        """
        return _probt_python3.plWeibull_get_parameters(self, gamma, alpha, mu)


    def __init__(self, *args):
        """
        __init__(self) -> plWeibull
        __init__(self, variable, gamma, alpha=1.0, mu=0.0) -> plWeibull
        __init__(self, variable, gamma, alpha=1.0) -> plWeibull
        __init__(self, variable, gamma) -> plWeibull
        __init__(self, arg2) -> plWeibull


        `plWeibull()`  
        `plWeibull(const plVariable &variable, plFloat gamma, plFloat alpha=PL_ONE,
            plFloat mu=PL_ZERO)`  
        `plWeibull(const plDistribution &)`  

        Overloaded function
        -------------------
        * `plWeibull()`  

            Default constructor.  

        * `plWeibull(const plVariable &variable, plFloat gamma, plFloat alpha=PL_ONE,
            plFloat mu=PL_ZERO)`  

            Constructs a Weibull distribution on the domain of *variable*.  

            Parameters:  
            * `variable` :  
                Variable over which the distribution is built. It must be continuous.  
            * `gamma` :  
                Shape parameter (also known as *k*) and must be > 0.  
            * `alpha` :  
                Scale parameter (also known as $ \lambda $) and must be > 0.  
            * `mu` :  
                Location parameter. Zero by default. The inferior bound of *variable*
                must be greater than or equal to $ \mu $.  

        * `plWeibull(const plDistribution &)`  

            Promote from a plDistribution.  

            If the object being copied is actually of the wrong type, an exception is
            raised.  

        """
        this = _probt_python3.new_plWeibull(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def is_base_class(self) -> "bool":
        """
        is_base_class(self) -> bool


        `is_base_class() const -> bool`  

        """
        return _probt_python3.plWeibull_is_base_class(self)


    def __getstate__(self) -> "std::string":
        """__getstate__(self) -> std::string"""
        return _probt_python3.plWeibull___getstate__(self)


    def __setstate_internal(self, sState: 'std::string const &') -> "void":
        """__setstate_internal(self, sState)"""
        return _probt_python3.plWeibull___setstate_internal(self, sState)


    def __setstate__(self, sState):
        self.__init__()
        self.__setstate_internal(sState)

plWeibull_swigregister = _probt_python3.plWeibull_swigregister
plWeibull_swigregister(plWeibull)

class plNormal(plDistribution):
    """

    `plNormal()`  
    `plNormal(const plVariablesConjunction &V, const plFloatVector &mu, const
        plFloatMatrix &Sigma)`  
    `plNormal(const plVariable &V, plFloat mu, plFloat sigma)`  
    `plNormal(const plDistribution &)`  

    This class implements Normal distributions on one or multiple dimensional space.  

    Constructors
    ------------
    * `plNormal()`  

        Default constructor, needed by the serialization code.  

    * `plNormal(const plVariablesConjunction &V, const plFloatVector &mu, const
        plFloatMatrix &Sigma)`  

        Constructor of an N-dimensional normal (Gaussian) distribution.  

        Parameters:  
        * `V` :  
            The N-dimentional variable on which the distribution is defined. They
            must be continuous  
        * `mu` :  
            The N-dimensional mean vector  
        * `Sigma` :  
            The NxN variance/covariance matrix (must be symetric positive)  

        The probability density function of the N-dimensional normal (Gaussian)
        distribution is: \[ p(x; \mu, \Sigma) = \frac {1} {\sqrt{|\Sigma|}
        (2\pi)^{N/2}} \exp\left( -0.5 (x-\mu) \Sigma^{-1} (x-\mu)^T \right)
        \]  

    * `plNormal(const plVariable &V, plFloat mu, plFloat sigma)`  

        Constructor of a one-dimensional normal (Gaussian) distribution.  

        Parameters:  
        * `V` :  
            The one-dimentional variable on which the distribution is defined  
        * `mu` :  
            The mean value  
        * `sigma` :  
            The standard deviation (square root of the variance), must be positive  

        The probability density function of the one-dimensional normal (Gaussian)
        distribution is: \[ p(x; \mu, \sigma) = \frac {1} {\sigma \sqrt{2\pi}
        } \exp\left( - \frac{(x-\mu)^2}{2\sigma^2} \right) \]  

    * `plNormal(const plDistribution &)`  

        Promote from a plDistribution.  

        If the object being copied is actually of the wrong type, an exception is
        raised.  

    C++ includes: plNormal.h

    """

    __swig_setmethods__ = {}
    for _s in [plDistribution]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plNormal, name, value)
    __swig_getmethods__ = {}
    for _s in [plDistribution]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plNormal, name)
    __repr__ = _swig_repr
    __swig_destroy__ = _probt_python3.delete_plNormal
    __del__ = lambda self: None

    def get_mean_vector(self) -> "plFloatVector":
        """
        get_mean_vector(self) -> plFloatVector


        `get_mean_vector() const -> plFloatVector`  

        Get mean vector.  

        """
        return _probt_python3.plNormal_get_mean_vector(self)


    def get_covariance_matrix(self) -> "plFloatMatrix":
        """
        get_covariance_matrix(self) -> plFloatMatrix


        `get_covariance_matrix() const -> plFloatMatrix`  

        Get covariance matrix.  

        """
        return _probt_python3.plNormal_get_covariance_matrix(self)


    def __init__(self, *args):
        """
        __init__(self) -> plNormal
        __init__(self, V, mu, Sigma) -> plNormal
        __init__(self, V, mu, sigma) -> plNormal
        __init__(self, arg2) -> plNormal


        `plNormal()`  
        `plNormal(const plVariablesConjunction &V, const plFloatVector &mu, const
            plFloatMatrix &Sigma)`  
        `plNormal(const plVariable &V, plFloat mu, plFloat sigma)`  
        `plNormal(const plDistribution &)`  

        Overloaded function
        -------------------
        * `plNormal()`  

            Default constructor, needed by the serialization code.  

        * `plNormal(const plVariablesConjunction &V, const plFloatVector &mu, const
            plFloatMatrix &Sigma)`  

            Constructor of an N-dimensional normal (Gaussian) distribution.  

            Parameters:  
            * `V` :  
                The N-dimentional variable on which the distribution is defined. They
                must be continuous  
            * `mu` :  
                The N-dimensional mean vector  
            * `Sigma` :  
                The NxN variance/covariance matrix (must be symetric positive)  

            The probability density function of the N-dimensional normal (Gaussian)
            distribution is: \[ p(x; \mu, \Sigma) = \frac {1} {\sqrt{|\Sigma|}
            (2\pi)^{N/2}} \exp\left( -0.5 (x-\mu) \Sigma^{-1} (x-\mu)^T \right)
            \]  

        * `plNormal(const plVariable &V, plFloat mu, plFloat sigma)`  

            Constructor of a one-dimensional normal (Gaussian) distribution.  

            Parameters:  
            * `V` :  
                The one-dimentional variable on which the distribution is defined  
            * `mu` :  
                The mean value  
            * `sigma` :  
                The standard deviation (square root of the variance), must be positive  

            The probability density function of the one-dimensional normal (Gaussian)
            distribution is: \[ p(x; \mu, \sigma) = \frac {1} {\sigma \sqrt{2\pi}
            } \exp\left( - \frac{(x-\mu)^2}{2\sigma^2} \right) \]  

        * `plNormal(const plDistribution &)`  

            Promote from a plDistribution.  

            If the object being copied is actually of the wrong type, an exception is
            raised.  

        """
        this = _probt_python3.new_plNormal(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def mahalanobis(self, *args) -> "plFloat":
        """
        mahalanobis(self, val) -> plFloat
        mahalanobis(self, val) -> plFloat
        mahalanobis(self, val) -> plFloat
        mahalanobis(self, val) -> plFloat
        mahalanobis(self, val) -> plFloat


        `mahalanobis(const std::vector< float > &val) const -> plFloat`  
        `mahalanobis(const std::vector< double > &val) const -> plFloat`  
        `mahalanobis(const std::vector< long double > &val) const -> plFloat`  
        `mahalanobis(const plValues &val) const -> plFloat`  
        `mahalanobis(const plFloatVector &val) const -> plFloat`  

        Overloaded function
        -------------------
        * `mahalanobis(const std::vector< float > &val) const -> plFloat`  

            Returns the Mahalanobis (normalized) distance.  

            Instantiated for Tval in std::vector<float>, std::vector<double>,
            std::vector<long double>, plValues, plFloatVector  

        * `mahalanobis(const std::vector< double > &val) const -> plFloat`  

        * `mahalanobis(const std::vector< long double > &val) const -> plFloat`  

        * `mahalanobis(const plValues &val) const -> plFloat`  

        * `mahalanobis(const plFloatVector &val) const -> plFloat`  

        """
        return _probt_python3.plNormal_mahalanobis(self, *args)


    def get_parameters(self, *args) -> "void":
        """
        get_parameters(self)
        get_parameters(self, m, sd)


        `get_parameters(plFloatVector &mu, plFloatMatrix &variance_matrix) const`  
        `get_parameters(plFloat &m, plFloat &sd) const`  

        Overloaded function
        -------------------
        * `get_parameters(plFloatVector &mu, plFloatMatrix &variance_matrix) const`  

            Get the parameters used for constructing this object.  

        * `get_parameters(plFloat &m, plFloat &sd) const`  

            Get the parameters used for constructing this object.  

            This function is valid only for 1D distributions.  

        """
        return _probt_python3.plNormal_get_parameters(self, *args)


    def mean(self) -> "plFloat":
        """
        mean(self) -> plFloat


        `mean() const -> plFloat`  

        Returns the mean of this distribution.  

        This function is valid only for 1D distributions.  

        """
        return _probt_python3.plNormal_mean(self)


    def standard_deviation(self) -> "plFloat":
        """
        standard_deviation(self) -> plFloat


        `standard_deviation() const -> plFloat`  

        Returns the standard deviation of this distribution.  

        This function is valid only for 1D distributions.  

        """
        return _probt_python3.plNormal_standard_deviation(self)


    def eigen_values(self) -> "plFloatVector const &":
        """
        eigen_values(self) -> plFloatVector


        `eigen_values() const -> const plFloatVector &`  

        Returns the eigen values of the covariance matrix.  

        This function is valid only for nD distributions.  

        """
        return _probt_python3.plNormal_eigen_values(self)


    def eigen_matrix(self) -> "plFloatMatrix const &":
        """
        eigen_matrix(self) -> plFloatMatrix


        `eigen_matrix() const -> const plFloatMatrix &`  

        Returns the eigen matrix the covariance matrix (each column is an eigen vector).  

        This function is valid only for nD distributions.  

        """
        return _probt_python3.plNormal_eigen_matrix(self)


    def variance_is_ok(self) -> "bool":
        """
        variance_is_ok(self) -> bool


        `variance_is_ok() const -> bool`  

        Return False if the determinante of the covariance matrix is > 0 (standard
        deviation > 0 in one-dimensional case)  

        """
        return _probt_python3.plNormal_variance_is_ok(self)


    def set_min_standard_deviation(val: 'plFloat') -> "void":
        """
        set_min_standard_deviation(val)


        `set_min_standard_deviation(plFloat val)`  

        Set/change the minimal allowed standard deviation (default is 1e-10)  

        Standard deviation values that are less than this value are replaced by this
        value  

        See also: get_min_standard_deviation()  

        """
        return _probt_python3.plNormal_set_min_standard_deviation(val)

    set_min_standard_deviation = staticmethod(set_min_standard_deviation)

    def get_min_standard_deviation() -> "plFloat":
        """
        get_min_standard_deviation() -> plFloat


        `get_min_standard_deviation() -> plFloat`  

        Get the minimal allowed standard deviation.  

        See also: set_min_standard_deviation()  

        """
        return _probt_python3.plNormal_get_min_standard_deviation()

    get_min_standard_deviation = staticmethod(get_min_standard_deviation)

    def __getstate__(self) -> "std::string":
        """__getstate__(self) -> std::string"""
        return _probt_python3.plNormal___getstate__(self)


    def __setstate_internal(self, sState: 'std::string const &') -> "void":
        """__setstate_internal(self, sState)"""
        return _probt_python3.plNormal___setstate_internal(self, sState)


    def __setstate__(self, sState):
        self.__init__()
        self.__setstate_internal(sState)

plNormal_swigregister = _probt_python3.plNormal_swigregister
plNormal_swigregister(plNormal)

def plNormal_set_min_standard_deviation(val: 'plFloat') -> "void":
    """
    plNormal_set_min_standard_deviation(val)


    `set_min_standard_deviation(plFloat val)`  

    Set/change the minimal allowed standard deviation (default is 1e-10)  

    Standard deviation values that are less than this value are replaced by this
    value  

    See also: get_min_standard_deviation()  

    """
    return _probt_python3.plNormal_set_min_standard_deviation(val)

def plNormal_get_min_standard_deviation() -> "plFloat":
    """
    plNormal_get_min_standard_deviation() -> plFloat


    `get_min_standard_deviation() -> plFloat`  

    Get the minimal allowed standard deviation.  

    See also: set_min_standard_deviation()  

    """
    return _probt_python3.plNormal_get_min_standard_deviation()

class plVonMises(plDistribution):
    """

    `plVonMises()`  
    `plVonMises(const plVariable &V, plFloat mean, plFloat k)`  
    `plVonMises(const plDistribution &)`  

    This class implements Von Mises distribution.  

    Von Mises distribution (also known as the circular normal distribution or
    Tikhonov distribution) is a continuous probability distribution on the circle.
    It is a close approximation to the wrapped normal distribution, which is the
    circular analogue of the normal distribution.  

    The probability density function of the Von Mises distribution is: \[ p(x;
    \mu, k) = \frac {\exp \left( k \times cos(x - \mu) \right)} {2 \pi
    I_0(k)} \] where I0(x) is the modified Bessel function of order 0.  

    Constructors
    ------------
    * `plVonMises()`  

        Default constructor, needed by the serialization code.  

    * `plVonMises(const plVariable &V, plFloat mean, plFloat k)`  

        Constructor.  

        Parameters:  
        * `V` :  
            The variable on which the distribution is defined  
        * `mean` :  
            (mu) The mean value  
        * `k` :  
            A measure of concentration (a reciprocal measure of dispersion, so 1/
            is analogous to the variance in Normal distribution).  

        The probability density function of the Von Mises distribution is: \[ p(x;
        \mu, k) = \frac {\exp(k \times cos(x - \mu))} {2 \pi I_0(k)} \] where
        I0(x) is the modified Bessel function of order 0.  

    * `plVonMises(const plDistribution &)`  

        Promote from a plDistribution.  

        If the object being copied is actually of the wrong type, an exception is
        raised.  

    C++ includes: plVonMises.h

    """

    __swig_setmethods__ = {}
    for _s in [plDistribution]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plVonMises, name, value)
    __swig_getmethods__ = {}
    for _s in [plDistribution]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plVonMises, name)
    __repr__ = _swig_repr
    __swig_destroy__ = _probt_python3.delete_plVonMises
    __del__ = lambda self: None

    def __init__(self, *args):
        """
        __init__(self) -> plVonMises
        __init__(self, V, mean, k) -> plVonMises
        __init__(self, arg2) -> plVonMises


        `plVonMises()`  
        `plVonMises(const plVariable &V, plFloat mean, plFloat k)`  
        `plVonMises(const plDistribution &)`  

        Overloaded function
        -------------------
        * `plVonMises()`  

            Default constructor, needed by the serialization code.  

        * `plVonMises(const plVariable &V, plFloat mean, plFloat k)`  

            Constructor.  

            Parameters:  
            * `V` :  
                The variable on which the distribution is defined  
            * `mean` :  
                (mu) The mean value  
            * `k` :  
                A measure of concentration (a reciprocal measure of dispersion, so 1/
                is analogous to the variance in Normal distribution).  

            The probability density function of the Von Mises distribution is: \[ p(x;
            \mu, k) = \frac {\exp(k \times cos(x - \mu))} {2 \pi I_0(k)} \] where
            I0(x) is the modified Bessel function of order 0.  

        * `plVonMises(const plDistribution &)`  

            Promote from a plDistribution.  

            If the object being copied is actually of the wrong type, an exception is
            raised.  

        """
        this = _probt_python3.new_plVonMises(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def get_parameters(self, mean: 'plFloat &', k: 'plFloat &') -> "void":
        """
        get_parameters(self, mean, k)


        `get_parameters(plFloat &mean, plFloat &k) const`  

        Get the parameters used for constructing this object.  

        """
        return _probt_python3.plVonMises_get_parameters(self, mean, k)


    def mean(self) -> "plFloat":
        """
        mean(self) -> plFloat


        `mean() const -> plFloat`  

        Returns the mean of this distribution.  

        """
        return _probt_python3.plVonMises_mean(self)


    def k(self) -> "plFloat":
        """
        k(self) -> plFloat


        `k() const -> plFloat`  

        Returns the 'k' parameter of this distribution.  

        """
        return _probt_python3.plVonMises_k(self)


    def __getstate__(self) -> "std::string":
        """__getstate__(self) -> std::string"""
        return _probt_python3.plVonMises___getstate__(self)


    def __setstate_internal(self, sState: 'std::string const &') -> "void":
        """__setstate_internal(self, sState)"""
        return _probt_python3.plVonMises___setstate_internal(self, sState)


    def __setstate__(self, sState):
        self.__init__()
        self.__setstate_internal(sState)

plVonMises_swigregister = _probt_python3.plVonMises_swigregister
plVonMises_swigregister(plVonMises)

class plDeterministic(plDistribution):
    """

    `plDeterministic()`  
    `plDeterministic(const plVariablesConjunction &variables, const plValues
        &values)`  
    `plDeterministic(const plValues &values)`  
    `plDeterministic(const plDistribution &)`  

    The *plDeterministic* class implements the "Dirac" or "Delta" function.  

    The probability (density for continuous variables) is 1.0 (infinity for
    continuous variables) in one and only one point of the domain of the variable
    *variable*.  

    Constructors
    ------------
    * `plDeterministic()`  

    * `plDeterministic(const plVariablesConjunction &variables, const plValues
        &values)`  

        Constructs a Dirac with variables *variables* at point *values*.  

    * `plDeterministic(const plValues &values)`  

        Constructs a Dirac at point *values*.  

    * `plDeterministic(const plDistribution &)`  

        Promote from a plDistribution.  

        If the object being copied is actually of the wrong type, an exception is
        raised.  

    C++ includes: plDeterministic.h

    """

    __swig_setmethods__ = {}
    for _s in [plDistribution]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plDeterministic, name, value)
    __swig_getmethods__ = {}
    for _s in [plDistribution]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plDeterministic, name)
    __repr__ = _swig_repr
    __swig_destroy__ = _probt_python3.delete_plDeterministic
    __del__ = lambda self: None

    def get_dirac_point(self) -> "plValues":
        """
        get_dirac_point(self) -> plValues


        `get_dirac_point() const -> plValues`  

        Get back the point where the probability is non null.  

        """
        return _probt_python3.plDeterministic_get_dirac_point(self)


    def __init__(self, *args):
        """
        __init__(self) -> plDeterministic
        __init__(self, variables, values) -> plDeterministic
        __init__(self, values) -> plDeterministic
        __init__(self, arg2) -> plDeterministic


        `plDeterministic()`  
        `plDeterministic(const plVariablesConjunction &variables, const plValues
            &values)`  
        `plDeterministic(const plValues &values)`  
        `plDeterministic(const plDistribution &)`  

        Overloaded function
        -------------------
        * `plDeterministic()`  

        * `plDeterministic(const plVariablesConjunction &variables, const plValues
            &values)`  

            Constructs a Dirac with variables *variables* at point *values*.  

        * `plDeterministic(const plValues &values)`  

            Constructs a Dirac at point *values*.  

        * `plDeterministic(const plDistribution &)`  

            Promote from a plDistribution.  

            If the object being copied is actually of the wrong type, an exception is
            raised.  

        """
        this = _probt_python3.new_plDeterministic(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def is_base_class(self) -> "bool":
        """
        is_base_class(self) -> bool


        `is_base_class() const -> bool`  

        """
        return _probt_python3.plDeterministic_is_base_class(self)


    def set_continuous_dirac_prob(val: 'plProbValue') -> "void":
        """
        set_continuous_dirac_prob(val)


        `set_continuous_dirac_prob(plProbValue val)`  

        Set/change probability value to be returned for the dirac point (default is 1.0)  

        See also: get_continuous_dirac_prob()  

        """
        return _probt_python3.plDeterministic_set_continuous_dirac_prob(val)

    set_continuous_dirac_prob = staticmethod(set_continuous_dirac_prob)

    def get_continuous_dirac_prob() -> "plProbValue":
        """
        get_continuous_dirac_prob() -> plProbValue


        `get_continuous_dirac_prob() -> plProbValue`  

        Get the probability value to be returned for the dirac point.  

        See also: set_continuous_dirac_prob()  

        """
        return _probt_python3.plDeterministic_get_continuous_dirac_prob()

    get_continuous_dirac_prob = staticmethod(get_continuous_dirac_prob)

    def __getstate__(self) -> "std::string":
        """__getstate__(self) -> std::string"""
        return _probt_python3.plDeterministic___getstate__(self)


    def __setstate_internal(self, sState: 'std::string const &') -> "void":
        """__setstate_internal(self, sState)"""
        return _probt_python3.plDeterministic___setstate_internal(self, sState)


    def __setstate__(self, sState):
        self.__init__()
        self.__setstate_internal(sState)

plDeterministic_swigregister = _probt_python3.plDeterministic_swigregister
plDeterministic_swigregister(plDeterministic)

def plDeterministic_set_continuous_dirac_prob(val: 'plProbValue') -> "void":
    """
    plDeterministic_set_continuous_dirac_prob(val)


    `set_continuous_dirac_prob(plProbValue val)`  

    Set/change probability value to be returned for the dirac point (default is 1.0)  

    See also: get_continuous_dirac_prob()  

    """
    return _probt_python3.plDeterministic_set_continuous_dirac_prob(val)

def plDeterministic_get_continuous_dirac_prob() -> "plProbValue":
    """
    plDeterministic_get_continuous_dirac_prob() -> plProbValue


    `get_continuous_dirac_prob() -> plProbValue`  

    Get the probability value to be returned for the dirac point.  

    See also: set_continuous_dirac_prob()  

    """
    return _probt_python3.plDeterministic_get_continuous_dirac_prob()

class plBinomial(plDistribution):
    """

    `plBinomial()`  
    `plBinomial(const plVariable &variable, plProbValue p)`  
    `plBinomial(const plDistribution &)`  

    This class implements the binomial distribution.  

    The binomial distribution is used when there are exactly two mutually exclusive
    outcomes of a trial. These outcomes are appropriately labeled *success* and
    *failure*. The binomial distribution is used to obtain the probability of
    observing *x* successes in *N* trials, with the probability of success on a
    single trial denoted by *p*. The binomial distribution assumes that *p* is fixed
    for all trials.  
     The binomial probability distribution has the following formula (for x = 0, 1,
    ..., N):  \[ P(x; p, N) = \frac{ N!~p^x~(1-p)^{N-x} }{x!~(N-x)! } \]  

    Constructors
    ------------
    * `plBinomial()`  

        Default constructor used for serialization.  

    * `plBinomial(const plVariable &variable, plProbValue p)`  

        Constructs a plBinomial distribution on the domain of the *variable*.  

        The parameter *p* is the probability of *success* (the probability that the
        single event happens).  
         The parameter *N* is the number of *trials* and is just the maximal value
        of the one-dimensional variable *variable* taking its value in 0...N.  
         The binomial probability distribution has the following formula (for x = 0,
        1, ..., N):  \[ P(x; p, N) = \frac{ N!~p^x~(1-p)^{N-x} }{x!~(N-x)! } \]  

        The parameter *N* in the formula above is extracted from the variable
        *variable* definition (the maximal value of *variable*).  

    * `plBinomial(const plDistribution &)`  

        Promote from a plDistribution.  

        If the object being copied is actually of the wrong type, an exception is
        raised.  

    C++ includes: plBinomial.h

    """

    __swig_setmethods__ = {}
    for _s in [plDistribution]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plBinomial, name, value)
    __swig_getmethods__ = {}
    for _s in [plDistribution]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plBinomial, name)
    __repr__ = _swig_repr
    __swig_destroy__ = _probt_python3.delete_plBinomial
    __del__ = lambda self: None

    def get_p(self) -> "plProbValue":
        """
        get_p(self) -> plProbValue


        `get_p() const -> plProbValue`  

        Get the parameter used for constructing this object.  

        """
        return _probt_python3.plBinomial_get_p(self)


    def __init__(self, *args):
        """
        __init__(self) -> plBinomial
        __init__(self, variable, p) -> plBinomial
        __init__(self, arg2) -> plBinomial


        `plBinomial()`  
        `plBinomial(const plVariable &variable, plProbValue p)`  
        `plBinomial(const plDistribution &)`  

        Overloaded function
        -------------------
        * `plBinomial()`  

            Default constructor used for serialization.  

        * `plBinomial(const plVariable &variable, plProbValue p)`  

            Constructs a plBinomial distribution on the domain of the *variable*.  

            The parameter *p* is the probability of *success* (the probability that the
            single event happens).  
             The parameter *N* is the number of *trials* and is just the maximal value
            of the one-dimensional variable *variable* taking its value in 0...N.  
             The binomial probability distribution has the following formula (for x = 0,
            1, ..., N):  \[ P(x; p, N) = \frac{ N!~p^x~(1-p)^{N-x} }{x!~(N-x)! } \]  

            The parameter *N* in the formula above is extracted from the variable
            *variable* definition (the maximal value of *variable*).  

        * `plBinomial(const plDistribution &)`  

            Promote from a plDistribution.  

            If the object being copied is actually of the wrong type, an exception is
            raised.  

        """
        this = _probt_python3.new_plBinomial(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def is_base_class(self) -> "bool":
        """
        is_base_class(self) -> bool


        `is_base_class() const -> bool`  

        """
        return _probt_python3.plBinomial_is_base_class(self)


    def __getstate__(self) -> "std::string":
        """__getstate__(self) -> std::string"""
        return _probt_python3.plBinomial___getstate__(self)


    def __setstate_internal(self, sState: 'std::string const &') -> "void":
        """__setstate_internal(self, sState)"""
        return _probt_python3.plBinomial___setstate_internal(self, sState)


    def __setstate__(self, sState):
        self.__init__()
        self.__setstate_internal(sState)

plBinomial_swigregister = _probt_python3.plBinomial_swigregister
plBinomial_swigregister(plBinomial)

class plPoisson(plDistribution):
    """

    `plPoisson()`  
    `plPoisson(const plVariable &v, plFloat mean)`  
    `plPoisson(const plDistribution &)`  

    This class implements the Poisson distribution.  

    Constructors
    ------------
    * `plPoisson()`  

        Default constructor, needed by the serialization code.  

    * `plPoisson(const plVariable &v, plFloat mean)`  

        Constructs a Poisson distribution on the domain of the *variable*.  

        The value "mean" (also called lambda) is the mean of the distribution.  
        The variable "variable" has to take solely positive or null integer
        values.  
        The formula for Poisson distribution is: p(x)= exp(-mean) * mean^x / x!  

    * `plPoisson(const plDistribution &)`  

        Promote from a plDistribution.  

        If the object being copied is actually of the wrong type, an exception is
        raised.  

    C++ includes: plPoisson.h

    """

    __swig_setmethods__ = {}
    for _s in [plDistribution]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plPoisson, name, value)
    __swig_getmethods__ = {}
    for _s in [plDistribution]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plPoisson, name)
    __repr__ = _swig_repr
    __swig_destroy__ = _probt_python3.delete_plPoisson
    __del__ = lambda self: None

    def get_parameters(self) -> "void":
        """
        get_parameters(self)


        `get_parameters(plFloat &mean) const`  

        Get the parameters used for constructing this object.  

        """
        return _probt_python3.plPoisson_get_parameters(self)


    def __init__(self, *args):
        """
        __init__(self) -> plPoisson
        __init__(self, v, mean) -> plPoisson
        __init__(self, arg2) -> plPoisson


        `plPoisson()`  
        `plPoisson(const plVariable &v, plFloat mean)`  
        `plPoisson(const plDistribution &)`  

        Overloaded function
        -------------------
        * `plPoisson()`  

            Default constructor, needed by the serialization code.  

        * `plPoisson(const plVariable &v, plFloat mean)`  

            Constructs a Poisson distribution on the domain of the *variable*.  

            The value "mean" (also called lambda) is the mean of the distribution.  
            The variable "variable" has to take solely positive or null integer
            values.  
            The formula for Poisson distribution is: p(x)= exp(-mean) * mean^x / x!  

        * `plPoisson(const plDistribution &)`  

            Promote from a plDistribution.  

            If the object being copied is actually of the wrong type, an exception is
            raised.  

        """
        this = _probt_python3.new_plPoisson(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def is_base_class(self) -> "bool":
        """
        is_base_class(self) -> bool


        `is_base_class() const -> bool`  

        """
        return _probt_python3.plPoisson_is_base_class(self)


    def __getstate__(self) -> "std::string":
        """__getstate__(self) -> std::string"""
        return _probt_python3.plPoisson___getstate__(self)


    def __setstate_internal(self, sState: 'std::string const &') -> "void":
        """__setstate_internal(self, sState)"""
        return _probt_python3.plPoisson___setstate_internal(self, sState)


    def __setstate__(self, sState):
        self.__init__()
        self.__setstate_internal(sState)

plPoisson_swigregister = _probt_python3.plPoisson_swigregister
plPoisson_swigregister(plPoisson)

class plUniform(plDistribution):
    """

    `plUniform()`  
    `plUniform(const plVariable &variable)`  
    `plUniform(const plVariable &variable, T min, T max)`  
    `plUniform(const plVariablesConjunction &variables)`  
    `plUniform(const plVariablesConjunction &variable, T min, T max)`  
    `plUniform(const plVariablesConjunction &variable, const std::vector< T > &min,
        const std::vector< T > &max)`  
    `plUniform(const plDistribution &)`  

    The *plUniform* class implements 1-dimensional uniform distributions.  

    Constructors
    ------------
    * `plUniform()`  

        Default constructor, needed by the serialization code.  

    * `plUniform(const plVariable &variable)`  

        Constructs a uniform distribution over the range of the variable *variable*.  

    * `plUniform(const plVariable &variable, T min, T max)`  

        Creates a uniform distribution over *variable* in the range {min,..., max}
        for discrete variables and in the range [min, max[ for continuous ones.  

        This template function is instantiated for int, unsigned int, float, double,
        and long double.  

    * `plUniform(const plVariablesConjunction &variables)`  

        Constructs a uniform distribution over the range of the variable *variable*.  

    * `plUniform(const plVariablesConjunction &variable, T min, T max)`  

        Creates a uniform distribution over *variable* in the range {min,..., max}
        for discrete variables and in the range [min, max[ for continuous ones.  

        This template function is instantiated for int, unsigned int, float, double,
        and long double.  

    * `plUniform(const plVariablesConjunction &variable, const std::vector< T >
        &min, const std::vector< T > &max)`  

        Creates a uniform distribution over *variable* in the range {min,..., max}
        for discrete variables and in the range [min, max[ for continuous ones.  

        This template function is instantiated for int, unsigned int, float, double,
        and long double.  

    * `plUniform(const plDistribution &)`  

        Promote from a plDistribution.  

        This makes sense because all the information is actually in parent class
        plDistribution. If the object being copied is actually of the wrong type, an
        exception is raised.  

    C++ includes: plUniform.h

    """

    __swig_setmethods__ = {}
    for _s in [plDistribution]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plUniform, name, value)
    __swig_getmethods__ = {}
    for _s in [plDistribution]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plUniform, name)
    __repr__ = _swig_repr

    def create_uniform(variables: 'plVariablesConjunction') -> "plDistribution":
        """
        create_uniform(variables) -> plDistribution


        `create_uniform(const plVariablesConjunction &variables) -> plDistribution`  

        Create a multi-dimensional uniform on a set of variables It's equivalent to
        plDistribution(
        plUniform(variables[0])*plUniform(variables[1])*...*plUniform(variables[variables.size()-1])
        )  

        """
        return _probt_python3.plUniform_create_uniform(variables)

    create_uniform = staticmethod(create_uniform)

    def __init__(self, *args):
        """
        __init__(self) -> plUniform
        __init__(self, variable) -> plUniform
        __init__(self, variables) -> plUniform
        __init__(self, arg2) -> plUniform


        `plUniform()`  
        `plUniform(const plVariable &variable)`  
        `plUniform(const plVariable &variable, T min, T max)`  
        `plUniform(const plVariablesConjunction &variables)`  
        `plUniform(const plVariablesConjunction &variable, T min, T max)`  
        `plUniform(const plVariablesConjunction &variable, const std::vector< T > &min,
            const std::vector< T > &max)`  
        `plUniform(const plDistribution &)`  

        Overloaded function
        -------------------
        * `plUniform()`  

            Default constructor, needed by the serialization code.  

        * `plUniform(const plVariable &variable)`  

            Constructs a uniform distribution over the range of the variable *variable*.  

        * `plUniform(const plVariable &variable, T min, T max)`  

            Creates a uniform distribution over *variable* in the range {min,..., max}
            for discrete variables and in the range [min, max[ for continuous ones.  

            This template function is instantiated for int, unsigned int, float, double,
            and long double.  

        * `plUniform(const plVariablesConjunction &variables)`  

            Constructs a uniform distribution over the range of the variable *variable*.  

        * `plUniform(const plVariablesConjunction &variable, T min, T max)`  

            Creates a uniform distribution over *variable* in the range {min,..., max}
            for discrete variables and in the range [min, max[ for continuous ones.  

            This template function is instantiated for int, unsigned int, float, double,
            and long double.  

        * `plUniform(const plVariablesConjunction &variable, const std::vector< T >
            &min, const std::vector< T > &max)`  

            Creates a uniform distribution over *variable* in the range {min,..., max}
            for discrete variables and in the range [min, max[ for continuous ones.  

            This template function is instantiated for int, unsigned int, float, double,
            and long double.  

        * `plUniform(const plDistribution &)`  

            Promote from a plDistribution.  

            This makes sense because all the information is actually in parent class
            plDistribution. If the object being copied is actually of the wrong type, an
            exception is raised.  

        """
        this = _probt_python3.new_plUniform(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def is_base_class(self) -> "bool":
        """
        is_base_class(self) -> bool


        `is_base_class() const -> bool`  

        """
        return _probt_python3.plUniform_is_base_class(self)


    def __getstate__(self) -> "std::string":
        """__getstate__(self) -> std::string"""
        return _probt_python3.plUniform___getstate__(self)


    def __setstate_internal(self, sState: 'std::string const &') -> "void":
        """__setstate_internal(self, sState)"""
        return _probt_python3.plUniform___setstate_internal(self, sState)


    def __setstate__(self, sState):
        self.__init__()
        self.__setstate_internal(sState)

    __swig_destroy__ = _probt_python3.delete_plUniform
    __del__ = lambda self: None
plUniform_swigregister = _probt_python3.plUniform_swigregister
plUniform_swigregister(plUniform)

def plUniform_create_uniform(variables: 'plVariablesConjunction') -> "plDistribution":
    """
    plUniform_create_uniform(variables) -> plDistribution


    `create_uniform(const plVariablesConjunction &variables) -> plDistribution`  

    Create a multi-dimensional uniform on a set of variables It's equivalent to
    plDistribution(
    plUniform(variables[0])*plUniform(variables[1])*...*plUniform(variables[variables.size()-1])
    )  

    """
    return _probt_python3.plUniform_create_uniform(variables)

class plProbTable(plDistribution):
    """

    `plProbTable()`  
    `plProbTable(const plVariablesConjunction &V, bool random_prob_values=false)`  
    `plProbTable(const plVariablesConjunction &V, const T *values, bool
        is_already_normalized=false)`  
    `plProbTable(const plVariablesConjunction &V, const double *values, bool
        is_already_normalized=false)`  
    `plProbTable(const plVariablesConjunction &V, const float *values, bool
        is_already_normalized=false)`  
    `plProbTable(const plVariablesConjunction &V, const std::vector< T > &values,
        bool is_already_normalized=false)`  
    `plProbTable(const plVariablesConjunction &V, const std::vector< double >
        &values, bool is_already_normalized=false)`  
    `plProbTable(const plVariablesConjunction &V, const std::vector< float >
        &values, bool is_already_normalized=false)`  
    `plProbTable(const plVariablesConjunction &V, Titerator begin, Titerator end,
        bool is_already_normalized=false)`  
    `plProbTable(const plDistribution &)`  

    A plProbTable represents a table of probability values on discrete and/or
    continuous-by-interval variables.  

    This includes both the one-dimensional case and the multi-dimensional case.  

    Constructors
    ------------
    * `plProbTable()`  

        Default constructor, needed by the serialization code.  

    * `plProbTable(const plVariablesConjunction &V, bool random_prob_values=false)`  

        Constructor 1: Constructs a probability table over the variable (s) *V*.  

        If *random_prob_values* is *true*, the table is filled at random. If If
        *random_prob_values* is *false* (the default), the probability table is set
        to zero.  

    * `plProbTable(const plVariablesConjunction &V, const T *values, bool
        is_already_normalized=false)`  

        Constructor2: Constructs a probability table on the variable (s) *V* and
        fills it using the values contained in the C array *values*.  

        You should set is_already_normalized to true if values is a normalized table
        of numbers.  
         In multi-dimentional cases (H = H1^H2), where *H1* and *H2* can take n1 and
        n2 values respectively, it constructs the probability table on P(H) using
        the values *values* as follows:  

        *   P([H1=1, H2=1]) = values[0]  
        *   P([H1=1, H2=2]) = values[1]  
            .  
            .  
            .  
        *   P([H1=1, H2=n2]) = values[n2-1]  
        *   P([H1=2, H2=1]) = values[n2])  
        *   P([H1=2, H2=2]) = values[n2+1]  
            .  
            .  
            .  
        *   P([H1=2, H2=n2]) = values[2*(n2-1)]  
            .  
            .  
            .  
        *   P([H1=n, H2=m]) = values[(n1-1)*(n2-1)]  

    * `plProbTable(const plVariablesConjunction &V, const double *values, bool
        is_already_normalized=false)`  

    * `plProbTable(const plVariablesConjunction &V, const float *values, bool
        is_already_normalized=false)`  

    * `plProbTable(const plVariablesConjunction &V, const std::vector< T > &values,
        bool is_already_normalized=false)`  

        Constructor 3: Constructs a probability table on the variable (s) *V* and
        fills it using the values contained in the STL vector *values*.  

        Same as Constructor2 for multi dimensional cases.  

    * `plProbTable(const plVariablesConjunction &V, const std::vector< double >
        &values, bool is_already_normalized=false)`  

    * `plProbTable(const plVariablesConjunction &V, const std::vector< float >
        &values, bool is_already_normalized=false)`  

    * `plProbTable(const plVariablesConjunction &V, Titerator begin, Titerator end,
        bool is_already_normalized=false)`  

        Constructor 4: Constructs a probability table on the variable (s) *V* and
        fills it using the values defined by the range begin [begin, end).  

        Same as Constructor2 for multi dimensional cases.  

    * `plProbTable(const plDistribution &)`  

        Promote from a plDistribution.  

        If the object being copied is actually of the wrong type, an exception is
        raised.  

    C++ includes: plProbTable.h

    """

    __swig_setmethods__ = {}
    for _s in [plDistribution]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plProbTable, name, value)
    __swig_getmethods__ = {}
    for _s in [plDistribution]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plProbTable, name)
    __repr__ = _swig_repr
    __swig_destroy__ = _probt_python3.delete_plProbTable
    __del__ = lambda self: None

    def get_parameters(self, values: 'DoubleVector') -> "void":
        """
        get_parameters(self, values)


        `get_parameters(std::vector< plProbValue > &values) const`  

        Get the parameters used for constructing this object.  

        """
        return _probt_python3.plProbTable_get_parameters(self, values)


    def __init__(self, *args):
        """
        __init__(self) -> plProbTable
        __init__(self, V, random_prob_values=False) -> plProbTable
        __init__(self, V) -> plProbTable
        __init__(self, V, values, is_already_normalized=False) -> plProbTable
        __init__(self, V, values) -> plProbTable
        __init__(self, V, values, is_already_normalized=False) -> plProbTable
        __init__(self, V, values) -> plProbTable
        __init__(self, arg2) -> plProbTable


        `plProbTable()`  
        `plProbTable(const plVariablesConjunction &V, bool random_prob_values=false)`  
        `plProbTable(const plVariablesConjunction &V, const T *values, bool
            is_already_normalized=false)`  
        `plProbTable(const plVariablesConjunction &V, const double *values, bool
            is_already_normalized=false)`  
        `plProbTable(const plVariablesConjunction &V, const float *values, bool
            is_already_normalized=false)`  
        `plProbTable(const plVariablesConjunction &V, const std::vector< T > &values,
            bool is_already_normalized=false)`  
        `plProbTable(const plVariablesConjunction &V, const std::vector< double >
            &values, bool is_already_normalized=false)`  
        `plProbTable(const plVariablesConjunction &V, const std::vector< float >
            &values, bool is_already_normalized=false)`  
        `plProbTable(const plVariablesConjunction &V, Titerator begin, Titerator end,
            bool is_already_normalized=false)`  
        `plProbTable(const plDistribution &)`  

        Overloaded function
        -------------------
        * `plProbTable()`  

            Default constructor, needed by the serialization code.  

        * `plProbTable(const plVariablesConjunction &V, bool random_prob_values=false)`  

            Constructor 1: Constructs a probability table over the variable (s) *V*.  

            If *random_prob_values* is *true*, the table is filled at random. If If
            *random_prob_values* is *false* (the default), the probability table is set
            to zero.  

        * `plProbTable(const plVariablesConjunction &V, const T *values, bool
            is_already_normalized=false)`  

            Constructor2: Constructs a probability table on the variable (s) *V* and
            fills it using the values contained in the C array *values*.  

            You should set is_already_normalized to true if values is a normalized table
            of numbers.  
             In multi-dimentional cases (H = H1^H2), where *H1* and *H2* can take n1 and
            n2 values respectively, it constructs the probability table on P(H) using
            the values *values* as follows:  

            *   P([H1=1, H2=1]) = values[0]  
            *   P([H1=1, H2=2]) = values[1]  
                .  
                .  
                .  
            *   P([H1=1, H2=n2]) = values[n2-1]  
            *   P([H1=2, H2=1]) = values[n2])  
            *   P([H1=2, H2=2]) = values[n2+1]  
                .  
                .  
                .  
            *   P([H1=2, H2=n2]) = values[2*(n2-1)]  
                .  
                .  
                .  
            *   P([H1=n, H2=m]) = values[(n1-1)*(n2-1)]  

        * `plProbTable(const plVariablesConjunction &V, const double *values, bool
            is_already_normalized=false)`  

        * `plProbTable(const plVariablesConjunction &V, const float *values, bool
            is_already_normalized=false)`  

        * `plProbTable(const plVariablesConjunction &V, const std::vector< T > &values,
            bool is_already_normalized=false)`  

            Constructor 3: Constructs a probability table on the variable (s) *V* and
            fills it using the values contained in the STL vector *values*.  

            Same as Constructor2 for multi dimensional cases.  

        * `plProbTable(const plVariablesConjunction &V, const std::vector< double >
            &values, bool is_already_normalized=false)`  

        * `plProbTable(const plVariablesConjunction &V, const std::vector< float >
            &values, bool is_already_normalized=false)`  

        * `plProbTable(const plVariablesConjunction &V, Titerator begin, Titerator end,
            bool is_already_normalized=false)`  

            Constructor 4: Constructs a probability table on the variable (s) *V* and
            fills it using the values defined by the range begin [begin, end).  

            Same as Constructor2 for multi dimensional cases.  

        * `plProbTable(const plDistribution &)`  

            Promote from a plDistribution.  

            If the object being copied is actually of the wrong type, an exception is
            raised.  

        """
        this = _probt_python3.new_plProbTable(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def table(self) -> "std::vector< plProbValue,std::allocator< plProbValue > > const &":
        """
        table(self) -> DoubleVector


        `table() const -> const std::vector< plProbValue > &`  

        Get a const reference to the probability table.  

        """
        return _probt_python3.plProbTable_table(self)


    def is_base_class(self) -> "bool":
        """
        is_base_class(self) -> bool


        `is_base_class() const -> bool`  

        """
        return _probt_python3.plProbTable_is_base_class(self)


    def __getstate__(self) -> "std::string":
        """__getstate__(self) -> std::string"""
        return _probt_python3.plProbTable___getstate__(self)


    def __setstate_internal(self, sState: 'std::string const &') -> "void":
        """__setstate_internal(self, sState)"""
        return _probt_python3.plProbTable___setstate_internal(self, sState)


    def __setstate__(self, sState):
        self.__init__()
        self.__setstate_internal(sState)

plProbTable_swigregister = _probt_python3.plProbTable_swigregister
plProbTable_swigregister(plProbTable)

class plUnknown(plDistribution):
    """

    `plUnknown()`  
    `plUnknown(const plVariablesConjunction &variable)`  
    `plUnknown(const plDistribution &)`  

    The *plUnknown* class permits to define an unknown distribution on a set of
    variables *variable*.  

    Constructors
    ------------
    * `plUnknown()`  

        Default constructor, needed by the serialization code.  

    * `plUnknown(const plVariablesConjunction &variable)`  

        Constructs an unknown distribution on a set of variables *variable*.  


        When using an unknown probability distribution on v (P(v)), we are only
        allowed to define inference problems that do not require this distribution
        (i.e the inferred expressions do not contain the P(v) term). Unknown
        distributions are used to provide the user with a formal way of writing
        correct decompositions (joint distributions), but are not intended to
        produce any numerical results. All methods applied to this distribution will
        result into an error.  

    * `plUnknown(const plDistribution &)`  

        Promote from a plDistribution.  

        If the object being copied is actually of the wrong type, an exception is
        raised.  

    C++ includes: plUnknown.h

    """

    __swig_setmethods__ = {}
    for _s in [plDistribution]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plUnknown, name, value)
    __swig_getmethods__ = {}
    for _s in [plDistribution]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plUnknown, name)
    __repr__ = _swig_repr
    __swig_destroy__ = _probt_python3.delete_plUnknown
    __del__ = lambda self: None

    def __init__(self, *args):
        """
        __init__(self) -> plUnknown
        __init__(self, variable) -> plUnknown
        __init__(self, arg2) -> plUnknown


        `plUnknown()`  
        `plUnknown(const plVariablesConjunction &variable)`  
        `plUnknown(const plDistribution &)`  

        Overloaded function
        -------------------
        * `plUnknown()`  

            Default constructor, needed by the serialization code.  

        * `plUnknown(const plVariablesConjunction &variable)`  

            Constructs an unknown distribution on a set of variables *variable*.  


            When using an unknown probability distribution on v (P(v)), we are only
            allowed to define inference problems that do not require this distribution
            (i.e the inferred expressions do not contain the P(v) term). Unknown
            distributions are used to provide the user with a formal way of writing
            correct decompositions (joint distributions), but are not intended to
            produce any numerical results. All methods applied to this distribution will
            result into an error.  

        * `plUnknown(const plDistribution &)`  

            Promote from a plDistribution.  

            If the object being copied is actually of the wrong type, an exception is
            raised.  

        """
        this = _probt_python3.new_plUnknown(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def is_base_class(self) -> "bool":
        """
        is_base_class(self) -> bool


        `is_base_class() const -> bool`  

        """
        return _probt_python3.plUnknown_is_base_class(self)


    def __getstate__(self) -> "std::string":
        """__getstate__(self) -> std::string"""
        return _probt_python3.plUnknown___getstate__(self)


    def __setstate_internal(self, sState: 'std::string const &') -> "void":
        """__setstate_internal(self, sState)"""
        return _probt_python3.plUnknown___setstate_internal(self, sState)


    def __setstate__(self, sState):
        self.__init__()
        self.__setstate_internal(sState)

plUnknown_swigregister = _probt_python3.plUnknown_swigregister
plUnknown_swigregister(plUnknown)

class plCndDistribution(plComputableObject):
    """

    `plCndDistribution()`  
    `plCndDistribution(const plVariablesConjunction &left, const
        plVariablesConjunction &right, const plComputableObjectType &sig)`  
    `plCndDistribution(const plCndDistribution &cnd_distribution)`  
    `plCndDistribution(const plComputableObject &)`  
    `plCndDistribution(const plComputableObjectList &fun_list)`  
    `plCndDistribution(const plComputableObjectList &func_lis, const
        plVariablesConjunction &left_variables, const plVariablesConjunction
        &right_variables)`  
    `plCndDistribution(const plVariablesConjunction &left, const
        plVariablesConjunction &right, const plProbValue *table, bool
        already_normalized=false)`  
    `plCndDistribution(const plVariablesConjunction &left, const
        plVariablesConjunction &right, const std::vector< plProbValue > &table, bool
        already_normalized=false)`  
    `plCndDistribution(const plVariablesConjunction &left, const
        plVariablesConjunction &right, const std::vector< std::vector< plProbValue >
        > &table, bool already_normalized=false)`  
    `plCndDistribution(const plVariablesConjunction &left, const
        plVariablesConjunction &right)`  

    plCndDistribution is the base class of all conditional probability (and density)
    distributions like P(A | B).  

    Constructors
    ------------
    * `plCndDistribution()`  

        Empty constructor.  

        The resulting object is invalid for most operations, except for being
        assigned to, or used as a return value.  

    * `plCndDistribution(const plVariablesConjunction &left, const
        plVariablesConjunction &right, const plComputableObjectType &sig)`  

        Constructor using the left and right variables and also the signature.  

    * `plCndDistribution(const plCndDistribution &cnd_distribution)`  

        Constructs a conditional distribution from another conditional distribution.  

    * `plCndDistribution(const plComputableObject &)`  

        Constructs from a plComputableObject.  

        The object transmitted as parameter has to actually point to a conditional
        distribution, else a plError is raised.  

    * `plCndDistribution(const plComputableObjectList &fun_list)`  

        Creates a conditional distribution as a product of a conditional and non
        conditional distributions.  

        Throws an exception if the result of the product is not actually a
        conditional distribution.  

        The left variables of the constructed computable object are the
        concatenation (in the same order) of the left variables of all the terms of
        the list. Its right variables are the concatenation of the right variables
        of all the terms and that are not in left one above.  

    * `plCndDistribution(const plComputableObjectList &func_lis, const
        plVariablesConjunction &left_variables, const plVariablesConjunction
        &right_variables)`  

        Creates a conditional distribution as a product of a conditional and non
        conditional distributions.  

        Throws an exception if the result of the product is not actually a
        conditional distribution. This constructor explicits the left and right
        variables of the constructed distribution.  

    * `plCndDistribution(const plVariablesConjunction &left, const
        plVariablesConjunction &right, const plProbValue *table, bool
        already_normalized=false)`  

        Construct a plCndDistribution with an array of plProbValues implicitly
        defining a set of plProbTables.  

        ATTENTION: This constructor is reserved for discrete/discretized variables.  

        See also: plDistributionTable  

    * `plCndDistribution(const plVariablesConjunction &left, const
        plVariablesConjunction &right, const std::vector< plProbValue > &table, bool
        already_normalized=false)`  

        Construct a plCndDistribution with a vector of plProbValues implicitly
        defining a set of plProbTables.  

        ATTENTION: This constructor is reserved for discrete variables.  

        See also: plDistributionTable  

    * `plCndDistribution(const plVariablesConjunction &left, const
        plVariablesConjunction &right, const std::vector< std::vector< plProbValue >
        > &table, bool already_normalized=false)`  

    * `plCndDistribution(const plVariablesConjunction &left, const
        plVariablesConjunction &right)`  

        Construct a plCndDistribution containing random probability tables.  

    C++ includes: plCndDistribution.h

    """

    __swig_setmethods__ = {}
    for _s in [plComputableObject]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plCndDistribution, name, value)
    __swig_getmethods__ = {}
    for _s in [plComputableObject]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plCndDistribution, name)
    __repr__ = _swig_repr

    def __init__(self, *args):
        """
        __init__(self) -> plCndDistribution
        __init__(self, left, right, sig) -> plCndDistribution
        __init__(self, cnd_distribution) -> plCndDistribution
        __init__(self, arg2) -> plCndDistribution
        __init__(self, fun_list) -> plCndDistribution
        __init__(self, func_lis, left_variables, right_variables) -> plCndDistribution
        __init__(self, left, right, table, already_normalized=False) -> plCndDistribution
        __init__(self, left, right, table) -> plCndDistribution
        __init__(self, left, right, table, already_normalized=False) -> plCndDistribution
        __init__(self, left, right, table) -> plCndDistribution
        __init__(self, left, right) -> plCndDistribution


        `plCndDistribution()`  
        `plCndDistribution(const plVariablesConjunction &left, const
            plVariablesConjunction &right, const plComputableObjectType &sig)`  
        `plCndDistribution(const plCndDistribution &cnd_distribution)`  
        `plCndDistribution(const plComputableObject &)`  
        `plCndDistribution(const plComputableObjectList &fun_list)`  
        `plCndDistribution(const plComputableObjectList &func_lis, const
            plVariablesConjunction &left_variables, const plVariablesConjunction
            &right_variables)`  
        `plCndDistribution(const plVariablesConjunction &left, const
            plVariablesConjunction &right, const plProbValue *table, bool
            already_normalized=false)`  
        `plCndDistribution(const plVariablesConjunction &left, const
            plVariablesConjunction &right, const std::vector< plProbValue > &table, bool
            already_normalized=false)`  
        `plCndDistribution(const plVariablesConjunction &left, const
            plVariablesConjunction &right, const std::vector< std::vector< plProbValue >
            > &table, bool already_normalized=false)`  
        `plCndDistribution(const plVariablesConjunction &left, const
            plVariablesConjunction &right)`  

        Overloaded function
        -------------------
        * `plCndDistribution()`  

            Empty constructor.  

            The resulting object is invalid for most operations, except for being
            assigned to, or used as a return value.  

        * `plCndDistribution(const plVariablesConjunction &left, const
            plVariablesConjunction &right, const plComputableObjectType &sig)`  

            Constructor using the left and right variables and also the signature.  

        * `plCndDistribution(const plCndDistribution &cnd_distribution)`  

            Constructs a conditional distribution from another conditional distribution.  

        * `plCndDistribution(const plComputableObject &)`  

            Constructs from a plComputableObject.  

            The object transmitted as parameter has to actually point to a conditional
            distribution, else a plError is raised.  

        * `plCndDistribution(const plComputableObjectList &fun_list)`  

            Creates a conditional distribution as a product of a conditional and non
            conditional distributions.  

            Throws an exception if the result of the product is not actually a
            conditional distribution.  

            The left variables of the constructed computable object are the
            concatenation (in the same order) of the left variables of all the terms of
            the list. Its right variables are the concatenation of the right variables
            of all the terms and that are not in left one above.  

        * `plCndDistribution(const plComputableObjectList &func_lis, const
            plVariablesConjunction &left_variables, const plVariablesConjunction
            &right_variables)`  

            Creates a conditional distribution as a product of a conditional and non
            conditional distributions.  

            Throws an exception if the result of the product is not actually a
            conditional distribution. This constructor explicits the left and right
            variables of the constructed distribution.  

        * `plCndDistribution(const plVariablesConjunction &left, const
            plVariablesConjunction &right, const plProbValue *table, bool
            already_normalized=false)`  

            Construct a plCndDistribution with an array of plProbValues implicitly
            defining a set of plProbTables.  

            ATTENTION: This constructor is reserved for discrete/discretized variables.  

            See also: plDistributionTable  

        * `plCndDistribution(const plVariablesConjunction &left, const
            plVariablesConjunction &right, const std::vector< plProbValue > &table, bool
            already_normalized=false)`  

            Construct a plCndDistribution with a vector of plProbValues implicitly
            defining a set of plProbTables.  

            ATTENTION: This constructor is reserved for discrete variables.  

            See also: plDistributionTable  

        * `plCndDistribution(const plVariablesConjunction &left, const
            plVariablesConjunction &right, const std::vector< std::vector< plProbValue >
            > &table, bool already_normalized=false)`  

        * `plCndDistribution(const plVariablesConjunction &left, const
            plVariablesConjunction &right)`  

            Construct a plCndDistribution containing random probability tables.  

        """
        this = _probt_python3.new_plCndDistribution(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this
    __swig_destroy__ = _probt_python3.delete_plCndDistribution
    __del__ = lambda self: None

    def partial_instantiate(self, *args) -> "plCndDistribution":
        """
        partial_instantiate(self, distribution_to_instantiate, variables_to_instantiate, values)
        partial_instantiate(self, distribution_to_instantiate, values)
        partial_instantiate(self, variables_to_instantiate, values) -> plCndDistribution
        partial_instantiate(self, values) -> plCndDistribution


        `partial_instantiate(plCndDistribution &distribution_to_instantiate, const
            plVariablesConjunction &variables_to_instantiate, const plValues &values)
            const`  
        `partial_instantiate(plCndDistribution &distribution_to_instantiate, const
            plValues &values) const`  
        `partial_instantiate(const plVariablesConjunction &variables_to_instantiate,
            const plValues &values) const -> plCndDistribution`  
        `partial_instantiate(const plValues &values) const -> plCndDistribution`  

        Overloaded function
        -------------------
        * `partial_instantiate(plCndDistribution &distribution_to_instantiate, const
            plVariablesConjunction &variables_to_instantiate, const plValues &values)
            const`  

            Produces a new conditional distribution by instantiating a subset of the
            known variables given by a the plValues *values*.  

        * `partial_instantiate(plCndDistribution &distribution_to_instantiate, const
            plValues &values) const`  

            Same as above but the variables are assumed to be those of the passed
            *values*.  

        * `partial_instantiate(const plVariablesConjunction &variables_to_instantiate,
            const plValues &values) const -> plCndDistribution`  

            Produces a new conditional distribution by instantiating a subset of the
            known variables given by a the plValues *values*.  

            ie P(A | B C).partial_instantiate(C, c) yields P(A | B c) Note that this
            method returns a freshly created object. If you are calling it in a loop,
            consider using the version that modifies an existing object instead.  

        * `partial_instantiate(const plValues &values) const -> plCndDistribution`  

            Same as above but the variables are assumed to be those of the passed
            *values*.  

        """
        return _probt_python3.plCndDistribution_partial_instantiate(self, *args)


    def instantiate(self, *args) -> "plDistribution":
        """
        instantiate(self, distribution_to_instantiate, values, ensure_normalization_on_compute=True)
        instantiate(self, distribution_to_instantiate, values)
        instantiate(self, values, ensure_normalization_on_compute=True) -> plDistribution
        instantiate(self, values) -> plDistribution
        instantiate(self, distribution_to_instantiate, parameter, ensure_normalization_on_compute=True)
        instantiate(self, distribution_to_instantiate, parameter)
        instantiate(self, parameter, ensure_normalization_on_compute=True) -> plDistribution
        instantiate(self, parameter) -> plDistribution
        instantiate(self, distribution_to_instantiate, parameter, ensure_normalization_on_compute=True)
        instantiate(self, distribution_to_instantiate, parameter)
        instantiate(self, parameter, ensure_normalization_on_compute=True) -> plDistribution
        instantiate(self, parameter) -> plDistribution
        instantiate(self, distribution_to_instantiate, parameter, ensure_normalization_on_compute=True)
        instantiate(self, distribution_to_instantiate, parameter)
        instantiate(self, parameter, ensure_normalization_on_compute=True) -> plDistribution
        instantiate(self, parameter) -> plDistribution
        instantiate(self, distribution_to_instantiate, parameter, ensure_normalization_on_compute=True)
        instantiate(self, distribution_to_instantiate, parameter)
        instantiate(self, parameter, ensure_normalization_on_compute=True) -> plDistribution
        instantiate(self, parameter) -> plDistribution
        instantiate(self, distribution_to_instantiate, parameter, ensure_normalization_on_compute=True)
        instantiate(self, distribution_to_instantiate, parameter)
        instantiate(self, parameter, ensure_normalization_on_compute=True) -> plDistribution
        instantiate(self, parameter) -> plDistribution
        instantiate(self, distribution_to_instantiate, parameter, ensure_normalization_on_compute=True)
        instantiate(self, distribution_to_instantiate, parameter)
        instantiate(self, parameter, ensure_normalization_on_compute=True) -> plDistribution
        instantiate(self, parameter) -> plDistribution
        instantiate(self, distribution_to_instantiate, parameter, ensure_normalization_on_compute=True)
        instantiate(self, distribution_to_instantiate, parameter)
        instantiate(self, parameter, ensure_normalization_on_compute=True) -> plDistribution
        instantiate(self, parameter) -> plDistribution
        instantiate(self, distribution_to_instantiate, parameter, ensure_normalization_on_compute=True)
        instantiate(self, distribution_to_instantiate, parameter)
        instantiate(self, parameter, ensure_normalization_on_compute=True) -> plDistribution
        instantiate(self, parameter) -> plDistribution
        instantiate(self, distribution_to_instantiate, parameter, ensure_normalization_on_compute=True)
        instantiate(self, distribution_to_instantiate, parameter)
        instantiate(self, parameter, ensure_normalization_on_compute=True) -> plDistribution
        instantiate(self, parameter) -> plDistribution
        instantiate(self, distribution_to_instantiate, parameter, ensure_normalization_on_compute=True)
        instantiate(self, distribution_to_instantiate, parameter)
        instantiate(self, parameter, ensure_normalization_on_compute=True) -> plDistribution
        instantiate(self, parameter) -> plDistribution
        instantiate(self, distribution_to_instantiate, parameter, ensure_normalization_on_compute=True)
        instantiate(self, distribution_to_instantiate, parameter)
        instantiate(self, parameter, ensure_normalization_on_compute=True) -> plDistribution
        instantiate(self, parameter) -> plDistribution
        instantiate(self, distribution_to_instantiate, parameter, ensure_normalization_on_compute=True)
        instantiate(self, distribution_to_instantiate, parameter)
        instantiate(self, parameter, ensure_normalization_on_compute=True) -> plDistribution
        instantiate(self, parameter) -> plDistribution
        instantiate(self, distribution_to_instantiate, parameter, ensure_normalization_on_compute=True)
        instantiate(self, distribution_to_instantiate, parameter)
        instantiate(self, parameter, ensure_normalization_on_compute=True) -> plDistribution
        instantiate(self, parameter) -> plDistribution
        instantiate(self, distribution_to_instantiate, parameter, ensure_normalization_on_compute=True)
        instantiate(self, distribution_to_instantiate, parameter)
        instantiate(self, distribution_to_instantiate, parameter, ensure_normalization_on_compute=True)
        instantiate(self, distribution_to_instantiate, parameter)
        instantiate(self, parameter, ensure_normalization_on_compute=True) -> plDistribution
        instantiate(self, parameter) -> plDistribution
        instantiate(self, parameter, ensure_normalization_on_compute=True) -> plDistribution
        instantiate(self, parameter) -> plDistribution
        instantiate(self, distribution_to_instantiate, parameter, ensure_normalization_on_compute=True)
        instantiate(self, distribution_to_instantiate, parameter)
        instantiate(self, parameter, ensure_normalization_on_compute=True) -> plDistribution
        instantiate(self, parameter) -> plDistribution
        instantiate(self, distribution_to_instantiate, parameter, ensure_normalization_on_compute=True)
        instantiate(self, distribution_to_instantiate, parameter)
        instantiate(self, parameter, ensure_normalization_on_compute=True) -> plDistribution
        instantiate(self, parameter) -> plDistribution


        `instantiate(plDistribution &distribution_to_instantiate, const plValues
            &values, bool ensure_normalization_on_compute=true) const`  
        `instantiate(const plValues &values, bool ensure_normalization_on_compute=true)
            const -> plDistribution`  
        `instantiate(plDistribution &distribution_to_instantiate, const int *parameter,
            bool ensure_normalization_on_compute=true) const`  
        `instantiate(const int *parameter, bool ensure_normalization_on_compute=true)
            const -> plDistribution`  
        `instantiate(plDistribution &distribution_to_instantiate, const unsigned int
            *parameter, bool ensure_normalization_on_compute=true) const`  
        `instantiate(const unsigned int *parameter, bool
            ensure_normalization_on_compute=true) const -> plDistribution`  
        `instantiate(plDistribution &distribution_to_instantiate, const float
            *parameter, bool ensure_normalization_on_compute=true) const`  
        `instantiate(const float *parameter, bool ensure_normalization_on_compute=true)
            const -> plDistribution`  
        `instantiate(plDistribution &distribution_to_instantiate, const double
            *parameter, bool ensure_normalization_on_compute=true) const`  
        `instantiate(const double *parameter, bool ensure_normalization_on_compute=true)
            const -> plDistribution`  
        `instantiate(plDistribution &distribution_to_instantiate, const long double
            *parameter, bool ensure_normalization_on_compute=true) const`  
        `instantiate(const long double *parameter, bool
            ensure_normalization_on_compute=true) const -> plDistribution`  
        `instantiate(plDistribution &distribution_to_instantiate, const std::vector< int
            > &parameter, bool ensure_normalization_on_compute=true) const`  
        `instantiate(const std::vector< int > &parameter, bool
            ensure_normalization_on_compute=true) const -> plDistribution`  
        `instantiate(plDistribution &distribution_to_instantiate, const std::vector<
            unsigned int > &parameter, bool ensure_normalization_on_compute=true) const`  
        `instantiate(const std::vector< unsigned int > &parameter, bool
            ensure_normalization_on_compute=true) const -> plDistribution`  
        `instantiate(plDistribution &distribution_to_instantiate, const std::vector<
            float > &parameter, bool ensure_normalization_on_compute=true) const`  
        `instantiate(const std::vector< float > &parameter, bool
            ensure_normalization_on_compute=true) const -> plDistribution`  
        `instantiate(plDistribution &distribution_to_instantiate, const std::vector<
            double > &parameter, bool ensure_normalization_on_compute=true) const`  
        `instantiate(const std::vector< double > &parameter, bool
            ensure_normalization_on_compute=true) const -> plDistribution`  
        `instantiate(plDistribution &distribution_to_instantiate, const std::vector<
            long double > &parameter, bool ensure_normalization_on_compute=true) const`  
        `instantiate(const std::vector< long double > &parameter, bool
            ensure_normalization_on_compute=true) const -> plDistribution`  
        `instantiate(plDistribution &distribution_to_instantiate, int parameter, bool
            ensure_normalization_on_compute=true) const`  
        `instantiate(int parameter, bool ensure_normalization_on_compute=true) const ->
            plDistribution`  
        `instantiate(plDistribution &distribution_to_instantiate, unsigned int
            parameter, bool ensure_normalization_on_compute=true) const`  
        `instantiate(unsigned int parameter, bool ensure_normalization_on_compute=true)
            const -> plDistribution`  
        `instantiate(plDistribution &distribution_to_instantiate, float parameter, bool
            ensure_normalization_on_compute=true) const`  
        `instantiate(float parameter, bool ensure_normalization_on_compute=true) const
            -> plDistribution`  
        `instantiate(plDistribution &distribution_to_instantiate, double parameter, bool
            ensure_normalization_on_compute=true) const`  
        `instantiate(plDistribution &distribution_to_instantiate, long double parameter,
            bool ensure_normalization_on_compute=true) const`  
        `instantiate(double parameter, bool ensure_normalization_on_compute=true) const
            -> plDistribution`  
        `instantiate(long double parameter, bool ensure_normalization_on_compute=true)
            const -> plDistribution`  
        `instantiate(plDistribution &distribution_to_instantiate, const std::string
            &parameter, bool ensure_normalization_on_compute=true) const`  
        `instantiate(const std::string &parameter, bool
            ensure_normalization_on_compute=true) const -> plDistribution`  
        `instantiate(plDistribution &distribution_to_instantiate, const char *parameter,
            bool ensure_normalization_on_compute=true) const`  
        `instantiate(const char *parameter, bool ensure_normalization_on_compute=true)
            const -> plDistribution`  

        Overloaded function
        -------------------
        * `instantiate(plDistribution &distribution_to_instantiate, const plValues
            &values, bool ensure_normalization_on_compute=true) const`  

            Produces a new distribution by instantiating the known variables given by a
            the plValues *values*.  

            If *ensure_normalization_on_compute* is true, the obtained Distribution will
            return normalized values on calling the compute() method. If
            *ensure_normalization_on_compute* is false (the default is true), the
            instantiation will be faster.  

        * `instantiate(const plValues &values, bool
            ensure_normalization_on_compute=true) const -> plDistribution`  

            Produces a new distribution by instantiating the known variables given by a
            the plValues *values*.  

            If *ensure_normalization_on_compute* is true, the obtained Distribution will
            return normalized values on calling the compute() method. If
            *ensure_normalization_on_compute* is false (the default is true), the
            instantiation will be faster.  
             Using this method instead of the one that modifies its first argument will
            considerably slow down the following calls to plDistribution::compile(). If
            speed (as opposed to ease of use) is one of your concerns, use the version
            that modifies an existing object instead.  

        * `instantiate(plDistribution &distribution_to_instantiate, const int
            *parameter, bool ensure_normalization_on_compute=true) const`  

            Produces a new distribution by instantiating the known variables using the
            values given in a vector of values.  

            If *ensure_normalization_on_compute* is true, the obtained Distribution will
            return normalized values on calling the compute() method. If
            *ensure_normalization_on_compute* is false (the default is true), the
            instantiation will be faster.  

        * `instantiate(const int *parameter, bool ensure_normalization_on_compute=true)
            const -> plDistribution`  

            Produces a new distribution by instantiating the known variables using the
            values given in a vector of values.  

            If *ensure_normalization_on_compute* is true, the obtained Distribution will
            return normalized values on calling the compute() method. If
            *ensure_normalization_on_compute* is false (the default is true), the
            instantiation will be faster.  

        * `instantiate(plDistribution &distribution_to_instantiate, const unsigned int
            *parameter, bool ensure_normalization_on_compute=true) const`  

        * `instantiate(const unsigned int *parameter, bool
            ensure_normalization_on_compute=true) const -> plDistribution`  

        * `instantiate(plDistribution &distribution_to_instantiate, const float
            *parameter, bool ensure_normalization_on_compute=true) const`  

            Produces a new distribution by instantiating the known variables using the
            values given in a vector of values.  

            If *ensure_normalization_on_compute* is true, the obtained Distribution will
            return normalized values on calling the compute() method. If
            *ensure_normalization_on_compute* is false (the default is true), the
            instantiation will be faster.  

        * `instantiate(const float *parameter, bool
            ensure_normalization_on_compute=true) const -> plDistribution`  

        * `instantiate(plDistribution &distribution_to_instantiate, const double
            *parameter, bool ensure_normalization_on_compute=true) const`  

            Produces a new distribution by instantiating the known variables using the
            values given in a vector of values.  

            If *ensure_normalization_on_compute* is true, the obtained Distribution will
            return normalized values on calling the compute() method. If
            *ensure_normalization_on_compute* is false (the default is true), the
            instantiation will be faster.  

        * `instantiate(const double *parameter, bool
            ensure_normalization_on_compute=true) const -> plDistribution`  

        * `instantiate(plDistribution &distribution_to_instantiate, const long double
            *parameter, bool ensure_normalization_on_compute=true) const`  

        * `instantiate(const long double *parameter, bool
            ensure_normalization_on_compute=true) const -> plDistribution`  

        * `instantiate(plDistribution &distribution_to_instantiate, const std::vector<
            int > &parameter, bool ensure_normalization_on_compute=true) const`  

            Produces a new distribution by instantiating the known variables using the
            values given in an STL vector.  

            If *ensure_normalization_on_compute* is true, the obtained Distribution will
            return normalized values on calling the compute() method. If
            *ensure_normalization_on_compute* is false (the default is true), the
            instantiation will be faster.  

        * `instantiate(const std::vector< int > &parameter, bool
            ensure_normalization_on_compute=true) const -> plDistribution`  

        * `instantiate(plDistribution &distribution_to_instantiate, const std::vector<
            unsigned int > &parameter, bool ensure_normalization_on_compute=true) const`  

            Produces a new distribution by instantiating the known variables using the
            values given in an STL vector.  

            If *ensure_normalization_on_compute* is true, the obtained Distribution will
            return normalized values on calling the compute() method. If
            *ensure_normalization_on_compute* is false (the default is true), the
            instantiation will be faster.  

        * `instantiate(const std::vector< unsigned int > &parameter, bool
            ensure_normalization_on_compute=true) const -> plDistribution`  

        * `instantiate(plDistribution &distribution_to_instantiate, const std::vector<
            float > &parameter, bool ensure_normalization_on_compute=true) const`  

            Produces a new distribution by instantiating the known variables using the
            values given in an STL vector.  

            If *ensure_normalization_on_compute* is true, the obtained Distribution will
            return normalized values on calling the compute() method. If
            *ensure_normalization_on_compute* is false (the default is true), the
            instantiation will be faster.  

        * `instantiate(const std::vector< float > &parameter, bool
            ensure_normalization_on_compute=true) const -> plDistribution`  

        * `instantiate(plDistribution &distribution_to_instantiate, const std::vector<
            double > &parameter, bool ensure_normalization_on_compute=true) const`  

            Produces a new distribution by instantiating the known variables using the
            values given in an STL vector.  

            If *ensure_normalization_on_compute* is true, the obtained Distribution will
            return normalized values on calling the compute() method. If
            *ensure_normalization_on_compute* is false (the default is true), the
            instantiation will be faster.  

        * `instantiate(const std::vector< double > &parameter, bool
            ensure_normalization_on_compute=true) const -> plDistribution`  

        * `instantiate(plDistribution &distribution_to_instantiate, const std::vector<
            long double > &parameter, bool ensure_normalization_on_compute=true) const`  

        * `instantiate(const std::vector< long double > &parameter, bool
            ensure_normalization_on_compute=true) const -> plDistribution`  

        * `instantiate(plDistribution &distribution_to_instantiate, int parameter, bool
            ensure_normalization_on_compute=true) const`  

            Produce a new distribution by instantiating the known variable using the
            value of a single value.  

            If *ensure_normalization_on_compute* is true, the obtained Distribution will
            return normalized values on calling the compute() method. If
            *ensure_normalization_on_compute* is false (the default is true), the
            instantiation will be faster.  

        * `instantiate(int parameter, bool ensure_normalization_on_compute=true) const
            -> plDistribution`  

            Produces a new distribution by instantiating the known variables given by a
            T (single value).  

            If *ensure_normalization_on_compute* is true, the obtained Distribution will
            return normalized values on calling the compute() method. If
            *ensure_normalization_on_compute* is false (the default is true), the
            instantiation will be faster.  
             Using this method instead of the one that modifies its first argument will
            considerably slow down the following calls to plDistribution::compile(). If
            speed (as opposed to ease of use) is one of your concerns, use the version
            that modifies an existing object instead.  
             This is the fonctionnal version of the method above. It permits the
            following syntax : pL_R.instantiate( special_Right_values ).compute(
            special_Left_values ) which is the PL programming form of P([L =
            special_Left_values]|[R = special_Right_values])  

        * `instantiate(plDistribution &distribution_to_instantiate, unsigned int
            parameter, bool ensure_normalization_on_compute=true) const`  

        * `instantiate(unsigned int parameter, bool
            ensure_normalization_on_compute=true) const -> plDistribution`  

        * `instantiate(plDistribution &distribution_to_instantiate, float parameter,
            bool ensure_normalization_on_compute=true) const`  

            Produce a new distribution by instantiating the known variable using the
            value of a single value.  

            If *ensure_normalization_on_compute* is true, the obtained Distribution will
            return normalized values on calling the compute() method. If
            *ensure_normalization_on_compute* is false (the default is true), the
            instantiation will be faster.  

        * `instantiate(float parameter, bool ensure_normalization_on_compute=true) const
            -> plDistribution`  

            Produces a new distribution by instantiating the known variables given by a
            T (single value).  

            If *ensure_normalization_on_compute* is true, the obtained Distribution will
            return normalized values on calling the compute() method. If
            *ensure_normalization_on_compute* is false (the default is true), the
            instantiation will be faster.  
             Using this method instead of the one that modifies its first argument will
            considerably slow down the following calls to plDistribution::compile(). If
            speed (as opposed to ease of use) is one of your concerns, use the version
            that modifies an existing object instead.  
             This is the fonctionnal version of the method above. It permits the
            following syntax : pL_R.instantiate( special_Right_values ).compute(
            special_Left_values ) which is the PL programming form of P([L =
            special_Left_values]|[R = special_Right_values])  

        * `instantiate(plDistribution &distribution_to_instantiate, double parameter,
            bool ensure_normalization_on_compute=true) const`  

            Produce a new distribution by instantiating the known variable using the
            value of a single value.  

            If *ensure_normalization_on_compute* is true, the obtained Distribution will
            return normalized values on calling the compute() method. If
            *ensure_normalization_on_compute* is false (the default is true), the
            instantiation will be faster.  

        * `instantiate(plDistribution &distribution_to_instantiate, long double
            parameter, bool ensure_normalization_on_compute=true) const`  

        * `instantiate(double parameter, bool ensure_normalization_on_compute=true)
            const -> plDistribution`  

            Produces a new distribution by instantiating the known variables given by a
            T (single value).  

            If *ensure_normalization_on_compute* is true, the obtained Distribution will
            return normalized values on calling the compute() method. If
            *ensure_normalization_on_compute* is false (the default is true), the
            instantiation will be faster.  
             Using this method instead of the one that modifies its first argument will
            considerably slow down the following calls to plDistribution::compile(). If
            speed (as opposed to ease of use) is one of your concerns, use the version
            that modifies an existing object instead.  
             This is the fonctionnal version of the method above. It permits the
            following syntax : pL_R.instantiate( special_Right_values ).compute(
            special_Left_values ) which is the PL programming form of P([L =
            special_Left_values]|[R = special_Right_values])  

        * `instantiate(long double parameter, bool ensure_normalization_on_compute=true)
            const -> plDistribution`  

        * `instantiate(plDistribution &distribution_to_instantiate, const std::string
            &parameter, bool ensure_normalization_on_compute=true) const`  

            Produce a new distribution by instantiating the known variable using the
            value of a single value.  

            If *ensure_normalization_on_compute* is true, the obtained Distribution will
            return normalized values on calling the compute() method. If
            *ensure_normalization_on_compute* is false (the default is true), the
            instantiation will be faster.  

        * `instantiate(const std::string &parameter, bool
            ensure_normalization_on_compute=true) const -> plDistribution`  

        * `instantiate(plDistribution &distribution_to_instantiate, const char
            *parameter, bool ensure_normalization_on_compute=true) const`  

        * `instantiate(const char *parameter, bool ensure_normalization_on_compute=true)
            const -> plDistribution`  

        """
        return _probt_python3.plCndDistribution_instantiate(self, *args)


    def compile_low_memory_use(self, result: 'plCndDistribution') -> "void":
        """
        compile_low_memory_use(self, result)


        `compile_low_memory_use(plCndDistribution &result) const`  

        Compiles the conditional distribution P(left_vars | right_vars) by constructing
        a DistributionTable of ProbTable.  

        The index variables of the DistributionTable are the discrete or discretized
        variables *right_vars*. For each value of *right_vars*, a ProbTable is
        constructed by exhaustively compiling the corresponding distribution (i.e. by
        visiting all points of the discrete or discretized *left_vars* space.  

        """
        return _probt_python3.plCndDistribution_compile_low_memory_use(self, result)


    def compile(self, *args) -> "plCndDistribution":
        """
        compile(self, result)
        compile(self) -> plCndDistribution
        compile(self, result, compiled_distrib_type)
        compile(self, compiled_distrib_type) -> plCndDistribution


        `compile(plCndDistribution &result) const`  
        `compile() const -> plCndDistribution`  
        `compile(plCndDistribution &result, plCompiledDistributionType
            compiled_distrib_type) const`  
        `compile(plCompiledDistributionType compiled_distrib_type) const ->
            plCndDistribution`  

        Overloaded function
        -------------------
        * `compile(plCndDistribution &result) const`  

            Compiles the conditional distribution P(left_vars | right_vars) by
            constructing a DistributionTable of ProbTable.  

            The index variables of the DistributionTable are the discrete or discretized
            variables *right_vars*. For each value of *right_vars*, a ProbTable is
            constructed by exhaustively compiling the corresponding distribution (i.e.
            by visiting all points of the discrete or discretized *left_vars* space.  

        * `compile() const -> plCndDistribution`  

            Compiles the conditional distribution P(left_vars | right_vars) by
            constructing a DistributionTable of ProbTable.  

            The index variables of the DistributionTable are the discrete or discretized
            variables *right_vars*. For each value of *right_vars*, a ProbTable is
            constructed by exhaustively compiling the corresponding distribution (i.e.
            by visiting all points of the discrete or discretized *left_vars* space.
            Note that this method returns a freshly created object. If you are calling
            it in a loop, consider using the version that modifies an existing object
            instead.  

        * `compile(plCndDistribution &result, plCompiledDistributionType
            compiled_distrib_type) const`  

            Compiles the conditional distribution P(left_vars | right_vars) by
            constructing a DistributionTable.  

            The index variables of the DistributionTable are the discrete or discretized
            variables *right_vars*. For each value of *right_vars*, a compiled
            distribution of type *compiled_distrib_type* is constructed by exhaustively
            compiling the corresponding distribution (i.e. by visiting all points of the
            discrete or discretized *left_vars* space.)  

        * `compile(plCompiledDistributionType compiled_distrib_type) const ->
            plCndDistribution`  

            Compiles the conditional distribution P(left_vars | right_vars) by
            constructing a DistributionTable.  

            The index variables of the DistributionTable are the discrete or discretized
            variables *right_vars*. For each value of *right_vars*, a compiled
            distribution of type *compiled_distrib_type* is constructed by exhaustively
            compiling the corresponding distribution (i.e. by visiting all points of the
            discrete or discretized *left_vars* space.) Note that this method returns a
            freshly created object. If you are calling it in a loop, consider using the
            version that modifies an existing object instead.  

        """
        return _probt_python3.plCndDistribution_compile(self, *args)


    def n_compile(self, result: 'plCndDistribution', n_iterations: 'unsigned int', generator_type: 'plGeneratorType'=PL_CHOOSE_GENERATOR_FOR_ME, compiled_distrib_type: 'plCompiledDistributionType'=PL_CHOOSE_COMP_TYPE_FOR_ME) -> "void":
        """
        n_compile(self, result, n_iterations, generator_type=PL_CHOOSE_GENERATOR_FOR_ME, compiled_distrib_type=PL_CHOOSE_COMP_TYPE_FOR_ME)
        n_compile(self, result, n_iterations, generator_type=PL_CHOOSE_GENERATOR_FOR_ME)
        n_compile(self, result, n_iterations)


        `n_compile(plCndDistribution &result, unsigned int n_iterations, plGeneratorType
            generator_type=PL_CHOOSE_GENERATOR_FOR_ME, plCompiledDistributionType
            compiled_distrib_type=PL_CHOOSE_COMP_TYPE_FOR_ME) const`  

        Compiles the conditional distribution P(left_vars | right_vars) by constructing
        a DistributionTable.  

        The index variables of the DistributionTable are the discrete or discretized
        variables *right_vars*. For each value of *right_vars*, the corresponding
        distribution is compiled by sampling it using a set of *n* points in the
        variables space The used points may be generated using 4 possible methods
        (according to the value of *generator_type*):  
         1) Using all points of the discrete or discretized variables space
        (PL_EXHAUSTIVE_GENERATOR)  
         2) Generating, for *time_in_seconds* seconds, a set of points at random from
        the variables space (PL_RANDOM_GENERATOR)  
         3) Generating, for *time_in_seconds* seconds, a set of points using a Monte
        Carlo generator from the variables space (PL_MC_GENERATOR).  
         4) Generating, for *time_in_seconds* seconds, a set of points using a Genetic
        Algorithm generator from the variables space (PL_GA_GENERATOR).  
        If *generator_type* is PL_CHOOSE_GENERATOR_FOR_ME (default value), ProBT will
        choose the optimal generator for you.  

        The result of the compilation is stored, according to the value of
        *compiled_distrib_type*, as:  
        1) a table (PL_TABLE).  
        2) an MRBT (PL_MRBT).  
        3) a map (PL_MAP) for non-null values.  
         If *compiled_distrib_type* is PL_CHOOSE_COMP_TYPE_FOR_ME (default value), ProBT
        will choose the optimal data structure for you.  

        """
        return _probt_python3.plCndDistribution_n_compile(self, result, n_iterations, generator_type, compiled_distrib_type)


    def time_compile(self, *args) -> "plCndDistribution":
        """
        time_compile(self, result, time_in_seconds, generator_type=PL_CHOOSE_GENERATOR_FOR_ME, compiled_distrib_type=PL_CHOOSE_COMP_TYPE_FOR_ME)
        time_compile(self, result, time_in_seconds, generator_type=PL_CHOOSE_GENERATOR_FOR_ME)
        time_compile(self, result, time_in_seconds)
        time_compile(self, time_in_seconds, generator_type=PL_CHOOSE_GENERATOR_FOR_ME, distrib_type=PL_CHOOSE_COMP_TYPE_FOR_ME) -> plCndDistribution
        time_compile(self, time_in_seconds, generator_type=PL_CHOOSE_GENERATOR_FOR_ME) -> plCndDistribution
        time_compile(self, time_in_seconds) -> plCndDistribution


        `time_compile(plCndDistribution &result, double time_in_seconds, plGeneratorType
            generator_type=PL_CHOOSE_GENERATOR_FOR_ME, plCompiledDistributionType
            compiled_distrib_type=PL_CHOOSE_COMP_TYPE_FOR_ME) const`  
        `time_compile(double time_in_seconds, plGeneratorType
            generator_type=PL_CHOOSE_GENERATOR_FOR_ME, plCompiledDistributionType
            distrib_type=PL_CHOOSE_COMP_TYPE_FOR_ME) const -> plCndDistribution`  

        Overloaded function
        -------------------
        * `time_compile(plCndDistribution &result, double time_in_seconds,
            plGeneratorType generator_type=PL_CHOOSE_GENERATOR_FOR_ME,
            plCompiledDistributionType compiled_distrib_type=PL_CHOOSE_COMP_TYPE_FOR_ME)
            const`  

            Compiles the conditional distribution P(left_vars | right_vars) by
            constructing a DistributionTable.  

            The index variables of the DistributionTable are the discrete or discretized
            variables *right_vars*. For each value of *right_vars*, the corresponding
            distribution is compiled by sampling it using a set of points in the
            variables space for *time_in_seconds*. The used points may be generated
            using 4 possible methods (according to the value of *generator_type*):  
             1) Using all points of the discrete or discretized variables space
            (PL_EXHAUSTIVE_GENERATOR)  
             2) Generating, for *time_in_seconds* seconds, a set of points at random
            from the variables space (PL_RANDOM_GENERATOR)  
             3) Generating, for *time_in_seconds* seconds, a set of points using a Monte
            Carlo generator from the variables space (PL_MC_GENERATOR).  
             4) Generating, for *time_in_seconds* seconds, a set of points using a
            Genetic Algorithm generator from the variables space (PL_GA_GENERATOR).  
            If *generator_type* is PL_CHOOSE_GENERATOR_FOR_ME (default value), ProBT
            will choose the optimal generator for you.  

            The result of the compilation is stored, according to the value of
            *compiled_distrib_type*, as:  
            1) a table (PL_TABLE).  
            2) an MRBT (PL_MRBT).  
            3) a map (PL_MAP) for non-null values.  
             If *compiled_distrib_type* is PL_CHOOSE_COMP_TYPE_FOR_ME (default value),
            ProBT will choose the optimal data structure for you.  

        * `time_compile(double time_in_seconds, plGeneratorType
            generator_type=PL_CHOOSE_GENERATOR_FOR_ME, plCompiledDistributionType
            distrib_type=PL_CHOOSE_COMP_TYPE_FOR_ME) const -> plCndDistribution`  

            Does a time_compile(), and returns the compiled distribution.  

            See time_compile() above for details.  

            Note that this method returns a freshly created object. If you are calling
            it in a loop, consider using the version that modifies an existing object
            instead.  

        """
        return _probt_python3.plCndDistribution_time_compile(self, *args)


    def as_builtin(ck: 'plCndDistribution') -> "plCndDistribution":
        """
        as_builtin(ck) -> plCndDistribution


        `as_builtin(const plCndDistribution &ck) -> plCndDistribution`  

        """
        return _probt_python3.plCndDistribution_as_builtin(ck)

    as_builtin = staticmethod(as_builtin)

    def compute(self, *args) -> "plProbValue":
        """
        compute(self, values) -> plProbValue
        compute(self, values) -> plProbValue
        compute(self, values) -> plProbValue
        compute(self, values) -> plProbValue
        compute(self, values) -> plProbValue
        compute(self, values) -> plProbValue
        compute(self, parameter) -> plProbValue
        compute(self, parameter) -> plProbValue
        compute(self, parameter) -> plProbValue
        compute(self, parameter) -> plProbValue
        compute(self, parameter) -> plProbValue
        compute(self, left_params, right_params) -> plProbValue
        compute(self, left_params, right_params) -> plProbValue
        compute(self, left_params, right_params) -> plProbValue
        compute(self, left_params, right_params) -> plProbValue
        compute(self, left_params, right_params) -> plProbValue
        compute(self, left_params, right_params) -> plProbValue
        compute(self, left_param, right_param) -> plProbValue
        compute(self, left_param, right_param) -> plProbValue
        compute(self, left_param, right_param) -> plProbValue
        compute(self, left_param, right_param) -> plProbValue
        compute(self, left_param, right_param) -> plProbValue
        compute(self, left_params, right_params) -> plProbValue
        compute(self, left_params, right_params) -> plProbValue
        compute(self, left_params, right_params) -> plProbValue
        compute(self, left_params, right_params) -> plProbValue
        compute(self, left_params, right_params) -> plProbValue
        compute(self, left_param, right_param) -> plProbValue
        compute(self, left_param, right_param) -> plProbValue


        `compute(const plValues &left_params, const plValues &right_params) const ->
            plProbValue`  
        `compute(const int *left_params, const int *right_params) const -> plProbValue`  
        `compute(const unsigned int *left_params, const unsigned int *right_params)
            const -> plProbValue`  
        `compute(const float *left_params, const float *right_params) const ->
            plProbValue`  
        `compute(const double *left_params, const double *right_params) const ->
            plProbValue`  
        `compute(const long double *left_params, const long double *right_params) const
            -> plProbValue`  
        `compute(int left_param, int right_param) const -> plProbValue`  
        `compute(unsigned int left_param, unsigned int right_param) const ->
            plProbValue`  
        `compute(float left_param, float right_param) const -> plProbValue`  
        `compute(double left_param, double right_param) const -> plProbValue`  
        `compute(long double left_param, long double right_param) const -> plProbValue`  
        `compute(const std::vector< int > &left_params, const std::vector< int >
            &right_params) const -> plProbValue`  
        `compute(const std::vector< unsigned int > &left_params, const std::vector<
            unsigned int > &right_params) const -> plProbValue`  
        `compute(const std::vector< float > &left_params, const std::vector< float >
            &right_params) const -> plProbValue`  
        `compute(const std::vector< double > &left_params, const std::vector< double >
            &right_params) const -> plProbValue`  
        `compute(const std::vector< long double > &left_params, const std::vector< long
            double > &right_params) const -> plProbValue`  
        `compute(const std::string &left_param, const std::string &right_param) const ->
            plProbValue`  
        `compute(const char *left_param, const char *right_param) const -> plProbValue`  

        Overloaded function
        -------------------
        * `compute(const plValues &left_params, const plValues &right_params) const ->
            plProbValue`  

            Computes the value of the function for the input parameters *left_params*
            and *right_params*.  

        * `compute(const int *left_params, const int *right_params) const ->
            plProbValue`  

            Computes the value of the function for the input parameters *left_params*
            and *right_params*.  

        * `compute(const unsigned int *left_params, const unsigned int *right_params)
            const -> plProbValue`  

            Computes the value of the function for the input parameters *left_params*
            and *right_params*.  

        * `compute(const float *left_params, const float *right_params) const ->
            plProbValue`  

            Computes the value of the function for the input parameters *left_params*
            and *right_params*.  

        * `compute(const double *left_params, const double *right_params) const ->
            plProbValue`  

            Computes the value of the function for the input parameters *left_params*
            and *right_params*.  

        * `compute(const long double *left_params, const long double *right_params)
            const -> plProbValue`  

            Computes the value of the function for the input parameters *left_params*
            and *right_params*.  

        * `compute(int left_param, int right_param) const -> plProbValue`  

            Computes the value of the function for the one-dimensional input parameters
            *left_param* and *right_param*.  

        * `compute(unsigned int left_param, unsigned int right_param) const ->
            plProbValue`  

            Computes the value of the function for the one-dimensional input parameters
            *left_param* and *right_param*.  

        * `compute(float left_param, float right_param) const -> plProbValue`  

            Computes the value of the function for the one-dimensional input parameters
            *left_param* and *right_param*.  

        * `compute(double left_param, double right_param) const -> plProbValue`  

            Computes the value of the function for the one-dimensional input parameters
            *left_param* and *right_param*.  

        * `compute(long double left_param, long double right_param) const ->
            plProbValue`  

            Computes the value of the function for the one-dimensional input parameters
            *left_param* and *right_param*.  

        * `compute(const std::vector< int > &left_params, const std::vector< int >
            &right_params) const -> plProbValue`  

            Computes the value of the function for the STL vector input *left_params*
            and *right_params*.  

        * `compute(const std::vector< unsigned int > &left_params, const std::vector<
            unsigned int > &right_params) const -> plProbValue`  

            Computes the value of the function for the STL vector input *left_params*
            and *right_params*.  

        * `compute(const std::vector< float > &left_params, const std::vector< float >
            &right_params) const -> plProbValue`  

            Computes the value of the function for the STL vector input *left_params*
            and *right_params*.  

        * `compute(const std::vector< double > &left_params, const std::vector< double >
            &right_params) const -> plProbValue`  

            Computes the value of the function for the STL vector input *left_params*
            and *right_params*.  

        * `compute(const std::vector< long double > &left_params, const std::vector<
            long double > &right_params) const -> plProbValue`  

            Computes the value of the function for the STL vector input *left_params*
            and *right_params*.  

        * `compute(const std::string &left_param, const std::string &right_param) const
            -> plProbValue`  

            Computes the value of the function for the string input *left_params* and
            *right_params*.  

        * `compute(const char *left_param, const char *right_param) const ->
            plProbValue`  

            Computes the value of the function for the string input *left_params* and
            *right_params*.  

        """
        return _probt_python3.plCndDistribution_compute(self, *args)


    def compute_log(self, *args) -> "plFloat":
        """
        compute_log(self, values) -> plFloat
        compute_log(self, values) -> plFloat
        compute_log(self, values) -> plFloat
        compute_log(self, values) -> plFloat
        compute_log(self, values) -> plFloat
        compute_log(self, values) -> plFloat
        compute_log(self, parameter) -> plFloat
        compute_log(self, parameter) -> plFloat
        compute_log(self, parameter) -> plFloat
        compute_log(self, parameter) -> plFloat
        compute_log(self, parameter) -> plFloat
        compute_log(self, left_params, right_params) -> plFloat
        compute_log(self, left_params, right_params) -> plFloat
        compute_log(self, left_params, right_params) -> plFloat
        compute_log(self, left_params, right_params) -> plFloat
        compute_log(self, left_params, right_params) -> plFloat
        compute_log(self, left_params, right_params) -> plFloat
        compute_log(self, left_param, right_param) -> plFloat
        compute_log(self, left_param, right_param) -> plFloat
        compute_log(self, left_param, right_param) -> plFloat
        compute_log(self, left_param, right_param) -> plFloat
        compute_log(self, left_param, right_param) -> plFloat
        compute_log(self, left_params, right_params) -> plFloat
        compute_log(self, left_params, right_params) -> plFloat
        compute_log(self, left_params, right_params) -> plFloat
        compute_log(self, left_params, right_params) -> plFloat
        compute_log(self, left_params, right_params) -> plFloat
        compute_log(self, left_param, right_param) -> plFloat
        compute_log(self, left_param, right_param) -> plFloat


        `compute_log(const plValues &left_params, const plValues &right_params) const ->
            plFloat`  
        `compute_log(const int *left_params, const int *right_params) const -> plFloat`  
        `compute_log(const unsigned int *left_params, const unsigned int *right_params)
            const -> plFloat`  
        `compute_log(const float *left_params, const float *right_params) const ->
            plFloat`  
        `compute_log(const double *left_params, const double *right_params) const ->
            plFloat`  
        `compute_log(const long double *left_params, const long double *right_params)
            const -> plFloat`  
        `compute_log(int left_param, int right_param) const -> plFloat`  
        `compute_log(unsigned int left_param, unsigned int right_param) const ->
            plFloat`  
        `compute_log(float left_param, float right_param) const -> plFloat`  
        `compute_log(double left_param, double right_param) const -> plFloat`  
        `compute_log(long double left_param, long double right_param) const -> plFloat`  
        `compute_log(const std::vector< int > &left_params, const std::vector< int >
            &right_params) const -> plFloat`  
        `compute_log(const std::vector< unsigned int > &left_params, const std::vector<
            unsigned int > &right_params) const -> plFloat`  
        `compute_log(const std::vector< float > &left_params, const std::vector< float >
            &right_params) const -> plFloat`  
        `compute_log(const std::vector< double > &left_params, const std::vector< double
            > &right_params) const -> plFloat`  
        `compute_log(const std::vector< long double > &left_params, const std::vector<
            long double > &right_params) const -> plFloat`  
        `compute_log(const std::string &left_param, const std::string &right_param)
            const -> plFloat`  
        `compute_log(const char *left_param, const char *right_param) const -> plFloat`  

        Overloaded function
        -------------------
        * `compute_log(const plValues &left_params, const plValues &right_params) const
            -> plFloat`  

            Computes the logarithm value of the function for the input parameters
            *left_params* and *right_params*.  

        * `compute_log(const int *left_params, const int *right_params) const ->
            plFloat`  

            Computes the logarithm value of the function for the array input parameters
            *left_params* and *right_params*.  

        * `compute_log(const unsigned int *left_params, const unsigned int
            *right_params) const -> plFloat`  

            Computes the logarithm value of the function for the array input parameters
            *left_params* and *right_params*.  

        * `compute_log(const float *left_params, const float *right_params) const ->
            plFloat`  

            Computes the logarithm value of the function for the array input parameters
            *left_params* and *right_params*.  

        * `compute_log(const double *left_params, const double *right_params) const ->
            plFloat`  

            Computes the logarithm value of the function for the array input parameters
            *left_params* and *right_params*.  

        * `compute_log(const long double *left_params, const long double *right_params)
            const -> plFloat`  

            Computes the logarithm value of the function for the array input parameters
            *left_params* and *right_params*.  

        * `compute_log(int left_param, int right_param) const -> plFloat`  

            Computes the logarithm value of the function for the one-dimensional input
            parameters *left_param* and *right_param*.  

        * `compute_log(unsigned int left_param, unsigned int right_param) const ->
            plFloat`  

            Computes the logarithm value of the function for the one-dimensional input
            parameters *left_param* and *right_param*.  

        * `compute_log(float left_param, float right_param) const -> plFloat`  

            Computes the logarithm value of the function for the one-dimensional input
            parameters *left_param* and *right_param*.  

        * `compute_log(double left_param, double right_param) const -> plFloat`  

            Computes the logarithm value of the function for the one-dimensional input
            parameters *left_param* and *right_param*.  

        * `compute_log(long double left_param, long double right_param) const ->
            plFloat`  

            Computes the logarithm value of the function for the one-dimensional input
            parameters *left_param* and *right_param*.  

        * `compute_log(const std::vector< int > &left_params, const std::vector< int >
            &right_params) const -> plFloat`  

            Computes the logarithm value of the function for the STL vector input
            *left_params* and *right_params*.  

        * `compute_log(const std::vector< unsigned int > &left_params, const
            std::vector< unsigned int > &right_params) const -> plFloat`  

            Computes the logarithm value of the function for the STL vector input
            *left_params* and *right_params*.  

        * `compute_log(const std::vector< float > &left_params, const std::vector< float
            > &right_params) const -> plFloat`  

            Computes the logarithm value of the function for the STL vector input
            *left_params* and *right_params*.  

        * `compute_log(const std::vector< double > &left_params, const std::vector<
            double > &right_params) const -> plFloat`  

            Computes the logarithm value of the function for the STL vector input
            *left_params* and *right_params*.  

        * `compute_log(const std::vector< long double > &left_params, const std::vector<
            long double > &right_params) const -> plFloat`  

            Computes the logarithm value of the function for the STL vector input
            *left_params* and *right_params*.  

        * `compute_log(const std::string &left_param, const std::string &right_param)
            const -> plFloat`  

            Computes the logarithm value of the function for the string input
            *left_params* and *right_params*.  

        * `compute_log(const char *left_param, const char *right_param) const ->
            plFloat`  

            Computes the logarithm value of the function for the string input
            *left_params* and *right_params*.  

        """
        return _probt_python3.plCndDistribution_compute_log(self, *args)


    def validate_prediction(self, *args) -> "plPredictionPerformanceReport":
        """
        validate_prediction(self, data, nrows) -> plPredictionPerformanceReport
        validate_prediction(self, data) -> plPredictionPerformanceReport
        validate_prediction(self, data) -> plPredictionPerformanceReport


        `validate_prediction(plDataDescriptor &data, unsigned int
            nrows=std::numeric_limits< unsigned int >::max()) const ->
            plPredictionPerformanceReport`  
        `validate_prediction(const std::vector< plValues > &data) const ->
            plPredictionPerformanceReport`  

        Overloaded function
        -------------------
        * `validate_prediction(plDataDescriptor &data, unsigned int
            nrows=std::numeric_limits< unsigned int >::max()) const ->
            plPredictionPerformanceReport`  

            Validate the conditional distribution used as predictor and return its
            prediction performance.  

            It assumes no missing values in the data set  

            See also: plBayesianNetwork::validate_prediction()  

        * `validate_prediction(const std::vector< plValues > &data) const ->
            plPredictionPerformanceReport`  

            Same as above but using a vector af plValues.  

        """
        return _probt_python3.plCndDistribution_validate_prediction(self, *args)


    def apply_prediction(self, *args) -> "std::vector< plValues,std::allocator< plValues > >":
        """
        apply_prediction(self, data, nrows) -> plValuesVector
        apply_prediction(self, data) -> plValuesVector
        apply_prediction(self, data) -> plValuesVector


        `apply_prediction(plDataDescriptor &data, unsigned int
            nrows=std::numeric_limits< unsigned int >::max()) const -> std::vector<
            plValues >`  
        `apply_prediction(const std::vector< plValues > &data) -> std::vector< plValues
            >`  

        Overloaded function
        -------------------
        * `apply_prediction(plDataDescriptor &data, unsigned int
            nrows=std::numeric_limits< unsigned int >::max()) const -> std::vector<
            plValues >`  

            Apply the conditional distribution used as predictor and return the
            predicted value for each data record.  

            It assumes no missing values in the data set  

            See also: plBayesianNetwork::apply_prediction()  

        * `apply_prediction(const std::vector< plValues > &data) -> std::vector<
            plValues >`  

            Same as above but using a vector af plValues.  

        """
        return _probt_python3.plCndDistribution_apply_prediction(self, *args)


    def apply_classification_proba(self, *args) -> "std::vector< std::vector< plProbValue,std::allocator< plProbValue > >,std::allocator< std::vector< plProbValue,std::allocator< plProbValue > > > >":
        """
        apply_classification_proba(self, data, nrows) -> DoubleVectorVector
        apply_classification_proba(self, data) -> DoubleVectorVector
        apply_classification_proba(self, data) -> DoubleVectorVector


        `apply_classification_proba(plDataDescriptor &data, unsigned int
            nrows=std::numeric_limits< unsigned int >::max()) const -> std::vector<
            std::vector< plProbValue > >`  
        `apply_classification_proba(const std::vector< plValues > &data) const ->
            std::vector< std::vector< plProbValue > >`  

        Overloaded function
        -------------------
        * `apply_classification_proba(plDataDescriptor &data, unsigned int
            nrows=std::numeric_limits< unsigned int >::max()) const -> std::vector<
            std::vector< plProbValue > >`  

            Same as apply_prediction() returning std::vector<plValues> but returning the
            classification probabilities for each data row.  

            See also: prediction()  

            See also: apply_prediction()  

            See also: plCndDistribution::apply_prediction()  

        * `apply_classification_proba(const std::vector< plValues > &data) const ->
            std::vector< std::vector< plProbValue > >`  

            Same as above but using a vector af plValues.  

        """
        return _probt_python3.plCndDistribution_apply_classification_proba(self, *args)


    def __getstate__(self) -> "std::string":
        """__getstate__(self) -> std::string"""
        return _probt_python3.plCndDistribution___getstate__(self)


    def __setstate_internal(self, sState: 'std::string const &') -> "void":
        """__setstate_internal(self, sState)"""
        return _probt_python3.plCndDistribution___setstate_internal(self, sState)


    def __setstate__(self, sState):
        self.__init__()
        self.__setstate_internal(sState)

plCndDistribution_swigregister = _probt_python3.plCndDistribution_swigregister
plCndDistribution_swigregister(plCndDistribution)

def plCndDistribution_as_builtin(ck: 'plCndDistribution') -> "plCndDistribution":
    """
    plCndDistribution_as_builtin(ck) -> plCndDistribution


    `as_builtin(const plCndDistribution &ck) -> plCndDistribution`  

    """
    return _probt_python3.plCndDistribution_as_builtin(ck)


@patch
def plCndDistribution_apply_prediction(orig, self, *args, **kwargs):
    return dataframe_of_values(orig(self, *args, **kwargs))


fixup_dataframe_input(plCndDistribution, 'validate_prediction', [0])
fixup_dataframe_input(plCndDistribution, 'apply_prediction',  [0, 1])
fixup_dataframe_input(plCndDistribution, 'apply_classification_proba',  [0])


class plCndAnonymousDistribution(plCndDistribution):
    """

    `plCndAnonymousDistribution()`  
    `plCndAnonymousDistribution(const plVariablesConjunction &left_variables, const
        plVariablesConjunction &right_variables, const plExternalProbFunction
        &function)`  
    `plCndAnonymousDistribution(const plCndDistribution &)`  

    The *plCndAnonymousDistribution* class implements a conditional distribution
    having the user's external function *function* as *compute* method.  

    The only information we have is a way to compute the probability (probability
    density) for a given value of the variables *search_variables* and the variables
    *known_variables*.  

    Constructors
    ------------
    * `plCndAnonymousDistribution()`  

        Default constructor, needed by the serialization code.  

    * `plCndAnonymousDistribution(const plVariablesConjunction &left_variables,
        const plVariablesConjunction &right_variables, const plExternalProbFunction
        &function)`  

        Constructs a Conditional Anonymous Distribution with the function *function*
        provided by the user.  

         Suppose one wants two define a custom conditional density function
        P(distance | B) over a "distance" variable given a parameter variable
        "B":  

            const plVariable dist("distance", plRealType(0.0, 10.0) );
            const plVariable B("B", plRealType(0.1, 1.0) );  

        An example showing the 3 ways allowing creating and using
        plExternalProbFunction for defining a custom P(distance | B) is as follows:  

        1) Using a non-member function:  

            plProbValue laplace(const plValues &distance_B_vals)
            {
             const double MU =  3.0;

             const double x = distance_B_vals[0];
             const double B = distance_B_vals[1];

             return 1.0/(2.0*B)*std::exp(-std::abs(x-MU)/B);
            }

            plExternalProbFunction distance_density_func(dist^B, &laplace);

            plCndAnonymousDistribution P_distance(dist, B, distance_density_func);  

        2) Using a member function:  

            class MyLaplaceClass
            {
            public:
             MyLaplaceClass(double MU)
             : MU_(MU)
             {}

             plProbValue laplace(const plValues &distance_B_vals)const
             {
              const double x = distance_B_vals[0];
              const double B = distance_B_vals[1];

              return 1.0/(2.0*B)*std::exp(-std::abs(x-MU_)/B);
             }
             private:
             double MU_;
            };

            MyLaplaceClass *my_laplace_obj_ptr = new MyLaplaceClass(3.0);
            plExternalProbFunction distance_density_func(dist^B, my_laplace_obj_ptr,
        &MyLaplaceClass::laplace);

            plCndAnonymousDistribution P_distance(dist, B, distance_density_func);  

        3) Using a C source code function:  

            const std::string laplace_C_code = "result =
        1.0/(2.0*B)*exp(-fabs(distance-3.0)/B);";

            plExternalProbFunction distance_density_func =
                      createExternalProbFunctionFromC(dist^B,
        laplace_C_code,"laplace_func");

            plCndAnonymousDistribution P_distance(dist, B, distance_density_func);  

        ATTENTION: for performance reasons, using this constructor requires that the
        passed conjunction left_variables^right_variables have the same order as the
        function's variables.  

    * `plCndAnonymousDistribution(const plCndDistribution &)`  

        Promote from a plCndDistribution.  

        If the object being copied is actually of the wrong type, an exception is
        raised.  

    C++ includes: plCndAnonymousDistribution.h

    """

    __swig_setmethods__ = {}
    for _s in [plCndDistribution]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plCndAnonymousDistribution, name, value)
    __swig_getmethods__ = {}
    for _s in [plCndDistribution]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plCndAnonymousDistribution, name)
    __repr__ = _swig_repr
    __swig_destroy__ = _probt_python3.delete_plCndAnonymousDistribution
    __del__ = lambda self: None

    def __init__(self, *args):
        """
        __init__(self) -> plCndAnonymousDistribution
        __init__(self, left_variables, right_variables, function) -> plCndAnonymousDistribution
        __init__(self, arg2) -> plCndAnonymousDistribution


        `plCndAnonymousDistribution()`  
        `plCndAnonymousDistribution(const plVariablesConjunction &left_variables, const
            plVariablesConjunction &right_variables, const plExternalProbFunction
            &function)`  
        `plCndAnonymousDistribution(const plCndDistribution &)`  

        Overloaded function
        -------------------
        * `plCndAnonymousDistribution()`  

            Default constructor, needed by the serialization code.  

        * `plCndAnonymousDistribution(const plVariablesConjunction &left_variables,
            const plVariablesConjunction &right_variables, const plExternalProbFunction
            &function)`  

            Constructs a Conditional Anonymous Distribution with the function *function*
            provided by the user.  

             Suppose one wants two define a custom conditional density function
            P(distance | B) over a "distance" variable given a parameter variable
            "B":  

                const plVariable dist("distance", plRealType(0.0, 10.0) );
                const plVariable B("B", plRealType(0.1, 1.0) );  

            An example showing the 3 ways allowing creating and using
            plExternalProbFunction for defining a custom P(distance | B) is as follows:  

            1) Using a non-member function:  

                plProbValue laplace(const plValues &distance_B_vals)
                {
                 const double MU =  3.0;

                 const double x = distance_B_vals[0];
                 const double B = distance_B_vals[1];

                 return 1.0/(2.0*B)*std::exp(-std::abs(x-MU)/B);
                }

                plExternalProbFunction distance_density_func(dist^B, &laplace);

                plCndAnonymousDistribution P_distance(dist, B, distance_density_func);  

            2) Using a member function:  

                class MyLaplaceClass
                {
                public:
                 MyLaplaceClass(double MU)
                 : MU_(MU)
                 {}

                 plProbValue laplace(const plValues &distance_B_vals)const
                 {
                  const double x = distance_B_vals[0];
                  const double B = distance_B_vals[1];

                  return 1.0/(2.0*B)*std::exp(-std::abs(x-MU_)/B);
                 }
                 private:
                 double MU_;
                };

                MyLaplaceClass *my_laplace_obj_ptr = new MyLaplaceClass(3.0);
                plExternalProbFunction distance_density_func(dist^B, my_laplace_obj_ptr,
            &MyLaplaceClass::laplace);

                plCndAnonymousDistribution P_distance(dist, B, distance_density_func);  

            3) Using a C source code function:  

                const std::string laplace_C_code = "result =
            1.0/(2.0*B)*exp(-fabs(distance-3.0)/B);";

                plExternalProbFunction distance_density_func =
                          createExternalProbFunctionFromC(dist^B,
            laplace_C_code,"laplace_func");

                plCndAnonymousDistribution P_distance(dist, B, distance_density_func);  

            ATTENTION: for performance reasons, using this constructor requires that the
            passed conjunction left_variables^right_variables have the same order as the
            function's variables.  

        * `plCndAnonymousDistribution(const plCndDistribution &)`  

            Promote from a plCndDistribution.  

            If the object being copied is actually of the wrong type, an exception is
            raised.  

        """
        this = _probt_python3.new_plCndAnonymousDistribution(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def get_prob_function(self) -> "plExternalProbFunction":
        """
        get_prob_function(self) -> plExternalProbFunction


        `get_prob_function() const -> plExternalProbFunction`  

        Get the external function used to construct this object.  

        """
        return _probt_python3.plCndAnonymousDistribution_get_prob_function(self)


    def is_base_class(self) -> "bool":
        """
        is_base_class(self) -> bool


        `is_base_class() const -> bool`  

        """
        return _probt_python3.plCndAnonymousDistribution_is_base_class(self)


    def __getstate__(self) -> "std::string":
        """__getstate__(self) -> std::string"""
        return _probt_python3.plCndAnonymousDistribution___getstate__(self)


    def __setstate_internal(self, sState: 'std::string const &') -> "void":
        """__setstate_internal(self, sState)"""
        return _probt_python3.plCndAnonymousDistribution___setstate_internal(self, sState)


    def __setstate__(self, sState):
        self.__init__()
        self.__setstate_internal(sState)

plCndAnonymousDistribution_swigregister = _probt_python3.plCndAnonymousDistribution_swigregister
plCndAnonymousDistribution_swigregister(plCndAnonymousDistribution)

class plCndLogNormal(plCndDistribution):
    """

    `plCndLogNormal()`  
    `plCndLogNormal(const plVariable &left, const plVariable &sigma, plFloat m)`  
    `plCndLogNormal(const plVariable &left, plFloat sigma, const plVariable &m)`  
    `plCndLogNormal(const plVariable &left, const plVariablesConjunction &right,
        const plExternalFunction &fsigma, plFloat m)`  
    `plCndLogNormal(const plVariable &left, const plVariablesConjunction &right,
        plFloat sigma, const plExternalFunction &fm)`  
    `plCndLogNormal(const plVariable &left, const plVariable &sigma, const
        plVariable &m)`  
    `plCndLogNormal(const plVariable &left, const plVariablesConjunction &right,
        const plExternalFunction &fsigma, const plExternalFunction &fm)`  
    `plCndLogNormal(const plVariable &left, const plVariablesConjunction &right,
        const plExternalFunction &f_sigma_m)`  
    `plCndLogNormal(const plCndDistribution &)`  

    This class implements conditional lognormal distributions.  

    A plCndLogNormal is a plLogNormal family for which m and sigma are not constant
    but are variables or user external functions (theta = 0). When it is
    instantiated, a plLogNormal is obtained.  

    Constructors
    ------------
    * `plCndLogNormal()`  

        Default contructor.  

    * `plCndLogNormal(const plVariable &left, const plVariable &sigma, plFloat m)`  

        Constructs a one-dimensional conditional log-normal distribution on the
        *left* variable.  

        *sigma* is a know variable *m* is a fixed value corresponding to the m
        parameter  

    * `plCndLogNormal(const plVariable &left, plFloat sigma, const plVariable &m)`  

        Constructs a one-dimensional conditional log-normal distribution on the
        *left* variable.  

        *sigma* is a fixed value corresponding to the sigma value. *m* is a know
        variable  

    * `plCndLogNormal(const plVariable &left, const plVariablesConjunction &right,
        const plExternalFunction &fsigma, plFloat m)`  

        Constructs a one-dimensional conditionnel log-normal distribution on the
        *left* variable.  

        with *sigma* = *fsigma(right)* and *m* is a fixed value corresponding to the
        m parameter.  

        An example assuming that the sigma value of the conditional log-normal P(X |
        Y Z) is the squared sum of the value of the two parent variables "Y" and
        "Z" is as follows. It assumes the following variable definitions:  

            const plVariable X("X", plRealType(-1000, 1000) );
            const plVariable Y("Y", plRealType(-1000, 1000) );  
            const plVariable Z("Z", plRealType(-1000, 1000) );  

        1) Using a non-member function:  

            // Non member function
            void sum2(plValues &sigma, const plValues &Y_Z_vals)
            {
            const double s = Y_Z_vals[Y] + Y_Z_vals[Z];
            // sigma is indexed by an integer
            sigma[0] = s*s;
            }

            plExternalFunction F_sigma__YZ(Y^Z, &sum2);
            plCndLogNormal P_X__YZ(X, Y^Z, F_sigma__YZ, 1);  

        2) Using a member function:  

            struct YZSum
            {
            void sum2(plValues &sigma, const plValues &Y_Z_vals) const
            {
            const double s = Y_Z_vals[Y] + Y_Z_vals[Z];
            // sigma is indexed by an integer
            sigma[0] = s*s;
            }

            };

            YZSum *sum_obj_ptr = new YZSum;
            plExternalFunction  F_sigma__YZ(Y^Z, sum_obj_ptr, &YZSum::sum2);
            plCndLogNormal P_X__YZ(X, Y^Z, F_sigma__YZ, 1);  

        3) Using a C source code function:  

            const std::string sum2_code = "output[0] = (Y+Z)*(Y+Z);";
            plExternalFunctionFromC  F_sigma__YZ = createExternalFunctionFromC(Y^Z,
        sum2_code, "sum2_func");
            plCndLogNormal P_X__YZ(X, Y^Z, F_sigma__YZ, 1);


    * `plCndLogNormal(const plVariable &left, const plVariablesConjunction &right,
        plFloat sigma, const plExternalFunction &fm)`  

        Constructs a one-dimensional contitional log-normal distribution on the
        *left* variable with *m* = *fm(right)* and *sigma* is a fixed value
        corresponding to the sigma value.  

        An example of how to create and use plExternalFunction as conditional
        distribution parameters can be found in 'using external functions example'.  

    * `plCndLogNormal(const plVariable &left, const plVariable &sigma, const
        plVariable &m)`  

        Constructs a contitional log-normal distribution on *left* variables.  

        *sigma* and *m* are known variables.  

    * `plCndLogNormal(const plVariable &left, const plVariablesConjunction &right,
        const plExternalFunction &fsigma, const plExternalFunction &fm)`  

        Constructs a contitional log-normal distribution on the *left* variables
        with *m* = *fm(right)* and *sigma* = *fsigma(right)*.  

        An example of how to create and use plExternalFunction as conditional
        distribution parameters can be found in 'using external functions example'.  

    * `plCndLogNormal(const plVariable &left, const plVariablesConjunction &right,
        const plExternalFunction &f_sigma_m)`  

        Constructs a contitional log-normal distribution on the *left* variables
        with **[sigma,m] = *f_sigma_m(right)*.  

        An example of how to create and use plExternalFunction as conditional
        distribution parameters can be found in 'using external functions example'.  

    * `plCndLogNormal(const plCndDistribution &)`  

        Promote from a plCndDistribution.  

        If the object being copied is actually of the wrong type, an exception is
        raised.  

    C++ includes: plCndLogNormal.h

    """

    __swig_setmethods__ = {}
    for _s in [plCndDistribution]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plCndLogNormal, name, value)
    __swig_getmethods__ = {}
    for _s in [plCndDistribution]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plCndLogNormal, name)
    __repr__ = _swig_repr
    __swig_destroy__ = _probt_python3.delete_plCndLogNormal
    __del__ = lambda self: None

    def __init__(self, *args):
        """
        __init__(self) -> plCndLogNormal
        __init__(self, left, sigma, m) -> plCndLogNormal
        __init__(self, left, sigma, m) -> plCndLogNormal
        __init__(self, left, right, fsigma, m) -> plCndLogNormal
        __init__(self, left, right, sigma, fm) -> plCndLogNormal
        __init__(self, left, sigma, m) -> plCndLogNormal
        __init__(self, left, right, fsigma, fm) -> plCndLogNormal
        __init__(self, left, right, f_sigma_m) -> plCndLogNormal
        __init__(self, arg2) -> plCndLogNormal


        `plCndLogNormal()`  
        `plCndLogNormal(const plVariable &left, const plVariable &sigma, plFloat m)`  
        `plCndLogNormal(const plVariable &left, plFloat sigma, const plVariable &m)`  
        `plCndLogNormal(const plVariable &left, const plVariablesConjunction &right,
            const plExternalFunction &fsigma, plFloat m)`  
        `plCndLogNormal(const plVariable &left, const plVariablesConjunction &right,
            plFloat sigma, const plExternalFunction &fm)`  
        `plCndLogNormal(const plVariable &left, const plVariable &sigma, const
            plVariable &m)`  
        `plCndLogNormal(const plVariable &left, const plVariablesConjunction &right,
            const plExternalFunction &fsigma, const plExternalFunction &fm)`  
        `plCndLogNormal(const plVariable &left, const plVariablesConjunction &right,
            const plExternalFunction &f_sigma_m)`  
        `plCndLogNormal(const plCndDistribution &)`  

        Overloaded function
        -------------------
        * `plCndLogNormal()`  

            Default contructor.  

        * `plCndLogNormal(const plVariable &left, const plVariable &sigma, plFloat m)`  

            Constructs a one-dimensional conditional log-normal distribution on the
            *left* variable.  

            *sigma* is a know variable *m* is a fixed value corresponding to the m
            parameter  

        * `plCndLogNormal(const plVariable &left, plFloat sigma, const plVariable &m)`  

            Constructs a one-dimensional conditional log-normal distribution on the
            *left* variable.  

            *sigma* is a fixed value corresponding to the sigma value. *m* is a know
            variable  

        * `plCndLogNormal(const plVariable &left, const plVariablesConjunction &right,
            const plExternalFunction &fsigma, plFloat m)`  

            Constructs a one-dimensional conditionnel log-normal distribution on the
            *left* variable.  

            with *sigma* = *fsigma(right)* and *m* is a fixed value corresponding to the
            m parameter.  

            An example assuming that the sigma value of the conditional log-normal P(X |
            Y Z) is the squared sum of the value of the two parent variables "Y" and
            "Z" is as follows. It assumes the following variable definitions:  

                const plVariable X("X", plRealType(-1000, 1000) );
                const plVariable Y("Y", plRealType(-1000, 1000) );  
                const plVariable Z("Z", plRealType(-1000, 1000) );  

            1) Using a non-member function:  

                // Non member function
                void sum2(plValues &sigma, const plValues &Y_Z_vals)
                {
                const double s = Y_Z_vals[Y] + Y_Z_vals[Z];
                // sigma is indexed by an integer
                sigma[0] = s*s;
                }

                plExternalFunction F_sigma__YZ(Y^Z, &sum2);
                plCndLogNormal P_X__YZ(X, Y^Z, F_sigma__YZ, 1);  

            2) Using a member function:  

                struct YZSum
                {
                void sum2(plValues &sigma, const plValues &Y_Z_vals) const
                {
                const double s = Y_Z_vals[Y] + Y_Z_vals[Z];
                // sigma is indexed by an integer
                sigma[0] = s*s;
                }

                };

                YZSum *sum_obj_ptr = new YZSum;
                plExternalFunction  F_sigma__YZ(Y^Z, sum_obj_ptr, &YZSum::sum2);
                plCndLogNormal P_X__YZ(X, Y^Z, F_sigma__YZ, 1);  

            3) Using a C source code function:  

                const std::string sum2_code = "output[0] = (Y+Z)*(Y+Z);";
                plExternalFunctionFromC  F_sigma__YZ = createExternalFunctionFromC(Y^Z,
            sum2_code, "sum2_func");
                plCndLogNormal P_X__YZ(X, Y^Z, F_sigma__YZ, 1);


        * `plCndLogNormal(const plVariable &left, const plVariablesConjunction &right,
            plFloat sigma, const plExternalFunction &fm)`  

            Constructs a one-dimensional contitional log-normal distribution on the
            *left* variable with *m* = *fm(right)* and *sigma* is a fixed value
            corresponding to the sigma value.  

            An example of how to create and use plExternalFunction as conditional
            distribution parameters can be found in 'using external functions example'.  

        * `plCndLogNormal(const plVariable &left, const plVariable &sigma, const
            plVariable &m)`  

            Constructs a contitional log-normal distribution on *left* variables.  

            *sigma* and *m* are known variables.  

        * `plCndLogNormal(const plVariable &left, const plVariablesConjunction &right,
            const plExternalFunction &fsigma, const plExternalFunction &fm)`  

            Constructs a contitional log-normal distribution on the *left* variables
            with *m* = *fm(right)* and *sigma* = *fsigma(right)*.  

            An example of how to create and use plExternalFunction as conditional
            distribution parameters can be found in 'using external functions example'.  

        * `plCndLogNormal(const plVariable &left, const plVariablesConjunction &right,
            const plExternalFunction &f_sigma_m)`  

            Constructs a contitional log-normal distribution on the *left* variables
            with **[sigma,m] = *f_sigma_m(right)*.  

            An example of how to create and use plExternalFunction as conditional
            distribution parameters can be found in 'using external functions example'.  

        * `plCndLogNormal(const plCndDistribution &)`  

            Promote from a plCndDistribution.  

            If the object being copied is actually of the wrong type, an exception is
            raised.  

        """
        this = _probt_python3.new_plCndLogNormal(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def sigma_is_constant(self) -> "bool":
        """
        sigma_is_constant(self) -> bool


        `sigma_is_constant() const -> bool`  

        Returns true if the sigma parameter is a constant.  

        """
        return _probt_python3.plCndLogNormal_sigma_is_constant(self)


    def get_sigma_constant(self) -> "plFloat":
        """
        get_sigma_constant(self) -> plFloat


        `get_sigma_constant() const -> plFloat`  

        Returns the value of the sigma parameter.  

        Do not call this method if sigma_is_constant() returned false.  

        """
        return _probt_python3.plCndLogNormal_get_sigma_constant(self)


    def sigma_is_variable(self) -> "bool":
        """
        sigma_is_variable(self) -> bool


        `sigma_is_variable() const -> bool`  

        Returns true if the sigma parameter is a variable.  

        """
        return _probt_python3.plCndLogNormal_sigma_is_variable(self)


    def get_sigma_variable(self) -> "plVariable":
        """
        get_sigma_variable(self) -> plVariable


        `get_sigma_variable() const -> plVariable`  

        Returns the sigma variable.  

        Do not call this method if sigma_is_variable() returned false.  

        """
        return _probt_python3.plCndLogNormal_get_sigma_variable(self)


    def sigma_is_function(self) -> "bool":
        """
        sigma_is_function(self) -> bool


        `sigma_is_function() const -> bool`  

        Returns true if the sigma parameter is a function.  

        """
        return _probt_python3.plCndLogNormal_sigma_is_function(self)


    def get_sigma_function(self) -> "plExternalFunction":
        """
        get_sigma_function(self) -> plExternalFunction


        `get_sigma_function() const -> plExternalFunction`  

        Returns the sigma function.  

        Do not call this method if sigma_is_function() returned false.  

        """
        return _probt_python3.plCndLogNormal_get_sigma_function(self)


    def m_is_constant(self) -> "bool":
        """
        m_is_constant(self) -> bool


        `m_is_constant() const -> bool`  

        Returns true if the m parameter is a constant.  

        """
        return _probt_python3.plCndLogNormal_m_is_constant(self)


    def get_m_constant(self) -> "plFloat":
        """
        get_m_constant(self) -> plFloat


        `get_m_constant() const -> plFloat`  

        Returns the value of the m parameter.  

        Do not call this method if m_is_constant() returned false.  

        """
        return _probt_python3.plCndLogNormal_get_m_constant(self)


    def m_is_variable(self) -> "bool":
        """
        m_is_variable(self) -> bool


        `m_is_variable() const -> bool`  

        Returns true if the m parameter is a variable.  

        """
        return _probt_python3.plCndLogNormal_m_is_variable(self)


    def get_m_variable(self) -> "plVariable":
        """
        get_m_variable(self) -> plVariable


        `get_m_variable() const -> plVariable`  

        Returns the m variable.  

        Do not call this method if m_is_variable() returned false.  

        """
        return _probt_python3.plCndLogNormal_get_m_variable(self)


    def m_is_function(self) -> "bool":
        """
        m_is_function(self) -> bool


        `m_is_function() const -> bool`  

        Returns true if the m parameter is a function.  

        """
        return _probt_python3.plCndLogNormal_m_is_function(self)


    def get_m_function(self) -> "plExternalFunction":
        """
        get_m_function(self) -> plExternalFunction


        `get_m_function() const -> plExternalFunction`  

        Returns the m function.  

        Do not call this method if m_is_function() returned false.  

        """
        return _probt_python3.plCndLogNormal_get_m_function(self)


    def sigma_and_m_are_one_function(self) -> "bool":
        """
        sigma_and_m_are_one_function(self) -> bool


        `sigma_and_m_are_one_function() const -> bool`  

        Returns true if the sigma and m parameters were given as a single function.  

        """
        return _probt_python3.plCndLogNormal_sigma_and_m_are_one_function(self)


    def get_sigma_m_function(self) -> "plExternalFunction":
        """
        get_sigma_m_function(self) -> plExternalFunction


        `get_sigma_m_function() const -> plExternalFunction`  

        Returns the parameters function.  

        Do not call this method if sigma_and_m_are_one_function() returned false.  

        """
        return _probt_python3.plCndLogNormal_get_sigma_m_function(self)


    def is_base_class(self) -> "bool":
        """
        is_base_class(self) -> bool


        `is_base_class() const -> bool`  

        """
        return _probt_python3.plCndLogNormal_is_base_class(self)


    def __getstate__(self) -> "std::string":
        """__getstate__(self) -> std::string"""
        return _probt_python3.plCndLogNormal___getstate__(self)


    def __setstate_internal(self, sState: 'std::string const &') -> "void":
        """__setstate_internal(self, sState)"""
        return _probt_python3.plCndLogNormal___setstate_internal(self, sState)


    def __setstate__(self, sState):
        self.__init__()
        self.__setstate_internal(sState)

plCndLogNormal_swigregister = _probt_python3.plCndLogNormal_swigregister
plCndLogNormal_swigregister(plCndLogNormal)

class plCndNormal(plCndDistribution):
    """

    `plCndNormal()`  
    `plCndNormal(const plVariable &left, const plVariable &mean, plFloat std_dev)`  
    `plCndNormal(const plVariable &left, plFloat mean, const plVariable
        &std_dev_var)`  
    `plCndNormal(const plVariable &left, const plVariablesConjunction &right, const
        plExternalFunction &fmean, plFloat std_dev)`  
    `plCndNormal(const plVariable &left, const plVariablesConjunction &right,
        plFloat mean, const plExternalFunction &fsd)`  
    `plCndNormal(const plVariablesConjunction &left, const plVariablesConjunction
        &mean, const plFloatMatrix &var_matrix)`  
    `plCndNormal(const plVariablesConjunction &left, const plFloatVector &mean,
        const plVariablesConjunction &variance_vars)`  
    `plCndNormal(const plVariablesConjunction &left, const plVariablesConjunction
        &right, const plExternalFunction &fm, const plFloatMatrix &var_matrix)`  
    `plCndNormal(const plVariablesConjunction &left, const plVariablesConjunction
        &right, const plFloatVector &mean, const plExternalFunction &fvariance)`  
    `plCndNormal(const plVariablesConjunction &left, const plVariablesConjunction
        &mean, const plVariablesConjunction &variance_vars)`  
    `plCndNormal(const plVariablesConjunction &left, const plVariablesConjunction
        &right, const plExternalFunction &fmean, const plExternalFunction
        &fvariance)`  
    `plCndNormal(const plVariablesConjunction &left, const plVariablesConjunction
        &right, const plExternalFunction &f_mean_variance)`  
    `plCndNormal(const plCndDistribution &)`  

    This class implements conditional normal distributions on one or multiple
    dimensional spaces.  

    A plCndNormal is a plNormal family for which mean (or mean vector) and/or
    standard deviation (or variance matrix) are not constant but are variables or
    user external functions. When it is instantiated, a plNormal is obtained.  

    Constructors
    ------------
    * `plCndNormal()`  

        Default constructor.  

    * `plCndNormal(const plVariable &left, const plVariable &mean, plFloat std_dev)`  

        Constructs a one-dimensional conditional normal distribution on the *left*
        variable.  

        *mean* is a know variable, *std_dev* is a fixed value corresponding to the
        standard deviation  

    * `plCndNormal(const plVariable &left, plFloat mean, const plVariable
        &std_dev_var)`  

        Constructs a one-dimensional conditional normal distribution on the *left*
        variable.  

        *std_dev_var* is a know variable *mean* is a fixed value corresponding to
        the mean value.  

    * `plCndNormal(const plVariable &left, const plVariablesConjunction &right,
        const plExternalFunction &fmean, plFloat std_dev)`  

        Constructs a one-dimensional conditionnel normal distribution on the *left*
        variable.  

        with *mean* = *fmean(right)* and *std_dev* is a fixed value corresponding to
        the standard deviation.  

        An example assuming that the mean value of the conditional normal P(X | Y Z)
        is the squared sum of the value of the two parent variables "Y" and "Z"
        is as follows. It assumes the following variable definitions:  

            const plVariable X("X", plRealType(-1000, 1000) );
            const plVariable Y("Y", plRealType(-1000, 1000) );  
            const plVariable Z("Z", plRealType(-1000, 1000) );  

        1) Using a non-member function:  

            // Non member function
            void sum2(plValues &mean, const plValues &Y_Z_vals)
            {
            const double s = Y_Z_vals[Y] + Y_Z_vals[Z];
            // mean is indexed by an integer
            mean[0] = s*s;
            }

            plExternalFunction F_mean__YZ(Y^Z, &sum2);
            plCndNormal P_X__YZ(X, Y^Z, F_mean__YZ, 1);  

        2) Using a member function:  

            struct YZSum
            {
            void sum2(plValues &mean, const plValues &Y_Z_vals) const
            {
            const double s = Y_Z_vals[Y] + Y_Z_vals[Z];
            // mean is indexed by an integer
            mean[0] = s*s;
            }

            };

            YZSum *sum_obj_ptr = new YZSum;
            plExternalFunction  F_mean__YZ(Y^Z, sum_obj_ptr, &YZSum::sum2);
            plCndNormal P_X__YZ(X, Y^Z, F_mean__YZ, 1);  

        3) Using a C source code function:  

            const std::string sum2_code = "output[0] = (Y+Z)*(Y+Z);";
            plExternalFunctionFromC  F_mean__YZ = createExternalFunctionFromC(Y^Z,
        sum2_code, "sum2_func");
            plCndNormal P_X__YZ(X, Y^Z, F_mean__YZ, 1);


    * `plCndNormal(const plVariable &left, const plVariablesConjunction &right,
        plFloat mean, const plExternalFunction &fsd)`  

        Constructs a one-dimensional contitional normal distribution on the *left*
        variable with *std_dev* = *fsd(right)* and *mean* is a fixed value
        corresponding to the mean value.  

        An example of how to create and use plExternalFunction as conditional
        distribution parameters can be found in 'using external functions example'.  

    * `plCndNormal(const plVariablesConjunction &left, const plVariablesConjunction
        &mean, const plFloatMatrix &var_matrix)`  

        Constructs a multi dimensional contitional normal distribution on the
        continuous *left* variables.  

        *mean* are known variables. *var_matrix* is a fixed covariance matrix.  

    * `plCndNormal(const plVariablesConjunction &left, const plFloatVector &mean,
        const plVariablesConjunction &variance_vars)`  

        Constructs a multi dimensional contitional normal distribution on the
        continuous*left* variables.  

        *variance_vars* are known variables. *mean* is a fixed mean vector.  

    * `plCndNormal(const plVariablesConjunction &left, const plVariablesConjunction
        &right, const plExternalFunction &fm, const plFloatMatrix &var_matrix)`  

        Constructs a multi dimensional contitional normal distribution on the
        continuous *left* variables with *mean* = *fm(right)* and *var_matrix* is a
        fixed matrix corresponding to the variance.  

        An example of how to create and use plExternalFunction as conditional
        distribution parameters can be found in 'using external functions example'.  

    * `plCndNormal(const plVariablesConjunction &left, const plVariablesConjunction
        &right, const plFloatVector &mean, const plExternalFunction &fvariance)`  

        Constructs a multi dimensional contitional normal distribution on the
        continuous *left* variables with *variance* = *fvariance(right)* and *mean*
        is a fixed vector corresponding to the mean vector.  

        An example of how to create and use plExternalFunction as conditional
        distribution parameters can be found in 'using external functions example'.  

    * `plCndNormal(const plVariablesConjunction &left, const plVariablesConjunction
        &mean, const plVariablesConjunction &variance_vars)`  

        Constructs a contitional normal distribution on *left* variables (must be
        continuous when multi-dimensional).  

        *mean* and *variance_vars* are known variables.  

        ATTENTION: *variance_vars* are the variance variables (corresponding to the
        variance matrix elements) for nd cases and stantard deviation ones in 1d
        cases.  

    * `plCndNormal(const plVariablesConjunction &left, const plVariablesConjunction
        &right, const plExternalFunction &fmean, const plExternalFunction
        &fvariance)`  

        Constructs a contitional normal distribution on the *left* variables (must
        be continuous when multi-dimensional) with *variance* = *fvariance(right)*
        and *mean* = *fmean(right)*.  

        ATTENTION: *fvariance* is the variance function (returning the variance
        matrix elements) for nd cases and simply the stantard deviation one in 1d
        ones.  

        An example of how to create and use plExternalFunction as conditional
        distribution parameters can be found in 'using external functions example'.  

    * `plCndNormal(const plVariablesConjunction &left, const plVariablesConjunction
        &right, const plExternalFunction &f_mean_variance)`  

        Constructs a contitional normal distribution on the *left* variables (must
        be continuous when multi-dimensional) with **[mean,variance] =
        *f_mean_variance(right)*.  

        ATTENTION: the variance part of *f_mean_variance* is the variance function
        for nd cases and stantard deviation one in 1d ones.  

        An example of how to create and use plExternalFunction as conditional
        distribution parameters can be found in 'using external functions example'.  

    * `plCndNormal(const plCndDistribution &)`  

        Promote from a plCndDistribution.  

        If the object being copied is actually of the wrong type, an exception is
        raised.  

    C++ includes: plCndNormal.h

    """

    __swig_setmethods__ = {}
    for _s in [plCndDistribution]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plCndNormal, name, value)
    __swig_getmethods__ = {}
    for _s in [plCndDistribution]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plCndNormal, name)
    __repr__ = _swig_repr
    __swig_destroy__ = _probt_python3.delete_plCndNormal
    __del__ = lambda self: None

    def __init__(self, *args):
        """
        __init__(self) -> plCndNormal
        __init__(self, left, mean, std_dev) -> plCndNormal
        __init__(self, left, mean, std_dev_var) -> plCndNormal
        __init__(self, left, right, fmean, std_dev) -> plCndNormal
        __init__(self, left, right, mean, fsd) -> plCndNormal
        __init__(self, left, mean, var_matrix) -> plCndNormal
        __init__(self, left, mean, variance_vars) -> plCndNormal
        __init__(self, left, right, fm, var_matrix) -> plCndNormal
        __init__(self, left, right, mean, fvariance) -> plCndNormal
        __init__(self, left, mean, variance_vars) -> plCndNormal
        __init__(self, left, right, fmean, fvariance) -> plCndNormal
        __init__(self, left, right, f_mean_variance) -> plCndNormal
        __init__(self, arg2) -> plCndNormal


        `plCndNormal()`  
        `plCndNormal(const plVariable &left, const plVariable &mean, plFloat std_dev)`  
        `plCndNormal(const plVariable &left, plFloat mean, const plVariable
            &std_dev_var)`  
        `plCndNormal(const plVariable &left, const plVariablesConjunction &right, const
            plExternalFunction &fmean, plFloat std_dev)`  
        `plCndNormal(const plVariable &left, const plVariablesConjunction &right,
            plFloat mean, const plExternalFunction &fsd)`  
        `plCndNormal(const plVariablesConjunction &left, const plVariablesConjunction
            &mean, const plFloatMatrix &var_matrix)`  
        `plCndNormal(const plVariablesConjunction &left, const plFloatVector &mean,
            const plVariablesConjunction &variance_vars)`  
        `plCndNormal(const plVariablesConjunction &left, const plVariablesConjunction
            &right, const plExternalFunction &fm, const plFloatMatrix &var_matrix)`  
        `plCndNormal(const plVariablesConjunction &left, const plVariablesConjunction
            &right, const plFloatVector &mean, const plExternalFunction &fvariance)`  
        `plCndNormal(const plVariablesConjunction &left, const plVariablesConjunction
            &mean, const plVariablesConjunction &variance_vars)`  
        `plCndNormal(const plVariablesConjunction &left, const plVariablesConjunction
            &right, const plExternalFunction &fmean, const plExternalFunction
            &fvariance)`  
        `plCndNormal(const plVariablesConjunction &left, const plVariablesConjunction
            &right, const plExternalFunction &f_mean_variance)`  
        `plCndNormal(const plCndDistribution &)`  

        Overloaded function
        -------------------
        * `plCndNormal()`  

            Default constructor.  

        * `plCndNormal(const plVariable &left, const plVariable &mean, plFloat std_dev)`  

            Constructs a one-dimensional conditional normal distribution on the *left*
            variable.  

            *mean* is a know variable, *std_dev* is a fixed value corresponding to the
            standard deviation  

        * `plCndNormal(const plVariable &left, plFloat mean, const plVariable
            &std_dev_var)`  

            Constructs a one-dimensional conditional normal distribution on the *left*
            variable.  

            *std_dev_var* is a know variable *mean* is a fixed value corresponding to
            the mean value.  

        * `plCndNormal(const plVariable &left, const plVariablesConjunction &right,
            const plExternalFunction &fmean, plFloat std_dev)`  

            Constructs a one-dimensional conditionnel normal distribution on the *left*
            variable.  

            with *mean* = *fmean(right)* and *std_dev* is a fixed value corresponding to
            the standard deviation.  

            An example assuming that the mean value of the conditional normal P(X | Y Z)
            is the squared sum of the value of the two parent variables "Y" and "Z"
            is as follows. It assumes the following variable definitions:  

                const plVariable X("X", plRealType(-1000, 1000) );
                const plVariable Y("Y", plRealType(-1000, 1000) );  
                const plVariable Z("Z", plRealType(-1000, 1000) );  

            1) Using a non-member function:  

                // Non member function
                void sum2(plValues &mean, const plValues &Y_Z_vals)
                {
                const double s = Y_Z_vals[Y] + Y_Z_vals[Z];
                // mean is indexed by an integer
                mean[0] = s*s;
                }

                plExternalFunction F_mean__YZ(Y^Z, &sum2);
                plCndNormal P_X__YZ(X, Y^Z, F_mean__YZ, 1);  

            2) Using a member function:  

                struct YZSum
                {
                void sum2(plValues &mean, const plValues &Y_Z_vals) const
                {
                const double s = Y_Z_vals[Y] + Y_Z_vals[Z];
                // mean is indexed by an integer
                mean[0] = s*s;
                }

                };

                YZSum *sum_obj_ptr = new YZSum;
                plExternalFunction  F_mean__YZ(Y^Z, sum_obj_ptr, &YZSum::sum2);
                plCndNormal P_X__YZ(X, Y^Z, F_mean__YZ, 1);  

            3) Using a C source code function:  

                const std::string sum2_code = "output[0] = (Y+Z)*(Y+Z);";
                plExternalFunctionFromC  F_mean__YZ = createExternalFunctionFromC(Y^Z,
            sum2_code, "sum2_func");
                plCndNormal P_X__YZ(X, Y^Z, F_mean__YZ, 1);


        * `plCndNormal(const plVariable &left, const plVariablesConjunction &right,
            plFloat mean, const plExternalFunction &fsd)`  

            Constructs a one-dimensional contitional normal distribution on the *left*
            variable with *std_dev* = *fsd(right)* and *mean* is a fixed value
            corresponding to the mean value.  

            An example of how to create and use plExternalFunction as conditional
            distribution parameters can be found in 'using external functions example'.  

        * `plCndNormal(const plVariablesConjunction &left, const plVariablesConjunction
            &mean, const plFloatMatrix &var_matrix)`  

            Constructs a multi dimensional contitional normal distribution on the
            continuous *left* variables.  

            *mean* are known variables. *var_matrix* is a fixed covariance matrix.  

        * `plCndNormal(const plVariablesConjunction &left, const plFloatVector &mean,
            const plVariablesConjunction &variance_vars)`  

            Constructs a multi dimensional contitional normal distribution on the
            continuous*left* variables.  

            *variance_vars* are known variables. *mean* is a fixed mean vector.  

        * `plCndNormal(const plVariablesConjunction &left, const plVariablesConjunction
            &right, const plExternalFunction &fm, const plFloatMatrix &var_matrix)`  

            Constructs a multi dimensional contitional normal distribution on the
            continuous *left* variables with *mean* = *fm(right)* and *var_matrix* is a
            fixed matrix corresponding to the variance.  

            An example of how to create and use plExternalFunction as conditional
            distribution parameters can be found in 'using external functions example'.  

        * `plCndNormal(const plVariablesConjunction &left, const plVariablesConjunction
            &right, const plFloatVector &mean, const plExternalFunction &fvariance)`  

            Constructs a multi dimensional contitional normal distribution on the
            continuous *left* variables with *variance* = *fvariance(right)* and *mean*
            is a fixed vector corresponding to the mean vector.  

            An example of how to create and use plExternalFunction as conditional
            distribution parameters can be found in 'using external functions example'.  

        * `plCndNormal(const plVariablesConjunction &left, const plVariablesConjunction
            &mean, const plVariablesConjunction &variance_vars)`  

            Constructs a contitional normal distribution on *left* variables (must be
            continuous when multi-dimensional).  

            *mean* and *variance_vars* are known variables.  

            ATTENTION: *variance_vars* are the variance variables (corresponding to the
            variance matrix elements) for nd cases and stantard deviation ones in 1d
            cases.  

        * `plCndNormal(const plVariablesConjunction &left, const plVariablesConjunction
            &right, const plExternalFunction &fmean, const plExternalFunction
            &fvariance)`  

            Constructs a contitional normal distribution on the *left* variables (must
            be continuous when multi-dimensional) with *variance* = *fvariance(right)*
            and *mean* = *fmean(right)*.  

            ATTENTION: *fvariance* is the variance function (returning the variance
            matrix elements) for nd cases and simply the stantard deviation one in 1d
            ones.  

            An example of how to create and use plExternalFunction as conditional
            distribution parameters can be found in 'using external functions example'.  

        * `plCndNormal(const plVariablesConjunction &left, const plVariablesConjunction
            &right, const plExternalFunction &f_mean_variance)`  

            Constructs a contitional normal distribution on the *left* variables (must
            be continuous when multi-dimensional) with **[mean,variance] =
            *f_mean_variance(right)*.  

            ATTENTION: the variance part of *f_mean_variance* is the variance function
            for nd cases and stantard deviation one in 1d ones.  

            An example of how to create and use plExternalFunction as conditional
            distribution parameters can be found in 'using external functions example'.  

        * `plCndNormal(const plCndDistribution &)`  

            Promote from a plCndDistribution.  

            If the object being copied is actually of the wrong type, an exception is
            raised.  

        """
        this = _probt_python3.new_plCndNormal(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def mean_is_constant(self) -> "bool":
        """
        mean_is_constant(self) -> bool


        `mean_is_constant() const -> bool`  

        Returns true if the mean parameter is a constant.  

        """
        return _probt_python3.plCndNormal_mean_is_constant(self)


    def get_mean_constant(self) -> "plFloatVector":
        """
        get_mean_constant(self) -> plFloatVector


        `get_mean_constant() const -> plFloatVector`  

        Returns the value of the mean parameter.  

        Do not call this method if mean_is_constant() returned false.  

        """
        return _probt_python3.plCndNormal_get_mean_constant(self)


    def mean_is_variable(self) -> "bool":
        """
        mean_is_variable(self) -> bool


        `mean_is_variable() const -> bool`  

        Returns true if the mean parameter is a variable.  

        """
        return _probt_python3.plCndNormal_mean_is_variable(self)


    def get_mean_variable(self) -> "plVariablesConjunction":
        """
        get_mean_variable(self) -> plVariablesConjunction


        `get_mean_variable() const -> plVariablesConjunction`  

        Returns the mean variable.  

        Do not call this method if mean_is_variable() returned false.  

        """
        return _probt_python3.plCndNormal_get_mean_variable(self)


    def mean_is_function(self) -> "bool":
        """
        mean_is_function(self) -> bool


        `mean_is_function() const -> bool`  

        Returns true if the mean parameter is a function.  

        """
        return _probt_python3.plCndNormal_mean_is_function(self)


    def get_mean_function(self) -> "plExternalFunction":
        """
        get_mean_function(self) -> plExternalFunction


        `get_mean_function() const -> plExternalFunction`  

        Returns the mean function.  

        Do not call this method if mean_is_function() returned false.  

        """
        return _probt_python3.plCndNormal_get_mean_function(self)


    def variance_is_constant(self) -> "bool":
        """
        variance_is_constant(self) -> bool


        `variance_is_constant() const -> bool`  

        Returns true if the variance (or stantard deviation in one-dimensional cases)
        parameter is a constant.  

        """
        return _probt_python3.plCndNormal_variance_is_constant(self)


    def get_variance_constant(self) -> "plFloatMatrix":
        """
        get_variance_constant(self) -> plFloatMatrix


        `get_variance_constant() const -> plFloatMatrix`  

        Returns the value of the variance (or stantard deviation in one-dimensional
        cases) parameter.  

        Do not call this method if variance_is_constant() returned false.  

        """
        return _probt_python3.plCndNormal_get_variance_constant(self)


    def variance_is_variable(self) -> "bool":
        """
        variance_is_variable(self) -> bool


        `variance_is_variable() const -> bool`  

        Returns true if the variance (or stantard deviation in one-dimensional cases)
        parameter is a variable.  

        """
        return _probt_python3.plCndNormal_variance_is_variable(self)


    def get_variance_variable(self) -> "plVariablesConjunction":
        """
        get_variance_variable(self) -> plVariablesConjunction


        `get_variance_variable() const -> plVariablesConjunction`  

        Returns the variance (or stantard deviation in one-dimensional cases) variable.  

        Do not call this method if variance_is_variable() returned false.  

        """
        return _probt_python3.plCndNormal_get_variance_variable(self)


    def variance_is_function(self) -> "bool":
        """
        variance_is_function(self) -> bool


        `variance_is_function() const -> bool`  

        Returns true if the standard deviation parameter is a function.  

        """
        return _probt_python3.plCndNormal_variance_is_function(self)


    def get_variance_function(self) -> "plExternalFunction":
        """
        get_variance_function(self) -> plExternalFunction


        `get_variance_function() const -> plExternalFunction`  

        Returns the variance (or stantard deviation in one-dimensional cases) function.  

        Do not call this method if variance_is_function() returned false.  

        """
        return _probt_python3.plCndNormal_get_variance_function(self)


    def mean_and_variance_are_one_function(self) -> "bool":
        """
        mean_and_variance_are_one_function(self) -> bool


        `mean_and_variance_are_one_function() const -> bool`  

        Returns true if the mean and variance (or stantard deviation in one-dimensional
        cases) parameters were given as a single function.  

        """
        return _probt_python3.plCndNormal_mean_and_variance_are_one_function(self)


    def get_mean_variance_function(self) -> "plExternalFunction":
        """
        get_mean_variance_function(self) -> plExternalFunction


        `get_mean_variance_function() const -> plExternalFunction`  

        Returns the parameters function.  

        Do not call this method if mean_and_variance_are_one_function() returned false.  

        """
        return _probt_python3.plCndNormal_get_mean_variance_function(self)


    def is_base_class(self) -> "bool":
        """
        is_base_class(self) -> bool


        `is_base_class() const -> bool`  

        """
        return _probt_python3.plCndNormal_is_base_class(self)


    def __getstate__(self) -> "std::string":
        """__getstate__(self) -> std::string"""
        return _probt_python3.plCndNormal___getstate__(self)


    def __setstate_internal(self, sState: 'std::string const &') -> "void":
        """__setstate_internal(self, sState)"""
        return _probt_python3.plCndNormal___setstate_internal(self, sState)


    def __setstate__(self, sState):
        self.__init__()
        self.__setstate_internal(sState)

plCndNormal_swigregister = _probt_python3.plCndNormal_swigregister
plCndNormal_swigregister(plCndNormal)

class plCndBinomial(plCndDistribution):
    """

    `plCndBinomial()`  
    `plCndBinomial(const plVariable &left, const plVariable &p)`  
    `plCndBinomial(const plVariable &left, const plVariablesConjunction &right,
        const plExternalFunction &fp)`  
    `plCndBinomial(const plCndDistribution &)`  

    Conditional Binomial distribution on one-dimensional space.  

    A *plCndBinomial* is a *plBinomial* familly for which the *p* parameter is not
    constant, but either a known *plVariable* or a *plExternalFunction*. When
    instantiated, a *plBinomial* is obtained.  

    Constructors
    ------------
    * `plCndBinomial()`  

        Default constructor.  

    * `plCndBinomial(const plVariable &left, const plVariable &p)`  

        Constructs a conditional binomial distribution on variable *left* in which
        mean *p* is a variable.  

        The variable *left* must be of type *plIntegerType*.  

    * `plCndBinomial(const plVariable &left, const plVariablesConjunction &right,
        const plExternalFunction &fp)`  

        Constructs a conditional binomial distribution on variable *left* in which p
        is fixed using an external function applied to variables *right*.  

        The variable *left* must be of type *plIntegerType*.  

        An example of how to create and use plExternalFunction as conditional
        distribution parameters can be found in 'using external functions example'.  

    * `plCndBinomial(const plCndDistribution &)`  

        Promote from a plCndDistribution.  

        If the object being copied is actually of the wrong type, an exception is
        raised.  

    C++ includes: plCndBinomial.h

    """

    __swig_setmethods__ = {}
    for _s in [plCndDistribution]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plCndBinomial, name, value)
    __swig_getmethods__ = {}
    for _s in [plCndDistribution]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plCndBinomial, name)
    __repr__ = _swig_repr
    __swig_destroy__ = _probt_python3.delete_plCndBinomial
    __del__ = lambda self: None

    def __init__(self, *args):
        """
        __init__(self) -> plCndBinomial
        __init__(self, left, p) -> plCndBinomial
        __init__(self, left, right, fp) -> plCndBinomial
        __init__(self, arg2) -> plCndBinomial


        `plCndBinomial()`  
        `plCndBinomial(const plVariable &left, const plVariable &p)`  
        `plCndBinomial(const plVariable &left, const plVariablesConjunction &right,
            const plExternalFunction &fp)`  
        `plCndBinomial(const plCndDistribution &)`  

        Overloaded function
        -------------------
        * `plCndBinomial()`  

            Default constructor.  

        * `plCndBinomial(const plVariable &left, const plVariable &p)`  

            Constructs a conditional binomial distribution on variable *left* in which
            mean *p* is a variable.  

            The variable *left* must be of type *plIntegerType*.  

        * `plCndBinomial(const plVariable &left, const plVariablesConjunction &right,
            const plExternalFunction &fp)`  

            Constructs a conditional binomial distribution on variable *left* in which p
            is fixed using an external function applied to variables *right*.  

            The variable *left* must be of type *plIntegerType*.  

            An example of how to create and use plExternalFunction as conditional
            distribution parameters can be found in 'using external functions example'.  

        * `plCndBinomial(const plCndDistribution &)`  

            Promote from a plCndDistribution.  

            If the object being copied is actually of the wrong type, an exception is
            raised.  

        """
        this = _probt_python3.new_plCndBinomial(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def p_is_variable(self) -> "bool":
        """
        p_is_variable(self) -> bool


        `p_is_variable() const -> bool`  

        Returns true if the p parameter is a variable.  

        """
        return _probt_python3.plCndBinomial_p_is_variable(self)


    def get_p_variable(self) -> "plVariablesConjunction":
        """
        get_p_variable(self) -> plVariablesConjunction


        `get_p_variable() const -> plVariablesConjunction`  

        Returns the p variable.  

        Do not call this method if p_is_variable() returned false.  

        """
        return _probt_python3.plCndBinomial_get_p_variable(self)


    def p_is_function(self) -> "bool":
        """
        p_is_function(self) -> bool


        `p_is_function() const -> bool`  

        Returns true if the p parameter is a function.  

        """
        return _probt_python3.plCndBinomial_p_is_function(self)


    def get_p_function(self) -> "plExternalFunction":
        """
        get_p_function(self) -> plExternalFunction


        `get_p_function() const -> plExternalFunction`  

        Returns the p function.  

        Do not call this method if p_is_function() returned false.  

        """
        return _probt_python3.plCndBinomial_get_p_function(self)


    def is_base_class(self) -> "bool":
        """
        is_base_class(self) -> bool


        `is_base_class() const -> bool`  

        """
        return _probt_python3.plCndBinomial_is_base_class(self)


    def __getstate__(self) -> "std::string":
        """__getstate__(self) -> std::string"""
        return _probt_python3.plCndBinomial___getstate__(self)


    def __setstate_internal(self, sState: 'std::string const &') -> "void":
        """__setstate_internal(self, sState)"""
        return _probt_python3.plCndBinomial___setstate_internal(self, sState)


    def __setstate__(self, sState):
        self.__init__()
        self.__setstate_internal(sState)

plCndBinomial_swigregister = _probt_python3.plCndBinomial_swigregister
plCndBinomial_swigregister(plCndBinomial)

class plCndPoisson(plCndDistribution):
    """

    `plCndPoisson()`  
    `plCndPoisson(const plVariable &left, const plVariable &mu)`  
    `plCndPoisson(const plVariable &left, const plVariablesConjunction &right, const
        plExternalFunction &fmu)`  
    `plCndPoisson(const plCndDistribution &)`  

    Conditional Poisson distribution on one-dimensional space.  

    A *plCndPoisson* is a *plPoisson* familly for which the *mu* parameter is not
    constant, but either a known *plVariable* or a *plExternalFunction*. When
    instantiated, a *plPoisson* is obtained.  

    Constructors
    ------------
    * `plCndPoisson()`  

        Default constructor.  

    * `plCndPoisson(const plVariable &left, const plVariable &mu)`  

        Constructs a conditional poisson distribution on variable *left* in which
        mean *mu* is a variable.  

        The variable *left* must be of type *plIntegerType*.  

    * `plCndPoisson(const plVariable &left, const plVariablesConjunction &right,
        const plExternalFunction &fmu)`  

        Constructs a conditional poisson distribution on variable *left* in which
        mean is fixed using an external function applied to variables *right*.  

        The variable *left* must be of type *plIntegerType*.  

    * `plCndPoisson(const plCndDistribution &)`  

        Promote from a plCndDistribution.  

        If the object being copied is actually of the wrong type, an exception is
        raised.  

    C++ includes: plCndPoisson.h

    """

    __swig_setmethods__ = {}
    for _s in [plCndDistribution]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plCndPoisson, name, value)
    __swig_getmethods__ = {}
    for _s in [plCndDistribution]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plCndPoisson, name)
    __repr__ = _swig_repr
    __swig_destroy__ = _probt_python3.delete_plCndPoisson
    __del__ = lambda self: None

    def __init__(self, *args):
        """
        __init__(self) -> plCndPoisson
        __init__(self, left, mu) -> plCndPoisson
        __init__(self, left, right, fmu) -> plCndPoisson
        __init__(self, arg2) -> plCndPoisson


        `plCndPoisson()`  
        `plCndPoisson(const plVariable &left, const plVariable &mu)`  
        `plCndPoisson(const plVariable &left, const plVariablesConjunction &right, const
            plExternalFunction &fmu)`  
        `plCndPoisson(const plCndDistribution &)`  

        Overloaded function
        -------------------
        * `plCndPoisson()`  

            Default constructor.  

        * `plCndPoisson(const plVariable &left, const plVariable &mu)`  

            Constructs a conditional poisson distribution on variable *left* in which
            mean *mu* is a variable.  

            The variable *left* must be of type *plIntegerType*.  

        * `plCndPoisson(const plVariable &left, const plVariablesConjunction &right,
            const plExternalFunction &fmu)`  

            Constructs a conditional poisson distribution on variable *left* in which
            mean is fixed using an external function applied to variables *right*.  

            The variable *left* must be of type *plIntegerType*.  

        * `plCndPoisson(const plCndDistribution &)`  

            Promote from a plCndDistribution.  

            If the object being copied is actually of the wrong type, an exception is
            raised.  

        """
        this = _probt_python3.new_plCndPoisson(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def mu_is_variable(self) -> "bool":
        """
        mu_is_variable(self) -> bool


        `mu_is_variable() const -> bool`  

        Returns true if the mu parameter is a variable.  

        """
        return _probt_python3.plCndPoisson_mu_is_variable(self)


    def get_mu_variable(self) -> "plVariablesConjunction":
        """
        get_mu_variable(self) -> plVariablesConjunction


        `get_mu_variable() const -> plVariablesConjunction`  

        Returns the mu variable.  

        Do not call this method if mu_is_variable() returned false.  

        """
        return _probt_python3.plCndPoisson_get_mu_variable(self)


    def mu_is_function(self) -> "bool":
        """
        mu_is_function(self) -> bool


        `mu_is_function() const -> bool`  

        Returns true if the mu parameter is a function.  

        """
        return _probt_python3.plCndPoisson_mu_is_function(self)


    def get_mu_function(self) -> "plExternalFunction":
        """
        get_mu_function(self) -> plExternalFunction


        `get_mu_function() const -> plExternalFunction`  

        Returns the mu function.  

        Do not call this method if mu_is_function() returned false.  

        """
        return _probt_python3.plCndPoisson_get_mu_function(self)


    def is_base_class(self) -> "bool":
        """
        is_base_class(self) -> bool


        `is_base_class() const -> bool`  

        """
        return _probt_python3.plCndPoisson_is_base_class(self)


    def __getstate__(self) -> "std::string":
        """__getstate__(self) -> std::string"""
        return _probt_python3.plCndPoisson___getstate__(self)


    def __setstate_internal(self, sState: 'std::string const &') -> "void":
        """__setstate_internal(self, sState)"""
        return _probt_python3.plCndPoisson___setstate_internal(self, sState)


    def __setstate__(self, sState):
        self.__init__()
        self.__setstate_internal(sState)

plCndPoisson_swigregister = _probt_python3.plCndPoisson_swigregister
plCndPoisson_swigregister(plCndPoisson)

class plCndVonMises(plCndDistribution):
    """

    `plCndVonMises()`  
    `plCndVonMises(const plVariable &left, const plVariable &mean, plFloat k)`  
    `plCndVonMises(const plVariable &left, plFloat mean, const plVariable &k)`  
    `plCndVonMises(const plVariable &left, const plVariablesConjunction &right,
        const plExternalFunction &fmean, plFloat k)`  
    `plCndVonMises(const plVariable &left, const plVariablesConjunction &right,
        plFloat mean, const plExternalFunction &fk)`  
    `plCndVonMises(const plVariable &left, const plVariable &mean, const plVariable
        &k)`  
    `plCndVonMises(const plVariable &left, const plVariablesConjunction &right,
        const plExternalFunction &fmean, const plExternalFunction &fk)`  
    `plCndVonMises(const plVariable &left, const plVariablesConjunction &right,
        const plExternalFunction &f_mean_k)`  
    `plCndVonMises(const plCndDistribution &)`  

    This class implements conditional Von Mises distributions.  

    A plCndVonMises is a plVonMises family for which 'mean' and 'k' are not constant
    but are variables or user external functions. When it is instantiated, a
    plVonMises is obtained.  

    Constructors
    ------------
    * `plCndVonMises()`  

        Default contructor.  

    * `plCndVonMises(const plVariable &left, const plVariable &mean, plFloat k)`  

        Constructs a conditional Von Mises distribution on the *left* variable.  

        *mean* is a know variable, *k* is a fixed value corresponding to the k
        parameter  

    * `plCndVonMises(const plVariable &left, plFloat mean, const plVariable &k)`  

        Constructs a conditional Von Mises distribution on the *left* variable.  

        *mean* is a fixed value corresponding to the mean parameter, *k* is a know
        variable  

    * `plCndVonMises(const plVariable &left, const plVariablesConjunction &right,
        const plExternalFunction &fmean, plFloat k)`  

        Constructs a conditionnel Von Mises distribution on the *left* variable.  

        with *mean* = *fmean(right)* and *k* is a fixed value corresponding to the k
        parameter.  

        An example assuming that the mean value of the conditional Von Mises P(X | Y
        Z) is the squared sum of the value of the two parent variables "Y" and
        "Z" is as follows. It assumes the following variable definitions:  

            const plVariable X("X", plRealType(-1000, 1000) );
            const plVariable Y("Y", plRealType(-1000, 1000) );  
            const plVariable Z("Z", plRealType(-1000, 1000) );  

        1) Using a non-member function:  

            // Non member function
            void sum2(plValues &mean, const plValues &Y_Z_vals)
            {
              const double s = Y_Z_vals[Y] + Y_Z_vals[Z];
              // mean is indexed by an integer
              mean[0] = s*s;
            }

            plExternalFunction F_mean__YZ(Y^Z, &sum2);
            plCndVonMises P_X__YZ(X, Y^Z, F_mean__YZ, 1);  

        2) Using a member function:  

            struct YZSum
            {
              void sum2(plValues &mean, const plValues &Y_Z_vals) const
              {
                const double s = Y_Z_vals[Y] + Y_Z_vals[Z];
                // mean is indexed by an integer
                mean[0] = s*s;
              }

            };

            YZSum *sum_obj_ptr = new YZSum;
            plExternalFunction  F_mean__YZ(Y^Z, sum_obj_ptr, &YZSum::sum2);
            plCndVonMises P_X__YZ(X, Y^Z, F_mean__YZ, 1);  

        3) Using a C source code function:  

            const std::string sum2_code = "output[0] = (Y+Z)*(Y+Z);";
            plExternalFunctionFromC  F_mean__YZ = createExternalFunctionFromC(Y^Z,
        sum2_code, "sum2_func");
            plCndVonMises P_X__YZ(X, Y^Z, F_mean__YZ, 1);


    * `plCndVonMises(const plVariable &left, const plVariablesConjunction &right,
        plFloat mean, const plExternalFunction &fk)`  

        Constructs a one-dimensional contitional Von Mises distribution on the
        *left* variable with *k* = *fk(right)* and *mean* is a fixed value
        corresponding to the mean value.  

        An example of how to create and use plExternalFunction as conditional
        distribution parameters can be found in 'using external functions example'.  

    * `plCndVonMises(const plVariable &left, const plVariable &mean, const
        plVariable &k)`  

        Constructs a contitional Von Mises distribution on *left* variables.  

        *mean* and *k* are known variables.  

    * `plCndVonMises(const plVariable &left, const plVariablesConjunction &right,
        const plExternalFunction &fmean, const plExternalFunction &fk)`  

        Constructs a contitional Von Mises distribution on the *left* variables with
        *mean* = *fmean(right)* and *k* = *fk(right)*.  

        An example of how to create and use plExternalFunction as conditional
        distribution parameters can be found in 'using external functions example'.  

    * `plCndVonMises(const plVariable &left, const plVariablesConjunction &right,
        const plExternalFunction &f_mean_k)`  

        Constructs a contitional Von Mises distribution on the *left* variables with
        **[mean,k] = *f_mean_k(right)*.  

        An example of how to create and use plExternalFunction as conditional
        distribution parameters can be found in 'using external functions example'.  

    * `plCndVonMises(const plCndDistribution &)`  

        Promote from a plCndDistribution.  

        If the object being copied is actually of the wrong type, an exception is
        raised.  

    C++ includes: plCndVonMises.h

    """

    __swig_setmethods__ = {}
    for _s in [plCndDistribution]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plCndVonMises, name, value)
    __swig_getmethods__ = {}
    for _s in [plCndDistribution]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plCndVonMises, name)
    __repr__ = _swig_repr
    __swig_destroy__ = _probt_python3.delete_plCndVonMises
    __del__ = lambda self: None

    def __init__(self, *args):
        """
        __init__(self) -> plCndVonMises
        __init__(self, left, mean, k) -> plCndVonMises
        __init__(self, left, mean, k) -> plCndVonMises
        __init__(self, left, right, fmean, k) -> plCndVonMises
        __init__(self, left, right, mean, fk) -> plCndVonMises
        __init__(self, left, mean, k) -> plCndVonMises
        __init__(self, left, right, fmean, fk) -> plCndVonMises
        __init__(self, left, right, f_mean_k) -> plCndVonMises
        __init__(self, arg2) -> plCndVonMises


        `plCndVonMises()`  
        `plCndVonMises(const plVariable &left, const plVariable &mean, plFloat k)`  
        `plCndVonMises(const plVariable &left, plFloat mean, const plVariable &k)`  
        `plCndVonMises(const plVariable &left, const plVariablesConjunction &right,
            const plExternalFunction &fmean, plFloat k)`  
        `plCndVonMises(const plVariable &left, const plVariablesConjunction &right,
            plFloat mean, const plExternalFunction &fk)`  
        `plCndVonMises(const plVariable &left, const plVariable &mean, const plVariable
            &k)`  
        `plCndVonMises(const plVariable &left, const plVariablesConjunction &right,
            const plExternalFunction &fmean, const plExternalFunction &fk)`  
        `plCndVonMises(const plVariable &left, const plVariablesConjunction &right,
            const plExternalFunction &f_mean_k)`  
        `plCndVonMises(const plCndDistribution &)`  

        Overloaded function
        -------------------
        * `plCndVonMises()`  

            Default contructor.  

        * `plCndVonMises(const plVariable &left, const plVariable &mean, plFloat k)`  

            Constructs a conditional Von Mises distribution on the *left* variable.  

            *mean* is a know variable, *k* is a fixed value corresponding to the k
            parameter  

        * `plCndVonMises(const plVariable &left, plFloat mean, const plVariable &k)`  

            Constructs a conditional Von Mises distribution on the *left* variable.  

            *mean* is a fixed value corresponding to the mean parameter, *k* is a know
            variable  

        * `plCndVonMises(const plVariable &left, const plVariablesConjunction &right,
            const plExternalFunction &fmean, plFloat k)`  

            Constructs a conditionnel Von Mises distribution on the *left* variable.  

            with *mean* = *fmean(right)* and *k* is a fixed value corresponding to the k
            parameter.  

            An example assuming that the mean value of the conditional Von Mises P(X | Y
            Z) is the squared sum of the value of the two parent variables "Y" and
            "Z" is as follows. It assumes the following variable definitions:  

                const plVariable X("X", plRealType(-1000, 1000) );
                const plVariable Y("Y", plRealType(-1000, 1000) );  
                const plVariable Z("Z", plRealType(-1000, 1000) );  

            1) Using a non-member function:  

                // Non member function
                void sum2(plValues &mean, const plValues &Y_Z_vals)
                {
                  const double s = Y_Z_vals[Y] + Y_Z_vals[Z];
                  // mean is indexed by an integer
                  mean[0] = s*s;
                }

                plExternalFunction F_mean__YZ(Y^Z, &sum2);
                plCndVonMises P_X__YZ(X, Y^Z, F_mean__YZ, 1);  

            2) Using a member function:  

                struct YZSum
                {
                  void sum2(plValues &mean, const plValues &Y_Z_vals) const
                  {
                    const double s = Y_Z_vals[Y] + Y_Z_vals[Z];
                    // mean is indexed by an integer
                    mean[0] = s*s;
                  }

                };

                YZSum *sum_obj_ptr = new YZSum;
                plExternalFunction  F_mean__YZ(Y^Z, sum_obj_ptr, &YZSum::sum2);
                plCndVonMises P_X__YZ(X, Y^Z, F_mean__YZ, 1);  

            3) Using a C source code function:  

                const std::string sum2_code = "output[0] = (Y+Z)*(Y+Z);";
                plExternalFunctionFromC  F_mean__YZ = createExternalFunctionFromC(Y^Z,
            sum2_code, "sum2_func");
                plCndVonMises P_X__YZ(X, Y^Z, F_mean__YZ, 1);


        * `plCndVonMises(const plVariable &left, const plVariablesConjunction &right,
            plFloat mean, const plExternalFunction &fk)`  

            Constructs a one-dimensional contitional Von Mises distribution on the
            *left* variable with *k* = *fk(right)* and *mean* is a fixed value
            corresponding to the mean value.  

            An example of how to create and use plExternalFunction as conditional
            distribution parameters can be found in 'using external functions example'.  

        * `plCndVonMises(const plVariable &left, const plVariable &mean, const
            plVariable &k)`  

            Constructs a contitional Von Mises distribution on *left* variables.  

            *mean* and *k* are known variables.  

        * `plCndVonMises(const plVariable &left, const plVariablesConjunction &right,
            const plExternalFunction &fmean, const plExternalFunction &fk)`  

            Constructs a contitional Von Mises distribution on the *left* variables with
            *mean* = *fmean(right)* and *k* = *fk(right)*.  

            An example of how to create and use plExternalFunction as conditional
            distribution parameters can be found in 'using external functions example'.  

        * `plCndVonMises(const plVariable &left, const plVariablesConjunction &right,
            const plExternalFunction &f_mean_k)`  

            Constructs a contitional Von Mises distribution on the *left* variables with
            **[mean,k] = *f_mean_k(right)*.  

            An example of how to create and use plExternalFunction as conditional
            distribution parameters can be found in 'using external functions example'.  

        * `plCndVonMises(const plCndDistribution &)`  

            Promote from a plCndDistribution.  

            If the object being copied is actually of the wrong type, an exception is
            raised.  

        """
        this = _probt_python3.new_plCndVonMises(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def mean_is_constant(self) -> "bool":
        """
        mean_is_constant(self) -> bool


        `mean_is_constant() const -> bool`  

        Returns true if the mean parameter is a constant.  

        """
        return _probt_python3.plCndVonMises_mean_is_constant(self)


    def get_mean_constant(self) -> "plFloat":
        """
        get_mean_constant(self) -> plFloat


        `get_mean_constant() const -> plFloat`  

        Returns the value of the mean parameter.  

        Do not call this method if mean_is_constant() returned false.  

        """
        return _probt_python3.plCndVonMises_get_mean_constant(self)


    def mean_is_variable(self) -> "bool":
        """
        mean_is_variable(self) -> bool


        `mean_is_variable() const -> bool`  

        Returns true if the mean parameter is a variable.  

        """
        return _probt_python3.plCndVonMises_mean_is_variable(self)


    def get_mean_variable(self) -> "plVariable":
        """
        get_mean_variable(self) -> plVariable


        `get_mean_variable() const -> plVariable`  

        Returns the mean variable.  

        Do not call this method if mean_is_variable() returned false.  

        """
        return _probt_python3.plCndVonMises_get_mean_variable(self)


    def mean_is_function(self) -> "bool":
        """
        mean_is_function(self) -> bool


        `mean_is_function() const -> bool`  

        Returns true if the mean parameter is a function.  

        """
        return _probt_python3.plCndVonMises_mean_is_function(self)


    def get_mean_function(self) -> "plExternalFunction":
        """
        get_mean_function(self) -> plExternalFunction


        `get_mean_function() const -> plExternalFunction`  

        Returns the mean function.  

        Do not call this method if mean_is_function() returned false.  

        """
        return _probt_python3.plCndVonMises_get_mean_function(self)


    def k_is_constant(self) -> "bool":
        """
        k_is_constant(self) -> bool


        `k_is_constant() const -> bool`  

        Returns true if the k parameter is a constant.  

        """
        return _probt_python3.plCndVonMises_k_is_constant(self)


    def get_k_constant(self) -> "plFloat":
        """
        get_k_constant(self) -> plFloat


        `get_k_constant() const -> plFloat`  

        Returns the value of the k parameter.  

        Do not call this method if k_is_constant() returned false.  

        """
        return _probt_python3.plCndVonMises_get_k_constant(self)


    def k_is_variable(self) -> "bool":
        """
        k_is_variable(self) -> bool


        `k_is_variable() const -> bool`  

        Returns true if the k parameter is a variable.  

        """
        return _probt_python3.plCndVonMises_k_is_variable(self)


    def get_k_variable(self) -> "plVariable":
        """
        get_k_variable(self) -> plVariable


        `get_k_variable() const -> plVariable`  

        Returns the k variable.  

        Do not call this method if k_is_variable() returned false.  

        """
        return _probt_python3.plCndVonMises_get_k_variable(self)


    def k_is_function(self) -> "bool":
        """
        k_is_function(self) -> bool


        `k_is_function() const -> bool`  

        Returns true if the k parameter is a function.  

        """
        return _probt_python3.plCndVonMises_k_is_function(self)


    def get_k_function(self) -> "plExternalFunction":
        """
        get_k_function(self) -> plExternalFunction


        `get_k_function() const -> plExternalFunction`  

        Returns the k function.  

        Do not call this method if k_is_function() returned false.  

        """
        return _probt_python3.plCndVonMises_get_k_function(self)


    def mean_and_k_are_one_function(self) -> "bool":
        """
        mean_and_k_are_one_function(self) -> bool


        `mean_and_k_are_one_function() const -> bool`  

        Returns true if the mean and k parameters were given as a single function.  

        """
        return _probt_python3.plCndVonMises_mean_and_k_are_one_function(self)


    def get_mean_k_function(self) -> "plExternalFunction":
        """
        get_mean_k_function(self) -> plExternalFunction


        `get_mean_k_function() const -> plExternalFunction`  

        Returns the parameters function.  

        Do not call this method if mean_and_k_are_one_function() returned false.  

        """
        return _probt_python3.plCndVonMises_get_mean_k_function(self)


    def is_base_class(self) -> "bool":
        """
        is_base_class(self) -> bool


        `is_base_class() const -> bool`  

        """
        return _probt_python3.plCndVonMises_is_base_class(self)


    def __getstate__(self) -> "std::string":
        """__getstate__(self) -> std::string"""
        return _probt_python3.plCndVonMises___getstate__(self)


    def __setstate_internal(self, sState: 'std::string const &') -> "void":
        """__setstate_internal(self, sState)"""
        return _probt_python3.plCndVonMises___setstate_internal(self, sState)


    def __setstate__(self, sState):
        self.__init__()
        self.__setstate_internal(sState)

plCndVonMises_swigregister = _probt_python3.plCndVonMises_swigregister
plCndVonMises_swigregister(plCndVonMises)

class plCndExponential(plCndDistribution):
    """

    `plCndExponential()`  
    `plCndExponential(const plVariable &left, const plVariable &beta, plFloat mu)`  
    `plCndExponential(const plVariable &left, plFloat beta, const plVariable &mu)`  
    `plCndExponential(const plVariable &left, const plVariablesConjunction &right,
        const plExternalFunction &fbeta, plFloat mu)`  
    `plCndExponential(const plVariable &left, const plVariablesConjunction &right,
        plFloat beta, const plExternalFunction &fmu)`  
    `plCndExponential(const plVariable &left, const plVariable &beta, const
        plVariable &mu)`  
    `plCndExponential(const plVariable &left, const plVariablesConjunction &right,
        const plExternalFunction &fbeta, const plExternalFunction &fmu)`  
    `plCndExponential(const plVariable &left, const plVariablesConjunction &right,
        const plExternalFunction &f_beta_mu)`  
    `plCndExponential(const plCndDistribution &)`  

    This class implements conditional Exponential distributions.  

    A plCndExponential is a plExponential family for which mu and beta are not
    constant but are variables or user external functions. When it is instantiated,
    a plExponential is obtained.  

    Constructors
    ------------
    * `plCndExponential()`  

        Default contructor.  

    * `plCndExponential(const plVariable &left, const plVariable &beta, plFloat mu)`  

        Constructs a one-dimensional conditional Exponential distribution on the
        *left* variable.  

        *beta* is a know variable, *mu* is a fixed value corresponding to the m
        parameter  

    * `plCndExponential(const plVariable &left, plFloat beta, const plVariable &mu)`  

        Constructs a one-dimensional conditional Exponential distribution on the
        *left* variable.  

        *beta* is a fixed value corresponding to the beta value. *mu* is a know
        variable  

    * `plCndExponential(const plVariable &left, const plVariablesConjunction &right,
        const plExternalFunction &fbeta, plFloat mu)`  

        Constructs a one-dimensional conditionnel Exponential distribution on the
        *left* variable.  

        with *beta* = *fbeta(right)* and *mu* is a fixed value corresponding to the
        m parameter.  

        An example assuming that the beta value of the conditional Exponential P(X |
        Y Z) is the squared sum of the value of the two parent variables "Y" and
        "Z" is as follows. It assumes the following variable definitions:  

            const plVariable X("X", plRealType(-1000, 1000) );
            const plVariable Y("Y", plRealType(-1000, 1000) );  
            const plVariable Z("Z", plRealType(-1000, 1000) );  

        1) Using a non-member function:  

            // Non member function
            void sum2(plValues &beta, const plValues &Y_Z_vals)
            {
            const double s = Y_Z_vals[Y] + Y_Z_vals[Z];
            // beta is indexed by an integer
            beta[0] = s*s;
            }

            plExternalFunction F_beta__YZ(Y^Z, &sum2);
            plCndExponential P_X__YZ(X, Y^Z, F_beta__YZ, 1);  

        2) Using a member function:  

            struct YZSum
            {
            void sum2(plValues &beta, const plValues &Y_Z_vals) const
            {
            const double s = Y_Z_vals[Y] + Y_Z_vals[Z];
            // beta is indexed by an integer
            beta[0] = s*s;
            }

            };

            YZSum *sum_obj_ptr = new YZSum;
            plExternalFunction  F_beta__YZ(Y^Z, sum_obj_ptr, &YZSum::sum2);
            plCndExponential P_X__YZ(X, Y^Z, F_beta__YZ, 1);  

        3) Using a C source code function:  

            const std::string sum2_code = "output[0] = (Y+Z)*(Y+Z);";
            plExternalFunctionFromC  F_beta__YZ = createExternalFunctionFromC(Y^Z,
        sum2_code, "sum2_func");
            plCndExponential P_X__YZ(X, Y^Z, F_beta__YZ);


    * `plCndExponential(const plVariable &left, const plVariablesConjunction &right,
        plFloat beta, const plExternalFunction &fmu)`  

        Constructs a one-dimensional contitional Exponential distribution on the
        *left* variable with *mu* = *fmu(right)* and *beta* is a fixed value
        corresponding to the beta value.  

        An example of how to create and use plExternalFunction as conditional
        distribution parameters can be found in 'using external functions example'.  

    * `plCndExponential(const plVariable &left, const plVariable &beta, const
        plVariable &mu)`  

        Constructs a contitional Exponential distribution on *left* variables.  

        *beta* and *mu* are known variables.  

    * `plCndExponential(const plVariable &left, const plVariablesConjunction &right,
        const plExternalFunction &fbeta, const plExternalFunction &fmu)`  

        Constructs a contitional Exponential distribution on the *left* variables
        with *mu* = *fmu(right)* and *beta* = *fbeta(right)*.  

        An example of how to create and use plExternalFunction as conditional
        distribution parameters can be found in 'using external functions example'.  

    * `plCndExponential(const plVariable &left, const plVariablesConjunction &right,
        const plExternalFunction &f_beta_mu)`  

        Constructs a contitional Exponential distribution on the *left* variables
        with **[beta,mu] = *f_beta_mu(right)*.  

        An example of how to create and use plExternalFunction as conditional
        distribution parameters can be found in 'using external functions example'.  

    * `plCndExponential(const plCndDistribution &)`  

        Promote from a plCndDistribution.  

        If the object being copied is actually of the wrong type, an exception is
        raised.  

    C++ includes: plCndExponential.h

    """

    __swig_setmethods__ = {}
    for _s in [plCndDistribution]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plCndExponential, name, value)
    __swig_getmethods__ = {}
    for _s in [plCndDistribution]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plCndExponential, name)
    __repr__ = _swig_repr
    __swig_destroy__ = _probt_python3.delete_plCndExponential
    __del__ = lambda self: None

    def __init__(self, *args):
        """
        __init__(self) -> plCndExponential
        __init__(self, left, beta, mu) -> plCndExponential
        __init__(self, left, beta, mu) -> plCndExponential
        __init__(self, left, right, fbeta, mu) -> plCndExponential
        __init__(self, left, right, beta, fmu) -> plCndExponential
        __init__(self, left, beta, mu) -> plCndExponential
        __init__(self, left, right, fbeta, fmu) -> plCndExponential
        __init__(self, left, right, f_beta_mu) -> plCndExponential
        __init__(self, arg2) -> plCndExponential


        `plCndExponential()`  
        `plCndExponential(const plVariable &left, const plVariable &beta, plFloat mu)`  
        `plCndExponential(const plVariable &left, plFloat beta, const plVariable &mu)`  
        `plCndExponential(const plVariable &left, const plVariablesConjunction &right,
            const plExternalFunction &fbeta, plFloat mu)`  
        `plCndExponential(const plVariable &left, const plVariablesConjunction &right,
            plFloat beta, const plExternalFunction &fmu)`  
        `plCndExponential(const plVariable &left, const plVariable &beta, const
            plVariable &mu)`  
        `plCndExponential(const plVariable &left, const plVariablesConjunction &right,
            const plExternalFunction &fbeta, const plExternalFunction &fmu)`  
        `plCndExponential(const plVariable &left, const plVariablesConjunction &right,
            const plExternalFunction &f_beta_mu)`  
        `plCndExponential(const plCndDistribution &)`  

        Overloaded function
        -------------------
        * `plCndExponential()`  

            Default contructor.  

        * `plCndExponential(const plVariable &left, const plVariable &beta, plFloat mu)`  

            Constructs a one-dimensional conditional Exponential distribution on the
            *left* variable.  

            *beta* is a know variable, *mu* is a fixed value corresponding to the m
            parameter  

        * `plCndExponential(const plVariable &left, plFloat beta, const plVariable &mu)`  

            Constructs a one-dimensional conditional Exponential distribution on the
            *left* variable.  

            *beta* is a fixed value corresponding to the beta value. *mu* is a know
            variable  

        * `plCndExponential(const plVariable &left, const plVariablesConjunction &right,
            const plExternalFunction &fbeta, plFloat mu)`  

            Constructs a one-dimensional conditionnel Exponential distribution on the
            *left* variable.  

            with *beta* = *fbeta(right)* and *mu* is a fixed value corresponding to the
            m parameter.  

            An example assuming that the beta value of the conditional Exponential P(X |
            Y Z) is the squared sum of the value of the two parent variables "Y" and
            "Z" is as follows. It assumes the following variable definitions:  

                const plVariable X("X", plRealType(-1000, 1000) );
                const plVariable Y("Y", plRealType(-1000, 1000) );  
                const plVariable Z("Z", plRealType(-1000, 1000) );  

            1) Using a non-member function:  

                // Non member function
                void sum2(plValues &beta, const plValues &Y_Z_vals)
                {
                const double s = Y_Z_vals[Y] + Y_Z_vals[Z];
                // beta is indexed by an integer
                beta[0] = s*s;
                }

                plExternalFunction F_beta__YZ(Y^Z, &sum2);
                plCndExponential P_X__YZ(X, Y^Z, F_beta__YZ, 1);  

            2) Using a member function:  

                struct YZSum
                {
                void sum2(plValues &beta, const plValues &Y_Z_vals) const
                {
                const double s = Y_Z_vals[Y] + Y_Z_vals[Z];
                // beta is indexed by an integer
                beta[0] = s*s;
                }

                };

                YZSum *sum_obj_ptr = new YZSum;
                plExternalFunction  F_beta__YZ(Y^Z, sum_obj_ptr, &YZSum::sum2);
                plCndExponential P_X__YZ(X, Y^Z, F_beta__YZ, 1);  

            3) Using a C source code function:  

                const std::string sum2_code = "output[0] = (Y+Z)*(Y+Z);";
                plExternalFunctionFromC  F_beta__YZ = createExternalFunctionFromC(Y^Z,
            sum2_code, "sum2_func");
                plCndExponential P_X__YZ(X, Y^Z, F_beta__YZ);


        * `plCndExponential(const plVariable &left, const plVariablesConjunction &right,
            plFloat beta, const plExternalFunction &fmu)`  

            Constructs a one-dimensional contitional Exponential distribution on the
            *left* variable with *mu* = *fmu(right)* and *beta* is a fixed value
            corresponding to the beta value.  

            An example of how to create and use plExternalFunction as conditional
            distribution parameters can be found in 'using external functions example'.  

        * `plCndExponential(const plVariable &left, const plVariable &beta, const
            plVariable &mu)`  

            Constructs a contitional Exponential distribution on *left* variables.  

            *beta* and *mu* are known variables.  

        * `plCndExponential(const plVariable &left, const plVariablesConjunction &right,
            const plExternalFunction &fbeta, const plExternalFunction &fmu)`  

            Constructs a contitional Exponential distribution on the *left* variables
            with *mu* = *fmu(right)* and *beta* = *fbeta(right)*.  

            An example of how to create and use plExternalFunction as conditional
            distribution parameters can be found in 'using external functions example'.  

        * `plCndExponential(const plVariable &left, const plVariablesConjunction &right,
            const plExternalFunction &f_beta_mu)`  

            Constructs a contitional Exponential distribution on the *left* variables
            with **[beta,mu] = *f_beta_mu(right)*.  

            An example of how to create and use plExternalFunction as conditional
            distribution parameters can be found in 'using external functions example'.  

        * `plCndExponential(const plCndDistribution &)`  

            Promote from a plCndDistribution.  

            If the object being copied is actually of the wrong type, an exception is
            raised.  

        """
        this = _probt_python3.new_plCndExponential(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def beta_is_constant(self) -> "bool":
        """
        beta_is_constant(self) -> bool


        `beta_is_constant() const -> bool`  

        Returns true if the beta parameter is a constant.  

        """
        return _probt_python3.plCndExponential_beta_is_constant(self)


    def get_beta_constant(self) -> "plFloat":
        """
        get_beta_constant(self) -> plFloat


        `get_beta_constant() const -> plFloat`  

        Returns the value of the beta parameter.  

        Do not call this method if beta_is_constant() returned false.  

        """
        return _probt_python3.plCndExponential_get_beta_constant(self)


    def beta_is_variable(self) -> "bool":
        """
        beta_is_variable(self) -> bool


        `beta_is_variable() const -> bool`  

        Returns true if the beta parameter is a variable.  

        """
        return _probt_python3.plCndExponential_beta_is_variable(self)


    def get_beta_variable(self) -> "plVariable":
        """
        get_beta_variable(self) -> plVariable


        `get_beta_variable() const -> plVariable`  

        Returns the beta variable.  

        Do not call this method if beta_is_variable() returned false.  

        """
        return _probt_python3.plCndExponential_get_beta_variable(self)


    def beta_is_function(self) -> "bool":
        """
        beta_is_function(self) -> bool


        `beta_is_function() const -> bool`  

        Returns true if the beta parameter is a function.  

        """
        return _probt_python3.plCndExponential_beta_is_function(self)


    def get_beta_function(self) -> "plExternalFunction":
        """
        get_beta_function(self) -> plExternalFunction


        `get_beta_function() const -> plExternalFunction`  

        Returns the beta function.  

        Do not call this method if beta_is_function() returned false.  

        """
        return _probt_python3.plCndExponential_get_beta_function(self)


    def mu_is_constant(self) -> "bool":
        """
        mu_is_constant(self) -> bool


        `mu_is_constant() const -> bool`  

        Returns true if the mu parameter is a constant.  

        """
        return _probt_python3.plCndExponential_mu_is_constant(self)


    def get_mu_constant(self) -> "plFloat":
        """
        get_mu_constant(self) -> plFloat


        `get_mu_constant() const -> plFloat`  

        Returns the value of the mu parameter.  

        Do not call this method if mu_is_constant() returned false.  

        """
        return _probt_python3.plCndExponential_get_mu_constant(self)


    def mu_is_variable(self) -> "bool":
        """
        mu_is_variable(self) -> bool


        `mu_is_variable() const -> bool`  

        Returns true if the mu parameter is a variable.  

        """
        return _probt_python3.plCndExponential_mu_is_variable(self)


    def get_mu_variable(self) -> "plVariable":
        """
        get_mu_variable(self) -> plVariable


        `get_mu_variable() const -> plVariable`  

        Returns the mu variable.  

        Do not call this method if mu_is_variable() returned false.  

        """
        return _probt_python3.plCndExponential_get_mu_variable(self)


    def mu_is_function(self) -> "bool":
        """
        mu_is_function(self) -> bool


        `mu_is_function() const -> bool`  

        Returns true if the mu parameter is a function.  

        """
        return _probt_python3.plCndExponential_mu_is_function(self)


    def get_mu_function(self) -> "plExternalFunction":
        """
        get_mu_function(self) -> plExternalFunction


        `get_mu_function() const -> plExternalFunction`  

        Returns the mu function.  

        Do not call this method if mu_is_function() returned false.  

        """
        return _probt_python3.plCndExponential_get_mu_function(self)


    def beta_and_mu_are_one_function(self) -> "bool":
        """
        beta_and_mu_are_one_function(self) -> bool


        `beta_and_mu_are_one_function() const -> bool`  

        Returns true if the beta and mu parameters were given as a single function.  

        """
        return _probt_python3.plCndExponential_beta_and_mu_are_one_function(self)


    def get_beta_mu_function(self) -> "plExternalFunction":
        """
        get_beta_mu_function(self) -> plExternalFunction


        `get_beta_mu_function() const -> plExternalFunction`  

        Returns the parameters function.  

        Do not call this method if beta_and_mu_are_one_function() returned false.  

        """
        return _probt_python3.plCndExponential_get_beta_mu_function(self)


    def is_base_class(self) -> "bool":
        """
        is_base_class(self) -> bool


        `is_base_class() const -> bool`  

        """
        return _probt_python3.plCndExponential_is_base_class(self)


    def __getstate__(self) -> "std::string":
        """__getstate__(self) -> std::string"""
        return _probt_python3.plCndExponential___getstate__(self)


    def __setstate_internal(self, sState: 'std::string const &') -> "void":
        """__setstate_internal(self, sState)"""
        return _probt_python3.plCndExponential___setstate_internal(self, sState)


    def __setstate__(self, sState):
        self.__init__()
        self.__setstate_internal(sState)

plCndExponential_swigregister = _probt_python3.plCndExponential_swigregister
plCndExponential_swigregister(plCndExponential)

class plCndGamma(plCndDistribution):
    """

    `plCndGamma()`  
    `plCndGamma(const plVariable &left, const plVariable &alpha, plFloat theta)`  
    `plCndGamma(const plVariable &left, plFloat alpha, const plVariable &theta)`  
    `plCndGamma(const plVariable &left, const plVariablesConjunction &right, const
        plExternalFunction &falpha, plFloat theta)`  
    `plCndGamma(const plVariable &left, const plVariablesConjunction &right, plFloat
        alpha, const plExternalFunction &ftheta)`  
    `plCndGamma(const plVariable &left, const plVariable &alpha, const plVariable
        &theta)`  
    `plCndGamma(const plVariable &left, const plVariablesConjunction &right, const
        plExternalFunction &falpha, const plExternalFunction &ftheta)`  
    `plCndGamma(const plVariable &left, const plVariablesConjunction &right, const
        plExternalFunction &f_alpha_theta)`  
    `plCndGamma(const plCndDistribution &)`  

    This class implements conditional Gamma distributions.  

    A plCndGamma is a plGamma family for which alpha and theta are not constant but
    are variables or user external functions (mu = 0). When it is instantiated, a
    plGamma is obtained.  

    Constructors
    ------------
    * `plCndGamma()`  

        Default contructor.  

    * `plCndGamma(const plVariable &left, const plVariable &alpha, plFloat theta)`  

        Constructs a one-dimensional conditional Gamma distribution on the *left*
        variable.  

        *alpha* is a know variable, *theta* is a fixed value corresponding to the m
        parameter  

    * `plCndGamma(const plVariable &left, plFloat alpha, const plVariable &theta)`  

        Constructs a one-dimensional conditional Gamma distribution on the *left*
        variable.  

        *alpha* is a fixed value corresponding to the alpha value. *theta* is a know
        variable  

    * `plCndGamma(const plVariable &left, const plVariablesConjunction &right, const
        plExternalFunction &falpha, plFloat theta)`  

        Constructs a one-dimensional conditionnel Gamma distribution on the *left*
        variable.  

        with *alpha* = *falpha(right)* and *theta* is a fixed value corresponding to
        the m parameter.  

        An example assuming that the alpha value of the conditional Gamma P(X | Y Z)
        is the squared sum of the value of the two parent variables "Y" and "Z"
        is as follows. It assumes the following variable definitions:  

            const plVariable X("X", plRealType(-1000, 1000) );
            const plVariable Y("Y", plRealType(-1000, 1000) );  
            const plVariable Z("Z", plRealType(-1000, 1000) );  

        1) Using a non-member function:  

            // Non member function
            void sum2(plValues &alpha, const plValues &Y_Z_vals)
            {
            const double s = Y_Z_vals[Y] + Y_Z_vals[Z];
            // alpha is indexed by an integer
            alpha[0] = s*s;
            }

            plExternalFunction F_alpha__YZ(Y^Z, &sum2);
            plCndGamma P_X__YZ(X, Y^Z, F_alpha__YZ, 2);  

        2) Using a member function:  

            struct YZSum
            {
            void sum2(plValues &alpha, const plValues &Y_Z_vals) const
            {
            const double s = Y_Z_vals[Y] + Y_Z_vals[Z];
            // alpha is indexed by an integer
            alpha[0] = s*s;
            }

            };

            YZSum *sum_obj_ptr = new YZSum;
            plExternalFunction  F_alpha__YZ(Y^Z, sum_obj_ptr, &YZSum::sum2);
            plCndGamma P_X__YZ(X, Y^Z, F_alpha__YZ, 2);  

        3) Using a C source code function:  

            const std::string sum2_code = "output[0] = (Y+Z)*(Y+Z);";
            plExternalFunctionFromC  F_alpha__YZ = createExternalFunctionFromC(Y^Z,
        sum2_code, "sum2_func");
            plCndGamma P_X__YZ(X, Y^Z, F_alpha__YZ, 2);


    * `plCndGamma(const plVariable &left, const plVariablesConjunction &right,
        plFloat alpha, const plExternalFunction &ftheta)`  

        Constructs a one-dimensional contitional Gamma distribution on the *left*
        variable with *theta* = *ftheta(right)* and *alpha* is a fixed value
        corresponding to the alpha value.  

        An example of how to create and use plExternalFunction as conditional
        distribution parameters can be found in 'using external functions example'.  

    * `plCndGamma(const plVariable &left, const plVariable &alpha, const plVariable
        &theta)`  

        Constructs a contitional Gamma distribution on *left* variables.  

        *alpha* and *theta* are known variables.  

    * `plCndGamma(const plVariable &left, const plVariablesConjunction &right, const
        plExternalFunction &falpha, const plExternalFunction &ftheta)`  

        Constructs a contitional Gamma distribution on the *left* variables with
        *theta* = *ftheta(right)* and *alpha* = *falpha(right)*.  

        An example of how to create and use plExternalFunction as conditional
        distribution parameters can be found in 'using external functions example'.  

    * `plCndGamma(const plVariable &left, const plVariablesConjunction &right, const
        plExternalFunction &f_alpha_theta)`  

        Constructs a contitional Gamma distribution on the *left* variables with
        **[alpha,theta] = *f_alpha_theta(right)*.  

        An example of how to create and use plExternalFunction as conditional
        distribution parameters can be found in 'using external functions example'.  

    * `plCndGamma(const plCndDistribution &)`  

        Promote from a plCndDistribution.  

        If the object being copied is actually of the wrong type, an exception is
        raised.  

    C++ includes: plCndGamma.h

    """

    __swig_setmethods__ = {}
    for _s in [plCndDistribution]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plCndGamma, name, value)
    __swig_getmethods__ = {}
    for _s in [plCndDistribution]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plCndGamma, name)
    __repr__ = _swig_repr
    __swig_destroy__ = _probt_python3.delete_plCndGamma
    __del__ = lambda self: None

    def __init__(self, *args):
        """
        __init__(self) -> plCndGamma
        __init__(self, left, alpha, theta) -> plCndGamma
        __init__(self, left, alpha, theta) -> plCndGamma
        __init__(self, left, right, falpha, theta) -> plCndGamma
        __init__(self, left, right, alpha, ftheta) -> plCndGamma
        __init__(self, left, alpha, theta) -> plCndGamma
        __init__(self, left, right, falpha, ftheta) -> plCndGamma
        __init__(self, left, right, f_alpha_theta) -> plCndGamma
        __init__(self, arg2) -> plCndGamma


        `plCndGamma()`  
        `plCndGamma(const plVariable &left, const plVariable &alpha, plFloat theta)`  
        `plCndGamma(const plVariable &left, plFloat alpha, const plVariable &theta)`  
        `plCndGamma(const plVariable &left, const plVariablesConjunction &right, const
            plExternalFunction &falpha, plFloat theta)`  
        `plCndGamma(const plVariable &left, const plVariablesConjunction &right, plFloat
            alpha, const plExternalFunction &ftheta)`  
        `plCndGamma(const plVariable &left, const plVariable &alpha, const plVariable
            &theta)`  
        `plCndGamma(const plVariable &left, const plVariablesConjunction &right, const
            plExternalFunction &falpha, const plExternalFunction &ftheta)`  
        `plCndGamma(const plVariable &left, const plVariablesConjunction &right, const
            plExternalFunction &f_alpha_theta)`  
        `plCndGamma(const plCndDistribution &)`  

        Overloaded function
        -------------------
        * `plCndGamma()`  

            Default contructor.  

        * `plCndGamma(const plVariable &left, const plVariable &alpha, plFloat theta)`  

            Constructs a one-dimensional conditional Gamma distribution on the *left*
            variable.  

            *alpha* is a know variable, *theta* is a fixed value corresponding to the m
            parameter  

        * `plCndGamma(const plVariable &left, plFloat alpha, const plVariable &theta)`  

            Constructs a one-dimensional conditional Gamma distribution on the *left*
            variable.  

            *alpha* is a fixed value corresponding to the alpha value. *theta* is a know
            variable  

        * `plCndGamma(const plVariable &left, const plVariablesConjunction &right, const
            plExternalFunction &falpha, plFloat theta)`  

            Constructs a one-dimensional conditionnel Gamma distribution on the *left*
            variable.  

            with *alpha* = *falpha(right)* and *theta* is a fixed value corresponding to
            the m parameter.  

            An example assuming that the alpha value of the conditional Gamma P(X | Y Z)
            is the squared sum of the value of the two parent variables "Y" and "Z"
            is as follows. It assumes the following variable definitions:  

                const plVariable X("X", plRealType(-1000, 1000) );
                const plVariable Y("Y", plRealType(-1000, 1000) );  
                const plVariable Z("Z", plRealType(-1000, 1000) );  

            1) Using a non-member function:  

                // Non member function
                void sum2(plValues &alpha, const plValues &Y_Z_vals)
                {
                const double s = Y_Z_vals[Y] + Y_Z_vals[Z];
                // alpha is indexed by an integer
                alpha[0] = s*s;
                }

                plExternalFunction F_alpha__YZ(Y^Z, &sum2);
                plCndGamma P_X__YZ(X, Y^Z, F_alpha__YZ, 2);  

            2) Using a member function:  

                struct YZSum
                {
                void sum2(plValues &alpha, const plValues &Y_Z_vals) const
                {
                const double s = Y_Z_vals[Y] + Y_Z_vals[Z];
                // alpha is indexed by an integer
                alpha[0] = s*s;
                }

                };

                YZSum *sum_obj_ptr = new YZSum;
                plExternalFunction  F_alpha__YZ(Y^Z, sum_obj_ptr, &YZSum::sum2);
                plCndGamma P_X__YZ(X, Y^Z, F_alpha__YZ, 2);  

            3) Using a C source code function:  

                const std::string sum2_code = "output[0] = (Y+Z)*(Y+Z);";
                plExternalFunctionFromC  F_alpha__YZ = createExternalFunctionFromC(Y^Z,
            sum2_code, "sum2_func");
                plCndGamma P_X__YZ(X, Y^Z, F_alpha__YZ, 2);


        * `plCndGamma(const plVariable &left, const plVariablesConjunction &right,
            plFloat alpha, const plExternalFunction &ftheta)`  

            Constructs a one-dimensional contitional Gamma distribution on the *left*
            variable with *theta* = *ftheta(right)* and *alpha* is a fixed value
            corresponding to the alpha value.  

            An example of how to create and use plExternalFunction as conditional
            distribution parameters can be found in 'using external functions example'.  

        * `plCndGamma(const plVariable &left, const plVariable &alpha, const plVariable
            &theta)`  

            Constructs a contitional Gamma distribution on *left* variables.  

            *alpha* and *theta* are known variables.  

        * `plCndGamma(const plVariable &left, const plVariablesConjunction &right, const
            plExternalFunction &falpha, const plExternalFunction &ftheta)`  

            Constructs a contitional Gamma distribution on the *left* variables with
            *theta* = *ftheta(right)* and *alpha* = *falpha(right)*.  

            An example of how to create and use plExternalFunction as conditional
            distribution parameters can be found in 'using external functions example'.  

        * `plCndGamma(const plVariable &left, const plVariablesConjunction &right, const
            plExternalFunction &f_alpha_theta)`  

            Constructs a contitional Gamma distribution on the *left* variables with
            **[alpha,theta] = *f_alpha_theta(right)*.  

            An example of how to create and use plExternalFunction as conditional
            distribution parameters can be found in 'using external functions example'.  

        * `plCndGamma(const plCndDistribution &)`  

            Promote from a plCndDistribution.  

            If the object being copied is actually of the wrong type, an exception is
            raised.  

        """
        this = _probt_python3.new_plCndGamma(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def alpha_is_constant(self) -> "bool":
        """
        alpha_is_constant(self) -> bool


        `alpha_is_constant() const -> bool`  

        Returns true if the alpha parameter is a constant.  

        """
        return _probt_python3.plCndGamma_alpha_is_constant(self)


    def get_alpha_constant(self) -> "plFloat":
        """
        get_alpha_constant(self) -> plFloat


        `get_alpha_constant() const -> plFloat`  

        Returns the value of the alpha parameter.  

        Do not call this method if alpha_is_constant() returned false.  

        """
        return _probt_python3.plCndGamma_get_alpha_constant(self)


    def alpha_is_variable(self) -> "bool":
        """
        alpha_is_variable(self) -> bool


        `alpha_is_variable() const -> bool`  

        Returns true if the alpha parameter is a variable.  

        """
        return _probt_python3.plCndGamma_alpha_is_variable(self)


    def get_alpha_variable(self) -> "plVariable":
        """
        get_alpha_variable(self) -> plVariable


        `get_alpha_variable() const -> plVariable`  

        Returns the alpha variable.  

        Do not call this method if alpha_is_variable() returned false.  

        """
        return _probt_python3.plCndGamma_get_alpha_variable(self)


    def alpha_is_function(self) -> "bool":
        """
        alpha_is_function(self) -> bool


        `alpha_is_function() const -> bool`  

        Returns true if the alpha parameter is a function.  

        """
        return _probt_python3.plCndGamma_alpha_is_function(self)


    def get_alpha_function(self) -> "plExternalFunction":
        """
        get_alpha_function(self) -> plExternalFunction


        `get_alpha_function() const -> plExternalFunction`  

        Returns the alpha function.  

        Do not call this method if alpha_is_function() returned false.  

        """
        return _probt_python3.plCndGamma_get_alpha_function(self)


    def theta_is_constant(self) -> "bool":
        """
        theta_is_constant(self) -> bool


        `theta_is_constant() const -> bool`  

        Returns true if the theta parameter is a constant.  

        """
        return _probt_python3.plCndGamma_theta_is_constant(self)


    def get_theta_constant(self) -> "plFloat":
        """
        get_theta_constant(self) -> plFloat


        `get_theta_constant() const -> plFloat`  

        Returns the value of the theta parameter.  

        Do not call this method if theta_is_constant() returned false.  

        """
        return _probt_python3.plCndGamma_get_theta_constant(self)


    def theta_is_variable(self) -> "bool":
        """
        theta_is_variable(self) -> bool


        `theta_is_variable() const -> bool`  

        Returns true if the theta parameter is a variable.  

        """
        return _probt_python3.plCndGamma_theta_is_variable(self)


    def get_theta_variable(self) -> "plVariable":
        """
        get_theta_variable(self) -> plVariable


        `get_theta_variable() const -> plVariable`  

        Returns the theta variable.  

        Do not call this method if theta_is_variable() returned false.  

        """
        return _probt_python3.plCndGamma_get_theta_variable(self)


    def theta_is_function(self) -> "bool":
        """
        theta_is_function(self) -> bool


        `theta_is_function() const -> bool`  

        Returns true if the theta parameter is a function.  

        """
        return _probt_python3.plCndGamma_theta_is_function(self)


    def get_theta_function(self) -> "plExternalFunction":
        """
        get_theta_function(self) -> plExternalFunction


        `get_theta_function() const -> plExternalFunction`  

        Returns the theta function.  

        Do not call this method if theta_is_function() returned false.  

        """
        return _probt_python3.plCndGamma_get_theta_function(self)


    def alpha_and_theta_are_one_function(self) -> "bool":
        """
        alpha_and_theta_are_one_function(self) -> bool


        `alpha_and_theta_are_one_function() const -> bool`  

        Returns true if the alpha and theta parameters were given as a single function.  

        """
        return _probt_python3.plCndGamma_alpha_and_theta_are_one_function(self)


    def get_alpha_theta_function(self) -> "plExternalFunction":
        """
        get_alpha_theta_function(self) -> plExternalFunction


        `get_alpha_theta_function() const -> plExternalFunction`  

        Returns the parameters function.  

        Do not call this method if alpha_and_theta_are_one_function() returned false.  

        """
        return _probt_python3.plCndGamma_get_alpha_theta_function(self)


    def is_base_class(self) -> "bool":
        """
        is_base_class(self) -> bool


        `is_base_class() const -> bool`  

        """
        return _probt_python3.plCndGamma_is_base_class(self)


    def __getstate__(self) -> "std::string":
        """__getstate__(self) -> std::string"""
        return _probt_python3.plCndGamma___getstate__(self)


    def __setstate_internal(self, sState: 'std::string const &') -> "void":
        """__setstate_internal(self, sState)"""
        return _probt_python3.plCndGamma___setstate_internal(self, sState)


    def __setstate__(self, sState):
        self.__init__()
        self.__setstate_internal(sState)

plCndGamma_swigregister = _probt_python3.plCndGamma_swigregister
plCndGamma_swigregister(plCndGamma)

class plCndUniform(plCndDistribution):
    """

    `plCndUniform()`  
    `plCndUniform(const plVariable &variable, const plVariable &min, plFloat max)`  
    `plCndUniform(const plVariable &variable, plFloat min, const plVariable &max)`  
    `plCndUniform(const plVariable &variable, const plVariablesConjunction &right,
        const plExternalFunction &fmin, plFloat max)`  
    `plCndUniform(const plVariable &variable, const plVariablesConjunction &right,
        plFloat min, const plExternalFunction &fmax)`  
    `plCndUniform(const plVariable &variable, const plVariable &min, const
        plVariable &max)`  
    `plCndUniform(const plVariable &variable, const plVariablesConjunction &right,
        const plExternalFunction &fmin, const plExternalFunction &fmax)`  
    `plCndUniform(const plVariable &variable, const plVariablesConjunction &right,
        const plExternalFunction &f_min_max)`  
    `plCndUniform(const plCndDistribution &)`  

    This class implements conditional uniform distributions on one dimensional
    space.  

    A plCndUniform is a plUniform family for which the lower and/or upper bounds are
    not constant but are variables or user external functions. When it is
    instantiated, a plUniform is obtained.  

    Constructors
    ------------
    * `plCndUniform()`  

        Default contructor.  

    * `plCndUniform(const plVariable &variable, const plVariable &min, plFloat max)`  

        Constructs a one-dimensional conditional uniform distribution on the
        *variable* variable.  

        *min* is a know variable, *max* is a fixed value corresponding to the upper
        bound  

    * `plCndUniform(const plVariable &variable, plFloat min, const plVariable &max)`  

        Constructs a one-dimensional conditional uniform distribution on the
        *variable* variable.  

        *min* is a fixed value corresponding to the lower bound *max* is a know
        variable corresponding to the upper bound  

    * `plCndUniform(const plVariable &variable, const plVariablesConjunction &right,
        const plExternalFunction &fmin, plFloat max)`  

        Constructs a one-dimensional conditionnel uniform distribution on the
        *variable* variable.  

        with *min* = *fmin(right)* and *max* is a fixed value corresponding to the
        max upper bound.  

        An example assuming that the min value of the conditional uniform P(X | Y Z)
        is the squared sum of the value of the two parent variables "Y" and "Z"
        is as follows. It assumes the following variable definitions:  

            const plVariable X("X", plRealType(-1000, 1000) );
            const plVariable Y("Y", plRealType(-1000, 1000) );  
            const plVariable Z("Z", plRealType(-1000, 1000) );  

        1) Using a non-member function:  

            // Non member function
            void sum2(plValues &min, const plValues &Y_Z_vals)
            {
            const double s = Y_Z_vals[Y] + Y_Z_vals[Z];
            // min is indexed by an integer
            min[0] = s*s;
            }

            plExternalFunction F_min__YZ(Y^Z, &sum2);
            plCndUniform P_X__YZ(X, Y^Z, F_min__YZ, 100);  

        2) Using a member function:  

            struct YZSum
            {
            void sum2(plValues &min, const plValues &Y_Z_vals) const
            {
            const double s = Y_Z_vals[Y] + Y_Z_vals[Z];
            // min is indexed by an integer
            min[0] = s*s;
            }

            };

            YZSum *sum_obj_ptr = new YZSum;
            plExternalFunction  F_min__YZ(Y^Z, sum_obj_ptr, &YZSum::sum2);
            plCndUniform P_X__YZ(X, Y^Z, F_min__YZ, 100);  

        3) Using a C source code function:  

            const std::string sum2_code = "output[0] = (Y+Z)*(Y+Z);";
            plExternalFunctionFromC  F_min__YZ = createExternalFunctionFromC(Y^Z,
        sum2_code, "sum2_func");
            plCndUniform P_X__YZ(X, Y^Z, F_min__YZ, 100);


    * `plCndUniform(const plVariable &variable, const plVariablesConjunction &right,
        plFloat min, const plExternalFunction &fmax)`  

        Constructs a one-dimensional contitional uniform distribution on the
        *variable* variable with *max* = *fmax(right)* and *min* is a fixed value
        corresponding to the min value.  

        An example of how to create and use plExternalFunction as conditional
        distribution parameters can be found in 'using external functions example'.  

    * `plCndUniform(const plVariable &variable, const plVariable &min, const
        plVariable &max)`  

        Constructs a contitional uniform distribution on *variable* variables.  

        *min* and *max* are known variables.  

    * `plCndUniform(const plVariable &variable, const plVariablesConjunction &right,
        const plExternalFunction &fmin, const plExternalFunction &fmax)`  

        Constructs a contitional uniform distribution on the *variable* variables
        with *max* = *fmax(right)* and *min* = *fmin(right)*.  

        An example of how to create and use plExternalFunction as conditional
        distribution parameters can be found in 'using external functions example'.  

    * `plCndUniform(const plVariable &variable, const plVariablesConjunction &right,
        const plExternalFunction &f_min_max)`  

        Constructs a contitional uniform distribution on the *variable* variables
        with **[min,max] = *f_min_max(right)*.  

        An example of how to create and use plExternalFunction as conditional
        distribution parameters can be found in 'using external functions example'.  

    * `plCndUniform(const plCndDistribution &)`  

        Promote from a plCndDistribution.  

        If the object being copied is actually of the wrong type, an exception is
        raised.  

    C++ includes: plCndUniform.h

    """

    __swig_setmethods__ = {}
    for _s in [plCndDistribution]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plCndUniform, name, value)
    __swig_getmethods__ = {}
    for _s in [plCndDistribution]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plCndUniform, name)
    __repr__ = _swig_repr
    __swig_destroy__ = _probt_python3.delete_plCndUniform
    __del__ = lambda self: None

    def __init__(self, *args):
        """
        __init__(self) -> plCndUniform
        __init__(self, variable, min, max) -> plCndUniform
        __init__(self, variable, min, max) -> plCndUniform
        __init__(self, variable, right, fmin, max) -> plCndUniform
        __init__(self, variable, right, min, fmax) -> plCndUniform
        __init__(self, variable, min, max) -> plCndUniform
        __init__(self, variable, right, fmin, fmax) -> plCndUniform
        __init__(self, variable, right, f_min_max) -> plCndUniform
        __init__(self, arg2) -> plCndUniform


        `plCndUniform()`  
        `plCndUniform(const plVariable &variable, const plVariable &min, plFloat max)`  
        `plCndUniform(const plVariable &variable, plFloat min, const plVariable &max)`  
        `plCndUniform(const plVariable &variable, const plVariablesConjunction &right,
            const plExternalFunction &fmin, plFloat max)`  
        `plCndUniform(const plVariable &variable, const plVariablesConjunction &right,
            plFloat min, const plExternalFunction &fmax)`  
        `plCndUniform(const plVariable &variable, const plVariable &min, const
            plVariable &max)`  
        `plCndUniform(const plVariable &variable, const plVariablesConjunction &right,
            const plExternalFunction &fmin, const plExternalFunction &fmax)`  
        `plCndUniform(const plVariable &variable, const plVariablesConjunction &right,
            const plExternalFunction &f_min_max)`  
        `plCndUniform(const plCndDistribution &)`  

        Overloaded function
        -------------------
        * `plCndUniform()`  

            Default contructor.  

        * `plCndUniform(const plVariable &variable, const plVariable &min, plFloat max)`  

            Constructs a one-dimensional conditional uniform distribution on the
            *variable* variable.  

            *min* is a know variable, *max* is a fixed value corresponding to the upper
            bound  

        * `plCndUniform(const plVariable &variable, plFloat min, const plVariable &max)`  

            Constructs a one-dimensional conditional uniform distribution on the
            *variable* variable.  

            *min* is a fixed value corresponding to the lower bound *max* is a know
            variable corresponding to the upper bound  

        * `plCndUniform(const plVariable &variable, const plVariablesConjunction &right,
            const plExternalFunction &fmin, plFloat max)`  

            Constructs a one-dimensional conditionnel uniform distribution on the
            *variable* variable.  

            with *min* = *fmin(right)* and *max* is a fixed value corresponding to the
            max upper bound.  

            An example assuming that the min value of the conditional uniform P(X | Y Z)
            is the squared sum of the value of the two parent variables "Y" and "Z"
            is as follows. It assumes the following variable definitions:  

                const plVariable X("X", plRealType(-1000, 1000) );
                const plVariable Y("Y", plRealType(-1000, 1000) );  
                const plVariable Z("Z", plRealType(-1000, 1000) );  

            1) Using a non-member function:  

                // Non member function
                void sum2(plValues &min, const plValues &Y_Z_vals)
                {
                const double s = Y_Z_vals[Y] + Y_Z_vals[Z];
                // min is indexed by an integer
                min[0] = s*s;
                }

                plExternalFunction F_min__YZ(Y^Z, &sum2);
                plCndUniform P_X__YZ(X, Y^Z, F_min__YZ, 100);  

            2) Using a member function:  

                struct YZSum
                {
                void sum2(plValues &min, const plValues &Y_Z_vals) const
                {
                const double s = Y_Z_vals[Y] + Y_Z_vals[Z];
                // min is indexed by an integer
                min[0] = s*s;
                }

                };

                YZSum *sum_obj_ptr = new YZSum;
                plExternalFunction  F_min__YZ(Y^Z, sum_obj_ptr, &YZSum::sum2);
                plCndUniform P_X__YZ(X, Y^Z, F_min__YZ, 100);  

            3) Using a C source code function:  

                const std::string sum2_code = "output[0] = (Y+Z)*(Y+Z);";
                plExternalFunctionFromC  F_min__YZ = createExternalFunctionFromC(Y^Z,
            sum2_code, "sum2_func");
                plCndUniform P_X__YZ(X, Y^Z, F_min__YZ, 100);


        * `plCndUniform(const plVariable &variable, const plVariablesConjunction &right,
            plFloat min, const plExternalFunction &fmax)`  

            Constructs a one-dimensional contitional uniform distribution on the
            *variable* variable with *max* = *fmax(right)* and *min* is a fixed value
            corresponding to the min value.  

            An example of how to create and use plExternalFunction as conditional
            distribution parameters can be found in 'using external functions example'.  

        * `plCndUniform(const plVariable &variable, const plVariable &min, const
            plVariable &max)`  

            Constructs a contitional uniform distribution on *variable* variables.  

            *min* and *max* are known variables.  

        * `plCndUniform(const plVariable &variable, const plVariablesConjunction &right,
            const plExternalFunction &fmin, const plExternalFunction &fmax)`  

            Constructs a contitional uniform distribution on the *variable* variables
            with *max* = *fmax(right)* and *min* = *fmin(right)*.  

            An example of how to create and use plExternalFunction as conditional
            distribution parameters can be found in 'using external functions example'.  

        * `plCndUniform(const plVariable &variable, const plVariablesConjunction &right,
            const plExternalFunction &f_min_max)`  

            Constructs a contitional uniform distribution on the *variable* variables
            with **[min,max] = *f_min_max(right)*.  

            An example of how to create and use plExternalFunction as conditional
            distribution parameters can be found in 'using external functions example'.  

        * `plCndUniform(const plCndDistribution &)`  

            Promote from a plCndDistribution.  

            If the object being copied is actually of the wrong type, an exception is
            raised.  

        """
        this = _probt_python3.new_plCndUniform(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def min_is_constant(self) -> "bool":
        """
        min_is_constant(self) -> bool


        `min_is_constant() const -> bool`  

        Returns true if the min parameter is a constant.  

        """
        return _probt_python3.plCndUniform_min_is_constant(self)


    def get_min_constant(self) -> "plFloat":
        """
        get_min_constant(self) -> plFloat


        `get_min_constant() const -> plFloat`  

        Returns the value of the min parameter.  

        Do not call this method if min_is_constant() returned false.  

        """
        return _probt_python3.plCndUniform_get_min_constant(self)


    def min_is_variable(self) -> "bool":
        """
        min_is_variable(self) -> bool


        `min_is_variable() const -> bool`  

        Returns true if the min parameter is a variable.  

        """
        return _probt_python3.plCndUniform_min_is_variable(self)


    def get_min_variable(self) -> "plVariable":
        """
        get_min_variable(self) -> plVariable


        `get_min_variable() const -> plVariable`  

        Returns the min variable.  

        Do not call this method if min_is_variable() returned false.  

        """
        return _probt_python3.plCndUniform_get_min_variable(self)


    def min_is_function(self) -> "bool":
        """
        min_is_function(self) -> bool


        `min_is_function() const -> bool`  

        Returns true if the min parameter is a function.  

        """
        return _probt_python3.plCndUniform_min_is_function(self)


    def get_min_function(self) -> "plExternalFunction":
        """
        get_min_function(self) -> plExternalFunction


        `get_min_function() const -> plExternalFunction`  

        Returns the min function.  

        Do not call this method if min_is_function() returned false.  

        """
        return _probt_python3.plCndUniform_get_min_function(self)


    def max_is_constant(self) -> "bool":
        """
        max_is_constant(self) -> bool


        `max_is_constant() const -> bool`  

        Returns true if the max parameter is a constant.  

        """
        return _probt_python3.plCndUniform_max_is_constant(self)


    def get_max_constant(self) -> "plFloat":
        """
        get_max_constant(self) -> plFloat


        `get_max_constant() const -> plFloat`  

        Returns the value of the max parameter.  

        Do not call this method if max_is_constant() returned false.  

        """
        return _probt_python3.plCndUniform_get_max_constant(self)


    def max_is_variable(self) -> "bool":
        """
        max_is_variable(self) -> bool


        `max_is_variable() const -> bool`  

        Returns true if the max parameter is a variable.  

        """
        return _probt_python3.plCndUniform_max_is_variable(self)


    def get_max_variable(self) -> "plVariable":
        """
        get_max_variable(self) -> plVariable


        `get_max_variable() const -> plVariable`  

        Returns the max variable.  

        Do not call this method if max_is_variable() returned false.  

        """
        return _probt_python3.plCndUniform_get_max_variable(self)


    def max_is_function(self) -> "bool":
        """
        max_is_function(self) -> bool


        `max_is_function() const -> bool`  

        Returns true if the max parameter is a function.  

        """
        return _probt_python3.plCndUniform_max_is_function(self)


    def get_max_function(self) -> "plExternalFunction":
        """
        get_max_function(self) -> plExternalFunction


        `get_max_function() const -> plExternalFunction`  

        Returns the max function.  

        Do not call this method if max_is_function() returned false.  

        """
        return _probt_python3.plCndUniform_get_max_function(self)


    def min_and_max_are_one_function(self) -> "bool":
        """
        min_and_max_are_one_function(self) -> bool


        `min_and_max_are_one_function() const -> bool`  

        Returns true if the min and max parameters were given as a single function.  

        """
        return _probt_python3.plCndUniform_min_and_max_are_one_function(self)


    def get_min_max_function(self) -> "plExternalFunction":
        """
        get_min_max_function(self) -> plExternalFunction


        `get_min_max_function() const -> plExternalFunction`  

        Returns the parameters function.  

        Do not call this method if min_and_max_are_one_function() returned false.  

        """
        return _probt_python3.plCndUniform_get_min_max_function(self)


    def is_base_class(self) -> "bool":
        """
        is_base_class(self) -> bool


        `is_base_class() const -> bool`  

        """
        return _probt_python3.plCndUniform_is_base_class(self)


    def __getstate__(self) -> "std::string":
        """__getstate__(self) -> std::string"""
        return _probt_python3.plCndUniform___getstate__(self)


    def __setstate_internal(self, sState: 'std::string const &') -> "void":
        """__setstate_internal(self, sState)"""
        return _probt_python3.plCndUniform___setstate_internal(self, sState)


    def __setstate__(self, sState):
        self.__init__()
        self.__setstate_internal(sState)

plCndUniform_swigregister = _probt_python3.plCndUniform_swigregister
plCndUniform_swigregister(plCndUniform)

class plCndUnknown(plCndDistribution):
    """

    `plCndUnknown()`  
    `plCndUnknown(const plVariablesConjunction &left, const plVariablesConjunction
        &right)`  
    `plCndUnknown(const plCndDistribution &)`  

    This class allows defining an unknown distribution on a set of variables *left*
    knowing an other set of variables *right*.  

    Constructors
    ------------
    * `plCndUnknown()`  

        Empty constructor.  

    * `plCndUnknown(const plVariablesConjunction &left, const plVariablesConjunction
        &right)`  

        Construct an unknown conditional distribution.  

        Unknown conditional distribution are used for to provide the user with a
        formal way of writing correct decomposition, but are not intended to produce
        any numerical results (i.e the inferred expressions do not contain the P(v)
        term). All methods applied to this distribution will result into an error.
        Excepted for the method instantiate which will return an Unknown
        distribution. Unknown distribution are used to build descriptions (joint
        distributions). Inference (using "ask" method) using this joint
        distribution should always contain all the set of "left" variables into
        their known variables.  

        Parameters:  
        * `left` :  
            is the set of variables on which the distribution applies.  
        * `right` :  
            is the set of variables which conditionalize the distribution.  

    * `plCndUnknown(const plCndDistribution &)`  

        Promote from a plCndDistribution.  

        If the object being copied is actually of the wrong type, an exception is
        raised.  

    C++ includes: plCndUnknown.h

    """

    __swig_setmethods__ = {}
    for _s in [plCndDistribution]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plCndUnknown, name, value)
    __swig_getmethods__ = {}
    for _s in [plCndDistribution]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plCndUnknown, name)
    __repr__ = _swig_repr
    __swig_destroy__ = _probt_python3.delete_plCndUnknown
    __del__ = lambda self: None

    def __init__(self, *args):
        """
        __init__(self) -> plCndUnknown
        __init__(self, left, right) -> plCndUnknown
        __init__(self, arg2) -> plCndUnknown


        `plCndUnknown()`  
        `plCndUnknown(const plVariablesConjunction &left, const plVariablesConjunction
            &right)`  
        `plCndUnknown(const plCndDistribution &)`  

        Overloaded function
        -------------------
        * `plCndUnknown()`  

            Empty constructor.  

        * `plCndUnknown(const plVariablesConjunction &left, const plVariablesConjunction
            &right)`  

            Construct an unknown conditional distribution.  

            Unknown conditional distribution are used for to provide the user with a
            formal way of writing correct decomposition, but are not intended to produce
            any numerical results (i.e the inferred expressions do not contain the P(v)
            term). All methods applied to this distribution will result into an error.
            Excepted for the method instantiate which will return an Unknown
            distribution. Unknown distribution are used to build descriptions (joint
            distributions). Inference (using "ask" method) using this joint
            distribution should always contain all the set of "left" variables into
            their known variables.  

            Parameters:  
            * `left` :  
                is the set of variables on which the distribution applies.  
            * `right` :  
                is the set of variables which conditionalize the distribution.  

        * `plCndUnknown(const plCndDistribution &)`  

            Promote from a plCndDistribution.  

            If the object being copied is actually of the wrong type, an exception is
            raised.  

        """
        this = _probt_python3.new_plCndUnknown(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def __getstate__(self) -> "std::string":
        """__getstate__(self) -> std::string"""
        return _probt_python3.plCndUnknown___getstate__(self)


    def __setstate_internal(self, sState: 'std::string const &') -> "void":
        """__setstate_internal(self, sState)"""
        return _probt_python3.plCndUnknown___setstate_internal(self, sState)


    def __setstate__(self, sState):
        self.__init__()
        self.__setstate_internal(sState)

plCndUnknown_swigregister = _probt_python3.plCndUnknown_swigregister
plCndUnknown_swigregister(plCndUnknown)

class plCndDeterministic(plCndDistribution):
    """

    `plCndDeterministic(const plVariablesConjunction &left_variables, const
        plVariablesConjunction &right_variables, const plExternalFunction &func)`  
    `plCndDeterministic(const plExternalFunction &func)`  
    `plCndDeterministic()`  
    `plCndDeterministic(const plCndDistribution &)`  

    The *plCndDeterministic* class implements deterministic dependencies using user-
    provided functions.  

    Constructors
    ------------
    * `plCndDeterministic(const plVariablesConjunction &left_variables, const
        plVariablesConjunction &right_variables, const plExternalFunction &func)`  

        Creates a deterministic (Dirac) conditional distribution.  

        The parameter *func* is a function provided by the user where
        *left_variables* = *func(right_variable)*: \[ P(left\_variables) =
        \left\{ \begin{array}{ll} p & if~~ left\_variables =
        func(right\_variable) \\ 0 & otherwise \end{array} \right. \] where $
        p = 1$ for discrete variables and $ p = \infty $ for continuous ones.  

        In the following, we will present 3 ways for defining a plCndDeterministic
        stating that the "C" variable is the sum of the "A" and "B" variables.
        It assumes the folloiwng variable definitions:  

            const plVariable A("A", plIntegerType(0, 10) );
            const plVariable B("B", plIntegerType(0, 10) );  
            const plVariable C("C", plIntegerType(0, 20) );  

        1) Using a non-member function:  

            // Non member function
            void sum(plValues &C_val, const plValues &A_B_vals)
            {
                C_val[C] = A_B_vals[A] + A_B_vals[B];
            }

            plExternalFunction F_C__AB(C, A^B, &sum);
            plCndDeterministic P_C__AB(C, A^B, F_C__AB);  

        2) Using a member function:  

            struct ABSum
            {
                void sum_method(plValues &C_val, const plValues &A_B_vals) const
                {
                    C_val[C] = A_B_vals[A] + A_B_vals[B];
                }

            };

            ABSum *sum_obj_ptr = new ABSum;
            plExternalFunction F_C__AB(C, A^B, sum_obj_ptr, &ABSum::sum_method);
            plCndDeterministic P_C__AB(C, A^B, F_C__AB);  

        3) Using a C source code function:  

            const std::string sum_code = "C = A + B";
            plExternalFunctionFromC  F_C__AB = createExternalFunctionFromC(C, A^B,
        sum_code, "sum_func");
            plCndDeterministic P_C__AB(C, A^B, F_C__AB);  

        ATTENTION: for performance reasons, using this constructor requires that the
        passed (left and right) variables have the same order as the function's
        (left and right) variables. You can also use the constructor
        plCndDeterministic(const plExternalFunction& func ) below.  

    * `plCndDeterministic(const plExternalFunction &func)`  

        Same as the constructr above however the left and right variables are
        assumed to be the same as the ones provided by the passed function.  

    * `plCndDeterministic()`  

        Default constructor.  

    * `plCndDeterministic(const plCndDistribution &)`  

        Promote from a plCndDistribution.  

        If the object being copied is actually of the wrong type, an exception is
        raised.  

    C++ includes: plCndDeterministic.h

    """

    __swig_setmethods__ = {}
    for _s in [plCndDistribution]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plCndDeterministic, name, value)
    __swig_getmethods__ = {}
    for _s in [plCndDistribution]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plCndDeterministic, name)
    __repr__ = _swig_repr
    __swig_destroy__ = _probt_python3.delete_plCndDeterministic
    __del__ = lambda self: None

    def __init__(self, *args):
        """
        __init__(self, left_variables, right_variables, func) -> plCndDeterministic
        __init__(self, func) -> plCndDeterministic
        __init__(self) -> plCndDeterministic
        __init__(self, arg2) -> plCndDeterministic


        `plCndDeterministic(const plVariablesConjunction &left_variables, const
            plVariablesConjunction &right_variables, const plExternalFunction &func)`  
        `plCndDeterministic(const plExternalFunction &func)`  
        `plCndDeterministic()`  
        `plCndDeterministic(const plCndDistribution &)`  

        Overloaded function
        -------------------
        * `plCndDeterministic(const plVariablesConjunction &left_variables, const
            plVariablesConjunction &right_variables, const plExternalFunction &func)`  

            Creates a deterministic (Dirac) conditional distribution.  

            The parameter *func* is a function provided by the user where
            *left_variables* = *func(right_variable)*: \[ P(left\_variables) =
            \left\{ \begin{array}{ll} p & if~~ left\_variables =
            func(right\_variable) \\ 0 & otherwise \end{array} \right. \] where $
            p = 1$ for discrete variables and $ p = \infty $ for continuous ones.  

            In the following, we will present 3 ways for defining a plCndDeterministic
            stating that the "C" variable is the sum of the "A" and "B" variables.
            It assumes the folloiwng variable definitions:  

                const plVariable A("A", plIntegerType(0, 10) );
                const plVariable B("B", plIntegerType(0, 10) );  
                const plVariable C("C", plIntegerType(0, 20) );  

            1) Using a non-member function:  

                // Non member function
                void sum(plValues &C_val, const plValues &A_B_vals)
                {
                    C_val[C] = A_B_vals[A] + A_B_vals[B];
                }

                plExternalFunction F_C__AB(C, A^B, &sum);
                plCndDeterministic P_C__AB(C, A^B, F_C__AB);  

            2) Using a member function:  

                struct ABSum
                {
                    void sum_method(plValues &C_val, const plValues &A_B_vals) const
                    {
                        C_val[C] = A_B_vals[A] + A_B_vals[B];
                    }

                };

                ABSum *sum_obj_ptr = new ABSum;
                plExternalFunction F_C__AB(C, A^B, sum_obj_ptr, &ABSum::sum_method);
                plCndDeterministic P_C__AB(C, A^B, F_C__AB);  

            3) Using a C source code function:  

                const std::string sum_code = "C = A + B";
                plExternalFunctionFromC  F_C__AB = createExternalFunctionFromC(C, A^B,
            sum_code, "sum_func");
                plCndDeterministic P_C__AB(C, A^B, F_C__AB);  

            ATTENTION: for performance reasons, using this constructor requires that the
            passed (left and right) variables have the same order as the function's
            (left and right) variables. You can also use the constructor
            plCndDeterministic(const plExternalFunction& func ) below.  

        * `plCndDeterministic(const plExternalFunction &func)`  

            Same as the constructr above however the left and right variables are
            assumed to be the same as the ones provided by the passed function.  

        * `plCndDeterministic()`  

            Default constructor.  

        * `plCndDeterministic(const plCndDistribution &)`  

            Promote from a plCndDistribution.  

            If the object being copied is actually of the wrong type, an exception is
            raised.  

        """
        this = _probt_python3.new_plCndDeterministic(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def get_function(self) -> "plExternalFunction":
        """
        get_function(self) -> plExternalFunction


        `get_function() const -> plExternalFunction`  

        Get the external function used to construct this object.  

        """
        return _probt_python3.plCndDeterministic_get_function(self)


    def is_base_class(self) -> "bool":
        """
        is_base_class(self) -> bool


        `is_base_class() const -> bool`  

        """
        return _probt_python3.plCndDeterministic_is_base_class(self)


    def __getstate__(self) -> "std::string":
        """__getstate__(self) -> std::string"""
        return _probt_python3.plCndDeterministic___getstate__(self)


    def __setstate_internal(self, sState: 'std::string const &') -> "void":
        """__setstate_internal(self, sState)"""
        return _probt_python3.plCndDeterministic___setstate_internal(self, sState)


    def __setstate__(self, sState):
        self.__init__()
        self.__setstate_internal(sState)

plCndDeterministic_swigregister = _probt_python3.plCndDeterministic_swigregister
plCndDeterministic_swigregister(plCndDeterministic)

class plIneqConstraint(plCndDistribution):
    """

    `plIneqConstraint()`  
    `plIneqConstraint(const plVariable &constraint_variable, const
        plExternalFunction &constraint_function, unsigned int constraint_size)`  
    `plIneqConstraint(const plCndDistribution &)`  

    The *plIneqConstraint* class defines a conditional distribution representing an
    *constraint_size-dimensional* inequality constraint on the Binary Variable
    *constraint_variable*.  

    This inequality constraint is defined using the *constraint_size-dimensional*
    user's external function *constraint_function*.  

    This conditional distribution is defined as follows:  

    P( [constraint_variable = 1] | [X = x0] ) =  

    *   1 if constraint_function(x0)[i] <= 0, for i = 0...constraint_size  
    *   0 otherwise  

    Constructors
    ------------
    * `plIneqConstraint()`  

        Default constructor, needed by the serialization code.  

    * `plIneqConstraint(const plVariable &constraint_variable, const
        plExternalFunction &constraint_function, unsigned int constraint_size)`  

        Defines an inequality constraint on the binary variable
        *constraint_variable* using the *constraint_size-dimensional* user's
        external function *constraint_function*.  

    * `plIneqConstraint(const plCndDistribution &)`  

        Promote from a plCndDistribution.  

        If the object being copied is actually of the wrong type, an exception is
        raised.  

    C++ includes: plIneqConstraint.h

    """

    __swig_setmethods__ = {}
    for _s in [plCndDistribution]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plIneqConstraint, name, value)
    __swig_getmethods__ = {}
    for _s in [plCndDistribution]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plIneqConstraint, name)
    __repr__ = _swig_repr
    __swig_destroy__ = _probt_python3.delete_plIneqConstraint
    __del__ = lambda self: None

    def __init__(self, *args):
        """
        __init__(self) -> plIneqConstraint
        __init__(self, constraint_variable, constraint_function, constraint_size) -> plIneqConstraint
        __init__(self, arg2) -> plIneqConstraint


        `plIneqConstraint()`  
        `plIneqConstraint(const plVariable &constraint_variable, const
            plExternalFunction &constraint_function, unsigned int constraint_size)`  
        `plIneqConstraint(const plCndDistribution &)`  

        Overloaded function
        -------------------
        * `plIneqConstraint()`  

            Default constructor, needed by the serialization code.  

        * `plIneqConstraint(const plVariable &constraint_variable, const
            plExternalFunction &constraint_function, unsigned int constraint_size)`  

            Defines an inequality constraint on the binary variable
            *constraint_variable* using the *constraint_size-dimensional* user's
            external function *constraint_function*.  

        * `plIneqConstraint(const plCndDistribution &)`  

            Promote from a plCndDistribution.  

            If the object being copied is actually of the wrong type, an exception is
            raised.  

        """
        this = _probt_python3.new_plIneqConstraint(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def get_function(self) -> "plExternalFunction":
        """
        get_function(self) -> plExternalFunction


        `get_function() const -> plExternalFunction`  

        Get the external function used to construct this object.  

        """
        return _probt_python3.plIneqConstraint_get_function(self)


    def get_constraint_size(self) -> "unsigned int":
        """
        get_constraint_size(self) -> unsigned int


        `get_constraint_size() const -> unsigned int`  

        Get the external function dimension.  

        """
        return _probt_python3.plIneqConstraint_get_constraint_size(self)


    def is_base_class(self) -> "bool":
        """
        is_base_class(self) -> bool


        `is_base_class() const -> bool`  

        """
        return _probt_python3.plIneqConstraint_is_base_class(self)


    def __getstate__(self) -> "std::string":
        """__getstate__(self) -> std::string"""
        return _probt_python3.plIneqConstraint___getstate__(self)


    def __setstate_internal(self, sState: 'std::string const &') -> "void":
        """__setstate_internal(self, sState)"""
        return _probt_python3.plIneqConstraint___setstate_internal(self, sState)


    def __setstate__(self, sState):
        self.__init__()
        self.__setstate_internal(sState)

plIneqConstraint_swigregister = _probt_python3.plIneqConstraint_swigregister
plIneqConstraint_swigregister(plIneqConstraint)

class plLinearRegression(plCndDistribution):
    """

    `plLinearRegression()`  
    `plLinearRegression(const plVariable &left_var, const plVariablesConjunction
        &right_variables, const std::vector< plFloat > &beta, plFloat
        regression_std_deviation)`  
    `plLinearRegression(const plCndDistribution &)`  

    This implements the computation part of the linear regression model (aka Linear
    Gaussian).  

    Given a continuous variable $Y$, and a set of $ n $ quantitative attribute
    variables $X_1, \cdots,X_n $, the probability density function over $Y$ is
    defined as: \[ p(Y~|~X_1=x_1,\cdots,X_n=x_n) = Normal(y, mean(x_1, ...,x_n),
    \sigma),\] in which \[ mean(x_1, \cdots,x_n) = \sum_{i=1}^n \beta_i
    \times x_i + \beta_{n+1}.\]  

    The parameter vector $ \beta $ can be learnt using plLearnLinearRegression.  

    See also: plLearnLinearRegression  

    Constructors
    ------------
    * `plLinearRegression()`  

        Default constructor.  

    * `plLinearRegression(const plVariable &left_var, const plVariablesConjunction
        &right_variables, const std::vector< plFloat > &beta, plFloat
        regression_std_deviation)`  

        Constructs a *plLinearRegression* distribution.  

        Parameters:  
        * `left_var` :  
            The regression quantitative output variable  
        * `right_variables` :  
            The right (parent) quantitative variables of which the regression is
            computed  
        * `beta` :  
            The beta parameter vector  
        * `regression_std_deviation` :  
            the standart deviation to be used around the regression value.  

    * `plLinearRegression(const plCndDistribution &)`  

        Promote from a plCndDistribution.  

        If the object being copied is actually of the wrong type, an exception is
        raised.  

    C++ includes: plLinearRegression.h

    """

    __swig_setmethods__ = {}
    for _s in [plCndDistribution]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plLinearRegression, name, value)
    __swig_getmethods__ = {}
    for _s in [plCndDistribution]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plLinearRegression, name)
    __repr__ = _swig_repr
    __swig_destroy__ = _probt_python3.delete_plLinearRegression
    __del__ = lambda self: None

    def __init__(self, *args):
        """
        __init__(self) -> plLinearRegression
        __init__(self, left_var, right_variables, beta, regression_std_deviation) -> plLinearRegression
        __init__(self, arg2) -> plLinearRegression


        `plLinearRegression()`  
        `plLinearRegression(const plVariable &left_var, const plVariablesConjunction
            &right_variables, const std::vector< plFloat > &beta, plFloat
            regression_std_deviation)`  
        `plLinearRegression(const plCndDistribution &)`  

        Overloaded function
        -------------------
        * `plLinearRegression()`  

            Default constructor.  

        * `plLinearRegression(const plVariable &left_var, const plVariablesConjunction
            &right_variables, const std::vector< plFloat > &beta, plFloat
            regression_std_deviation)`  

            Constructs a *plLinearRegression* distribution.  

            Parameters:  
            * `left_var` :  
                The regression quantitative output variable  
            * `right_variables` :  
                The right (parent) quantitative variables of which the regression is
                computed  
            * `beta` :  
                The beta parameter vector  
            * `regression_std_deviation` :  
                the standart deviation to be used around the regression value.  

        * `plLinearRegression(const plCndDistribution &)`  

            Promote from a plCndDistribution.  

            If the object being copied is actually of the wrong type, an exception is
            raised.  

        """
        this = _probt_python3.new_plLinearRegression(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def get_beta(self) -> "std::vector< plFloat,std::allocator< plFloat > > const &":
        """
        get_beta(self) -> DoubleVector


        `get_beta() const -> const std::vector< plFloat > &`  

        Get the beta parameter vector.  

        """
        return _probt_python3.plLinearRegression_get_beta(self)


    def get_regression_std_deviation(self) -> "plFloat":
        """
        get_regression_std_deviation(self) -> plFloat


        `get_regression_std_deviation() const -> plFloat`  

        Get the regression residual strandard deviation.  

        """
        return _probt_python3.plLinearRegression_get_regression_std_deviation(self)


    def is_base_class(self) -> "bool":
        """
        is_base_class(self) -> bool


        `is_base_class() const -> bool`  

        """
        return _probt_python3.plLinearRegression_is_base_class(self)


    def __getstate__(self) -> "std::string":
        """__getstate__(self) -> std::string"""
        return _probt_python3.plLinearRegression___getstate__(self)


    def __setstate_internal(self, sState: 'std::string const &') -> "void":
        """__setstate_internal(self, sState)"""
        return _probt_python3.plLinearRegression___setstate_internal(self, sState)


    def __setstate__(self, sState):
        self.__init__()
        self.__setstate_internal(sState)

plLinearRegression_swigregister = _probt_python3.plLinearRegression_swigregister
plLinearRegression_swigregister(plLinearRegression)

class plNoisyOR(plCndDistribution):
    """

    `plNoisyOR()`  
    `plNoisyOR(const plVariable &left_binary_var, const plVariablesConjunction
        &right_variables, const std::vector< std::vector< plProbValue > >
        &table_B_0_probabilities)`  
    `plNoisyOR(const plCndDistribution &)`  

    This class implements the computation part of the NoisyOR discrimination model.  

    Given a binary class variable $C$, and a set of $ n $ discrete attribute
    variables $A_1, \cdots,A_n $, the idea of the NoisyOR model is to assume that
    the value of the binary class variable $C$ is the deterministic result of the OR
    operator on another set of $ n $ intermediate (latent) binary variables $B_1,
    \cdots,B_n $ (see the corresponding initial and transformed graphs at the end
    of this section).  

    This leads to the formula: \[ P(C=0~|~A_1=a_1,\cdots,A_n=a_n) =
    \prod_{i=1}^{n} P(B_i=0~|~A_i=a_i). \]  

    The parameter matrix $ P(B_i = 0~|~A_i = a_i^j)$ for $ i = 1,\cdots,n; j =
    1,\cdots,card(A_i) $ can be computed using an EM algorithm (see
    plLearnNoisyOR).  

                     C

                  ^    ^
                 /      \
                /        \
               /          \
              /            \
             /              \

            A1                An

              INITIAL MODEL



                    |
                    |
                    |
                    |
                    |
                    V



                    C

                  ^    ^
                 /      \
                /        \
               /          \
              /            \
             /              \

            B1  .........    Bn

            ^                 ^
            |                 |
            |   .........     |
            |                 |
            |                 |
            |                 |

            A1                An

              TRANSFORMED MODEL  

    See also: plLearnNoisyOR  

    See also: plSoftmax  

    Constructors
    ------------
    * `plNoisyOR()`  

        Default constructor.  

    * `plNoisyOR(const plVariable &left_binary_var, const plVariablesConjunction
        &right_variables, const std::vector< std::vector< plProbValue > >
        &table_B_0_probabilities)`  

        Constructs a *plNoisyOR* distribution.  

        Parameters:  
        * `left_binary_var` :  
            The binary class variable  
        * `right_variables` :  
            The $ n $ attribute variables $ A_i, i=0..n-1$  
        * `table_B_0_probabilities` :  
            The parameter matrix $ P(B_i = 0~|~A_i = a_i^j)$ for $ i = 1,\cdots,n;
            j = 1,\cdots,card(A_i) $  

    * `plNoisyOR(const plCndDistribution &)`  

        Promote from a plCndDistribution.  

        If the object being copied is actually of the wrong type, an exception is
        raised.  

    C++ includes: plNoisyOR.h

    """

    __swig_setmethods__ = {}
    for _s in [plCndDistribution]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plNoisyOR, name, value)
    __swig_getmethods__ = {}
    for _s in [plCndDistribution]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plNoisyOR, name)
    __repr__ = _swig_repr
    __swig_destroy__ = _probt_python3.delete_plNoisyOR
    __del__ = lambda self: None

    def __init__(self, *args):
        """
        __init__(self) -> plNoisyOR
        __init__(self, left_binary_var, right_variables, table_B_0_probabilities) -> plNoisyOR
        __init__(self, arg2) -> plNoisyOR


        `plNoisyOR()`  
        `plNoisyOR(const plVariable &left_binary_var, const plVariablesConjunction
            &right_variables, const std::vector< std::vector< plProbValue > >
            &table_B_0_probabilities)`  
        `plNoisyOR(const plCndDistribution &)`  

        Overloaded function
        -------------------
        * `plNoisyOR()`  

            Default constructor.  

        * `plNoisyOR(const plVariable &left_binary_var, const plVariablesConjunction
            &right_variables, const std::vector< std::vector< plProbValue > >
            &table_B_0_probabilities)`  

            Constructs a *plNoisyOR* distribution.  

            Parameters:  
            * `left_binary_var` :  
                The binary class variable  
            * `right_variables` :  
                The $ n $ attribute variables $ A_i, i=0..n-1$  
            * `table_B_0_probabilities` :  
                The parameter matrix $ P(B_i = 0~|~A_i = a_i^j)$ for $ i = 1,\cdots,n;
                j = 1,\cdots,card(A_i) $  

        * `plNoisyOR(const plCndDistribution &)`  

            Promote from a plCndDistribution.  

            If the object being copied is actually of the wrong type, an exception is
            raised.  

        """
        this = _probt_python3.new_plNoisyOR(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def get_parameters(self) -> "std::vector< std::vector< plProbValue,std::allocator< plProbValue > >,std::allocator< std::vector< plProbValue,std::allocator< plProbValue > > > > const &":
        """
        get_parameters(self) -> DoubleVectorVector


        `get_parameters() const -> const std::vector< std::vector< plProbValue > > &`  

        Get the parameter matrix $ P(B_i = 0~|~A_i = a_i^j)$ for $ i = 1,\cdots,n; j =
        1,\cdots,card(A_i) $.  

        """
        return _probt_python3.plNoisyOR_get_parameters(self)


    def is_base_class(self) -> "bool":
        """
        is_base_class(self) -> bool


        `is_base_class() const -> bool`  

        """
        return _probt_python3.plNoisyOR_is_base_class(self)


    def __getstate__(self) -> "std::string":
        """__getstate__(self) -> std::string"""
        return _probt_python3.plNoisyOR___getstate__(self)


    def __setstate_internal(self, sState: 'std::string const &') -> "void":
        """__setstate_internal(self, sState)"""
        return _probt_python3.plNoisyOR___setstate_internal(self, sState)


    def __setstate__(self, sState):
        self.__init__()
        self.__setstate_internal(sState)

plNoisyOR_swigregister = _probt_python3.plNoisyOR_swigregister
plNoisyOR_swigregister(plNoisyOR)

class plSoftmax(plCndDistribution):
    """

    `plSoftmax()`  
    `plSoftmax(const plVariable &left_var, const plVariablesConjunction
        &right_variables, const std::vector< std::vector< plFloat > > &beta)`  
    `plSoftmax(const plCndDistribution &)`  

    This implements the computation part of the Softmax (aka multinomial logistic or
    multinomial logit) regression.  

    It's a generalization of the binary Sigmoid regression for multiclass cases.  

    Given a discrete class variable $C$ with $m$ modalities, and a set of $ n $
    quantitative attribute variables $A_1, \cdots,A_n $, the Softmax regression
    assumes that \[ \log \frac {P(C=k~|~A_1=a_1,\cdots,A_n=a_n)}
    {P(C>k~|~A_1=a_1,\cdots,A_n=a_n)} = \sum_{i=1}^n \beta_i^k \times a_i +
    \beta_{n+1}^k, k=0,\cdots, m-2,\] and \[P(C=m-1~|~A_1=a_1,\cdots,A_n=a_n) =
    1 - \sum_{k=0}^{m-2} P(C=k~|~A_1=a_1,\cdots,A_n=a_n). \]  

    This leads to the recursive formula: \[ P(C=0~|~A_1=a_1,\cdots,A_n=a_n) =
    P_0(A) = Sigmoid( z\left(A, \beta^0 ) \right),\] \[
    P(C=k~|~A_1=a_1,\cdots,A_n=a_n) = P_k(A) = \left[ 1 - \sum_{i=0}^{k-1} P_i(A)
    \right] \times Sigmoid( z\left(A, \beta^k ) \right), k=0,\cdots, m-2,\]
    \[ P(C=m-1~|~A_1=a_1,\cdots,A_n=a_n) = P_{m-1}(A) = 1 - \sum_{i=0}^{m-2}
    P_i(A), \] in which \[ z(A, \beta^k) = \sum_{i=1}^n \beta_i^k \times a_i +
    \beta_{n+1}^k, \] \[ Sigmoid(t) = \frac {1} {1+\exp(-t)}. \]  

    The parameter matrix $\beta$ can be learnt using plLearnSoftmax.  

    See also: plLearnSoftmax  

    See also: plLearnNoisyOR  

    See also: plNoisyOR  

    Constructors
    ------------
    * `plSoftmax()`  

        Default constructor.  

    * `plSoftmax(const plVariable &left_var, const plVariablesConjunction
        &right_variables, const std::vector< std::vector< plFloat > > &beta)`  

        Constructs a *plSoftmax* distribution.  

        Parameters:  
        * `left_var` :  
            The class variable (n modalities)  
        * `right_variables` :  
            The m quantitative attribute parent variables  
        * `beta` :  
            The beta parameter vector. It should be of size (n-1) x (m+1)  

    * `plSoftmax(const plCndDistribution &)`  

        Promote from a plCndDistribution.  

        If the object being copied is actually of the wrong type, an exception is
        raised.  

    C++ includes: plSoftmax.h

    """

    __swig_setmethods__ = {}
    for _s in [plCndDistribution]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plSoftmax, name, value)
    __swig_getmethods__ = {}
    for _s in [plCndDistribution]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plSoftmax, name)
    __repr__ = _swig_repr
    __swig_destroy__ = _probt_python3.delete_plSoftmax
    __del__ = lambda self: None

    def __init__(self, *args):
        """
        __init__(self) -> plSoftmax
        __init__(self, left_var, right_variables, beta) -> plSoftmax
        __init__(self, arg2) -> plSoftmax


        `plSoftmax()`  
        `plSoftmax(const plVariable &left_var, const plVariablesConjunction
            &right_variables, const std::vector< std::vector< plFloat > > &beta)`  
        `plSoftmax(const plCndDistribution &)`  

        Overloaded function
        -------------------
        * `plSoftmax()`  

            Default constructor.  

        * `plSoftmax(const plVariable &left_var, const plVariablesConjunction
            &right_variables, const std::vector< std::vector< plFloat > > &beta)`  

            Constructs a *plSoftmax* distribution.  

            Parameters:  
            * `left_var` :  
                The class variable (n modalities)  
            * `right_variables` :  
                The m quantitative attribute parent variables  
            * `beta` :  
                The beta parameter vector. It should be of size (n-1) x (m+1)  

        * `plSoftmax(const plCndDistribution &)`  

            Promote from a plCndDistribution.  

            If the object being copied is actually of the wrong type, an exception is
            raised.  

        """
        this = _probt_python3.new_plSoftmax(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def get_beta(self) -> "std::vector< std::vector< plFloat,std::allocator< plFloat > >,std::allocator< std::vector< plFloat,std::allocator< plFloat > > > > const &":
        """
        get_beta(self) -> DoubleVectorVector


        `get_beta() const -> const std::vector< std::vector< plFloat > > &`  

        Get the beta parameter vector.  

        """
        return _probt_python3.plSoftmax_get_beta(self)


    def is_base_class(self) -> "bool":
        """
        is_base_class(self) -> bool


        `is_base_class() const -> bool`  

        """
        return _probt_python3.plSoftmax_is_base_class(self)


    def __getstate__(self) -> "std::string":
        """__getstate__(self) -> std::string"""
        return _probt_python3.plSoftmax___getstate__(self)


    def __setstate_internal(self, sState: 'std::string const &') -> "void":
        """__setstate_internal(self, sState)"""
        return _probt_python3.plSoftmax___setstate_internal(self, sState)


    def __setstate__(self, sState):
        self.__init__()
        self.__setstate_internal(sState)

plSoftmax_swigregister = _probt_python3.plSoftmax_swigregister
plSoftmax_swigregister(plSoftmax)

class plDistributionTable(plCndDistribution):
    """

    `plDistributionTable()`  
    `plDistributionTable(const plVariablesConjunction &left, const
        plVariablesConjunction &right, bool force_use_map=false)`  
    `plDistributionTable(const plVariablesConjunction &left, const
        plVariablesConjunction &right, const plVariablesConjunction &right_index,
        bool force_use_map=false)`  
    `plDistributionTable(const plVariablesConjunction &left, const
        plVariablesConjunction &right, const plProbValue *table, bool
        already_normalized=false)`  
    `plDistributionTable(const plVariablesConjunction &left, const
        plVariablesConjunction &right, const std::vector< T > &table, bool
        already_normalized=false)`  
    `plDistributionTable(const plVariablesConjunction &left, const
        plVariablesConjunction &right, plProbValue(*f)(const plValues &left_values,
        const plValues &right_values), bool already_normalized=false)`  
    `plDistributionTable(const plVariablesConjunction &left, const
        plVariablesConjunction &right, T *obj, plProbValue(T::*method)(const
        plValues &left_values, const plValues &right_values), bool
        already_normalized=false)`  
    `plDistributionTable(const plCndDistribution &)`  

    A plDistributionTable is a way to define a conditional distribution from a set
    of Computable Objects (Distributions and/or Conditional Distributions) having
    the same left variables than the building blocks.  

    It can be use to switch from one distribution to another according to the value
    of a subset of the right variables. This subset of variables have to be discrete
    or discretized. The set of Computable objects is stored in a table.  

    Constructors
    ------------
    * `plDistributionTable()`  

        Default constructor.  

    * `plDistributionTable(const plVariablesConjunction &left, const
        plVariablesConjunction &right, bool force_use_map=false)`  

        A plDistributionTable indexed by the set of variables *right*.  

        Parameters:  
        * `left` :  
            a set of left variables  
        * `right` :  
            a set of right variables used to select the appropriate distribution  
        * `force_use_map` :  
            if set to true, the internal storage will use a map instead of vector.
            If set to false (the default) the storage will use a vector unless the
            index variables are continuous or too large  

    * `plDistributionTable(const plVariablesConjunction &left, const
        plVariablesConjunction &right, const plVariablesConjunction &right_index,
        bool force_use_map=false)`  

        Construct a plDistributionTable conditional distribution.  

        Parameters:  
        * `left` :  
            a set of left variables  
        * `right` :  
            a set of right variables  
        * `right_index` :  
            a subset of the right variables used to select the appropriate
            distribution  
        * `force_use_map` :  
            if set to true, the internal storage will use a map instead of vector.
            If set to false (the default) the storage will use a vector unless the
            index variables are continuous or too large  

    * `plDistributionTable(const plVariablesConjunction &left, const
        plVariablesConjunction &right, const plProbValue *table, bool
        already_normalized=false)`  

        Construct a plDistributionTable with an array of plProbValues implicitly
        defining a set of plProbTables.  

        Use this constructor only when you need to change the conditional
        distribution later. Consider using the more efficient constructor
        plCndDistribution(const plVariablesConjunction&, const
        plVariablesConjunction&, const plProbValue *, bool) if you do not need to
        change it.  

        ATTENTION: This constructor is reserved for discrete left variables.  

    * `plDistributionTable(const plVariablesConjunction &left, const
        plVariablesConjunction &right, const std::vector< T > &table, bool
        already_normalized=false)`  

    * `plDistributionTable(const plVariablesConjunction &left, const
        plVariablesConjunction &right, plProbValue(*f)(const plValues &left_values,
        const plValues &right_values), bool already_normalized=false)`  

        Constructs a fully tabulated discrete distribution table, with static
        initialisation using a provided function.  

        If you want dynamic use of externally provided data, use a
        plExternalFunction instead.  
        If you're building P(A B | C D), f(left, right) should return the
        probability of P(A=left[A], B=left[B] | C=right[C],D=right[D]).  

    * `plDistributionTable(const plVariablesConjunction &left, const
        plVariablesConjunction &right, T *obj, plProbValue(T::*method)(const
        plValues &left_values, const plValues &right_values), bool
        already_normalized=false)`  

        Constructs a fully tabulated discrete distribution table, with static
        initialisation using a provided method.  

        If you want dynamic use of externally provided data, use a
        plExternalFunction instead.  
        If you're building P(A B | C D), obj->method(left, right) should return the
        probability of P(A=left[A], B=left[B] | C=right[C],D=right[D]).  

    * `plDistributionTable(const plCndDistribution &)`  

        Promote from a plCndDistribution.  

        If the object being copied is actually of the wrong type, an exception is
        raised.  

    C++ includes: plDistributionTable.h

    """

    __swig_setmethods__ = {}
    for _s in [plCndDistribution]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plDistributionTable, name, value)
    __swig_getmethods__ = {}
    for _s in [plCndDistribution]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plDistributionTable, name)
    __repr__ = _swig_repr
    __swig_destroy__ = _probt_python3.delete_plDistributionTable
    __del__ = lambda self: None

    def push(self, *args) -> "void":
        """
        push(self, compObj, values)
        push(self, values, compObj)
        push(self, compObj, value)
        push(self, value, compObj)
        push(self, compObj, value)
        push(self, value, compObj)
        push(self, values, probVector)
        push(self, probVector, values)


        `push(const plComputableObject &compObj, const plValues &values)`  
        `push(const plValues &values, const plComputableObject &compObj)`  
        `push(const plComputableObject &compObj, int value)`  
        `push(int value, const plComputableObject &compObj)`  
        `push(const plComputableObject &compObj, plFloat value)`  
        `push(plFloat value, const plComputableObject &compObj)`  
        `push(const plValues &values, const std::vector< plProbValue > &probVector)`  
        `push(const std::vector< plProbValue > &probVector, const plValues &values)`  

        Overloaded function
        -------------------
        * `push(const plComputableObject &compObj, const plValues &values)`  

            Push is used to incrementaly construct the the condtional distribution.  

            Parameters:  
            * `compObj` :  
                : must have the same left variables than the original Distribution
                Table. If compObj is a Conditional Distribution, then its right
                variables must be a subset of the right variables of the Distribution
                Table.  
            * `values` :  
                : this values is relative to the set of variables used as index.  

        * `push(const plValues &values, const plComputableObject &compObj)`  

        * `push(const plComputableObject &compObj, int value)`  

            Inserts a new distribution *compObj* with an specified integer key value
            *value*.  

        * `push(int value, const plComputableObject &compObj)`  

        * `push(const plComputableObject &compObj, plFloat value)`  

            Inserts a new distribution *compObj* with an specified float key value
            *value*.  

        * `push(plFloat value, const plComputableObject &compObj)`  

        * `push(const plValues &values, const std::vector< plProbValue > &probVector)`  

            Makes a push of a plProbTable implicitly defined by *probVector*.  

        * `push(const std::vector< plProbValue > &probVector, const plValues &values)`  

            Makes a push of a plProbTable implicitly defined by *probVector*.  

        """
        return _probt_python3.plDistributionTable_push(self, *args)


    def push_default(self, compObj: 'plComputableObject') -> "void":
        """
        push_default(self, compObj)


        `push_default(const plComputableObject &compObj)`  

        push_default is used to push a default distribution that will be used for cases
        that have never been pushed in the DistributionTable  

        """
        return _probt_python3.plDistributionTable_push_default(self, compObj)


    def has_default(self) -> "bool":
        """
        has_default(self) -> bool


        `has_default() const -> bool`  

        Return true if a default computable object has been set.  

        """
        return _probt_python3.plDistributionTable_has_default(self)


    def get_default(self) -> "plComputableObject":
        """
        get_default(self) -> plComputableObject


        `get_default() const -> plComputableObject`  

        Get back the default distribution.  

        """
        return _probt_python3.plDistributionTable_get_default(self)


    def find(self, values: 'plValues') -> "bool":
        """
        find(self, values) -> bool


        `find(const plValues &values) const -> bool`  

        Returns *true* if a computable object has been already pushed for the case
        *value*.  

        Returns *false* otherwise  

        """
        return _probt_python3.plDistributionTable_find(self, values)


    def __init__(self, *args):
        """
        __init__(self) -> plDistributionTable
        __init__(self, left, right, force_use_map=False) -> plDistributionTable
        __init__(self, left, right) -> plDistributionTable
        __init__(self, left, right, right_index, force_use_map=False) -> plDistributionTable
        __init__(self, left, right, right_index) -> plDistributionTable
        __init__(self, left, right, table, already_normalized=False) -> plDistributionTable
        __init__(self, left, right, table) -> plDistributionTable
        __init__(self, left, right, f, already_normalized=False) -> plDistributionTable
        __init__(self, left, right, f) -> plDistributionTable
        __init__(self, arg2) -> plDistributionTable


        `plDistributionTable()`  
        `plDistributionTable(const plVariablesConjunction &left, const
            plVariablesConjunction &right, bool force_use_map=false)`  
        `plDistributionTable(const plVariablesConjunction &left, const
            plVariablesConjunction &right, const plVariablesConjunction &right_index,
            bool force_use_map=false)`  
        `plDistributionTable(const plVariablesConjunction &left, const
            plVariablesConjunction &right, const plProbValue *table, bool
            already_normalized=false)`  
        `plDistributionTable(const plVariablesConjunction &left, const
            plVariablesConjunction &right, const std::vector< T > &table, bool
            already_normalized=false)`  
        `plDistributionTable(const plVariablesConjunction &left, const
            plVariablesConjunction &right, plProbValue(*f)(const plValues &left_values,
            const plValues &right_values), bool already_normalized=false)`  
        `plDistributionTable(const plVariablesConjunction &left, const
            plVariablesConjunction &right, T *obj, plProbValue(T::*method)(const
            plValues &left_values, const plValues &right_values), bool
            already_normalized=false)`  
        `plDistributionTable(const plCndDistribution &)`  

        Overloaded function
        -------------------
        * `plDistributionTable()`  

            Default constructor.  

        * `plDistributionTable(const plVariablesConjunction &left, const
            plVariablesConjunction &right, bool force_use_map=false)`  

            A plDistributionTable indexed by the set of variables *right*.  

            Parameters:  
            * `left` :  
                a set of left variables  
            * `right` :  
                a set of right variables used to select the appropriate distribution  
            * `force_use_map` :  
                if set to true, the internal storage will use a map instead of vector.
                If set to false (the default) the storage will use a vector unless the
                index variables are continuous or too large  

        * `plDistributionTable(const plVariablesConjunction &left, const
            plVariablesConjunction &right, const plVariablesConjunction &right_index,
            bool force_use_map=false)`  

            Construct a plDistributionTable conditional distribution.  

            Parameters:  
            * `left` :  
                a set of left variables  
            * `right` :  
                a set of right variables  
            * `right_index` :  
                a subset of the right variables used to select the appropriate
                distribution  
            * `force_use_map` :  
                if set to true, the internal storage will use a map instead of vector.
                If set to false (the default) the storage will use a vector unless the
                index variables are continuous or too large  

        * `plDistributionTable(const plVariablesConjunction &left, const
            plVariablesConjunction &right, const plProbValue *table, bool
            already_normalized=false)`  

            Construct a plDistributionTable with an array of plProbValues implicitly
            defining a set of plProbTables.  

            Use this constructor only when you need to change the conditional
            distribution later. Consider using the more efficient constructor
            plCndDistribution(const plVariablesConjunction&, const
            plVariablesConjunction&, const plProbValue *, bool) if you do not need to
            change it.  

            ATTENTION: This constructor is reserved for discrete left variables.  

        * `plDistributionTable(const plVariablesConjunction &left, const
            plVariablesConjunction &right, const std::vector< T > &table, bool
            already_normalized=false)`  

        * `plDistributionTable(const plVariablesConjunction &left, const
            plVariablesConjunction &right, plProbValue(*f)(const plValues &left_values,
            const plValues &right_values), bool already_normalized=false)`  

            Constructs a fully tabulated discrete distribution table, with static
            initialisation using a provided function.  

            If you want dynamic use of externally provided data, use a
            plExternalFunction instead.  
            If you're building P(A B | C D), f(left, right) should return the
            probability of P(A=left[A], B=left[B] | C=right[C],D=right[D]).  

        * `plDistributionTable(const plVariablesConjunction &left, const
            plVariablesConjunction &right, T *obj, plProbValue(T::*method)(const
            plValues &left_values, const plValues &right_values), bool
            already_normalized=false)`  

            Constructs a fully tabulated discrete distribution table, with static
            initialisation using a provided method.  

            If you want dynamic use of externally provided data, use a
            plExternalFunction instead.  
            If you're building P(A B | C D), obj->method(left, right) should return the
            probability of P(A=left[A], B=left[B] | C=right[C],D=right[D]).  

        * `plDistributionTable(const plCndDistribution &)`  

            Promote from a plCndDistribution.  

            If the object being copied is actually of the wrong type, an exception is
            raised.  

        """
        this = _probt_python3.new_plDistributionTable(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def get_pushed_distribution(self, values: 'plValues') -> "plComputableObject":
        """
        get_pushed_distribution(self, values) -> plComputableObject


        `get_pushed_distribution(const plValues &values) const -> plComputableObject`  

        Get a previously pushed object.  

        """
        return _probt_python3.plDistributionTable_get_pushed_distribution(self, values)


    def get_index_variables(self) -> "plVariablesConjunction":
        """
        get_index_variables(self) -> plVariablesConjunction


        `get_index_variables() const -> plVariablesConjunction`  

        Get the subset of the right variables used as index.  

        """
        return _probt_python3.plDistributionTable_get_index_variables(self)


    def is_base_class(self) -> "bool":
        """
        is_base_class(self) -> bool


        `is_base_class() const -> bool`  

        """
        return _probt_python3.plDistributionTable_is_base_class(self)


    def get_pushed_values(self) -> "std::vector< plValues,std::allocator< plValues > >":
        """
        get_pushed_values(self) -> plValuesVector


        `get_pushed_values() const -> std::vector< plValues >`  

        Return the values previously inserted in the distribution map.  

        If you want to access the distributions corresponding to these values, then use
        instantiate().  

        """
        return _probt_python3.plDistributionTable_get_pushed_values(self)


    def __getstate__(self) -> "std::string":
        """__getstate__(self) -> std::string"""
        return _probt_python3.plDistributionTable___getstate__(self)


    def __setstate_internal(self, sState: 'std::string const &') -> "void":
        """__setstate_internal(self, sState)"""
        return _probt_python3.plDistributionTable___setstate_internal(self, sState)


    def __setstate__(self, sState):
        self.__init__()
        self.__setstate_internal(sState)

plDistributionTable_swigregister = _probt_python3.plDistributionTable_swigregister
plDistributionTable_swigregister(plDistributionTable)


@patch
def plDistributionTable_get_pushed_values(orig, self, *args, **kwargs):
  return dataframe_of_values(orig(self, *args, **kwargs))

class plCndJtDistribution(plCndDistribution):
    """

    `plCndJtDistribution()`  
    `plCndJtDistribution(kplCndJtKernel const &vroot)`  

    Conditional distribution as returned by asking a question to a plJunctionTree.  

    Constructors
    ------------
    * `plCndJtDistribution()`  

        Empty constructor.  

    * `plCndJtDistribution(kplCndJtKernel const &vroot)`  

    C++ includes: plJtDistribution.h

    """

    __swig_setmethods__ = {}
    for _s in [plCndDistribution]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plCndJtDistribution, name, value)
    __swig_getmethods__ = {}
    for _s in [plCndDistribution]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plCndJtDistribution, name)
    __repr__ = _swig_repr

    def __init__(self, *args):
        """
        __init__(self) -> plCndJtDistribution
        __init__(self, vroot) -> plCndJtDistribution


        `plCndJtDistribution()`  
        `plCndJtDistribution(kplCndJtKernel const &vroot)`  

        Overloaded function
        -------------------
        * `plCndJtDistribution()`  

            Empty constructor.  

        * `plCndJtDistribution(kplCndJtKernel const &vroot)`  

        """
        this = _probt_python3.new_plCndJtDistribution(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def specialise(self, added_known: 'plVariablesConjunction') -> "plCndJtDistribution":
        """
        specialise(self, added_known) -> plCndJtDistribution


        `specialise(plVariablesConjunction const &added_known) -> plCndJtDistribution`  

        Returns a specialised version of this distribution.  

        Specialising transforms a summed or non-instantiated variable into an
        instantiated variable.  

        For instance, P(A | D).specialise(B C D) == k * P(A | B C D).  

        The specialized expression should share as many caches as possible with the
        original expression.  

        Parameters
        ----------
        * `added_known` :  
            Variables to specialise. None of these should be already in the right
            variable set.  

        """
        return _probt_python3.plCndJtDistribution_specialise(self, added_known)


    def output_dot(self) -> "void":
        """
        output_dot(self)


        `output_dot(std::ostream &os) const`  

        Outputs the formula inside this distribution in dot format.  

        The formula is represented as a tree of expressions. Together with other
        formulas from other distributions, it forms a DAG of expressions that helps see
        the shared computations produced by the junction tree algorithm.  

        """
        return _probt_python3.plCndJtDistribution_output_dot(self)


    def __getstate__(self) -> "std::string":
        """__getstate__(self) -> std::string"""
        return _probt_python3.plCndJtDistribution___getstate__(self)


    def __setstate_internal(self, sState: 'std::string const &') -> "void":
        """__setstate_internal(self, sState)"""
        return _probt_python3.plCndJtDistribution___setstate_internal(self, sState)


    def __setstate__(self, sState):
        self.__init__()
        self.__setstate_internal(sState)

    __swig_destroy__ = _probt_python3.delete_plCndJtDistribution
    __del__ = lambda self: None
plCndJtDistribution_swigregister = _probt_python3.plCndJtDistribution_swigregister
plCndJtDistribution_swigregister(plCndJtDistribution)

class plJtDistribution(plDistribution):
    """

    `plJtDistribution()`  
    `plJtDistribution(kplJtKernel const &vroot)`  

    Non-conditional distribution as returned by asking a question to a
    plJunctionTree.  

    Constructors
    ------------
    * `plJtDistribution()`  

        Empty constructor.  

    * `plJtDistribution(kplJtKernel const &vroot)`  

    C++ includes: plJtDistribution.h

    """

    __swig_setmethods__ = {}
    for _s in [plDistribution]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plJtDistribution, name, value)
    __swig_getmethods__ = {}
    for _s in [plDistribution]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plJtDistribution, name)
    __repr__ = _swig_repr

    def __init__(self, *args):
        """
        __init__(self) -> plJtDistribution
        __init__(self, vroot) -> plJtDistribution


        `plJtDistribution()`  
        `plJtDistribution(kplJtKernel const &vroot)`  

        Overloaded function
        -------------------
        * `plJtDistribution()`  

            Empty constructor.  

        * `plJtDistribution(kplJtKernel const &vroot)`  

        """
        this = _probt_python3.new_plJtDistribution(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def specialise(self, added_known: 'plVariablesConjunction') -> "plCndJtDistribution":
        """
        specialise(self, added_known) -> plCndJtDistribution


        `specialise(plVariablesConjunction const &added_known) -> plCndJtDistribution`  

        Returns a specialised version of this distribution.  

        Specialising adds or moves a variable to the right variable set.  

        For instance, P(A D).specialise(B C D) == P(A | B C D).  

        The specialized expression shares as many caches as possible with the original
        expression. This is therefore more efficient than asking P(A D) and P(A | B C D)
        separately to a plJunctionTree or plJointDistribution.  

        Parameters
        ----------
        * `added_known` :  
            Variables to specialise. None of these should be already in the right
            variable set.  

        """
        return _probt_python3.plJtDistribution_specialise(self, added_known)


    def output_dot(self) -> "void":
        """
        output_dot(self)


        `output_dot(std::ostream &os) const`  

        Outputs the formula inside this distribution in dot format.  

        The formula is represented as a tree of expressions. Together with other
        formulas from other distributions, it forms a DAG of expressions that helps see
        the shared computations produced by the junction tree algorithm.  

        """
        return _probt_python3.plJtDistribution_output_dot(self)


    def __getstate__(self) -> "std::string":
        """__getstate__(self) -> std::string"""
        return _probt_python3.plJtDistribution___getstate__(self)


    def __setstate_internal(self, sState: 'std::string const &') -> "void":
        """__setstate_internal(self, sState)"""
        return _probt_python3.plJtDistribution___setstate_internal(self, sState)


    def __setstate__(self, sState):
        self.__init__()
        self.__setstate_internal(sState)

    __swig_destroy__ = _probt_python3.delete_plJtDistribution
    __del__ = lambda self: None
plJtDistribution_swigregister = _probt_python3.plJtDistribution_swigregister
plJtDistribution_swigregister(plJtDistribution)

class plDataValues(_object):
    """

    `plDataValues(size_t size=0)`  
    `plDataValues(size_t size, plData::plData_type type)`  
    `plDataValues(const plDataValues &other)`  
    `plDataValues(const kplVariableList &variables_list)`  

    Constructors
    ------------
    * `plDataValues(size_t size=0)`  

    * `plDataValues(size_t size, plData::plData_type type)`  

    * `plDataValues(const plDataValues &other)`  

    * `plDataValues(const kplVariableList &variables_list)`  

    """

    __swig_setmethods__ = {}
    __setattr__ = lambda self, name, value: _swig_setattr(self, plDataValues, name, value)
    __swig_getmethods__ = {}
    __getattr__ = lambda self, name: _swig_getattr(self, plDataValues, name)
    __repr__ = _swig_repr

    def size(self) -> "size_t":
        """
        size(self) -> size_t


        `size() const -> size_t`  

        """
        return _probt_python3.plDataValues_size(self)


    def __getitem__(self, index: 'int') -> "plData":
        """__getitem__(self, index) -> plData"""
        return _probt_python3.plDataValues___getitem__(self, index)


    def __setitem__(self, *args) -> "void":
        """
        __setitem__(self, index, value)
        __setitem__(self, index, value)
        __setitem__(self, index, value)
        """
        return _probt_python3.plDataValues___setitem__(self, *args)


    def __len__(self) -> "int":
        """__len__(self) -> int"""
        return _probt_python3.plDataValues___len__(self)


    def __init__(self):
        """
        __init__(self) -> plDataValues


        `plDataValues(size_t size=0)`  
        `plDataValues(size_t size, plData::plData_type type)`  
        `plDataValues(const plDataValues &other)`  
        `plDataValues(const kplVariableList &variables_list)`  

        Overloaded function
        -------------------
        * `plDataValues(size_t size=0)`  

        * `plDataValues(size_t size, plData::plData_type type)`  

        * `plDataValues(const plDataValues &other)`  

        * `plDataValues(const kplVariableList &variables_list)`  

        """
        this = _probt_python3.new_plDataValues()
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this
    __swig_destroy__ = _probt_python3.delete_plDataValues
    __del__ = lambda self: None
plDataValues_swigregister = _probt_python3.plDataValues_swigregister
plDataValues_swigregister(plDataValues)

class plExternalFunction(plUserFunction):
    """

    `plExternalFunction()`  
    `plExternalFunction(const plExternalFunction &f)`  
    `plExternalFunction(const plVariablesConjunction &input_params, callback_t
        call_function, std::string func_name="")`  
    `plExternalFunction(const plVariablesConjunction &output_params, const
        plVariablesConjunction &input_params, callback_t call_function, std::string
        func_name="")`  
    `plExternalFunction(const plVariablesConjunction &input_params, T *obj,
        void(T::*method)(plValues &output_values, const plValues &input_values),
        std::string func_name="")`  
    `plExternalFunction(const plVariablesConjunction &input_params, const T *obj,
        void(T::*method)(plValues &output_values, const plValues &input_values)
        const, std::string func_name="")`  
    `plExternalFunction(const plVariablesConjunction &output_params, const
        plVariablesConjunction &input_params, T *obj, void(T::*method)(plValues
        &output_values, const plValues &input_values), std::string func_name="")`  
    `plExternalFunction(const plVariablesConjunction &output_params, const
        plVariablesConjunction &input_params, const T *obj,
        void(T::*method)(plValues &output_values, const plValues &input_values)
        const, std::string func_name="")`  

    A function defined by the user, generaly used to define a *plCndDeterministic*.  

    It's also used with conditional distributions accepting user functions as a way
    to fix the *known* (*right*) parameters.  

    Examples of creating and using plExternalFunction can be found in
    dirac_func_example (deterministic distributions) and in param_func_example
    (functions as distribution parameters).  

    Constructors
    ------------
    * `plExternalFunction()`  

        Default constructor.  

    * `plExternalFunction(const plExternalFunction &f)`  

        Copy constructor.  

    * `plExternalFunction(const plVariablesConjunction &input_params, callback_t
        call_function, std::string func_name="")`  

        Defines a user-function with print name *func_name* where *output_params* =
        *call_function(input_params)*, and the callback *call_function* is a non-
        member function.  

        This constructor variant is to be used with conditional parametric forms
        (the output_params are implicitly defined as the parameter you want to
        express as a user-function).  

    * `plExternalFunction(const plVariablesConjunction &output_params, const
        plVariablesConjunction &input_params, callback_t call_function, std::string
        func_name="")`  

        Defines a user-function with print name *func_name* where *output_params* =
        *call_function(input_params)*, and the callback *call_function* is a non-
        member function.  

        This constructor variant is to be used with plCndDeterministic.  

    * `plExternalFunction(const plVariablesConjunction &input_params, T *obj,
        void(T::*method)(plValues &output_values, const plValues &input_values),
        std::string func_name="")`  

        Defines a user-function with print name *func_name* where *output_params* =
        *obj->method(input_params)*, and the callback *method* is a member function.  

        This constructor variant is to be used with conditional parametric forms
        (the output_params are implicitly defined as the parameter you want to
        express as a user-function).  

    * `plExternalFunction(const plVariablesConjunction &input_params, const T *obj,
        void(T::*method)(plValues &output_values, const plValues &input_values)
        const, std::string func_name="")`  

        Defines a user-function with print name *func_name* where *output_params* =
        *obj->method(input_params)*, and the callback *method* is a member function.  

        This constructor variant is to be used with conditional parametric forms
        (the output_params are implicitly defined as the parameter you want to
        express as a user-function).  

    * `plExternalFunction(const plVariablesConjunction &output_params, const
        plVariablesConjunction &input_params, T *obj, void(T::*method)(plValues
        &output_values, const plValues &input_values), std::string func_name="")`  

        Defines a user-function with print name *func_name* where *output_params* =
        *obj->method(input_params)*, and the callback *method* is a member function.  

        This constructor variant is to be used with plCndDeterministic.  

    * `plExternalFunction(const plVariablesConjunction &output_params, const
        plVariablesConjunction &input_params, const T *obj,
        void(T::*method)(plValues &output_values, const plValues &input_values)
        const, std::string func_name="")`  

        Defines a user-function with print name *func_name* where *output_params* =
        *obj->method(input_params)*, and the callback *method* is a member function.  

        This constructor variant is to be used with plCndDeterministic.  

    C++ includes: plExternalFunction.h

    """

    __swig_setmethods__ = {}
    for _s in [plUserFunction]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plExternalFunction, name, value)
    __swig_getmethods__ = {}
    for _s in [plUserFunction]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plExternalFunction, name)
    __repr__ = _swig_repr
    __swig_destroy__ = _probt_python3.delete_plExternalFunction
    __del__ = lambda self: None

    def __init__(self, *args):
        """
        __init__(self) -> plExternalFunction
        __init__(self, f) -> plExternalFunction
        __init__(self, input_params, call_function, func_name) -> plExternalFunction
        __init__(self, input_params, call_function) -> plExternalFunction
        __init__(self, output_params, input_params, call_function, func_name) -> plExternalFunction
        __init__(self, output_params, input_params, call_function) -> plExternalFunction


        `plExternalFunction()`  
        `plExternalFunction(const plExternalFunction &f)`  
        `plExternalFunction(const plVariablesConjunction &input_params, callback_t
            call_function, std::string func_name="")`  
        `plExternalFunction(const plVariablesConjunction &output_params, const
            plVariablesConjunction &input_params, callback_t call_function, std::string
            func_name="")`  
        `plExternalFunction(const plVariablesConjunction &input_params, T *obj,
            void(T::*method)(plValues &output_values, const plValues &input_values),
            std::string func_name="")`  
        `plExternalFunction(const plVariablesConjunction &input_params, const T *obj,
            void(T::*method)(plValues &output_values, const plValues &input_values)
            const, std::string func_name="")`  
        `plExternalFunction(const plVariablesConjunction &output_params, const
            plVariablesConjunction &input_params, T *obj, void(T::*method)(plValues
            &output_values, const plValues &input_values), std::string func_name="")`  
        `plExternalFunction(const plVariablesConjunction &output_params, const
            plVariablesConjunction &input_params, const T *obj,
            void(T::*method)(plValues &output_values, const plValues &input_values)
            const, std::string func_name="")`  

        Overloaded function
        -------------------
        * `plExternalFunction()`  

            Default constructor.  

        * `plExternalFunction(const plExternalFunction &f)`  

            Copy constructor.  

        * `plExternalFunction(const plVariablesConjunction &input_params, callback_t
            call_function, std::string func_name="")`  

            Defines a user-function with print name *func_name* where *output_params* =
            *call_function(input_params)*, and the callback *call_function* is a non-
            member function.  

            This constructor variant is to be used with conditional parametric forms
            (the output_params are implicitly defined as the parameter you want to
            express as a user-function).  

        * `plExternalFunction(const plVariablesConjunction &output_params, const
            plVariablesConjunction &input_params, callback_t call_function, std::string
            func_name="")`  

            Defines a user-function with print name *func_name* where *output_params* =
            *call_function(input_params)*, and the callback *call_function* is a non-
            member function.  

            This constructor variant is to be used with plCndDeterministic.  

        * `plExternalFunction(const plVariablesConjunction &input_params, T *obj,
            void(T::*method)(plValues &output_values, const plValues &input_values),
            std::string func_name="")`  

            Defines a user-function with print name *func_name* where *output_params* =
            *obj->method(input_params)*, and the callback *method* is a member function.  

            This constructor variant is to be used with conditional parametric forms
            (the output_params are implicitly defined as the parameter you want to
            express as a user-function).  

        * `plExternalFunction(const plVariablesConjunction &input_params, const T *obj,
            void(T::*method)(plValues &output_values, const plValues &input_values)
            const, std::string func_name="")`  

            Defines a user-function with print name *func_name* where *output_params* =
            *obj->method(input_params)*, and the callback *method* is a member function.  

            This constructor variant is to be used with conditional parametric forms
            (the output_params are implicitly defined as the parameter you want to
            express as a user-function).  

        * `plExternalFunction(const plVariablesConjunction &output_params, const
            plVariablesConjunction &input_params, T *obj, void(T::*method)(plValues
            &output_values, const plValues &input_values), std::string func_name="")`  

            Defines a user-function with print name *func_name* where *output_params* =
            *obj->method(input_params)*, and the callback *method* is a member function.  

            This constructor variant is to be used with plCndDeterministic.  

        * `plExternalFunction(const plVariablesConjunction &output_params, const
            plVariablesConjunction &input_params, const T *obj,
            void(T::*method)(plValues &output_values, const plValues &input_values)
            const, std::string func_name="")`  

            Defines a user-function with print name *func_name* where *output_params* =
            *obj->method(input_params)*, and the callback *method* is a member function.  

            This constructor variant is to be used with plCndDeterministic.  

        """
        this = _probt_python3.new_plExternalFunction(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def assign_from(self, other: 'plExternalFunction') -> "plExternalFunction &":
        """
        assign_from(self, other) -> plExternalFunction


        `assign_from(const plExternalFunction &other) -> plExternalFunction &`  

        Same as operator=()  

        """
        return _probt_python3.plExternalFunction_assign_from(self, other)


    def __call__(self, values: 'plValues') -> "plDataValues":
        """__call__(self, values) -> plDataValues"""
        return _probt_python3.plExternalFunction___call__(self, values)


    def get_variables(self) -> "plVariablesConjunction":
        """
        get_variables(self) -> plVariablesConjunction


        `get_variables() const -> plVariablesConjunction`  

        Returns all the variables (left and right) of the function.  

        This is equivalent to get_left_variables() ^ get_right_variables().  

        """
        return _probt_python3.plExternalFunction_get_variables(self)


    def get_left_variables(self) -> "plVariablesConjunction":
        """
        get_left_variables(self) -> plVariablesConjunction


        `get_left_variables() const -> plVariablesConjunction`  

        Returns the left variables of the function.  

        """
        return _probt_python3.plExternalFunction_get_left_variables(self)


    def get_right_variables(self) -> "plVariablesConjunction":
        """
        get_right_variables(self) -> plVariablesConjunction


        `get_right_variables() const -> plVariablesConjunction`  

        Returns the right variables of the function.  

        """
        return _probt_python3.plExternalFunction_get_right_variables(self)


    def set_has_side_effect(self, hse: 'bool') -> "void":
        """
        set_has_side_effect(self, hse)


        `set_has_side_effect(bool hse)`  

        Set/unset the *has_side_effect* flag of the function.  

        The *has_side_effect* flag is used for deciding if distributions using the
        function are cached or not in the inference process. The default value of this
        flag is *false*.  

        See also: has_side_effect  

        """
        return _probt_python3.plExternalFunction_set_has_side_effect(self, hse)


    def has_side_effect(self) -> "bool":
        """
        has_side_effect(self) -> bool


        `has_side_effect() const -> bool`  

        Return the *has_side_effect* flag of the function.  

        See also: set_has_side_effect  

        """
        return _probt_python3.plExternalFunction_has_side_effect(self)


    def get_name(self) -> "std::string const &":
        """
        get_name(self) -> std::string const &


        `get_name() const -> const std::string &`  

        Get function's name.  

        """
        return _probt_python3.plExternalFunction_get_name(self)


    def sum(the_sum: 'plValues', vals: 'plValues') -> "void":
        """
        sum(the_sum, vals)


        `sum(plValues &the_sum, const plValues &vals)`  

        The Sum function.  

        """
        return _probt_python3.plExternalFunction_sum(the_sum, vals)

    sum = staticmethod(sum)

    def product(the_product: 'plValues', vals: 'plValues') -> "void":
        """
        product(the_product, vals)


        `product(plValues &the_product, const plValues &vals)`  

        The Product function.  

        """
        return _probt_python3.plExternalFunction_product(the_product, vals)

    product = staticmethod(product)

    def average(the_average: 'plValues', vals: 'plValues') -> "void":
        """
        average(the_average, vals)


        `average(plValues &the_average, const plValues &vals)`  

        The Average function.  

        """
        return _probt_python3.plExternalFunction_average(the_average, vals)

    average = staticmethod(average)

    def identity(the_id: 'plValues', vals: 'plValues') -> "void":
        """
        identity(the_id, vals)


        `identity(plValues &the_id, const plValues &vals)`  

        The Identity function.  

        """
        return _probt_python3.plExternalFunction_identity(the_id, vals)

    identity = staticmethod(identity)

    def min(the_min: 'plValues', vals: 'plValues') -> "void":
        """
        min(the_min, vals)


        `min(plValues &the_min, const plValues &vals)`  

        The Min function.  

        """
        return _probt_python3.plExternalFunction_min(the_min, vals)

    min = staticmethod(min)

    def max(the_max: 'plValues', vals: 'plValues') -> "void":
        """
        max(the_max, vals)


        `max(plValues &the_max, const plValues &vals)`  

        The Max function.  

        """
        return _probt_python3.plExternalFunction_max(the_max, vals)

    max = staticmethod(max)

    def logical_or(or_result: 'plValues', vals: 'plValues') -> "void":
        """
        logical_or(or_result, vals)


        `logical_or(plValues &or_result, const plValues &vals)`  

        Logical or.  

        The input values are interpreted as booleans. The output value is a 0/1 value
        representing the logical OR between all the inputs.  

        """
        return _probt_python3.plExternalFunction_logical_or(or_result, vals)

    logical_or = staticmethod(logical_or)

    def logical_and(and_result: 'plValues', vals: 'plValues') -> "void":
        """
        logical_and(and_result, vals)


        `logical_and(plValues &and_result, const plValues &vals)`  

        Logical and.  

        The input values are interpreted as booleans. The output value is a 0/1 value
        representing the logical AND (conjunction) between all the inputs.  

        """
        return _probt_python3.plExternalFunction_logical_and(and_result, vals)

    logical_and = staticmethod(logical_and)
plExternalFunction_swigregister = _probt_python3.plExternalFunction_swigregister
plExternalFunction_swigregister(plExternalFunction)

def plExternalFunction_sum(the_sum: 'plValues', vals: 'plValues') -> "void":
    """
    plExternalFunction_sum(the_sum, vals)


    `sum(plValues &the_sum, const plValues &vals)`  

    The Sum function.  

    """
    return _probt_python3.plExternalFunction_sum(the_sum, vals)

def plExternalFunction_product(the_product: 'plValues', vals: 'plValues') -> "void":
    """
    plExternalFunction_product(the_product, vals)


    `product(plValues &the_product, const plValues &vals)`  

    The Product function.  

    """
    return _probt_python3.plExternalFunction_product(the_product, vals)

def plExternalFunction_average(the_average: 'plValues', vals: 'plValues') -> "void":
    """
    plExternalFunction_average(the_average, vals)


    `average(plValues &the_average, const plValues &vals)`  

    The Average function.  

    """
    return _probt_python3.plExternalFunction_average(the_average, vals)

def plExternalFunction_identity(the_id: 'plValues', vals: 'plValues') -> "void":
    """
    plExternalFunction_identity(the_id, vals)


    `identity(plValues &the_id, const plValues &vals)`  

    The Identity function.  

    """
    return _probt_python3.plExternalFunction_identity(the_id, vals)

def plExternalFunction_min(the_min: 'plValues', vals: 'plValues') -> "void":
    """
    plExternalFunction_min(the_min, vals)


    `min(plValues &the_min, const plValues &vals)`  

    The Min function.  

    """
    return _probt_python3.plExternalFunction_min(the_min, vals)

def plExternalFunction_max(the_max: 'plValues', vals: 'plValues') -> "void":
    """
    plExternalFunction_max(the_max, vals)


    `max(plValues &the_max, const plValues &vals)`  

    The Max function.  

    """
    return _probt_python3.plExternalFunction_max(the_max, vals)

def plExternalFunction_logical_or(or_result: 'plValues', vals: 'plValues') -> "void":
    """
    plExternalFunction_logical_or(or_result, vals)


    `logical_or(plValues &or_result, const plValues &vals)`  

    Logical or.  

    The input values are interpreted as booleans. The output value is a 0/1 value
    representing the logical OR between all the inputs.  

    """
    return _probt_python3.plExternalFunction_logical_or(or_result, vals)

def plExternalFunction_logical_and(and_result: 'plValues', vals: 'plValues') -> "void":
    """
    plExternalFunction_logical_and(and_result, vals)


    `logical_and(plValues &and_result, const plValues &vals)`  

    Logical and.  

    The input values are interpreted as booleans. The output value is a 0/1 value
    representing the logical AND (conjunction) between all the inputs.  

    """
    return _probt_python3.plExternalFunction_logical_and(and_result, vals)

class plExternalObjectInterface(_object):
    """


    Interface of object that provides the callback for an external function.  

    C++ includes: plExternalFunction.h

    """

    __swig_setmethods__ = {}
    __setattr__ = lambda self, name, value: _swig_setattr(self, plExternalObjectInterface, name, value)
    __swig_getmethods__ = {}
    __getattr__ = lambda self, name: _swig_getattr(self, plExternalObjectInterface, name)

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined - class is abstract")
    __repr__ = _swig_repr
    __swig_destroy__ = _probt_python3.delete_plExternalObjectInterface
    __del__ = lambda self: None

    def f(self, output: 'plValues', input: 'plValues') -> "void":
        """
        f(self, output, input)


        `f(plValues &output, plValues const &input)=0`  

        """
        return _probt_python3.plExternalObjectInterface_f(self, output, input)

plExternalObjectInterface_swigregister = _probt_python3.plExternalObjectInterface_swigregister
plExternalObjectInterface_swigregister(plExternalObjectInterface)


def plCreateExternalFunction(*args) -> "plExternalFunction":
    """
    plCreateExternalFunction(input_variables, object, func_name) -> plExternalFunction
    plCreateExternalFunction(input_variables, object) -> plExternalFunction


    `plCreateExternalFunction(plVariablesConjunction const &input_variables,
        plExternalObjectInterface *object, std::string const &func_name="") ->
        PL_DLL_API plExternalFunction`  

    Creates a plExternalFunction from an object with the appropriate f() method.  

    Parameters
    ----------
    * `input_variables` :  
        Input variables of the function.  
    * `object` :  
        Pointer to object implementing the plExternalObjectInterface interface. This
        object must not be destroyed before the returned plExternalFunction.  
    * `func_name` :  
        Optional function name for pretty-printing.  

    To use it, inherit plExternalObjectInterface, and implement f() :  

        class A : plExternalObjectInterface {
        public:
          ...
          virtual void f(plValues & output, plValues const & input) {
            ... // fill in output from input
          }
        };
        int main() {
          A a;
          plExternalFunction f = plCreateExternalFunction(input_variables, &a);
          ...
        }


    """
    return _probt_python3.plCreateExternalFunction(*args)
class plExternalFunctionFromSource(plExternalFunction):
    """

    `plExternalFunctionFromSource()`  
    `plExternalFunctionFromSource(const plExternalFunction &other)`  

    A special kind of plExternalFunction defined by dynamically compiling source
    code provided by the user.  

    The advantage over normal plExternalFunction objects is that instances of this
    class are guaranteed to be serializable.  

    Constructors
    ------------
    * `plExternalFunctionFromSource()`  

    * `plExternalFunctionFromSource(const plExternalFunction &other)`  

        Promote from a plExternalFunction.  

        If the object being copied is actually of the wrong type, an exception is
        raised.  

    C++ includes: plExternalFunctionFromSource.h

    """

    __swig_setmethods__ = {}
    for _s in [plExternalFunction]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plExternalFunctionFromSource, name, value)
    __swig_getmethods__ = {}
    for _s in [plExternalFunction]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plExternalFunctionFromSource, name)
    __repr__ = _swig_repr

    def __init__(self, *args):
        """
        __init__(self) -> plExternalFunctionFromSource
        __init__(self, other) -> plExternalFunctionFromSource


        `plExternalFunctionFromSource()`  
        `plExternalFunctionFromSource(const plExternalFunction &other)`  

        Overloaded function
        -------------------
        * `plExternalFunctionFromSource()`  

        * `plExternalFunctionFromSource(const plExternalFunction &other)`  

            Promote from a plExternalFunction.  

            If the object being copied is actually of the wrong type, an exception is
            raised.  

        """
        this = _probt_python3.new_plExternalFunctionFromSource(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def get_code(self) -> "std::string":
        """
        get_code(self) -> std::string


        `get_code() const -> std::string`  

        Get the source code.  

        """
        return _probt_python3.plExternalFunctionFromSource_get_code(self)

    __swig_destroy__ = _probt_python3.delete_plExternalFunctionFromSource
    __del__ = lambda self: None
plExternalFunctionFromSource_swigregister = _probt_python3.plExternalFunctionFromSource_swigregister
plExternalFunctionFromSource_swigregister(plExternalFunctionFromSource)

class plExternalFunctionFromC(plExternalFunctionFromSource):
    """

    `plExternalFunctionFromC()`  
    `plExternalFunctionFromC(const plExternalFunction &other)`  
    `plExternalFunctionFromC(const plVariablesConjunction &input_params, const
        std::string &func_code, std::string func_name)`  
    `plExternalFunctionFromC(const plVariablesConjunction &output_params, const
        plVariablesConjunction &input_params, const std::string &func_code,
        std::string func_name)`  

    A special kind of plExternalFunction defined by dynamically compiling C source
    code provided by the user.  

    The advantage over normal plExternalFunction is that instances of this class can
    always be serialized.  

    Constructors
    ------------
    * `plExternalFunctionFromC()`  

    * `plExternalFunctionFromC(const plExternalFunction &other)`  

        Promote from a plExternalFunction.  

        If the object being copied is actually of the wrong type, an exception is
        raised.  

    * `plExternalFunctionFromC(const plVariablesConjunction &input_params, const
        std::string &func_code, std::string func_name)`  

        Defines an External Function with print name *func_name* where
        *output_params* = *call_function(input_params)*.  

        This version is for dynamically compiled C functions.  

    * `plExternalFunctionFromC(const plVariablesConjunction &output_params, const
        plVariablesConjunction &input_params, const std::string &func_code,
        std::string func_name)`  

        Defines an External Function with print name *func_name* where
        *output_params* = *call_function(input_params)*.  

        This version is for dynamically compiled C functions.  

    C++ includes: plExternalFunctionFromC.h

    """

    __swig_setmethods__ = {}
    for _s in [plExternalFunctionFromSource]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plExternalFunctionFromC, name, value)
    __swig_getmethods__ = {}
    for _s in [plExternalFunctionFromSource]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plExternalFunctionFromC, name)
    __repr__ = _swig_repr

    def __init__(self, *args):
        """
        __init__(self) -> plExternalFunctionFromC
        __init__(self, other) -> plExternalFunctionFromC
        __init__(self, input_params, func_code, func_name) -> plExternalFunctionFromC
        __init__(self, output_params, input_params, func_code, func_name) -> plExternalFunctionFromC


        `plExternalFunctionFromC()`  
        `plExternalFunctionFromC(const plExternalFunction &other)`  
        `plExternalFunctionFromC(const plVariablesConjunction &input_params, const
            std::string &func_code, std::string func_name)`  
        `plExternalFunctionFromC(const plVariablesConjunction &output_params, const
            plVariablesConjunction &input_params, const std::string &func_code,
            std::string func_name)`  

        Overloaded function
        -------------------
        * `plExternalFunctionFromC()`  

        * `plExternalFunctionFromC(const plExternalFunction &other)`  

            Promote from a plExternalFunction.  

            If the object being copied is actually of the wrong type, an exception is
            raised.  

        * `plExternalFunctionFromC(const plVariablesConjunction &input_params, const
            std::string &func_code, std::string func_name)`  

            Defines an External Function with print name *func_name* where
            *output_params* = *call_function(input_params)*.  

            This version is for dynamically compiled C functions.  

        * `plExternalFunctionFromC(const plVariablesConjunction &output_params, const
            plVariablesConjunction &input_params, const std::string &func_code,
            std::string func_name)`  

            Defines an External Function with print name *func_name* where
            *output_params* = *call_function(input_params)*.  

            This version is for dynamically compiled C functions.  

        """
        this = _probt_python3.new_plExternalFunctionFromC(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def add_symbol(self, name: 'std::string const &', addr: 'void *') -> "void":
        """
        add_symbol(self, name, addr)


        `add_symbol(const std::string &name, void *addr)`  

        Make a local symbol accessible to the dynamically compiled code.  

        This must be done before the function is associated to a distribution.  

        """
        return _probt_python3.plExternalFunctionFromC_add_symbol(self, name, addr)


    def __getstate__(self) -> "std::string":
        """__getstate__(self) -> std::string"""
        return _probt_python3.plExternalFunctionFromC___getstate__(self)


    def __setstate_internal(self, sState: 'std::string const &') -> "void":
        """__setstate_internal(self, sState)"""
        return _probt_python3.plExternalFunctionFromC___setstate_internal(self, sState)


    def __setstate__(self, sState):
        self.__init__()
        self.__setstate_internal(sState)

    __swig_destroy__ = _probt_python3.delete_plExternalFunctionFromC
    __del__ = lambda self: None
plExternalFunctionFromC_swigregister = _probt_python3.plExternalFunctionFromC_swigregister
plExternalFunctionFromC_swigregister(plExternalFunctionFromC)


def createExternalFunctionFromC(*args) -> "plExternalFunctionFromC":
    """
    createExternalFunctionFromC(output, input, code, name) -> plExternalFunctionFromC
    createExternalFunctionFromC(input, code, name) -> plExternalFunctionFromC


    `createExternalFunctionFromC(const plVariablesConjunction &output, const
        plVariablesConjunction &input, const std::string &code, const std::string
        &name) -> PL_DLL_API plExternalFunctionFromC`  
    `createExternalFunctionFromC(const plVariablesConjunction &input, const
        std::string &code, const std::string &name) -> PL_DLL_API
        plExternalFunctionFromC`  

    Overloaded function
    -------------------
    * `createExternalFunctionFromC(const plVariablesConjunction &output, const
        plVariablesConjunction &input, const std::string &code, const std::string
        &name) -> PL_DLL_API plExternalFunctionFromC`  

        Helper function for creating plExternalFunctionFromC objects.  

        This takes the function body as input, and takes care of generating the
        function header and footer such as you can use directly the variable names
        in the code. This version is to be used with the plCndDeterministic
        distributions.  

    * `createExternalFunctionFromC(const plVariablesConjunction &input, const
        std::string &code, const std::string &name) -> PL_DLL_API
        plExternalFunctionFromC`  

        Helper function for creating plExternalFunctionFromC objects.  

        This takes the function body as input, and takes care of generating the
        function header and footer such as you can use directly the input variable
        names in the code. You still have to use "output[0]" for the first output,
        "output[1]" for second, etc... This version is to be used for the
        parametric distributions such as conditional normals, conditional uniforms
        and so on. The user-code is given as one or several affectations.  

    """
    return _probt_python3.createExternalFunctionFromC(*args)

def createExternalFunctionFromCExpression(input: 'plVariablesConjunction', code: 'std::string const &', name: 'std::string const &') -> "plExternalFunctionFromC":
    """
    createExternalFunctionFromCExpression(input, code, name) -> plExternalFunctionFromC


    `createExternalFunctionFromCExpression(const plVariablesConjunction &input,
        const std::string &code, const std::string &name) -> PL_DLL_API
        plExternalFunctionFromC`  

    Helper function for creating plExternalFunctionFromC objects.  

    This takes a C expression as input, and takes care of generating the function
    header and footer such as you can use directly the right variable names in the
    code. This version is to be used for the parametric distributions such as
    conditional normals, conditional uniforms and so on. The user-code is given as a
    single scalar expression which will be affected to the first output. If you need
    several output values, use the 3-parameters version of
    createExternalFunctionFromC() instead.  

    """
    return _probt_python3.createExternalFunctionFromCExpression(input, code, name)
class plPythonExternalFunction(plExternalFunction):
    """

    `plPythonExternalFunction(const plVariablesConjunction &input_params, PyObject
        *python_function, std::string function_name="")`  
    `plPythonExternalFunction(const plVariablesConjunction &output_params, const
        plVariablesConjunction &input_params, PyObject *python_function, std::string
        function_name="")`  
    `plPythonExternalFunction(const plVariablesConjunction &input_params, PyObject
        *python_instance, PyObject *python_method, std::string function_name="")`  
    `plPythonExternalFunction(const plVariablesConjunction &output_params, const
        plVariablesConjunction &input_params, PyObject *python_instance, PyObject
        *python_method, std::string function_name="")`  

    This class is intended to be used from the Python bindings only.  

    It defines a Python callback function defined by the user, generaly used to
    define a *plCndDeterministic*. It's also used with conditional distributions
    accepting user functions as a way to fix the *known* (*right*) parameters.  

    Examples of creating and using plExternalFunction can be found in
    dirac_func_example (deterministic distributions) and in param_func_example
    (functions as distribution parameters).  

    Constructors
    ------------
    * `plPythonExternalFunction(const plVariablesConjunction &input_params, PyObject
        *python_function, std::string function_name="")`  

        Defines a user-function with print name *function_name* where
        *output_params* = *python_function(input_params)*, and the callback
        *python_function* is a non-member function.  

        This constructor variant is to be used with conditional parametric forms
        (the output_params are implicitly defined as the parameter you want to
        express as a user-function).  

    * `plPythonExternalFunction(const plVariablesConjunction &output_params, const
        plVariablesConjunction &input_params, PyObject *python_function, std::string
        function_name="")`  

        Defines a user-function with print name *function_name* where
        *output_params* = *python_function(input_params)*, and the callback
        *python_function* is a non-member function.  

        This constructor variant is to be used with plCndDeterministic.  

    * `plPythonExternalFunction(const plVariablesConjunction &input_params, PyObject
        *python_instance, PyObject *python_method, std::string function_name="")`  

        Defines a user-function with print name *function_name* where
        *output_params* = *python_instance.python_method(input_params)*, and the
        callback *python_method* is a member function.  

        This constructor variant is to be used with conditional parametric forms
        (the output_params are implicitly defined as the parameter you want to
        express as a user-function).  

    * `plPythonExternalFunction(const plVariablesConjunction &output_params, const
        plVariablesConjunction &input_params, PyObject *python_instance, PyObject
        *python_method, std::string function_name="")`  

        Defines a user-function with print name *function_name* where
        *output_params* = *python_instance.python_method(input_params)*, and the
        callback *python_method* is a member function.  

        This constructor variant is to be used with plCndDeterministic.  

    C++ includes: plPythonExternalFunction.h

    """

    __swig_setmethods__ = {}
    for _s in [plExternalFunction]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plPythonExternalFunction, name, value)
    __swig_getmethods__ = {}
    for _s in [plExternalFunction]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plPythonExternalFunction, name)
    __repr__ = _swig_repr

    def __init__(self, *args):
        """
        __init__(self, input_params, python_function, function_name) -> plPythonExternalFunction
        __init__(self, input_params, python_function) -> plPythonExternalFunction
        __init__(self, output_params, input_params, python_function, function_name) -> plPythonExternalFunction
        __init__(self, output_params, input_params, python_function) -> plPythonExternalFunction
        __init__(self, input_params, python_instance, python_method, function_name) -> plPythonExternalFunction
        __init__(self, input_params, python_instance, python_method) -> plPythonExternalFunction
        __init__(self, output_params, input_params, python_instance, python_method, function_name) -> plPythonExternalFunction
        __init__(self, output_params, input_params, python_instance, python_method) -> plPythonExternalFunction


        `plPythonExternalFunction(const plVariablesConjunction &input_params, PyObject
            *python_function, std::string function_name="")`  
        `plPythonExternalFunction(const plVariablesConjunction &output_params, const
            plVariablesConjunction &input_params, PyObject *python_function, std::string
            function_name="")`  
        `plPythonExternalFunction(const plVariablesConjunction &input_params, PyObject
            *python_instance, PyObject *python_method, std::string function_name="")`  
        `plPythonExternalFunction(const plVariablesConjunction &output_params, const
            plVariablesConjunction &input_params, PyObject *python_instance, PyObject
            *python_method, std::string function_name="")`  

        Overloaded function
        -------------------
        * `plPythonExternalFunction(const plVariablesConjunction &input_params, PyObject
            *python_function, std::string function_name="")`  

            Defines a user-function with print name *function_name* where
            *output_params* = *python_function(input_params)*, and the callback
            *python_function* is a non-member function.  

            This constructor variant is to be used with conditional parametric forms
            (the output_params are implicitly defined as the parameter you want to
            express as a user-function).  

        * `plPythonExternalFunction(const plVariablesConjunction &output_params, const
            plVariablesConjunction &input_params, PyObject *python_function, std::string
            function_name="")`  

            Defines a user-function with print name *function_name* where
            *output_params* = *python_function(input_params)*, and the callback
            *python_function* is a non-member function.  

            This constructor variant is to be used with plCndDeterministic.  

        * `plPythonExternalFunction(const plVariablesConjunction &input_params, PyObject
            *python_instance, PyObject *python_method, std::string function_name="")`  

            Defines a user-function with print name *function_name* where
            *output_params* = *python_instance.python_method(input_params)*, and the
            callback *python_method* is a member function.  

            This constructor variant is to be used with conditional parametric forms
            (the output_params are implicitly defined as the parameter you want to
            express as a user-function).  

        * `plPythonExternalFunction(const plVariablesConjunction &output_params, const
            plVariablesConjunction &input_params, PyObject *python_instance, PyObject
            *python_method, std::string function_name="")`  

            Defines a user-function with print name *function_name* where
            *output_params* = *python_instance.python_method(input_params)*, and the
            callback *python_method* is a member function.  

            This constructor variant is to be used with plCndDeterministic.  

        """
        this = _probt_python3.new_plPythonExternalFunction(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this
    __swig_destroy__ = _probt_python3.delete_plPythonExternalFunction
    __del__ = lambda self: None
plPythonExternalFunction_swigregister = _probt_python3.plPythonExternalFunction_swigregister
plPythonExternalFunction_swigregister(plPythonExternalFunction)

class plExternalProbFunction(plUserFunction):
    """

    `plExternalProbFunction()`  
    `plExternalProbFunction(const plExternalProbFunction &f)`  
    `plExternalProbFunction(const plVariablesConjunction &variables, callback_t
        function, std::string func_name="")`  
    `plExternalProbFunction(const plVariablesConjunction &variables, T *obj,
        plProbValue(T::*method)(const plValues &input_values), std::string
        func_name="")`  
    `plExternalProbFunction(const plVariablesConjunction &variables, const T *obj,
        plProbValue(T::*method)(const plValues &input_values) const, std::string
        func_name="")`  

    A function defined by the user to be used as a probability or a density
    function.  

    It's generaly used to define a *plAnonymousDistribution* or a
    *plCndAnonymousDistribution*.  

    Examples of creating and using plExternalProbFunction can be found in
    prob_func_example (plAnonymousDistribution) and in prob_func_cnd_example
    (plCndAnonymousDistribution).  

    Constructors
    ------------
    * `plExternalProbFunction()`  

        Default constructor.  

    * `plExternalProbFunction(const plExternalProbFunction &f)`  

    * `plExternalProbFunction(const plVariablesConjunction &variables, callback_t
        function, std::string func_name="")`  

        Defines an anonymous probability (density) C function with print name
        *func_name* where *P(variables)* = *function(variables)*.  

    * `plExternalProbFunction(const plVariablesConjunction &variables, T *obj,
        plProbValue(T::*method)(const plValues &input_values), std::string
        func_name="")`  

        Defines an anonymous probability (density) method with print name
        *func_name* where *P(variables)* = *obj->method(variables)*.  

    * `plExternalProbFunction(const plVariablesConjunction &variables, const T *obj,
        plProbValue(T::*method)(const plValues &input_values) const, std::string
        func_name="")`  

        Defines an anonymous probability (density) method with print name
        *func_name* where *P(variables)* = *obj->method(variables)*.  

    C++ includes: plExternalProbFunction.h

    """

    __swig_setmethods__ = {}
    for _s in [plUserFunction]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plExternalProbFunction, name, value)
    __swig_getmethods__ = {}
    for _s in [plUserFunction]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plExternalProbFunction, name)
    __repr__ = _swig_repr
    __swig_destroy__ = _probt_python3.delete_plExternalProbFunction
    __del__ = lambda self: None

    def __init__(self, *args):
        """
        __init__(self) -> plExternalProbFunction
        __init__(self, f) -> plExternalProbFunction
        __init__(self, variables, function, func_name) -> plExternalProbFunction
        __init__(self, variables, function) -> plExternalProbFunction


        `plExternalProbFunction()`  
        `plExternalProbFunction(const plExternalProbFunction &f)`  
        `plExternalProbFunction(const plVariablesConjunction &variables, callback_t
            function, std::string func_name="")`  
        `plExternalProbFunction(const plVariablesConjunction &variables, T *obj,
            plProbValue(T::*method)(const plValues &input_values), std::string
            func_name="")`  
        `plExternalProbFunction(const plVariablesConjunction &variables, const T *obj,
            plProbValue(T::*method)(const plValues &input_values) const, std::string
            func_name="")`  

        Overloaded function
        -------------------
        * `plExternalProbFunction()`  

            Default constructor.  

        * `plExternalProbFunction(const plExternalProbFunction &f)`  

        * `plExternalProbFunction(const plVariablesConjunction &variables, callback_t
            function, std::string func_name="")`  

            Defines an anonymous probability (density) C function with print name
            *func_name* where *P(variables)* = *function(variables)*.  

        * `plExternalProbFunction(const plVariablesConjunction &variables, T *obj,
            plProbValue(T::*method)(const plValues &input_values), std::string
            func_name="")`  

            Defines an anonymous probability (density) method with print name
            *func_name* where *P(variables)* = *obj->method(variables)*.  

        * `plExternalProbFunction(const plVariablesConjunction &variables, const T *obj,
            plProbValue(T::*method)(const plValues &input_values) const, std::string
            func_name="")`  

            Defines an anonymous probability (density) method with print name
            *func_name* where *P(variables)* = *obj->method(variables)*.  

        """
        this = _probt_python3.new_plExternalProbFunction(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def assign_from(self, other: 'plExternalProbFunction') -> "plExternalProbFunction &":
        """
        assign_from(self, other) -> plExternalProbFunction


        `assign_from(const plExternalProbFunction &other) -> plExternalProbFunction &`  

        Same as operator=()  

        """
        return _probt_python3.plExternalProbFunction_assign_from(self, other)


    def __call__(self, values: 'plValues') -> "plProbValue":
        """__call__(self, values) -> plProbValue"""
        return _probt_python3.plExternalProbFunction___call__(self, values)


    def get_variables(self) -> "plVariablesConjunction":
        """
        get_variables(self) -> plVariablesConjunction


        `get_variables() const -> plVariablesConjunction`  

        Returns the variables of the function.  

        """
        return _probt_python3.plExternalProbFunction_get_variables(self)


    def set_has_side_effect(self, hse: 'bool') -> "void":
        """
        set_has_side_effect(self, hse)


        `set_has_side_effect(bool hse)`  

        Set/unset the *has_side_effect* flag of the function.  

        The *has_side_effect* flag is used for deciding if distributions using the
        function are cached or not in the inference process. The default value of this
        flag is *false*.  

        See also: has_side_effect  

        """
        return _probt_python3.plExternalProbFunction_set_has_side_effect(self, hse)


    def has_side_effect(self) -> "bool":
        """
        has_side_effect(self) -> bool


        `has_side_effect() const -> bool`  

        Return the *has_side_effect* flag of the function.  

        See also: set_has_side_effect  

        """
        return _probt_python3.plExternalProbFunction_has_side_effect(self)


    def get_name(self) -> "std::string const &":
        """
        get_name(self) -> std::string const &


        `get_name() const -> const std::string &`  

        """
        return _probt_python3.plExternalProbFunction_get_name(self)

plExternalProbFunction_swigregister = _probt_python3.plExternalProbFunction_swigregister
plExternalProbFunction_swigregister(plExternalProbFunction)

class plExternalProbObjectInterface(_object):
    """


    """

    __swig_setmethods__ = {}
    __setattr__ = lambda self, name, value: _swig_setattr(self, plExternalProbObjectInterface, name, value)
    __swig_getmethods__ = {}
    __getattr__ = lambda self, name: _swig_getattr(self, plExternalProbObjectInterface, name)

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined - class is abstract")
    __repr__ = _swig_repr
    __swig_destroy__ = _probt_python3.delete_plExternalProbObjectInterface
    __del__ = lambda self: None

    def f(self, input_values: 'plValues') -> "plProbValue":
        """
        f(self, input_values) -> plProbValue


        `f(plValues const &input_values)=0 -> plProbValue`  

        """
        return _probt_python3.plExternalProbObjectInterface_f(self, input_values)

plExternalProbObjectInterface_swigregister = _probt_python3.plExternalProbObjectInterface_swigregister
plExternalProbObjectInterface_swigregister(plExternalProbObjectInterface)


def plCreateExternalProbFunction(*args) -> "plExternalProbFunction":
    """
    plCreateExternalProbFunction(input_variables, object, func_name) -> plExternalProbFunction
    plCreateExternalProbFunction(input_variables, object) -> plExternalProbFunction


    `plCreateExternalProbFunction(plVariablesConjunction const &input_variables,
        plExternalProbObjectInterface *object, std::string const &func_name="") ->
        PL_DLL_API plExternalProbFunction`  

    """
    return _probt_python3.plCreateExternalProbFunction(*args)
class plExternalProbFunctionFromSource(plExternalProbFunction):
    """

    `plExternalProbFunctionFromSource()`  
    `plExternalProbFunctionFromSource(const plExternalProbFunction &other)`  

    A special kind of plExternalProbFunction defined by dynamically compiling source
    code provided by the user.  

    The advantage over normal plExternalProbFunction objects is that instances of
    this class are guaranteed to be serializable.  

    Constructors
    ------------
    * `plExternalProbFunctionFromSource()`  

    * `plExternalProbFunctionFromSource(const plExternalProbFunction &other)`  

        Promote from a plExternalProbFunction.  

        If the object being copied is actually of the wrong type, an exception is
        raised.  

    C++ includes: plExternalProbFunctionFromSource.h

    """

    __swig_setmethods__ = {}
    for _s in [plExternalProbFunction]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plExternalProbFunctionFromSource, name, value)
    __swig_getmethods__ = {}
    for _s in [plExternalProbFunction]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plExternalProbFunctionFromSource, name)
    __repr__ = _swig_repr

    def __init__(self, *args):
        """
        __init__(self) -> plExternalProbFunctionFromSource
        __init__(self, other) -> plExternalProbFunctionFromSource


        `plExternalProbFunctionFromSource()`  
        `plExternalProbFunctionFromSource(const plExternalProbFunction &other)`  

        Overloaded function
        -------------------
        * `plExternalProbFunctionFromSource()`  

        * `plExternalProbFunctionFromSource(const plExternalProbFunction &other)`  

            Promote from a plExternalProbFunction.  

            If the object being copied is actually of the wrong type, an exception is
            raised.  

        """
        this = _probt_python3.new_plExternalProbFunctionFromSource(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def get_code(self) -> "std::string":
        """
        get_code(self) -> std::string


        `get_code() const -> std::string`  

        Get the source code.  

        """
        return _probt_python3.plExternalProbFunctionFromSource_get_code(self)

    __swig_destroy__ = _probt_python3.delete_plExternalProbFunctionFromSource
    __del__ = lambda self: None
plExternalProbFunctionFromSource_swigregister = _probt_python3.plExternalProbFunctionFromSource_swigregister
plExternalProbFunctionFromSource_swigregister(plExternalProbFunctionFromSource)

class plExternalProbFunctionFromC(plExternalProbFunctionFromSource):
    """

    `plExternalProbFunctionFromC()`  
    `plExternalProbFunctionFromC(const plExternalProbFunction &other)`  
    `plExternalProbFunctionFromC(const plVariablesConjunction &variables, const
        std::string &func_code, std::string func_name)`  

    A special kind of plExternalProbFunction defined by dynamically compiling C
    source code provided by the user.  

    The advantage over normal plExternalProbFunction is that this class can be
    serialized.  

    Constructors
    ------------
    * `plExternalProbFunctionFromC()`  

    * `plExternalProbFunctionFromC(const plExternalProbFunction &other)`  

        Promote from a plExternalProbFunction.  

        If the object being copied is actually of the wrong type, an exception is
        raised.  

    * `plExternalProbFunctionFromC(const plVariablesConjunction &variables, const
        std::string &func_code, std::string func_name)`  

        Defines an anonymous probability (density) C function with print name
        *func_name* where *P(variables)* = *function(variables)*.  

        This version is for dynamically compiled C functions.  

    C++ includes: plExternalProbFunctionFromC.h

    """

    __swig_setmethods__ = {}
    for _s in [plExternalProbFunctionFromSource]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plExternalProbFunctionFromC, name, value)
    __swig_getmethods__ = {}
    for _s in [plExternalProbFunctionFromSource]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plExternalProbFunctionFromC, name)
    __repr__ = _swig_repr

    def __init__(self, *args):
        """
        __init__(self) -> plExternalProbFunctionFromC
        __init__(self, other) -> plExternalProbFunctionFromC
        __init__(self, variables, func_code, func_name) -> plExternalProbFunctionFromC


        `plExternalProbFunctionFromC()`  
        `plExternalProbFunctionFromC(const plExternalProbFunction &other)`  
        `plExternalProbFunctionFromC(const plVariablesConjunction &variables, const
            std::string &func_code, std::string func_name)`  

        Overloaded function
        -------------------
        * `plExternalProbFunctionFromC()`  

        * `plExternalProbFunctionFromC(const plExternalProbFunction &other)`  

            Promote from a plExternalProbFunction.  

            If the object being copied is actually of the wrong type, an exception is
            raised.  

        * `plExternalProbFunctionFromC(const plVariablesConjunction &variables, const
            std::string &func_code, std::string func_name)`  

            Defines an anonymous probability (density) C function with print name
            *func_name* where *P(variables)* = *function(variables)*.  

            This version is for dynamically compiled C functions.  

        """
        this = _probt_python3.new_plExternalProbFunctionFromC(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def add_symbol(self, name: 'std::string const &', addr: 'void *') -> "void":
        """
        add_symbol(self, name, addr)


        `add_symbol(const std::string &name, void *addr)`  

        Make a local symbol accessible to the dynamically compiled code.  

        This must be done before the function is associated to a distribution.  

        """
        return _probt_python3.plExternalProbFunctionFromC_add_symbol(self, name, addr)


    def __getstate__(self) -> "std::string":
        """__getstate__(self) -> std::string"""
        return _probt_python3.plExternalProbFunctionFromC___getstate__(self)


    def __setstate_internal(self, sState: 'std::string const &') -> "void":
        """__setstate_internal(self, sState)"""
        return _probt_python3.plExternalProbFunctionFromC___setstate_internal(self, sState)


    def __setstate__(self, sState):
        self.__init__()
        self.__setstate_internal(sState)

    __swig_destroy__ = _probt_python3.delete_plExternalProbFunctionFromC
    __del__ = lambda self: None
plExternalProbFunctionFromC_swigregister = _probt_python3.plExternalProbFunctionFromC_swigregister
plExternalProbFunctionFromC_swigregister(plExternalProbFunctionFromC)


def createExternalProbFunctionFromC(input: 'plVariablesConjunction', code: 'std::string const &', name: 'std::string const &') -> "plExternalProbFunctionFromC":
    """
    createExternalProbFunctionFromC(input, code, name) -> plExternalProbFunctionFromC


    `createExternalProbFunctionFromC(const plVariablesConjunction &input, const
        std::string &code, const std::string &name) -> PL_DLL_API
        plExternalProbFunctionFromC`  

    Helper function for creating plExternalProbFunctionFromC objects.  

    This takes the function body as input, and takes care of generating the function
    header and footer such as you can use directly the variable names in the code.
    The returned probability value of the function is the value of the variable
    "result".  

    """
    return _probt_python3.createExternalProbFunctionFromC(input, code, name)
class plPythonExternalProbFunction(plExternalProbFunction):
    """

    `plPythonExternalProbFunction(const plVariablesConjunction &variables, PyObject
        *python_function, std::string function_name="")`  
    `plPythonExternalProbFunction(const plVariablesConjunction &variables, PyObject
        *python_instance, PyObject *python_method, std::string function_name="")`  

    This class is intended to be used from the Python bindings only.  

    It defines a Python callback function defined by the user to be used as a
    probability or a density function. It's generaly used to define a
    *plAnonymousDistribution* or a *plCndAnonymousDistribution*.  

    Examples of creating and using plExternalProbFunction can be found in
    prob_func_example (plAnonymousDistribution) and in prob_func_cnd_example
    (plCndAnonymousDistribution).  

    Constructors
    ------------
    * `plPythonExternalProbFunction(const plVariablesConjunction &variables,
        PyObject *python_function, std::string function_name="")`  

        Defines an anonymous probability (density) using a Python non-member
        function with print name *function_name* where *P(variables)* =
        *python_function(variables)*.  

    * `plPythonExternalProbFunction(const plVariablesConjunction &variables,
        PyObject *python_instance, PyObject *python_method, std::string
        function_name="")`  

        Defines an anonymous probability (density) using a Python member function
        (method) with print name *function_name* where *P(variables)* =
        *python_instance.python_method(variables)*.  

    C++ includes: plPythonExternalProbFunction.h

    """

    __swig_setmethods__ = {}
    for _s in [plExternalProbFunction]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plPythonExternalProbFunction, name, value)
    __swig_getmethods__ = {}
    for _s in [plExternalProbFunction]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plPythonExternalProbFunction, name)
    __repr__ = _swig_repr

    def __init__(self, *args):
        """
        __init__(self, variables, python_function, function_name) -> plPythonExternalProbFunction
        __init__(self, variables, python_function) -> plPythonExternalProbFunction
        __init__(self, variables, python_instance, python_method, function_name) -> plPythonExternalProbFunction
        __init__(self, variables, python_instance, python_method) -> plPythonExternalProbFunction


        `plPythonExternalProbFunction(const plVariablesConjunction &variables, PyObject
            *python_function, std::string function_name="")`  
        `plPythonExternalProbFunction(const plVariablesConjunction &variables, PyObject
            *python_instance, PyObject *python_method, std::string function_name="")`  

        Overloaded function
        -------------------
        * `plPythonExternalProbFunction(const plVariablesConjunction &variables,
            PyObject *python_function, std::string function_name="")`  

            Defines an anonymous probability (density) using a Python non-member
            function with print name *function_name* where *P(variables)* =
            *python_function(variables)*.  

        * `plPythonExternalProbFunction(const plVariablesConjunction &variables,
            PyObject *python_instance, PyObject *python_method, std::string
            function_name="")`  

            Defines an anonymous probability (density) using a Python member function
            (method) with print name *function_name* where *P(variables)* =
            *python_instance.python_method(variables)*.  

        """
        this = _probt_python3.new_plPythonExternalProbFunction(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this
    __swig_destroy__ = _probt_python3.delete_plPythonExternalProbFunction
    __del__ = lambda self: None
plPythonExternalProbFunction_swigregister = _probt_python3.plPythonExternalProbFunction_swigregister
plPythonExternalProbFunction_swigregister(plPythonExternalProbFunction)

class plJointDistribution(plDistribution):
    """

    `plJointDistribution()`  
    `plJointDistribution(const plVariablesConjunction &all_params, const
        plDistribution &f)`  
    `plJointDistribution(const plDistribution &f)`  
    `plJointDistribution(const plVariablesConjunction &all_params, const
        plComputableObjectList &decomposition)`  
    `plJointDistribution(const plComputableObjectList &decomposition)`  
    `plJointDistribution(const plJointDistribution &other)`  

    The *plJointDistribution* class is used to describe a probabilistic model by
    providing a decomposition of the joint distribution of the whole model variables
    as a product of elementary conditional and non conditional distributions.  

    Defining this decomposition is equivalent to the graph construction part in
    standard Bayesian Networks (BN) creation tools, while defining the parametric
    forms of the elementary distributions corresponds to the probability assessment
    part in standard BN creation tools.  

    Therefore, a *plJointDistribution* object contains both the structural
    information (i.e dependencies between variables) and information on the
    parametric forms of the used elementary distributions (already constructed and
    passed as parameters to the constructor).  

    Given a *plJointDistribution* object, one can infer any target (query)
    distribution using the *ask* methods to construct the corresponding *exact* or
    *approximate* (Monte Carlo) expression (see the *ask* methods and their
    parameters) using Bayes rule and some other symbolic simplifications.  

    Constructors
    ------------
    * `plJointDistribution()`  

        Default constructor used for serialization.  

    * `plJointDistribution(const plVariablesConjunction &all_params, const
        plDistribution &f)`  

        Creates a joint distribution (probabilistic model) using a single
        distribution.  

    * `plJointDistribution(const plDistribution &f)`  

        Creates a joint distribution (probabilistic model) using a single
        distribution.  

    * `plJointDistribution(const plVariablesConjunction &all_params, const
        plComputableObjectList &decomposition)`  

        Creates a joint distribution (probabilistic model) as a product of
        distributions.  

    * `plJointDistribution(const plComputableObjectList &decomposition)`  

        Creates a joint distribution (probabilistic model) as a product of
        distributions.  

        The variables of the constructed computable object are the concatenation (in
        the same order) of the left variables of all the terms of the list.  

    * `plJointDistribution(const plJointDistribution &other)`  

        Copy constructor.  

    C++ includes: plJointDistribution.h

    """

    __swig_setmethods__ = {}
    for _s in [plDistribution]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plJointDistribution, name, value)
    __swig_getmethods__ = {}
    for _s in [plDistribution]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plJointDistribution, name)
    __repr__ = _swig_repr

    def __init__(self, *args):
        """
        __init__(self) -> plJointDistribution
        __init__(self, all_params, f) -> plJointDistribution
        __init__(self, f) -> plJointDistribution
        __init__(self, all_params, decomposition) -> plJointDistribution
        __init__(self, decomposition) -> plJointDistribution
        __init__(self, other) -> plJointDistribution


        `plJointDistribution()`  
        `plJointDistribution(const plVariablesConjunction &all_params, const
            plDistribution &f)`  
        `plJointDistribution(const plDistribution &f)`  
        `plJointDistribution(const plVariablesConjunction &all_params, const
            plComputableObjectList &decomposition)`  
        `plJointDistribution(const plComputableObjectList &decomposition)`  
        `plJointDistribution(const plJointDistribution &other)`  

        Overloaded function
        -------------------
        * `plJointDistribution()`  

            Default constructor used for serialization.  

        * `plJointDistribution(const plVariablesConjunction &all_params, const
            plDistribution &f)`  

            Creates a joint distribution (probabilistic model) using a single
            distribution.  

        * `plJointDistribution(const plDistribution &f)`  

            Creates a joint distribution (probabilistic model) using a single
            distribution.  

        * `plJointDistribution(const plVariablesConjunction &all_params, const
            plComputableObjectList &decomposition)`  

            Creates a joint distribution (probabilistic model) as a product of
            distributions.  

        * `plJointDistribution(const plComputableObjectList &decomposition)`  

            Creates a joint distribution (probabilistic model) as a product of
            distributions.  

            The variables of the constructed computable object are the concatenation (in
            the same order) of the left variables of all the terms of the list.  

        * `plJointDistribution(const plJointDistribution &other)`  

            Copy constructor.  

        """
        this = _probt_python3.new_plJointDistribution(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this
    __swig_destroy__ = _probt_python3.delete_plJointDistribution
    __del__ = lambda self: None

    def draw_graph(self, *args) -> "void":
        """
        draw_graph(self, file_name, drawing_language)
        draw_graph(self, file_name)
        draw_graph(self, graph)


        `draw_graph(std::ostream &out, plDrawingLanguage drawing_language=PL_XFIG_GRAPH)
            const`  
        `draw_graph(const std::string &file_name, plDrawingLanguage
            drawing_language=PL_XFIG_GRAPH) const`  
        `draw_graph(const char *file_name, plDrawingLanguage
            drawing_language=PL_XFIG_GRAPH) const`  
        `draw_graph(plGraph &graph) const`  

        Overloaded function
        -------------------
        * `draw_graph(std::ostream &out, plDrawingLanguage
            drawing_language=PL_XFIG_GRAPH) const`  

            Writes the drawing instructions to represent the Graph of the joint
            distribution on the ostream out.  

            The current implementation allows using xfig and graphvis dot.  

        * `draw_graph(const std::string &file_name, plDrawingLanguage
            drawing_language=PL_XFIG_GRAPH) const`  

            Writes the drawing instructions to represent the Graph of the joint
            distribution in *file_name*.  

            The current implementation allows using xfig and graphvis dot.  

        * `draw_graph(const char *file_name, plDrawingLanguage
            drawing_language=PL_XFIG_GRAPH) const`  

            Writes the drawing instructions to represent the Graph of the joint
            distribution in *file_name*.  

            The current implementation allows using xfig and graphvis dot.  

        * `draw_graph(plGraph &graph) const`  

            Sets the object *graph* so that it contains the necessary information for
            drawing a graphical representation of the joint distribution.  

        """
        return _probt_python3.plJointDistribution_draw_graph(self, *args)


    def as_graph_dot(self, *args) -> "std::string":
        """
        as_graph_dot(self, dot_graph_label, dot_node_shape, dot_node_color, dot_node_fill_color, dot_background_color, dot_edge_color, dot_rankdir) -> std::string
        as_graph_dot(self, dot_graph_label, dot_node_shape, dot_node_color, dot_node_fill_color, dot_background_color, dot_edge_color) -> std::string
        as_graph_dot(self, dot_graph_label, dot_node_shape, dot_node_color, dot_node_fill_color, dot_background_color) -> std::string
        as_graph_dot(self, dot_graph_label, dot_node_shape, dot_node_color, dot_node_fill_color) -> std::string
        as_graph_dot(self, dot_graph_label, dot_node_shape, dot_node_color) -> std::string
        as_graph_dot(self, dot_graph_label, dot_node_shape) -> std::string
        as_graph_dot(self, dot_graph_label) -> std::string
        as_graph_dot(self) -> std::string


        `as_graph_dot(const std::string &dot_graph_label="", const std::string
            &dot_node_shape="ellipse", const std::string &dot_node_color="black",
            const std::string &dot_node_fill_color="lightblue", const std::string
            &dot_background_color="white", const std::string
            &dot_edge_color="black", const std::string &dot_rankdir="TD") const ->
            std::string`  

        Return the graphvis dot drawing instructions to represent the graph of the joint
        distribution.  

        """
        return _probt_python3.plJointDistribution_as_graph_dot(self, *args)


    def draw_graph_dot(self, *args) -> "void":
        """
        draw_graph_dot(self, file_name, dot_graph_label, dot_node_shape, dot_node_color, dot_node_fill_color, dot_background_color, dot_edge_color, dot_rankdir)
        draw_graph_dot(self, file_name, dot_graph_label, dot_node_shape, dot_node_color, dot_node_fill_color, dot_background_color, dot_edge_color)
        draw_graph_dot(self, file_name, dot_graph_label, dot_node_shape, dot_node_color, dot_node_fill_color, dot_background_color)
        draw_graph_dot(self, file_name, dot_graph_label, dot_node_shape, dot_node_color, dot_node_fill_color)
        draw_graph_dot(self, file_name, dot_graph_label, dot_node_shape, dot_node_color)
        draw_graph_dot(self, file_name, dot_graph_label, dot_node_shape)
        draw_graph_dot(self, file_name, dot_graph_label)
        draw_graph_dot(self, file_name)


        `draw_graph_dot(std::ostream &out, const std::string &dot_graph_label="",
            const std::string &dot_node_shape="ellipse", const std::string
            &dot_node_color="black", const std::string
            &dot_node_fill_color="lightblue", const std::string
            &dot_background_color="white", const std::string
            &dot_edge_color="black", const std::string &dot_rankdir="TD") const`  
        `draw_graph_dot(const std::string &file_name, const std::string
            &dot_graph_label="", const std::string &dot_node_shape="ellipse", const
            std::string &dot_node_color="black", const std::string
            &dot_node_fill_color="lightblue", const std::string
            &dot_background_color="white", const std::string
            &dot_edge_color="black", const std::string &dot_rankdir="TD") const`  

        Overloaded function
        -------------------
        * `draw_graph_dot(std::ostream &out, const std::string &dot_graph_label="",
            const std::string &dot_node_shape="ellipse", const std::string
            &dot_node_color="black", const std::string
            &dot_node_fill_color="lightblue", const std::string
            &dot_background_color="white", const std::string
            &dot_edge_color="black", const std::string &dot_rankdir="TD") const`  

            Writes the graphvis dot drawing instructions to represent the graph of the
            joint distribution on the ostream out.  

            The parameters dot_node_shape, dot_node_color, dot_node_fill_color,
            dot_background_color, and dot_rankdir correspond to graphiz dot ones (see
            http://www.graphviz.org/pdf/dotguide.pdf). There values will be inserted in
            the generated dot file without checking their validity.  

        * `draw_graph_dot(const std::string &file_name, const std::string
            &dot_graph_label="", const std::string &dot_node_shape="ellipse", const
            std::string &dot_node_color="black", const std::string
            &dot_node_fill_color="lightblue", const std::string
            &dot_background_color="white", const std::string
            &dot_edge_color="black", const std::string &dot_rankdir="TD") const`  

            Writes the graphvis dot drawing instructions to represent the graph of the
            joint distribution in *file_name*.  

            The parameters dot_node_shape, dot_node_color, dot_node_fill_color,
            dot_background_color, and dot_rankdir correspond to graphiz dot ones (see
            http://www.graphviz.org/pdf/dotguide.pdf). There values will be inserted in
            the generated dot file without checking their validity.  

        """
        return _probt_python3.plJointDistribution_draw_graph_dot(self, *args)


    def python_draw_graph(self) -> "void":
        """
        python_draw_graph(self)


        `python_draw_graph()`  

        Only for Python: Same as draw_graph_dot() above.  

        """
        return _probt_python3.plJointDistribution_python_draw_graph(self)


    def ask(self, *args) -> "plDistribution":
        """
        ask(self, CndExpr, searched_variables, known_variables, optimization=PL_NO_OPTIMIZATION, do_not_build_normalization_expression=False)
        ask(self, CndExpr, searched_variables, known_variables, optimization=PL_NO_OPTIMIZATION)
        ask(self, CndExpr, searched_variables, known_variables)
        ask(self, searched_variables, known_variables, optimization=PL_NO_OPTIMIZATION, do_not_build_normalization_expression=False) -> plCndDistribution
        ask(self, searched_variables, known_variables, optimization=PL_NO_OPTIMIZATION) -> plCndDistribution
        ask(self, searched_variables, known_variables) -> plCndDistribution
        ask(self, Expr, searched_variables, optimization=PL_NO_OPTIMIZATION)
        ask(self, Expr, searched_variables)
        ask(self, searched_variables, optimization=PL_NO_OPTIMIZATION) -> plDistribution
        ask(self, searched_variables) -> plDistribution


        `ask(plCndDistribution &CndExpr, const plVariablesConjunction
            &searched_variables, const plVariablesConjunction &known_variables,
            plOptimizationCriterion optimization=PL_NO_OPTIMIZATION, bool
            do_not_build_normalization_expression=false) const`  
        `ask(const plVariablesConjunction &searched_variables, const
            plVariablesConjunction &known_variables, plOptimizationCriterion
            optimization=PL_NO_OPTIMIZATION, bool
            do_not_build_normalization_expression=false) const -> plCndDistribution`  
        `ask(plDistribution &Expr, const plVariablesConjunction &searched_variables,
            plOptimizationCriterion optimization=PL_NO_OPTIMIZATION) const`  
        `ask(const plVariablesConjunction &searched_variables, plOptimizationCriterion
            optimization=PL_NO_OPTIMIZATION) const -> plDistribution`  

        Overloaded function
        -------------------
        * `ask(plCndDistribution &CndExpr, const plVariablesConjunction
            &searched_variables, const plVariablesConjunction &known_variables,
            plOptimizationCriterion optimization=PL_NO_OPTIMIZATION, bool
            do_not_build_normalization_expression=false) const`  

            Creates a conditional probability expression P(searched_variables |
            known_variables) using exact marginalization over the missing variables.  

            This requires that the marginalized variables are discrete (otherwise, use
            ask_mc_nsamples() or ask_mc_convergence()).  

            Parameters:  
            * `CndExpr` :  
                The conditional probability expression resulting from the query.  
            * `searched_variables` :  
                The searched (left) variables of the question.  
            * `known_variables` :  
                The known (right) variables of the question.  
            * `optimization` :  
                The optimality criterion when constructing the evaluation tree.  
            * `do_not_build_normalization_expression` :  
                Set it to *true*, if you don't need to compute the normalization any
                more. You should use the default value (*false*) unless you know what
                you are doing.  

            The optimality criterion *optimization* should take a value among:  

            1) PL_NO_OPTIMIZATION will not attempt to optimize the expression for any
            particular purpose.  
             2) PL_OPTIMIZE_COMPILATION_TIME will optimize the expression for the first
            instantiate-compile sequence that will follow (usage pattern: ask-
            instantiate-compile).  
             3) PL_OPTIMIZE_UPDATE_TIME will optimize the expression for repeated
            instantiate-compile sequences (usage pattern: ask once, instantiate-compile
            many times).  
             4) PL_OPTIMIZE_MEMORY_USE will optimize the expression for minimal memory
            use.  
             You may inspect the produced evaluation tree using
            plComputableObject::print_evaluation_tree_infos().  
             Note that to take advantage of these optimizations, you must use the forms
            of plCndDistribution::instantiate() and plDistribution::compile() that give
            their result in their first argument (by reference) and return void, not
            those that return their result directly. Also, only the exhaustive
            plDistribution::compile() can take advantage of these optimization hints.
            plDistribution::n_compile() and plDistribution::time_compile(), for
            instance, will not be able to use them.  

        * `ask(const plVariablesConjunction &searched_variables, const
            plVariablesConjunction &known_variables, plOptimizationCriterion
            optimization=PL_NO_OPTIMIZATION, bool
            do_not_build_normalization_expression=false) const -> plCndDistribution`  

            Same as ask(plCndDistribution &, const plVariablesConjunction &, const
            plVariablesConjunction &, plOptimizationCriterion, bool) above but returns a
            freshly created plCndDistribution object.  

            If you are calling it in a loop, consider using the version that modifies an
            existing object instead.  

        * `ask(plDistribution &Expr, const plVariablesConjunction &searched_variables,
            plOptimizationCriterion optimization=PL_NO_OPTIMIZATION) const`  

            Creates a non conditional probability expression P(searched_variables) using
            exact marginalization over the missing variables.  

            This requires that the marginalized variables are discrete (otherwise, use
            ask_mc_nsamples() or ask_mc_convergence()).  

            Parameters:  
            * `Expr` :  
                The non conditional probability expression resulting from the query.  
            * `searched_variables` :  
                The searched (left) variables of the question.  
            * `optimization` :  
                The optimality criterion when constructing the evaluation tree.  

            The optimality criterion *optimization* should take a value among:  

            1) PL_NO_OPTIMIZATION will not attempt to optimize the expression for any
            particular purpose.  
             2) PL_OPTIMIZE_COMPILATION_TIME will optimize the expression for the first
            instantiate-compile sequence that will follow (usage pattern: ask-
            instantiate-compile).  
             3) PL_OPTIMIZE_UPDATE_TIME will optimize the expression for repeated
            instantiate-compile sequences (usage pattern: ask once, instantiate-compile
            many times).  
             4) PL_OPTIMIZE_MEMORY_USE will optimize the expression for minimal memory
            use.  
             You may inspect the produced evaluation tree using
            plComputableObject::print_evaluation_tree_infos().  

        * `ask(const plVariablesConjunction &searched_variables, plOptimizationCriterion
            optimization=PL_NO_OPTIMIZATION) const -> plDistribution`  

            Same as ask(plDistribution &, const plVariablesConjunction &,
            plOptimizationCriterion) above but returns a freshly created plDistribution
            object.  

        """
        return _probt_python3.plJointDistribution_ask(self, *args)


    def ask_mc_nsamples(self, *args) -> "plDistribution":
        """
        ask_mc_nsamples(self, CndExpr, searched_variables, known_variables, mc_nsamples, do_not_build_normalization_expression=False)
        ask_mc_nsamples(self, CndExpr, searched_variables, known_variables, mc_nsamples)
        ask_mc_nsamples(self, searched_variables, known_variables, mc_nsamples, do_not_build_normalization_expression=False) -> plCndDistribution
        ask_mc_nsamples(self, searched_variables, known_variables, mc_nsamples) -> plCndDistribution
        ask_mc_nsamples(self, Expr, searched_variables, mc_nsamples)
        ask_mc_nsamples(self, searched_variables, mc_nsamples) -> plDistribution


        `ask_mc_nsamples(plCndDistribution &CndExpr, const plVariablesConjunction
            &searched_variables, const plVariablesConjunction &known_variables, int
            mc_nsamples, bool do_not_build_normalization_expression=false) const`  
        `ask_mc_nsamples(const plVariablesConjunction &searched_variables, const
            plVariablesConjunction &known_variables, int mc_nsamples, bool
            do_not_build_normalization_expression=false) const -> plCndDistribution`  
        `ask_mc_nsamples(plDistribution &Expr, const plVariablesConjunction
            &searched_variables, int mc_nsamples) const`  
        `ask_mc_nsamples(const plVariablesConjunction &searched_variables, int
            mc_nsamples) const -> plDistribution`  

        Overloaded function
        -------------------
        * `ask_mc_nsamples(plCndDistribution &CndExpr, const plVariablesConjunction
            &searched_variables, const plVariablesConjunction &known_variables, int
            mc_nsamples, bool do_not_build_normalization_expression=false) const`  

            Creates a conditional probability expression P(searched_variables |
            known_variables) using Monte Carlo marginalization over the missing
            variables.  

            Parameters:  
            * `CndExpr` :  
                The conditional probability expression resulting from the query.  
            * `searched_variables` :  
                The searched (left) variables of the question.  
            * `known_variables` :  
                The known (right) variables of the question.  
            * `mc_nsamples` :  
                The number of Monte Carlo sample points to be used for approximating
                marginalization (i.e., computation of the sums/integrals). When
                negative, the atual number will be n = -mc_nsamples x free_vars_dim in
                which free_vars_dim is the number of variables on which we will
                marginalize  
            * `do_not_build_normalization_expression` :  
                Set it to *true*, if you don't need to compute the normalization any
                more. You should use the default value (*false*) unless you know what
                you are doing.  

        * `ask_mc_nsamples(const plVariablesConjunction &searched_variables, const
            plVariablesConjunction &known_variables, int mc_nsamples, bool
            do_not_build_normalization_expression=false) const -> plCndDistribution`  

            Same as ask_mc_nsamples(plCndDistribution &, const plVariablesConjunction &,
            const plVariablesConjunction &, int, bool) above but returns a freshly
            created plCndDistribution object.  

        * `ask_mc_nsamples(plDistribution &Expr, const plVariablesConjunction
            &searched_variables, int mc_nsamples) const`  

            Creates a non conditional probability expression P(searched_variables) using
            Monte Carlo marginalization over the missing variables.  

            Parameters:  
            * `Expr` :  
                The non conditional probability expression resulting from the query.  
            * `searched_variables` :  
                The searched (left) variables of the question.  
            * `mc_nsamples` :  
                The number of Monte Carlo sample points to be used for approximating
                marginalization (i.e., computation of the sums/integrals). When
                negative, the atual number will be n = -mc_nsamples x free_vars_dim in
                which free_vars_dim is the number of variables on which we will
                marginalize  

        * `ask_mc_nsamples(const plVariablesConjunction &searched_variables, int
            mc_nsamples) const -> plDistribution`  

            Same as ask_mc_nsamples(plDistribution &, const plVariablesConjunction &,
            int) above but returns a freshly created plDistribution object.  

        """
        return _probt_python3.plJointDistribution_ask_mc_nsamples(self, *args)


    def ask_mc_convergence(self, *args) -> "plDistribution":
        """
        ask_mc_convergence(self, CndExpr, searched_variables, known_variables, conv_threshold, do_not_build_normalization_expression=False)
        ask_mc_convergence(self, CndExpr, searched_variables, known_variables, conv_threshold)
        ask_mc_convergence(self, searched_variables, known_variables, conv_threshold, do_not_build_normalization_expression=False) -> plCndDistribution
        ask_mc_convergence(self, searched_variables, known_variables, conv_threshold) -> plCndDistribution
        ask_mc_convergence(self, CndExpr, searched_variables, known_variables, conv_threshold, do_not_build_normalization_expression=False)
        ask_mc_convergence(self, CndExpr, searched_variables, known_variables, conv_threshold)
        ask_mc_convergence(self, searched_variables, known_variables, conv_threshold, do_not_build_normalization_expression=False) -> plCndDistribution
        ask_mc_convergence(self, searched_variables, known_variables, conv_threshold) -> plCndDistribution
        ask_mc_convergence(self, Expr, searched_variables, conv_threshold)
        ask_mc_convergence(self, searched_variables, conv_threshold) -> plDistribution
        ask_mc_convergence(self, Expr, searched_variables, conv_threshold)
        ask_mc_convergence(self, searched_variables, conv_threshold) -> plDistribution


        `ask_mc_convergence(plCndDistribution &CndExpr, const plVariablesConjunction
            &searched_variables, const plVariablesConjunction &known_variables, float
            conv_threshold, bool do_not_build_normalization_expression=false) const`  
        `ask_mc_convergence(const plVariablesConjunction &searched_variables, const
            plVariablesConjunction &known_variables, float conv_threshold, bool
            do_not_build_normalization_expression=false) const -> plCndDistribution`  
        `ask_mc_convergence(plCndDistribution &CndExpr, const plVariablesConjunction
            &searched_variables, const plVariablesConjunction &known_variables, double
            conv_threshold, bool do_not_build_normalization_expression=false) const`  
        `ask_mc_convergence(const plVariablesConjunction &searched_variables, const
            plVariablesConjunction &known_variables, double conv_threshold, bool
            do_not_build_normalization_expression=false) const -> plCndDistribution`  
        `ask_mc_convergence(plDistribution &Expr, const plVariablesConjunction
            &searched_variables, float conv_threshold) const`  
        `ask_mc_convergence(const plVariablesConjunction &searched_variables, float
            conv_threshold) const -> plDistribution`  
        `ask_mc_convergence(plDistribution &Expr, const plVariablesConjunction
            &searched_variables, double conv_threshold) const`  
        `ask_mc_convergence(const plVariablesConjunction &searched_variables, double
            conv_threshold) const -> plDistribution`  

        Overloaded function
        -------------------
        * `ask_mc_convergence(plCndDistribution &CndExpr, const plVariablesConjunction
            &searched_variables, const plVariablesConjunction &known_variables, float
            conv_threshold, bool do_not_build_normalization_expression=false) const`  

        * `ask_mc_convergence(const plVariablesConjunction &searched_variables, const
            plVariablesConjunction &known_variables, float conv_threshold, bool
            do_not_build_normalization_expression=false) const -> plCndDistribution`  

        * `ask_mc_convergence(plCndDistribution &CndExpr, const plVariablesConjunction
            &searched_variables, const plVariablesConjunction &known_variables, double
            conv_threshold, bool do_not_build_normalization_expression=false) const`  

            Creates a conditional probability expression P(searched_variables |
            known_variables) using Monte Carlo marginalization over the missing
            variables.  

            Parameters:  
            * `CndExpr` :  
                The conditional probability expression resulting from the query.  
            * `searched_variables` :  
                The searched (left) variables of the question.  
            * `known_variables` :  
                The known (right) variables of the question.  
            * `conv_threshold` :  
                The convergence threshold to be used for approximating marginalization.
                The computation of the sums (integrals) is performed using a number of
                points that allows convergence of the estimation according to the
                threshold value *conv_threshold:* | Estim(t) - Estim(t-1) | /
                (Estim(t)+Estim(t-1)/2.0) < conv_threshold.  
            * `do_not_build_normalization_expression` :  
                Set it to *true*, if you don't need to compute the normalization any
                more. You should use the default value (*false*) unless you know what
                you are doing.  

        * `ask_mc_convergence(const plVariablesConjunction &searched_variables, const
            plVariablesConjunction &known_variables, double conv_threshold, bool
            do_not_build_normalization_expression=false) const -> plCndDistribution`  

            Same as ask_mc_convergence(plCndDistribution &, const plVariablesConjunction
            &, const plVariablesConjunction &, double, bool) above but returns a freshly
            created plCndDistribution object.  

        * `ask_mc_convergence(plDistribution &Expr, const plVariablesConjunction
            &searched_variables, float conv_threshold) const`  

        * `ask_mc_convergence(const plVariablesConjunction &searched_variables, float
            conv_threshold) const -> plDistribution`  

        * `ask_mc_convergence(plDistribution &Expr, const plVariablesConjunction
            &searched_variables, double conv_threshold) const`  

            Creates a non conditional probability expression P(searched_variables) using
            Monte Carlo marginalization over the missing variables.  

            Parameters:  
            * `Expr` :  
                The conditional probability expression resulting from the query.  
            * `searched_variables` :  
                The searched (left) variables of the question.  
            * `conv_threshold` :  
                The convergence threshold to be used for approximating marginalization.
                The computation of the sums (integrals) is performed using a number of
                points that allows convergence of the estimation according to the
                threshold value *conv_threshold:* | Estim(t) - Estim(t-1) | /
                (Estim(t)+Estim(t-1)/2.0) < conv_threshold.  

        * `ask_mc_convergence(const plVariablesConjunction &searched_variables, double
            conv_threshold) const -> plDistribution`  

            Same as ask_mc_convergence(plDistribution &, const plVariablesConjunction &,
            double) above but returns a freshly created plDistribution object.  

        """
        return _probt_python3.plJointDistribution_ask_mc_convergence(self, *args)


    def get_computable_object_list(self) -> "plComputableObjectList":
        """
        get_computable_object_list(self) -> plComputableObjectList


        `get_computable_object_list() const -> plComputableObjectList`  

        Get back the list of computable objects.  

        """
        return _probt_python3.plJointDistribution_get_computable_object_list(self)


    def get_markov_blanket(self, s: 'plVariable') -> "plVariablesConjunction":
        """
        get_markov_blanket(self, s) -> plVariablesConjunction


        `get_markov_blanket(const plVariable &s) const -> plVariablesConjunction`  

        Return markov blanket for a given variable.  

        """
        return _probt_python3.plJointDistribution_get_markov_blanket(self, s)


    def set_soft_evidence_variables(self, variables: 'plVariablesConjunction') -> "void":
        """
        set_soft_evidence_variables(self, variables)


        `set_soft_evidence_variables(const plVariablesConjunction &variables)`  

        Set the potential soft evidence variables.  

        This ensures that the symbolic simplification does not remove the corresponding
        evaluation nodes  

        """
        return _probt_python3.plJointDistribution_set_soft_evidence_variables(self, variables)


    def get_soft_evidence_variables(self) -> "plVariablesConjunction":
        """
        get_soft_evidence_variables(self) -> plVariablesConjunction


        `get_soft_evidence_variables() const -> plVariablesConjunction`  

        Get the potential soft evidence variables.  

        """
        return _probt_python3.plJointDistribution_get_soft_evidence_variables(self)


    def clear_soft_evidence_variables(self) -> "void":
        """
        clear_soft_evidence_variables(self)


        `clear_soft_evidence_variables()`  

        Clear the potential soft evidence variables.  

        Equivalent to calling set_soft_evidence_variables(plVariablesConjunction())  

        """
        return _probt_python3.plJointDistribution_clear_soft_evidence_variables(self)


    def ancestral_order_variables(self) -> "plVariablesConjunction":
        """
        ancestral_order_variables(self) -> plVariablesConjunction


        `ancestral_order_variables() const -> plVariablesConjunction`  

        Get an ancestral ordering of the variables.  

        """
        return _probt_python3.plJointDistribution_ancestral_order_variables(self)


    def is_base_class(self) -> "bool":
        """
        is_base_class(self) -> bool


        `is_base_class() const -> bool`  

        """
        return _probt_python3.plJointDistribution_is_base_class(self)


    def save_as_genie(self, file_name: 'std::string const &') -> "void":
        """
        save_as_genie(self, file_name)


        `save_as_genie(const std::string &file_name) const`  

        Save as Genie xdsl file.  

        """
        return _probt_python3.plJointDistribution_save_as_genie(self, file_name)


    def load_from_genie(self, file_name: 'std::string const &') -> "void":
        """
        load_from_genie(self, file_name)


        `load_from_genie(const std::string &file_name)`  

        Load from a Genie xdsl file.  

        """
        return _probt_python3.plJointDistribution_load_from_genie(self, file_name)


    def save_as_netica(self, file_name: 'std::string const &') -> "void":
        """
        save_as_netica(self, file_name)


        `save_as_netica(const std::string &file_name) const`  

        Save as Netica dne file.  

        """
        return _probt_python3.plJointDistribution_save_as_netica(self, file_name)


    def load_from_netica(self, file_name: 'std::string const &') -> "void":
        """
        load_from_netica(self, file_name)


        `load_from_netica(const std::string &file_name)`  

        Load from a Netica dne file.  

        """
        return _probt_python3.plJointDistribution_load_from_netica(self, file_name)


    def save_as_hugin(self, file_name: 'std::string const &') -> "void":
        """
        save_as_hugin(self, file_name)


        `save_as_hugin(const std::string &file_name) const`  

        Save as Hugin net file.  

        """
        return _probt_python3.plJointDistribution_save_as_hugin(self, file_name)


    def load_from_hugin(self, file_name: 'std::string const &') -> "void":
        """
        load_from_hugin(self, file_name)


        `load_from_hugin(const std::string &file_name)`  

        Load from a Hugin net file.  

        """
        return _probt_python3.plJointDistribution_load_from_hugin(self, file_name)


    def __getstate__(self) -> "std::string":
        """__getstate__(self) -> std::string"""
        return _probt_python3.plJointDistribution___getstate__(self)


    def __setstate_internal(self, sState: 'std::string const &') -> "void":
        """__setstate_internal(self, sState)"""
        return _probt_python3.plJointDistribution___setstate_internal(self, sState)


    def __setstate__(self, sState):
        self.__init__()
        self.__setstate_internal(sState)

plJointDistribution_swigregister = _probt_python3.plJointDistribution_swigregister
plJointDistribution_swigregister(plJointDistribution)

class plJunctionTree(plObject):
    """

    `plJunctionTree()`  
    `plJunctionTree(plComputableObjectList const &decomposition)`  
    `plJunctionTree(plJointDistribution const &joint)`  
    `plJunctionTree(plJunctionTree const &)`  

    Implements exact inference using a junction tree.  

    A junction tree is a structure computed from a joint distribution, that allows
    estabshing formulas for answering questions in a way that maximises the amount
    of shared computations between different questions. For instance, a junction
    tree built from a decomposition of P(A B C) will be able to share intermediate
    numerical results used to answer P(A | c=0) and P(B | c=0), or P(A | c=0) and
    P(A | c=1).  

    A junction tree can only be built from a decomposition where all factors have
    exactly one left variable. Moreover, all factors must be discretizable
    distributions (distributions that can be compiled).  

    Asking a question to a plJunctionTree triggers transparently the construction of
    the tree (if necessary), and yields a symbolic expression in the form of a
    plJtDistribution or plCndJtDistribution. The resulting distribution can then be
    compiled, instantiated, as with other distributions.  

    In order to maximise sharing between questions having the same left variables,
    but different-but-included sets of right variables, such as: P(A), P(A | B), P(A
    | B C), P(A | B D), you should use specialise(), like so:  

    *   P(A) = junction_tree.ask(A)  
    *   P(A | B) = P(A).specialise(B)  
    *   P(A | B C) = P(A | B).specialise(C)  
    *   P(A | B D) = P(A | B).specialise(D)  

    This will result in a better sharing than the one obtained from asking all these
    questions separately to the plJunctionTree.  

    Constructors
    ------------
    * `plJunctionTree()`  

        Default constructor.  

        Use set_joint_distribution() or set_decomposition() to link a decomposition
        to this junction tree after calling this constructor.  

    * `plJunctionTree(plComputableObjectList const &decomposition)`  

        Constructs a junction tree object from a decomposition.  

        This is light : no symbolic or numeric computations occurs until a question
        is asked with ask().  

        Parameters:  
        * `decomposition` :  
            The decomposition this tree will operate with. This must contain only
            discretizable distributions (that is, distributions it is possible to
            compile()). All factors of the decomposition must have exactly one left
            variable (and zero or more right variables).  

    * `plJunctionTree(plJointDistribution const &joint)`  

        Constructs a junction tree object from a joint distribution.  

        This is light : no symbolic or numeric computations occurs until a question
        is asked with ask().  

        This is a convenience constructor that just builds the junction tree from
        the decomposition inside the joint distribution.  

        Parameters:  
        * `joint` :  
            The joint distribution this tree will operate with. This must contain
            only discretizable distributions (that is, distributions it is possible
            to compile()). All factors of the decomposition must have exactly one
            left variable (and zero or more right variables).  

    * `plJunctionTree(plJunctionTree const &)`  

        Copy constructor.  

    C++ includes: plJunctionTree.h

    """

    __swig_setmethods__ = {}
    for _s in [plObject]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plJunctionTree, name, value)
    __swig_getmethods__ = {}
    for _s in [plObject]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plJunctionTree, name)
    __repr__ = _swig_repr
    __swig_destroy__ = _probt_python3.delete_plJunctionTree
    __del__ = lambda self: None

    def __init__(self, *args):
        """
        __init__(self) -> plJunctionTree
        __init__(self, decomposition) -> plJunctionTree
        __init__(self, joint) -> plJunctionTree
        __init__(self, arg2) -> plJunctionTree


        `plJunctionTree()`  
        `plJunctionTree(plComputableObjectList const &decomposition)`  
        `plJunctionTree(plJointDistribution const &joint)`  
        `plJunctionTree(plJunctionTree const &)`  

        Overloaded function
        -------------------
        * `plJunctionTree()`  

            Default constructor.  

            Use set_joint_distribution() or set_decomposition() to link a decomposition
            to this junction tree after calling this constructor.  

        * `plJunctionTree(plComputableObjectList const &decomposition)`  

            Constructs a junction tree object from a decomposition.  

            This is light : no symbolic or numeric computations occurs until a question
            is asked with ask().  

            Parameters:  
            * `decomposition` :  
                The decomposition this tree will operate with. This must contain only
                discretizable distributions (that is, distributions it is possible to
                compile()). All factors of the decomposition must have exactly one left
                variable (and zero or more right variables).  

        * `plJunctionTree(plJointDistribution const &joint)`  

            Constructs a junction tree object from a joint distribution.  

            This is light : no symbolic or numeric computations occurs until a question
            is asked with ask().  

            This is a convenience constructor that just builds the junction tree from
            the decomposition inside the joint distribution.  

            Parameters:  
            * `joint` :  
                The joint distribution this tree will operate with. This must contain
                only discretizable distributions (that is, distributions it is possible
                to compile()). All factors of the decomposition must have exactly one
                left variable (and zero or more right variables).  

        * `plJunctionTree(plJunctionTree const &)`  

            Copy constructor.  

        """
        this = _probt_python3.new_plJunctionTree(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def set_decomposition(self, decomposition: 'plComputableObjectList') -> "void":
        """
        set_decomposition(self, decomposition)


        `set_decomposition(plComputableObjectList const &decomposition)`  

        Sets the decomposition for this tree.  

        Parameters
        ----------
        * `decomposition` :  
            The decomposition this tree will operate with. This must contain only
            discretizable distributions (that is, distributions it is possible to
            compile()). All factors of the decomposition must have exactly one left
            variable (and zero or more right variables).  

        """
        return _probt_python3.plJunctionTree_set_decomposition(self, decomposition)


    def ask(self, *args) -> "plCndJtDistribution":
        """
        ask(self, variables) -> plJtDistribution
        ask(self, left, right, do_not_build_normalization_expression=False) -> plCndJtDistribution
        ask(self, left, right) -> plCndJtDistribution


        `ask(plVariablesConjunction const &variables) -> plJtDistribution`  
        `ask(plVariablesConjunction const &left, plVariablesConjunction const &right,
            bool do_not_build_normalization_expression=false) -> plCndJtDistribution`  

        Overloaded function
        -------------------
        * `ask(plVariablesConjunction const &variables) -> plJtDistribution`  

            Asks a non-conditional question to the tree.  

            Parameters:  
            * `variables` :  
                Variables for this question.  

            Returns:
            A symbolic distribution corresponding to P(variables).  

        * `ask(plVariablesConjunction const &left, plVariablesConjunction const &right,
            bool do_not_build_normalization_expression=false) -> plCndJtDistribution`  

            Asks a conditional question to the tree.  

            Parameters:  
            * `left` :  
                Left variables for this question.  
            * `right` :  
                Right variables for this question.  
            * `do_not_build_normalization_expression` :  
                Whether we should not attempt to normalize the results of
                plCndJtDistribution::compute() on the question.  

            Returns:
            A symbolic conditional distribution corresponding to P(left | right).  

        """
        return _probt_python3.plJunctionTree_ask(self, *args)


    def as_graph_dot(self, *args) -> "std::string":
        """
        as_graph_dot(self, dot_graph_label, dot_node_shape, dot_node_color, dot_node_fill_color, dot_background_color, dot_edge_color, dot_rankdir) -> std::string
        as_graph_dot(self, dot_graph_label, dot_node_shape, dot_node_color, dot_node_fill_color, dot_background_color, dot_edge_color) -> std::string
        as_graph_dot(self, dot_graph_label, dot_node_shape, dot_node_color, dot_node_fill_color, dot_background_color) -> std::string
        as_graph_dot(self, dot_graph_label, dot_node_shape, dot_node_color, dot_node_fill_color) -> std::string
        as_graph_dot(self, dot_graph_label, dot_node_shape, dot_node_color) -> std::string
        as_graph_dot(self, dot_graph_label, dot_node_shape) -> std::string
        as_graph_dot(self, dot_graph_label) -> std::string
        as_graph_dot(self) -> std::string


        `as_graph_dot(const std::string &dot_graph_label="", const std::string
            &dot_node_shape="ellipse", const std::string &dot_node_color="black",
            const std::string &dot_node_fill_color="lightblue", const std::string
            &dot_background_color="white", const std::string
            &dot_edge_color="black", const std::string &dot_rankdir="TD") const ->
            std::string`  

        Return the graphvis dot drawing instructions to represent the graph of the joint
        distribution.  

        """
        return _probt_python3.plJunctionTree_as_graph_dot(self, *args)


    def output_clique_tree_dot(self, *args) -> "void":
        """
        output_clique_tree_dot(self, file_name, dot_graph_label, dot_node_shape, dot_node_color, dot_node_fill_color, dot_background_color, dot_edge_color, dot_rankdir)
        output_clique_tree_dot(self, file_name, dot_graph_label, dot_node_shape, dot_node_color, dot_node_fill_color, dot_background_color, dot_edge_color)
        output_clique_tree_dot(self, file_name, dot_graph_label, dot_node_shape, dot_node_color, dot_node_fill_color, dot_background_color)
        output_clique_tree_dot(self, file_name, dot_graph_label, dot_node_shape, dot_node_color, dot_node_fill_color)
        output_clique_tree_dot(self, file_name, dot_graph_label, dot_node_shape, dot_node_color)
        output_clique_tree_dot(self, file_name, dot_graph_label, dot_node_shape)
        output_clique_tree_dot(self, file_name, dot_graph_label)
        output_clique_tree_dot(self, file_name)


        `output_clique_tree_dot(std::ostream &os, const std::string
            &dot_graph_label="", const std::string &dot_node_shape="ellipse", const
            std::string &dot_node_color="black", const std::string
            &dot_node_fill_color="lightblue", const std::string
            &dot_background_color="white", const std::string
            &dot_edge_color="black", const std::string &dot_rankdir="TD") const`  
        `output_clique_tree_dot(const std::string &file_name, const std::string
            &dot_graph_label="", const std::string &dot_node_shape="ellipse", const
            std::string &dot_node_color="black", const std::string
            &dot_node_fill_color="lightblue", const std::string
            &dot_background_color="white", const std::string
            &dot_edge_color="black", const std::string &dot_rankdir="TD") const`  

        Overloaded function
        -------------------
        * `output_clique_tree_dot(std::ostream &os, const std::string
            &dot_graph_label="", const std::string &dot_node_shape="ellipse", const
            std::string &dot_node_color="black", const std::string
            &dot_node_fill_color="lightblue", const std::string
            &dot_background_color="white", const std::string
            &dot_edge_color="black", const std::string &dot_rankdir="TD") const`  

            Outputs the internal structures of the clique graph in this junction tree.  

        * `output_clique_tree_dot(const std::string &file_name, const std::string
            &dot_graph_label="", const std::string &dot_node_shape="ellipse", const
            std::string &dot_node_color="black", const std::string
            &dot_node_fill_color="lightblue", const std::string
            &dot_background_color="white", const std::string
            &dot_edge_color="black", const std::string &dot_rankdir="TD") const`  

            Outputs the internal structures of the clique graph in this junction tree.  

        """
        return _probt_python3.plJunctionTree_output_clique_tree_dot(self, *args)


    def python_draw_clique_tree(self) -> "void":
        """
        python_draw_clique_tree(self)


        `python_draw_clique_tree()`  

        Only for Python: Same as output_clique_tree_dot() above.  

        See also: output_clique_tree_dot()  

        """
        return _probt_python3.plJunctionTree_python_draw_clique_tree(self)


    def print_clique_tree(self) -> "std::string":
        """
        print_clique_tree(self) -> std::string


        `print_clique_tree() const -> std::string`  

        Outputs the internal structures of the clique graph in this junction tree.  

        """
        return _probt_python3.plJunctionTree_print_clique_tree(self)

plJunctionTree_swigregister = _probt_python3.plJunctionTree_swigregister
plJunctionTree_swigregister(plJunctionTree)

class plMutableDistribution(plDistribution):
    """


    Template class to make computable objects mutable.  

    This template is instantiated for plComputableObject, plDistribution, and
    plCndDistribution classes. These explicit instantiations are defined as
    plMutableComputableObject, plMutableDistribution, and plMutableCndDistribution
    types respectively. It's recommended to use these typedefs instead of using the
    template directly.  

    Mutability is the ability for a given computable object to change its shape
    dynamically. This property is especially useful for defining dynamic
    probabilistic models such as Bayesian filters.  

    When a mutable computable object is mutated, all non-compiled computable objects
    referencing it will receive a notification with this mutation. These non-
    compiled computable objects are:  

    *   Expressions obtained using the plJointDistribution::ask() method or using
        the plCndDistribution::instantiate() method on an expression.  
    *   Product expressions constructed using
        plComputableObject::plComputableObject(const plComputableObjectList &)
        constructor.  
    *   Joint distribution objects (plJointDistribution).  

    ATTENTION: In some situations, mutability affects inference performances because
    it makes impossible caching intermediate calculation using mutable computable
    objects.  

    See also: plComputableObject::replace  

    C++ includes: plMutable.h

    """

    __swig_setmethods__ = {}
    for _s in [plDistribution]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plMutableDistribution, name, value)
    __swig_getmethods__ = {}
    for _s in [plDistribution]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plMutableDistribution, name)
    __repr__ = _swig_repr

    def __init__(self, *args):
        """
        __init__(self) -> plMutableDistribution
        __init__(self, init_object) -> plMutableDistribution
        __init__(self, other) -> plMutableDistribution


        `plMutable()`  
        `plMutable(const T &init_object)`  
        `plMutable(const plMutable< T > &other)`  

        Overloaded function
        -------------------
        * `plMutable()`  

            Default constructor.  

        * `plMutable(const T &init_object)`  

            Construction and initialization.  

        * `plMutable(const plMutable< T > &other)`  

            Copy constructor.  

        """
        this = _probt_python3.new_plMutableDistribution(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this
    __swig_destroy__ = _probt_python3.delete_plMutableDistribution
    __del__ = lambda self: None

    def mutate(self, new_object: 'plDistribution') -> "void":
        """
        mutate(self, new_object)


        `mutate(const T &new_object)`  

        Mutate the object to the new value *new_object*.  

        """
        return _probt_python3.plMutableDistribution_mutate(self, new_object)

plMutableDistribution_swigregister = _probt_python3.plMutableDistribution_swigregister
plMutableDistribution_swigregister(plMutableDistribution)

class plMutableCndDistribution(plCndDistribution):
    """


    Template class to make computable objects mutable.  

    This template is instantiated for plComputableObject, plDistribution, and
    plCndDistribution classes. These explicit instantiations are defined as
    plMutableComputableObject, plMutableDistribution, and plMutableCndDistribution
    types respectively. It's recommended to use these typedefs instead of using the
    template directly.  

    Mutability is the ability for a given computable object to change its shape
    dynamically. This property is especially useful for defining dynamic
    probabilistic models such as Bayesian filters.  

    When a mutable computable object is mutated, all non-compiled computable objects
    referencing it will receive a notification with this mutation. These non-
    compiled computable objects are:  

    *   Expressions obtained using the plJointDistribution::ask() method or using
        the plCndDistribution::instantiate() method on an expression.  
    *   Product expressions constructed using
        plComputableObject::plComputableObject(const plComputableObjectList &)
        constructor.  
    *   Joint distribution objects (plJointDistribution).  

    ATTENTION: In some situations, mutability affects inference performances because
    it makes impossible caching intermediate calculation using mutable computable
    objects.  

    See also: plComputableObject::replace  

    C++ includes: plMutable.h

    """

    __swig_setmethods__ = {}
    for _s in [plCndDistribution]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plMutableCndDistribution, name, value)
    __swig_getmethods__ = {}
    for _s in [plCndDistribution]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plMutableCndDistribution, name)
    __repr__ = _swig_repr

    def __init__(self, *args):
        """
        __init__(self) -> plMutableCndDistribution
        __init__(self, init_object) -> plMutableCndDistribution
        __init__(self, other) -> plMutableCndDistribution


        `plMutable()`  
        `plMutable(const T &init_object)`  
        `plMutable(const plMutable< T > &other)`  

        Overloaded function
        -------------------
        * `plMutable()`  

            Default constructor.  

        * `plMutable(const T &init_object)`  

            Construction and initialization.  

        * `plMutable(const plMutable< T > &other)`  

            Copy constructor.  

        """
        this = _probt_python3.new_plMutableCndDistribution(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this
    __swig_destroy__ = _probt_python3.delete_plMutableCndDistribution
    __del__ = lambda self: None

    def mutate(self, new_object: 'plCndDistribution') -> "void":
        """
        mutate(self, new_object)


        `mutate(const T &new_object)`  

        Mutate the object to the new value *new_object*.  

        """
        return _probt_python3.plMutableCndDistribution_mutate(self, new_object)

plMutableCndDistribution_swigregister = _probt_python3.plMutableCndDistribution_swigregister
plMutableCndDistribution_swigregister(plMutableCndDistribution)

class plMutableComputableObject(plComputableObject):
    """


    Template class to make computable objects mutable.  

    This template is instantiated for plComputableObject, plDistribution, and
    plCndDistribution classes. These explicit instantiations are defined as
    plMutableComputableObject, plMutableDistribution, and plMutableCndDistribution
    types respectively. It's recommended to use these typedefs instead of using the
    template directly.  

    Mutability is the ability for a given computable object to change its shape
    dynamically. This property is especially useful for defining dynamic
    probabilistic models such as Bayesian filters.  

    When a mutable computable object is mutated, all non-compiled computable objects
    referencing it will receive a notification with this mutation. These non-
    compiled computable objects are:  

    *   Expressions obtained using the plJointDistribution::ask() method or using
        the plCndDistribution::instantiate() method on an expression.  
    *   Product expressions constructed using
        plComputableObject::plComputableObject(const plComputableObjectList &)
        constructor.  
    *   Joint distribution objects (plJointDistribution).  

    ATTENTION: In some situations, mutability affects inference performances because
    it makes impossible caching intermediate calculation using mutable computable
    objects.  

    See also: plComputableObject::replace  

    C++ includes: plMutable.h

    """

    __swig_setmethods__ = {}
    for _s in [plComputableObject]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plMutableComputableObject, name, value)
    __swig_getmethods__ = {}
    for _s in [plComputableObject]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plMutableComputableObject, name)
    __repr__ = _swig_repr

    def __init__(self, *args):
        """
        __init__(self) -> plMutableComputableObject
        __init__(self, init_object) -> plMutableComputableObject
        __init__(self, other) -> plMutableComputableObject


        `plMutable()`  
        `plMutable(const T &init_object)`  
        `plMutable(const plMutable< T > &other)`  

        Overloaded function
        -------------------
        * `plMutable()`  

            Default constructor.  

        * `plMutable(const T &init_object)`  

            Construction and initialization.  

        * `plMutable(const plMutable< T > &other)`  

            Copy constructor.  

        """
        this = _probt_python3.new_plMutableComputableObject(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this
    __swig_destroy__ = _probt_python3.delete_plMutableComputableObject
    __del__ = lambda self: None

    def mutate(self, new_object: 'plComputableObject') -> "void":
        """
        mutate(self, new_object)


        `mutate(const T &new_object)`  

        Mutate the object to the new value *new_object*.  

        """
        return _probt_python3.plMutableComputableObject_mutate(self, new_object)

plMutableComputableObject_swigregister = _probt_python3.plMutableComputableObject_swigregister
plMutableComputableObject_swigregister(plMutableComputableObject)

class plVariableIndexer(plSampleSpaceObject):
    """

    `plVariableIndexer()`  
    `plVariableIndexer(const plVariablesConjunction &vars)`  
    `plVariableIndexer(const plVariableIndexer &other)`  

    Helper class for indexing the values of a discrete/discretized variable
    conjunction.  

    Constructors
    ------------
    * `plVariableIndexer()`  

        Empty constructor.  

    * `plVariableIndexer(const plVariablesConjunction &vars)`  

        Constructor using a variables conjunction.  

    * `plVariableIndexer(const plVariableIndexer &other)`  

        Copy constructor.  

    C++ includes: plVariableIndexer.h

    """

    __swig_setmethods__ = {}
    for _s in [plSampleSpaceObject]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plVariableIndexer, name, value)
    __swig_getmethods__ = {}
    for _s in [plSampleSpaceObject]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plVariableIndexer, name)
    __repr__ = _swig_repr

    def __init__(self, *args):
        """
        __init__(self) -> plVariableIndexer
        __init__(self, vars) -> plVariableIndexer
        __init__(self, other) -> plVariableIndexer


        `plVariableIndexer()`  
        `plVariableIndexer(const plVariablesConjunction &vars)`  
        `plVariableIndexer(const plVariableIndexer &other)`  

        Overloaded function
        -------------------
        * `plVariableIndexer()`  

            Empty constructor.  

        * `plVariableIndexer(const plVariablesConjunction &vars)`  

            Constructor using a variables conjunction.  

        * `plVariableIndexer(const plVariableIndexer &other)`  

            Copy constructor.  

        """
        this = _probt_python3.new_plVariableIndexer(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def assign_from(self, other: 'plVariableIndexer') -> "plVariableIndexer &":
        """
        assign_from(self, other) -> plVariableIndexer


        `assign_from(const plVariableIndexer &other) -> plVariableIndexer &`  

        Same as operator=()  

        """
        return _probt_python3.plVariableIndexer_assign_from(self, other)

    __swig_destroy__ = _probt_python3.delete_plVariableIndexer
    __del__ = lambda self: None

    def get_symbol_cardinality(self, n: 'unsigned int') -> "unsigned int":
        """
        get_symbol_cardinality(self, n) -> unsigned int


        `get_symbol_cardinality(unsigned int n) const -> unsigned int`  

        Get the cardinality of the n-th symbol in the conjunction.  

        """
        return _probt_python3.plVariableIndexer_get_symbol_cardinality(self, n)


    def get_index_from_value(self, *args) -> "bool":
        """
        get_index_from_value(self, value, index) -> bool
        get_index_from_value(self, value, index) -> bool


        `get_index_from_value(const plValues &value, unsigned int &index) const -> bool`  
        `get_index_from_value(const std::vector< vectorT > &value, unsigned int &index)
            const -> bool`  
        `get_index_from_value(arrayT *value, unsigned int &index) const -> bool`  
        `get_index_from_value(const plDataValues &value, unsigned int &index) const ->
            bool`  

        Overloaded function
        -------------------
        * `get_index_from_value(const plValues &value, unsigned int &index) const ->
            bool`  

            Get the index corresponding to a given value in the output parameter
            'index'.  

            Returns 'true' if the value is in the range.  

        * `get_index_from_value(const std::vector< vectorT > &value, unsigned int
            &index) const -> bool`  

            Get the index corresponding to a given value in the output parameter
            'index'.  

            Returns 'true' if the value is in the range. This template method is
            instantiated for 'int', 'unsigned int', 'float', 'double', and 'long
            double'.  

        * `get_index_from_value(arrayT *value, unsigned int &index) const -> bool`  

            Get the index corresponding to a given value in the output parameter
            'index'.  

            Returns 'true' if the value is in the range. This template method is
            instantiated for 'int', 'unsigned int', 'float', 'double', and 'long
            double'.  

        * `get_index_from_value(const plDataValues &value, unsigned int &index) const ->
            bool`  

        """
        return _probt_python3.plVariableIndexer_get_index_from_value(self, *args)


    def get_value_from_index(self, *args) -> "bool":
        """
        get_value_from_index(self, index, value) -> bool
        get_value_from_index(self, index, value) -> bool


        `get_value_from_index(unsigned int index, plValues &value) const -> bool`  
        `get_value_from_index(unsigned int index, std::vector< vectorT > &value) const
            -> bool`  
        `get_value_from_index(unsigned int index, arrayT *value) const -> bool`  
        `get_value_from_index(unsigned int index, plDataValues &value) const -> bool`  

        Overloaded function
        -------------------
        * `get_value_from_index(unsigned int index, plValues &value) const -> bool`  

            Get the value corresponding to a given index in the output parameter
            'value'.  

            Returns 'true' if the index is in the range.  

        * `get_value_from_index(unsigned int index, std::vector< vectorT > &value) const
            -> bool`  

            Get the value corresponding to a given index in the output parameter
            'value'.  

            Returns 'true' if the index is in the range. This template method is
            instantiated for 'int', 'unsigned int', 'float', 'double', and 'long
            double'.  

        * `get_value_from_index(unsigned int index, arrayT *value) const -> bool`  

            Get the value corresponding to a given index in the output parameter
            'value'.  

            Returns 'true' if the index is in the range. This template method is
            instantiated for 'int', 'unsigned int', 'float', 'double', and 'long
            double'.  

        * `get_value_from_index(unsigned int index, plDataValues &value) const -> bool`  

        """
        return _probt_python3.plVariableIndexer_get_value_from_index(self, *args)


    def __getstate__(self) -> "std::string":
        """__getstate__(self) -> std::string"""
        return _probt_python3.plVariableIndexer___getstate__(self)


    def __setstate_internal(self, sState: 'std::string const &') -> "void":
        """__setstate_internal(self, sState)"""
        return _probt_python3.plVariableIndexer___setstate_internal(self, sState)


    def __setstate__(self, sState):
        self.__init__()
        self.__setstate_internal(sState)

plVariableIndexer_swigregister = _probt_python3.plVariableIndexer_swigregister
plVariableIndexer_swigregister(plVariableIndexer)

PL_DEFAULT_PLOT = _probt_python3.PL_DEFAULT_PLOT
PL_EPS_COLOR_PLOT = _probt_python3.PL_EPS_COLOR_PLOT
PL_EPS_PLOT = _probt_python3.PL_EPS_PLOT
PL_FIG_PLOT = _probt_python3.PL_FIG_PLOT
PL_JPEG_PLOT = _probt_python3.PL_JPEG_PLOT
PL_LATEX_PLOT = _probt_python3.PL_LATEX_PLOT
PL_PDF_COLOR_PLOT = _probt_python3.PL_PDF_COLOR_PLOT
PL_PDF_PLOT = _probt_python3.PL_PDF_PLOT
PL_PNG_PLOT = _probt_python3.PL_PNG_PLOT
PL_POSTSCRIPT_COLOR_PLOT = _probt_python3.PL_POSTSCRIPT_COLOR_PLOT
PL_POSTSCRIPT_PLOT = _probt_python3.PL_POSTSCRIPT_PLOT
class plKalmanFilter(plBuiltinModel):
    """

    `plKalmanFilter()`  
    `plKalmanFilter(unsigned int state_dim, unsigned int obs_dim, unsigned int
        command_dim=0)`  
    `plKalmanFilter(const plFloatVector &init_estimation_mean, const plFloatMatrix
        &init_estimation_cov_matrix, const plFloatMatrix &prediction_matrix, const
        plFloatMatrix &prediction_noise_cov_matrix, const plFloatMatrix
        &observation_matrix, const plFloatMatrix &observation_noise_cov_matrix,
        const plFloatMatrix &control_matrix=plFloatMatrix())`  

    This class implements the Linear Kalman Filter.  

    The system is defined by the two equations:  

    System (prediction) linear equation: \[ x_k = A x_{k-1} + B u_k + w_{k-1} \]
    with: \[ p(w) = {\cal N}(0, Q) \]  

    Observation (measurement) linear equation: \[ z_k = H x_{k} + v_{k} \] with:
    \[ p(v) = {\cal N}(0, R) \]  

    Constructors
    ------------
    * `plKalmanFilter()`  

        Default constructor used for serialization.  

    * `plKalmanFilter(unsigned int state_dim, unsigned int obs_dim, unsigned int
        command_dim=0)`  

        Constructor.  

        Parameters:  
        * `state_dim` :  
            state dimension  
        * `obs_dim` :  
            observation dimension  
        * `command_dim` :  
            command dimension  

    * `plKalmanFilter(const plFloatVector &init_estimation_mean, const plFloatMatrix
        &init_estimation_cov_matrix, const plFloatMatrix &prediction_matrix, const
        plFloatMatrix &prediction_noise_cov_matrix, const plFloatMatrix
        &observation_matrix, const plFloatMatrix &observation_noise_cov_matrix,
        const plFloatMatrix &control_matrix=plFloatMatrix())`  

        Construction and initialization.  

        Parameters:  
        * `init_estimation_mean` :  
            initial estimation mean vector (x0)  
        * `init_estimation_cov_matrix` :  
            initial estimation covariance matrix (P0)  
        * `prediction_matrix` :  
            prediction (system) matrix (A)  
        * `prediction_noise_cov_matrix` :  
            prediction noise covariance matrix (Q)  
        * `observation_matrix` :  
            observation (measurement) matrix (H)  
        * `observation_noise_cov_matrix` :  
            observation noise covariance matrix (R)  
        * `control_matrix` :  
            command (control) matrix (B)  

    Attributes
    ----------
    * `A` : `plFloatMatrix`  
        System (prediction) matrix.  

        Store the system (prediction) model Jacobian for the non-linear case.  

    * `H` : `plFloatMatrix`  
        Observation (measurement) matrix.  

        Store the observation (measurement) model Jacobian for the non-linear case.  

    * `B` : `plFloatMatrix`  
        Control (command) matrix.  

    * `z` : `plFloatVector`  
        Current observation.  

    * `u` : `plFloatVector`  
        Current command.  

    * `Q` : `plFloatMatrix`  
        System (prediction) noise covariance matrix.  

    * `R` : `plFloatMatrix`  
        Observation (measurement) noise covariance matrix.  

    * `x_current_estimation` : `plFloatVector`  
        Current estimate mean vector.  

    * `P_current_estimation` : `plFloatMatrix`  
        Current estimate covariance matrix.  

    C++ includes: plKalmanFilter.h

    """

    __swig_setmethods__ = {}
    for _s in [plBuiltinModel]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plKalmanFilter, name, value)
    __swig_getmethods__ = {}
    for _s in [plBuiltinModel]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plKalmanFilter, name)
    __repr__ = _swig_repr

    def normalize_angle_range(*args) -> "plFloatVector &":
        """
        normalize_angle_range(val) -> plFloat
        normalize_angle_range(vals, angle_indices) -> plFloatVector


        `normalize_angle_range(plFloat &val) -> plFloat`  
        `normalize_angle_range(plFloatVector &vals, const std::vector< unsigned int >
            &angle_indices) -> plFloatVector &`  

        Overloaded function
        -------------------
        * `normalize_angle_range(plFloat &val) -> plFloat`  

            Set the angle value in the range [-PI, PI[.  

        * `normalize_angle_range(plFloatVector &vals, const std::vector< unsigned int >
            &angle_indices) -> plFloatVector &`  

            Set the angle values at indices angle_indices in the range [-PI, PI[.  

        """
        return _probt_python3.plKalmanFilter_normalize_angle_range(*args)

    normalize_angle_range = staticmethod(normalize_angle_range)

    def __init__(self, *args):
        """
        __init__(self) -> plKalmanFilter
        __init__(self, state_dim, obs_dim, command_dim=0) -> plKalmanFilter
        __init__(self, state_dim, obs_dim) -> plKalmanFilter
        __init__(self, init_estimation_mean, init_estimation_cov_matrix, prediction_matrix, prediction_noise_cov_matrix, observation_matrix, observation_noise_cov_matrix, control_matrix) -> plKalmanFilter
        __init__(self, init_estimation_mean, init_estimation_cov_matrix, prediction_matrix, prediction_noise_cov_matrix, observation_matrix, observation_noise_cov_matrix) -> plKalmanFilter


        `plKalmanFilter()`  
        `plKalmanFilter(unsigned int state_dim, unsigned int obs_dim, unsigned int
            command_dim=0)`  
        `plKalmanFilter(const plFloatVector &init_estimation_mean, const plFloatMatrix
            &init_estimation_cov_matrix, const plFloatMatrix &prediction_matrix, const
            plFloatMatrix &prediction_noise_cov_matrix, const plFloatMatrix
            &observation_matrix, const plFloatMatrix &observation_noise_cov_matrix,
            const plFloatMatrix &control_matrix=plFloatMatrix())`  

        Overloaded function
        -------------------
        * `plKalmanFilter()`  

            Default constructor used for serialization.  

        * `plKalmanFilter(unsigned int state_dim, unsigned int obs_dim, unsigned int
            command_dim=0)`  

            Constructor.  

            Parameters:  
            * `state_dim` :  
                state dimension  
            * `obs_dim` :  
                observation dimension  
            * `command_dim` :  
                command dimension  

        * `plKalmanFilter(const plFloatVector &init_estimation_mean, const plFloatMatrix
            &init_estimation_cov_matrix, const plFloatMatrix &prediction_matrix, const
            plFloatMatrix &prediction_noise_cov_matrix, const plFloatMatrix
            &observation_matrix, const plFloatMatrix &observation_noise_cov_matrix,
            const plFloatMatrix &control_matrix=plFloatMatrix())`  

            Construction and initialization.  

            Parameters:  
            * `init_estimation_mean` :  
                initial estimation mean vector (x0)  
            * `init_estimation_cov_matrix` :  
                initial estimation covariance matrix (P0)  
            * `prediction_matrix` :  
                prediction (system) matrix (A)  
            * `prediction_noise_cov_matrix` :  
                prediction noise covariance matrix (Q)  
            * `observation_matrix` :  
                observation (measurement) matrix (H)  
            * `observation_noise_cov_matrix` :  
                observation noise covariance matrix (R)  
            * `control_matrix` :  
                command (control) matrix (B)  

        """
        if self.__class__ == plKalmanFilter:
            _self = None
        else:
            _self = self
        this = _probt_python3.new_plKalmanFilter(_self, *args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def get_state_dim(self) -> "size_t":
        """
        get_state_dim(self) -> size_t


        `get_state_dim() const -> size_t`  

        Get the state dimension.  

        """
        return _probt_python3.plKalmanFilter_get_state_dim(self)


    def get_observation_dim(self) -> "size_t":
        """
        get_observation_dim(self) -> size_t


        `get_observation_dim() const -> size_t`  

        Get the observation dimension.  

        """
        return _probt_python3.plKalmanFilter_get_observation_dim(self)


    def get_command_dim(self) -> "size_t":
        """
        get_command_dim(self) -> size_t


        `get_command_dim() const -> size_t`  

        Get the command dimension.  

        """
        return _probt_python3.plKalmanFilter_get_command_dim(self)

    __swig_destroy__ = _probt_python3.delete_plKalmanFilter
    __del__ = lambda self: None

    def set_prediction_matrix(self, Ain: 'plFloatMatrix') -> "void":
        """
        set_prediction_matrix(self, Ain)


        `set_prediction_matrix(const plFloatMatrix &Ain)`  

        Set the prediction matrix A.  

        """
        return _probt_python3.plKalmanFilter_set_prediction_matrix(self, Ain)


    def set_prediction_noise_cov_matrix(self, QS: 'plFloatMatrix') -> "void":
        """
        set_prediction_noise_cov_matrix(self, QS)


        `set_prediction_noise_cov_matrix(const plFloatMatrix &QS)`  

        Set system noise covariance matrix Q.  

        """
        return _probt_python3.plKalmanFilter_set_prediction_noise_cov_matrix(self, QS)


    def set_observation_matrix(self, Hin: 'plFloatMatrix') -> "void":
        """
        set_observation_matrix(self, Hin)


        `set_observation_matrix(const plFloatMatrix &Hin)`  

        Set observation matrix H.  

        """
        return _probt_python3.plKalmanFilter_set_observation_matrix(self, Hin)


    def set_observation_noise_cov_matrix(self, Ro: 'plFloatMatrix') -> "void":
        """
        set_observation_noise_cov_matrix(self, Ro)


        `set_observation_noise_cov_matrix(const plFloatMatrix &Ro)`  

        Set observation noise covariance matrix R.  

        """
        return _probt_python3.plKalmanFilter_set_observation_noise_cov_matrix(self, Ro)


    def set_control_matrix(self, Bin: 'plFloatMatrix') -> "void":
        """
        set_control_matrix(self, Bin)


        `set_control_matrix(const plFloatMatrix &Bin)`  

        Set control matrix B.  

        """
        return _probt_python3.plKalmanFilter_set_control_matrix(self, Bin)


    def set_control(self, Uin: 'plFloatVector') -> "void":
        """
        set_control(self, Uin)


        `set_control(const plFloatVector &Uin)`  

        Set the current command u.  

        """
        return _probt_python3.plKalmanFilter_set_control(self, Uin)


    def set_initial_estimation(self, Xo: 'plFloatVector', Po: 'plFloatMatrix') -> "void":
        """
        set_initial_estimation(self, Xo, Po)


        `set_initial_estimation(const plFloatVector &Xo, const plFloatMatrix &Po)`  

        Set the initial estimation x0 ans P0.  

        """
        return _probt_python3.plKalmanFilter_set_initial_estimation(self, Xo, Po)


    def set_observation(self, Zin: 'plFloatVector', observation_weight_in: 'plFloat'=1.0) -> "void":
        """
        set_observation(self, Zin, observation_weight_in=1.0)
        set_observation(self, Zin)


        `set_observation(const plFloatVector &Zin, plFloat
            observation_weight_in=PL_ONE)`  

        Set the current observation z.  

        """
        return _probt_python3.plKalmanFilter_set_observation(self, Zin, observation_weight_in)


    def prediction(self) -> "void":
        """
        prediction(self)


        `prediction()`  

        Prediction step.  

        \[ \hat x^{-}_k = A \hat x_{k-1} + B u_k \]  

        \[ P^{-}_k = A P_{k-1} A^T + Q \]  

        """
        return _probt_python3.plKalmanFilter_prediction(self)


    def update(self) -> "void":
        """
        update(self)


        `update()`  

        Update step assuming that the observation has been inserted using
        set_observation() function.  

        \[ K_k = P^{-}_k H^T (H P^{-}_k H^T + R)^{-1} \]  

        \[ \hat x_k = \hat x^{-}_k + K_k (z_k - H_k \hat x^{-}_k ) \]  

        \[ P_k = (I - K_k H) P^{-}_k \]  

        """
        return _probt_python3.plKalmanFilter_update(self)


    def observation(self, *args) -> "void":
        """
        observation(self, zo, observation_weight=1.0)
        observation(self, zo)
        observation(self, zo, Ro, observation_weight=1.0)
        observation(self, zo, Ro)


        `observation(const plFloatVector &zo, plFloat observation_weight=PL_ONE)`  
        `observation(const plFloatVector &zo, const plFloatMatrix &Ro, plFloat
            observation_weight=PL_ONE)`  

        Overloaded function
        -------------------
        * `observation(const plFloatVector &zo, plFloat observation_weight=PL_ONE)`  

            Update step using observation vector *zo*.  

            Equivalent to calling (without changing *z* internally however):  

            *   set_observation(zo, observation_weight)  
            *   update()  

        * `observation(const plFloatVector &zo, const plFloatMatrix &Ro, plFloat
            observation_weight=PL_ONE)`  

            Update step using observation vector *zo* and its corresponding covariance
            matrix *Ro*.  

            Equivalent to calling (without changing *z* and *R* internally however):  

            *   set_observation_noise_cov_matrix(Ro)  
            *   set_observation(zo, observation_weight)  
            *   update()  

        """
        return _probt_python3.plKalmanFilter_observation(self, *args)


    def prediction_observation(self, *args) -> "void":
        """
        prediction_observation(self, zo, observation_weight=1.0)
        prediction_observation(self, zo)
        prediction_observation(self, zo, Ro, observation_weight=1.0)
        prediction_observation(self, zo, Ro)


        `prediction_observation(const plFloatVector &zo, plFloat
            observation_weight=PL_ONE)`  
        `prediction_observation(const plFloatVector &zo, const plFloatMatrix &Ro,
            plFloat observation_weight=PL_ONE)`  

        Overloaded function
        -------------------
        * `prediction_observation(const plFloatVector &zo, plFloat
            observation_weight=PL_ONE)`  

            Prediction and update step using the observation vector *zo*.  

            It performs a prediction step followed by an observation (update) step.  

        * `prediction_observation(const plFloatVector &zo, const plFloatMatrix &Ro,
            plFloat observation_weight=PL_ONE)`  

            Prediction and update step using the observation vector *zo* and its
            corresponding covariance matrix *Ro*.  

            It performs a prediction step followed by an observation (update) step.  

        """
        return _probt_python3.plKalmanFilter_prediction_observation(self, *args)


    def get_estimation_mean(self) -> "plFloatVector const &":
        """
        get_estimation_mean(self) -> plFloatVector


        `get_estimation_mean() const -> const plFloatVector &`  

        Return the current estimation mean vector.  

        """
        return _probt_python3.plKalmanFilter_get_estimation_mean(self)


    def get_estimation_covariance(self) -> "plFloatMatrix const &":
        """
        get_estimation_covariance(self) -> plFloatMatrix


        `get_estimation_covariance() const -> const plFloatMatrix &`  

        Return the current estimation covariance matrix.  

        """
        return _probt_python3.plKalmanFilter_get_estimation_covariance(self)


    def get_observation_mahalanobis_distance(self, *args) -> "plFloat":
        """
        get_observation_mahalanobis_distance(self, zo) -> plFloat
        get_observation_mahalanobis_distance(self, zo, det) -> plFloat
        get_observation_mahalanobis_distance(self, zo, Ro) -> plFloat
        get_observation_mahalanobis_distance(self, zo, Ro, det) -> plFloat


        `get_observation_mahalanobis_distance(const plFloatVector &zo) const -> plFloat`  
        `get_observation_mahalanobis_distance(const plFloatVector &zo, plFloat &det)
            const -> plFloat`  
        `get_observation_mahalanobis_distance(const plFloatVector &zo, const
            plFloatMatrix &Ro) const -> plFloat`  
        `get_observation_mahalanobis_distance(const plFloatVector &zo, const
            plFloatMatrix &Ro, plFloat &det) const -> plFloat`  

        Overloaded function
        -------------------
        * `get_observation_mahalanobis_distance(const plFloatVector &zo) const ->
            plFloat`  

            Return the Mahalanobis distance of a given observation.  

        * `get_observation_mahalanobis_distance(const plFloatVector &zo, plFloat &det)
            const -> plFloat`  

            Return the Mahalanobis distance of a given observation and the determinant
            of the convariance matrix.  

        * `get_observation_mahalanobis_distance(const plFloatVector &zo, const
            plFloatMatrix &Ro) const -> plFloat`  

            Return the Mahalanobis distance of a given observation.  

        * `get_observation_mahalanobis_distance(const plFloatVector &zo, const
            plFloatMatrix &Ro, plFloat &det) const -> plFloat`  

            Return the Mahalanobis distance of a given observation and the determinant
            of the convariance matrix.  

        """
        return _probt_python3.plKalmanFilter_get_observation_mahalanobis_distance(self, *args)


    def get_pdf_value(self, *args) -> "plProbValue":
        """
        get_pdf_value(self, zo) -> plProbValue
        get_pdf_value(self, zo, Ro) -> plProbValue


        `get_pdf_value(const plFloatVector &zo) const -> plProbValue`  
        `get_pdf_value(const plFloatVector &zo, const plFloatMatrix &Ro) const ->
            plProbValue`  

        Overloaded function
        -------------------
        * `get_pdf_value(const plFloatVector &zo) const -> plProbValue`  

            Return, for the observation *zo*, the value of the density function value
            corresponding to the current gaussian estimate.  

            It assumes that the variance matrix associated to the observation is the
            default *R*.  

        * `get_pdf_value(const plFloatVector &zo, const plFloatMatrix &Ro) const ->
            plProbValue`  

            Return, for the observation *zo* and the corresponding variance matrix *Ro*,
            the value of the density function value according to the current gaussian
            estimate.  

        """
        return _probt_python3.plKalmanFilter_get_pdf_value(self, *args)


    def likelihood(self, *args) -> "plProbValue":
        """
        likelihood(self, zo) -> plProbValue
        likelihood(self, zo, Ro) -> plProbValue


        `likelihood(const plFloatVector &zo) const -> plProbValue`  
        `likelihood(const plFloatVector &zo, const plFloatMatrix &Ro) const ->
            plProbValue`  

        Overloaded function
        -------------------
        * `likelihood(const plFloatVector &zo) const -> plProbValue`  

            Same as get_pdf_value()  

        * `likelihood(const plFloatVector &zo, const plFloatMatrix &Ro) const ->
            plProbValue`  

            Same as get_pdf_value()  

        """
        return _probt_python3.plKalmanFilter_likelihood(self, *args)


    def get_pdf_value_log(self, *args) -> "plFloat":
        """
        get_pdf_value_log(self, zo) -> plFloat
        get_pdf_value_log(self, zo, Ro) -> plFloat


        `get_pdf_value_log(const plFloatVector &zo) const -> plFloat`  
        `get_pdf_value_log(const plFloatVector &zo, const plFloatMatrix &Ro) const ->
            plFloat`  

        Overloaded function
        -------------------
        * `get_pdf_value_log(const plFloatVector &zo) const -> plFloat`  

            Same as above but using log.  

        * `get_pdf_value_log(const plFloatVector &zo, const plFloatMatrix &Ro) const ->
            plFloat`  

            Same as above but using log.  

        """
        return _probt_python3.plKalmanFilter_get_pdf_value_log(self, *args)


    def log_likelihood(self, *args) -> "plFloat":
        """
        log_likelihood(self, zo) -> plFloat
        log_likelihood(self, zo, Ro) -> plFloat


        `log_likelihood(const plFloatVector &zo) const -> plFloat`  
        `log_likelihood(const plFloatVector &zo, const plFloatMatrix &Ro) const ->
            plFloat`  

        Overloaded function
        -------------------
        * `log_likelihood(const plFloatVector &zo) const -> plFloat`  

            Same as get_pdf_value_log()  

        * `log_likelihood(const plFloatVector &zo, const plFloatMatrix &Ro) const ->
            plFloat`  

            Same as get_pdf_value_log()  

        """
        return _probt_python3.plKalmanFilter_log_likelihood(self, *args)


    def use_eigen_decomposition_matrix_inversion(self, eigen_decomposition_inversion: 'bool') -> "void":
        """
        use_eigen_decomposition_matrix_inversion(self, eigen_decomposition_inversion)


        `use_eigen_decomposition_matrix_inversion(bool eigen_decomposition_inversion)`  

        Set/unset matrix inversion method using eigen decomposition.  

        If set to 'false' (the default is 'true'), Greville's algorithm will be used.  

        Inversion using eigen decomposition is more robust than using Greville's
        algorithm. Greville's algorithm is slightly faster.  

        See also: set_greville_inversion_threshold()  

        """
        return _probt_python3.plKalmanFilter_use_eigen_decomposition_matrix_inversion(self, eigen_decomposition_inversion)


    def set_greville_inversion_threshold(self, threshold: 'plFloat') -> "void":
        """
        set_greville_inversion_threshold(self, threshold)


        `set_greville_inversion_threshold(plFloat threshold)`  

        Set/change Greville's inversion threshold.  

        This parameter is used only when eigen_decomposition_inversion is set to
        'false'. The default value is std::numeric_limits<plFloat>::min().  

        See also: use_eigen_decomposition_matrix_inversion()  

        See also: plFloatMatrix::inverse_using_greville()  

        """
        return _probt_python3.plKalmanFilter_set_greville_inversion_threshold(self, threshold)


    def residual_observation(self, z1: 'plFloatVector', z2: 'plFloatVector') -> "plFloatVector":
        """
        residual_observation(self, z1, z2) -> plFloatVector


        `residual_observation(const plFloatVector &z1, const plFloatVector &z2) const ->
            plFloatVector`  

        Function that computes the residual (difference) between two observation vectors
        z1 and z2.  

        You will have to reimplement this if your observation variable cannot support
        subtraction. The case of angle variables (359-1 degrees is 2, not 358) is
        handled based on the reimplementation of the function
        get_observation_angle_indices()  

        """
        return _probt_python3.plKalmanFilter_residual_observation(self, z1, z2)


    def get_Q(self) -> "plFloatMatrix":
        """get_Q(self) -> plFloatMatrix"""
        return _probt_python3.plKalmanFilter_get_Q(self)

    __swig_setmethods__["A"] = _probt_python3.plKalmanFilter_A_set
    __swig_getmethods__["A"] = _probt_python3.plKalmanFilter_A_get
    if _newclass:
        A = _swig_property(_probt_python3.plKalmanFilter_A_get, _probt_python3.plKalmanFilter_A_set)
    __swig_setmethods__["H"] = _probt_python3.plKalmanFilter_H_set
    __swig_getmethods__["H"] = _probt_python3.plKalmanFilter_H_get
    if _newclass:
        H = _swig_property(_probt_python3.plKalmanFilter_H_get, _probt_python3.plKalmanFilter_H_set)
    __swig_setmethods__["B"] = _probt_python3.plKalmanFilter_B_set
    __swig_getmethods__["B"] = _probt_python3.plKalmanFilter_B_get
    if _newclass:
        B = _swig_property(_probt_python3.plKalmanFilter_B_get, _probt_python3.plKalmanFilter_B_set)
    __swig_setmethods__["z"] = _probt_python3.plKalmanFilter_z_set
    __swig_getmethods__["z"] = _probt_python3.plKalmanFilter_z_get
    if _newclass:
        z = _swig_property(_probt_python3.plKalmanFilter_z_get, _probt_python3.plKalmanFilter_z_set)
    __swig_setmethods__["u"] = _probt_python3.plKalmanFilter_u_set
    __swig_getmethods__["u"] = _probt_python3.plKalmanFilter_u_get
    if _newclass:
        u = _swig_property(_probt_python3.plKalmanFilter_u_get, _probt_python3.plKalmanFilter_u_set)
    __swig_setmethods__["Q"] = _probt_python3.plKalmanFilter_Q_set
    __swig_getmethods__["Q"] = _probt_python3.plKalmanFilter_Q_get
    if _newclass:
        Q = _swig_property(_probt_python3.plKalmanFilter_Q_get, _probt_python3.plKalmanFilter_Q_set)
    __swig_setmethods__["R"] = _probt_python3.plKalmanFilter_R_set
    __swig_getmethods__["R"] = _probt_python3.plKalmanFilter_R_get
    if _newclass:
        R = _swig_property(_probt_python3.plKalmanFilter_R_get, _probt_python3.plKalmanFilter_R_set)
    __swig_setmethods__["x_current_estimation"] = _probt_python3.plKalmanFilter_x_current_estimation_set
    __swig_getmethods__["x_current_estimation"] = _probt_python3.plKalmanFilter_x_current_estimation_get
    if _newclass:
        x_current_estimation = _swig_property(_probt_python3.plKalmanFilter_x_current_estimation_get, _probt_python3.plKalmanFilter_x_current_estimation_set)
    __swig_setmethods__["P_current_estimation"] = _probt_python3.plKalmanFilter_P_current_estimation_set
    __swig_getmethods__["P_current_estimation"] = _probt_python3.plKalmanFilter_P_current_estimation_get
    if _newclass:
        P_current_estimation = _swig_property(_probt_python3.plKalmanFilter_P_current_estimation_get, _probt_python3.plKalmanFilter_P_current_estimation_set)

    def get_observation_angle_indices(self) -> "std::vector< unsigned int,std::allocator< unsigned int > >":
        """get_observation_angle_indices(self) -> UnsignedIntVector"""
        return _probt_python3.plKalmanFilter_get_observation_angle_indices(self)


    def Output(self) -> "void":
        """Output(self)"""
        return _probt_python3.plKalmanFilter_Output(self)

    def __disown__(self):
        self.this.disown()
        _probt_python3.disown_plKalmanFilter(self)
        return weakref_proxy(self)
plKalmanFilter_swigregister = _probt_python3.plKalmanFilter_swigregister
plKalmanFilter_swigregister(plKalmanFilter)

def plKalmanFilter_normalize_angle_range(*args) -> "plFloatVector &":
    """
    normalize_angle_range(val) -> plFloat
    plKalmanFilter_normalize_angle_range(vals, angle_indices) -> plFloatVector


    `normalize_angle_range(plFloat &val) -> plFloat`  
    `normalize_angle_range(plFloatVector &vals, const std::vector< unsigned int >
        &angle_indices) -> plFloatVector &`  

    Overloaded function
    -------------------
    * `normalize_angle_range(plFloat &val) -> plFloat`  

        Set the angle value in the range [-PI, PI[.  

    * `normalize_angle_range(plFloatVector &vals, const std::vector< unsigned int >
        &angle_indices) -> plFloatVector &`  

        Set the angle values at indices angle_indices in the range [-PI, PI[.  

    """
    return _probt_python3.plKalmanFilter_normalize_angle_range(*args)

class plKalmanFilterCV2D(plKalmanFilter):
    """

    `plKalmanFilterCV2D(plFloat var_a_x, plFloat var_a_y, plFloat dt, bool
        observe_velocity)`  

    2D Constant Velocity (zero-mean acceleration) Linear Kalman Filter.  

    State [X, VX, AX, Y, VY, AY] in which the acceleration AX, AY is always zero.  

    By default, the observation is assumed to be [X, Y, Z] (Only the position is
    observed) It can be changed by setting the parameter 'observe_velocity' to
    'true' in the constructor.  

    For each dimension among X, Y we have:  

        x_k = x_{k-1} + dt v_{k-1} +      1/2 dt^2 a_{k-1}
        v_k = v_{k-1} +                   dt a_{k-1}

        with x the position, v the velocity, and a the acceleration.

        X_k = [x_k, v_k]^T

        X_k = A X_{k-1} + W

              | 1  dt |
        A  =  |       |
              | 0  1  |

        W = a_{k-1} [ 1/2 dt^2, dt ]^T
          = a_{k-1} G

        E(W) = E(a_{k-1}) G
             = 0

        Q = Var(W W^T)
          = G Var(a_{k-1}) G^T
          = sigma^2_a G G^T

                      | 1/4 dt^4   1/2 dt^3 |
          = sigma^2_a |                     |
                      | 1/2 dt^3   dt^2     |


    Constructors
    ------------
    * `plKalmanFilterCV2D(plFloat var_a_x, plFloat var_a_y, plFloat dt, bool
        observe_velocity)`  

        Constructor.  

        Parameters:  
        * `var_a_x` :  
            the variance of the x acceleration (m^2/s^4) (can be changed using
            set_parameters())  
        * `var_a_y` :  
            the variance of the y acceleration (m^2/s^4) (can be changed using
            set_parameters())  
        * `dt` :  
            the time step (can be changed using set_parameters())  
        * `observe_velocity` :  
            if 'false' (the default), the observation is assumed to be [X, Y, Z]. If
            'true', the observation is assumed to be [X, Y, Z, VX, VY, VZ]  

    C++ includes: plKalmanFilterCV.h

    """

    __swig_setmethods__ = {}
    for _s in [plKalmanFilter]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plKalmanFilterCV2D, name, value)
    __swig_getmethods__ = {}
    for _s in [plKalmanFilter]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plKalmanFilterCV2D, name)
    __repr__ = _swig_repr
    X = _probt_python3.plKalmanFilterCV2D_X
    VX = _probt_python3.plKalmanFilterCV2D_VX
    AX = _probt_python3.plKalmanFilterCV2D_AX
    Y = _probt_python3.plKalmanFilterCV2D_Y
    VY = _probt_python3.plKalmanFilterCV2D_VY
    AY = _probt_python3.plKalmanFilterCV2D_AY
    NSTATES = _probt_python3.plKalmanFilterCV2D_NSTATES
    OX = _probt_python3.plKalmanFilterCV2D_OX
    OY = _probt_python3.plKalmanFilterCV2D_OY
    OVX = _probt_python3.plKalmanFilterCV2D_OVX
    OVY = _probt_python3.plKalmanFilterCV2D_OVY
    NOBS = _probt_python3.plKalmanFilterCV2D_NOBS

    def __init__(self, var_a_x: 'plFloat', var_a_y: 'plFloat', dt: 'plFloat', observe_velocity: 'bool'):
        """
        __init__(self, var_a_x, var_a_y, dt, observe_velocity) -> plKalmanFilterCV2D


        `plKalmanFilterCV2D(plFloat var_a_x, plFloat var_a_y, plFloat dt, bool
            observe_velocity)`  

        Constructor.  

        Parameters
        ----------
        * `var_a_x` :  
            the variance of the x acceleration (m^2/s^4) (can be changed using
            set_parameters())  
        * `var_a_y` :  
            the variance of the y acceleration (m^2/s^4) (can be changed using
            set_parameters())  
        * `dt` :  
            the time step (can be changed using set_parameters())  
        * `observe_velocity` :  
            if 'false' (the default), the observation is assumed to be [X, Y, Z]. If
            'true', the observation is assumed to be [X, Y, Z, VX, VY, VZ]  

        """
        this = _probt_python3.new_plKalmanFilterCV2D(var_a_x, var_a_y, dt, observe_velocity)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def set_parameters(self, var_a_x: 'plFloat', var_a_y: 'plFloat', dt: 'plFloat') -> "void":
        """
        set_parameters(self, var_a_x, var_a_y, dt)


        `set_parameters(plFloat var_a_x, plFloat var_a_y, plFloat dt)`  

        Change filter's parameters.  

        Parameters
        ----------
        * `var_a_x` :  
            the variance of the x acceleration (m^2/s^4)  
        * `var_a_y` :  
            the variance of the y acceleration (m^2/s^4)  
        * `dt` :  
            the time step  

        """
        return _probt_python3.plKalmanFilterCV2D_set_parameters(self, var_a_x, var_a_y, dt)

    __swig_destroy__ = _probt_python3.delete_plKalmanFilterCV2D
    __del__ = lambda self: None
plKalmanFilterCV2D_swigregister = _probt_python3.plKalmanFilterCV2D_swigregister
plKalmanFilterCV2D_swigregister(plKalmanFilterCV2D)

class plKalmanFilterCV3D(plKalmanFilter):
    """

    `plKalmanFilterCV3D(plFloat var_a_x, plFloat var_a_y, plFloat var_a_z, plFloat
        dt, bool observe_velocity)`  

    3D Constant Velocity (zero-mean acceleration) Linear Kalman Filter.  

    State [X, VX, AX, Y, VY, AY, Z, VZ, AZ] in which the acceleration AX, AY, AZ
    will be always zero.  

    By default, the observation is assumed to be [X, Y, Z] (Only the position is
    observed) It can be changed by setting the parameter 'observe_velocity' to
    'true' in the constructor.  

    For each dimension among X, Y, Z we have:  

        x_k = x_{k-1} + dt v_{k-1} +      1/2 dt^2 a_{k-1}
        v_k = v_{k-1} +                   dt a_{k-1}

        with x the position, v the velocity, and a the acceleration.

        X_k = [x_k, v_k]^T

        X_k = A X_{k-1} + W

              | 1  dt |
        A  =  |       |
              | 0  1  |

        W = a_{k-1} [ 1/2 dt^2, dt ]^T
          = a_{k-1} G

        E(W) = E(a_{k-1}) G
             = 0

        Q = Var(W W^T)
          = G Var(a_{k-1}) G^T
          = sigma^2_a G G^T

                      | 1/4 dt^4   1/2 dt^3 |
          = sigma^2_a |                     |
                      | 1/2 dt^3   dt^2     |


    Constructors
    ------------
    * `plKalmanFilterCV3D(plFloat var_a_x, plFloat var_a_y, plFloat var_a_z, plFloat
        dt, bool observe_velocity)`  

        Constructor.  

        Parameters:  
        * `var_a_x` :  
            the x variance of the acceleration (m^2/s^4) (can be changed using
            set_parameters())  
        * `var_a_y` :  
            the y variance of the acceleration (m^2/s^4) (can be changed using
            set_parameters())  
        * `var_a_z` :  
            the z variance of the acceleration (m^2/s^4) (can be changed using
            set_parameters())  
        * `dt` :  
            the time step (can be changed using set_parameters())  
        * `observe_velocity` :  
            if 'false' (the default), the observation is assumed to be [X, Y, Z]. If
            'true', the observation is assumed to be [X, Y, Z, VX, VY, VZ]  

    C++ includes: plKalmanFilterCV.h

    """

    __swig_setmethods__ = {}
    for _s in [plKalmanFilter]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plKalmanFilterCV3D, name, value)
    __swig_getmethods__ = {}
    for _s in [plKalmanFilter]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plKalmanFilterCV3D, name)
    __repr__ = _swig_repr
    X = _probt_python3.plKalmanFilterCV3D_X
    VX = _probt_python3.plKalmanFilterCV3D_VX
    AX = _probt_python3.plKalmanFilterCV3D_AX
    Y = _probt_python3.plKalmanFilterCV3D_Y
    VY = _probt_python3.plKalmanFilterCV3D_VY
    AY = _probt_python3.plKalmanFilterCV3D_AY
    Z = _probt_python3.plKalmanFilterCV3D_Z
    VZ = _probt_python3.plKalmanFilterCV3D_VZ
    AZ = _probt_python3.plKalmanFilterCV3D_AZ
    NSTATES = _probt_python3.plKalmanFilterCV3D_NSTATES
    OX = _probt_python3.plKalmanFilterCV3D_OX
    OY = _probt_python3.plKalmanFilterCV3D_OY
    OZ = _probt_python3.plKalmanFilterCV3D_OZ
    OVX = _probt_python3.plKalmanFilterCV3D_OVX
    OVY = _probt_python3.plKalmanFilterCV3D_OVY
    OVZ = _probt_python3.plKalmanFilterCV3D_OVZ
    NOBS = _probt_python3.plKalmanFilterCV3D_NOBS

    def __init__(self, var_a_x: 'plFloat', var_a_y: 'plFloat', var_a_z: 'plFloat', dt: 'plFloat', observe_velocity: 'bool'):
        """
        __init__(self, var_a_x, var_a_y, var_a_z, dt, observe_velocity) -> plKalmanFilterCV3D


        `plKalmanFilterCV3D(plFloat var_a_x, plFloat var_a_y, plFloat var_a_z, plFloat
            dt, bool observe_velocity)`  

        Constructor.  

        Parameters
        ----------
        * `var_a_x` :  
            the x variance of the acceleration (m^2/s^4) (can be changed using
            set_parameters())  
        * `var_a_y` :  
            the y variance of the acceleration (m^2/s^4) (can be changed using
            set_parameters())  
        * `var_a_z` :  
            the z variance of the acceleration (m^2/s^4) (can be changed using
            set_parameters())  
        * `dt` :  
            the time step (can be changed using set_parameters())  
        * `observe_velocity` :  
            if 'false' (the default), the observation is assumed to be [X, Y, Z]. If
            'true', the observation is assumed to be [X, Y, Z, VX, VY, VZ]  

        """
        this = _probt_python3.new_plKalmanFilterCV3D(var_a_x, var_a_y, var_a_z, dt, observe_velocity)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def set_parameters(self, var_a_x: 'plFloat', var_a_y: 'plFloat', var_a_z: 'plFloat', dt: 'plFloat') -> "void":
        """
        set_parameters(self, var_a_x, var_a_y, var_a_z, dt)


        `set_parameters(plFloat var_a_x, plFloat var_a_y, plFloat var_a_z, plFloat dt)`  

        Change filter's parameters.  

        Parameters
        ----------
        * `var_a_x` :  
            the variance of the x acceleration (m^2/s^4)  
        * `var_a_y` :  
            the variance of the y acceleration (m^2/s^4)  
        * `var_a_z` :  
            the variance of the z acceleration (m^2/s^4)  
        * `dt` :  
            the time step  

        """
        return _probt_python3.plKalmanFilterCV3D_set_parameters(self, var_a_x, var_a_y, var_a_z, dt)

    __swig_destroy__ = _probt_python3.delete_plKalmanFilterCV3D
    __del__ = lambda self: None
plKalmanFilterCV3D_swigregister = _probt_python3.plKalmanFilterCV3D_swigregister
plKalmanFilterCV3D_swigregister(plKalmanFilterCV3D)

class plKalmanFilterCA2D(plKalmanFilter):
    """

    `plKalmanFilterCA2D(plFloat var_jerk_x, plFloat var_jerk_y, plFloat dt, bool
        observe_velocity)`  

    2D Constant Acceleration (zero-mean jerk) Linear Kalman Filter.  

    State [X, VX, AX, Y, VY, AY].  

    By default, the observation is assumed to be [X, Y] (Only the position is
    observed) It can be changed by setting the parameter 'observe_velocity' to
    'true' in the constructor.  

    For each dimension among X, Y we have:  

         x_k = x_{k-1} + dt v_{k-1} + 1/2 dt^2 a_{k-1} +    1/6 dt^3 j_{k-1}
         v_k = v_{k-1} + dt a_{k-1} +                       1/2 dt^2 j_{k-1}
         a_k = a_{k-1} +                                    dt j_{k-1}

         with x the position, v the velocity, a the acceleration, and j the jerk.

         X_k = [x_k, v_k, a_k]^T

         X_k = A X_{k-1} + W

               | 1    dt   1/2 dt^2 |
         A  =  |                    |
               | 0    1    dt       |
               |                    |
               | 0    0    1        |

         W = j_{k-1} [ 1/6 dt^3, 1/2 dt^2, dt ]^T
           = j_{k-1} G

        E(W) = E(j_{k-1}) G
             = 0

        Q = Var(W W^T)
          = G Var(j_{k-1}) G^T
          = sigma^2_j G G^T

                      | a   b   c |
                      |           |
          = sigma^2_j | b   d   e |
                      |           |
                      | c   e   f |

        a = 1/36 dt^6
        b = 1/12 dt^5
        c = 1/6  dt^4
        d = 1/4  dt^4
        e = 1/2  dt^3
        f =      dt^2


    Constructors
    ------------
    * `plKalmanFilterCA2D(plFloat var_jerk_x, plFloat var_jerk_y, plFloat dt, bool
        observe_velocity)`  

        Constructor.  

        Parameters:  
        * `var_jerk_x` :  
            the variance of x the jerk (m^2/s^6) (can be changed using
            set_parameters())  
        * `var_jerk_y` :  
            the variance of y the jerk (m^2/s^6) (can be changed using
            set_parameters())  
        * `dt` :  
            the time step (can be changed using set_parameters())  
        * `observe_velocity` :  
            if 'false' (the default), the observation is assumed to be [X, Y]. If
            'true', the observation is assumed to be [X, Y, VX, VY]  

    C++ includes: plKalmanFilterCA.h

    """

    __swig_setmethods__ = {}
    for _s in [plKalmanFilter]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plKalmanFilterCA2D, name, value)
    __swig_getmethods__ = {}
    for _s in [plKalmanFilter]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plKalmanFilterCA2D, name)
    __repr__ = _swig_repr
    X = _probt_python3.plKalmanFilterCA2D_X
    VX = _probt_python3.plKalmanFilterCA2D_VX
    AX = _probt_python3.plKalmanFilterCA2D_AX
    Y = _probt_python3.plKalmanFilterCA2D_Y
    VY = _probt_python3.plKalmanFilterCA2D_VY
    AY = _probt_python3.plKalmanFilterCA2D_AY
    NSTATES = _probt_python3.plKalmanFilterCA2D_NSTATES
    OX = _probt_python3.plKalmanFilterCA2D_OX
    OY = _probt_python3.plKalmanFilterCA2D_OY
    OVX = _probt_python3.plKalmanFilterCA2D_OVX
    OVY = _probt_python3.plKalmanFilterCA2D_OVY
    NOBS = _probt_python3.plKalmanFilterCA2D_NOBS

    def __init__(self, var_jerk_x: 'plFloat', var_jerk_y: 'plFloat', dt: 'plFloat', observe_velocity: 'bool'):
        """
        __init__(self, var_jerk_x, var_jerk_y, dt, observe_velocity) -> plKalmanFilterCA2D


        `plKalmanFilterCA2D(plFloat var_jerk_x, plFloat var_jerk_y, plFloat dt, bool
            observe_velocity)`  

        Constructor.  

        Parameters
        ----------
        * `var_jerk_x` :  
            the variance of x the jerk (m^2/s^6) (can be changed using set_parameters())  
        * `var_jerk_y` :  
            the variance of y the jerk (m^2/s^6) (can be changed using set_parameters())  
        * `dt` :  
            the time step (can be changed using set_parameters())  
        * `observe_velocity` :  
            if 'false' (the default), the observation is assumed to be [X, Y]. If
            'true', the observation is assumed to be [X, Y, VX, VY]  

        """
        this = _probt_python3.new_plKalmanFilterCA2D(var_jerk_x, var_jerk_y, dt, observe_velocity)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def set_parameters(self, var_jerk_x: 'plFloat', var_jerk_y: 'plFloat', dt: 'plFloat') -> "void":
        """
        set_parameters(self, var_jerk_x, var_jerk_y, dt)


        `set_parameters(plFloat var_jerk_x, plFloat var_jerk_y, plFloat dt)`  

        Change filter's parameters.  

        Parameters
        ----------
        * `var_jerk_x` :  
            the variance of the x jerk (m^2/s^6)  
        * `var_jerk_y` :  
            the variance of the y jerk (m^2/s^6)  
        * `dt` :  
            the time step  

        """
        return _probt_python3.plKalmanFilterCA2D_set_parameters(self, var_jerk_x, var_jerk_y, dt)

    __swig_destroy__ = _probt_python3.delete_plKalmanFilterCA2D
    __del__ = lambda self: None
plKalmanFilterCA2D_swigregister = _probt_python3.plKalmanFilterCA2D_swigregister
plKalmanFilterCA2D_swigregister(plKalmanFilterCA2D)

class plKalmanFilterCA3D(plKalmanFilter):
    """

    `plKalmanFilterCA3D(plFloat var_jerk_x, plFloat var_jerk_y, plFloat var_jerk_z,
        plFloat dt, bool observe_velocity)`  

    3D Constant Acceleration (zero-mean jerk) Linear Kalman Filter.  

    State [X, VX, AX, Y, VY, AY, Z, VZ, AZ].  

    By default, the observation is assumed to be [X, Y, Z] (Only the position is
    observed) It can be changed by setting the parameter 'observe_velocity' to
    'true' in the constructor.  

    For each dimension among X, Y, Z we have:  

         x_k = x_{k-1} + dt v_{k-1} + 1/2 dt^2 a_{k-1} +    1/6 dt^3 j_{k-1}
         v_k = v_{k-1} + dt a_{k-1} +                       1/2 dt^2 j_{k-1}
         a_k = a_{k-1} +                                    dt j_{k-1}

         with x the position, v the velocity, a the acceleration, and j the jerk.

         X_k = [x_k, v_k, a_k]^T

         X_k = A X_{k-1} + W

               | 1    dt   1/2 dt^2 |
         A  =  |                    |
               | 0    1    dt       |
               |                    |
               | 0    0    1        |

         W = j_{k-1} [ 1/6 dt^3, 1/2 dt^2, dt ]^T
           = j_{k-1} G

        E(W) = E(j_{k-1}) G
             = 0

        Q = Var(W W^T)
          = G Var(j_{k-1}) G^T
          = sigma^2_j G G^T

                      | a   b   c |
                      |           |
          = sigma^2_j | b   d   e |
                      |           |
                      | c   e   f |

        a = 1/36 dt^6
        b = 1/12 dt^5
        c = 1/6  dt^4
        d = 1/4  dt^4
        e = 1/2  dt^3
        f =      dt^2


    Constructors
    ------------
    * `plKalmanFilterCA3D(plFloat var_jerk_x, plFloat var_jerk_y, plFloat
        var_jerk_z, plFloat dt, bool observe_velocity)`  

        Constructor.  

        Parameters:  
        * `var_jerk_x` :  
            the variance of the x jerk (m^2/s^6) (can be changed using
            set_parameters())  
        * `var_jerk_y` :  
            the variance of the y jerk (m^2/s^6) (can be changed using
            set_parameters())  
        * `var_jerk_z` :  
            the variance of the z jerk (m^2/s^6) (can be changed using
            set_parameters())  
        * `dt` :  
            the time step (can be changed using set_parameters())  
        * `observe_velocity` :  
            if 'false' (the default), the observation is assumed to be [X, Y, Z]. If
            'true', the observation is assumed to be [X, Y, Z, VX, VY, VZ]  

    C++ includes: plKalmanFilterCA.h

    """

    __swig_setmethods__ = {}
    for _s in [plKalmanFilter]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plKalmanFilterCA3D, name, value)
    __swig_getmethods__ = {}
    for _s in [plKalmanFilter]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plKalmanFilterCA3D, name)
    __repr__ = _swig_repr
    X = _probt_python3.plKalmanFilterCA3D_X
    VX = _probt_python3.plKalmanFilterCA3D_VX
    AX = _probt_python3.plKalmanFilterCA3D_AX
    Y = _probt_python3.plKalmanFilterCA3D_Y
    VY = _probt_python3.plKalmanFilterCA3D_VY
    AY = _probt_python3.plKalmanFilterCA3D_AY
    Z = _probt_python3.plKalmanFilterCA3D_Z
    VZ = _probt_python3.plKalmanFilterCA3D_VZ
    AZ = _probt_python3.plKalmanFilterCA3D_AZ
    NSTATES = _probt_python3.plKalmanFilterCA3D_NSTATES
    OX = _probt_python3.plKalmanFilterCA3D_OX
    OY = _probt_python3.plKalmanFilterCA3D_OY
    OZ = _probt_python3.plKalmanFilterCA3D_OZ
    OVX = _probt_python3.plKalmanFilterCA3D_OVX
    OVY = _probt_python3.plKalmanFilterCA3D_OVY
    OVZ = _probt_python3.plKalmanFilterCA3D_OVZ
    NOBS = _probt_python3.plKalmanFilterCA3D_NOBS

    def __init__(self, var_jerk_x: 'plFloat', var_jerk_y: 'plFloat', var_jerk_z: 'plFloat', dt: 'plFloat', observe_velocity: 'bool'):
        """
        __init__(self, var_jerk_x, var_jerk_y, var_jerk_z, dt, observe_velocity) -> plKalmanFilterCA3D


        `plKalmanFilterCA3D(plFloat var_jerk_x, plFloat var_jerk_y, plFloat var_jerk_z,
            plFloat dt, bool observe_velocity)`  

        Constructor.  

        Parameters
        ----------
        * `var_jerk_x` :  
            the variance of the x jerk (m^2/s^6) (can be changed using set_parameters())  
        * `var_jerk_y` :  
            the variance of the y jerk (m^2/s^6) (can be changed using set_parameters())  
        * `var_jerk_z` :  
            the variance of the z jerk (m^2/s^6) (can be changed using set_parameters())  
        * `dt` :  
            the time step (can be changed using set_parameters())  
        * `observe_velocity` :  
            if 'false' (the default), the observation is assumed to be [X, Y, Z]. If
            'true', the observation is assumed to be [X, Y, Z, VX, VY, VZ]  

        """
        this = _probt_python3.new_plKalmanFilterCA3D(var_jerk_x, var_jerk_y, var_jerk_z, dt, observe_velocity)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def set_parameters(self, var_jerk_x: 'plFloat', var_jerk_y: 'plFloat', var_jerk_z: 'plFloat', dt: 'plFloat') -> "void":
        """
        set_parameters(self, var_jerk_x, var_jerk_y, var_jerk_z, dt)


        `set_parameters(plFloat var_jerk_x, plFloat var_jerk_y, plFloat var_jerk_z,
            plFloat dt)`  

        Change filter's parameters.  

        Parameters
        ----------
        * `var_jerk_x` :  
            the variance of the x jerk (m^2/s^6)  
        * `var_jerk_y` :  
            the variance of the y jerk (m^2/s^6)  
        * `var_jerk_z` :  
            the variance of the z jerk (m^2/s^6)  
        * `dt` :  
            the time step  

        """
        return _probt_python3.plKalmanFilterCA3D_set_parameters(self, var_jerk_x, var_jerk_y, var_jerk_z, dt)

    __swig_destroy__ = _probt_python3.delete_plKalmanFilterCA3D
    __del__ = lambda self: None
plKalmanFilterCA3D_swigregister = _probt_python3.plKalmanFilterCA3D_swigregister
plKalmanFilterCA3D_swigregister(plKalmanFilterCA3D)


def imm_dim_error(func_name: 'std::string const &') -> "void":
    """
    imm_dim_error(func_name)


    `imm_dim_error(const std::string &func_name)`  

    """
    return _probt_python3.imm_dim_error(func_name)

def check_norm(probs: 'plFloatVector') -> "void":
    """
    check_norm(probs)


    `check_norm(const plFloatVector &probs)`  

    """
    return _probt_python3.check_norm(probs)

def check_col_norm(probs: 'plFloatMatrix') -> "void":
    """
    check_col_norm(probs)


    `check_col_norm(const plFloatMatrix &probs)`  

    """
    return _probt_python3.check_col_norm(probs)
class plIMM(plKalmanFilter):
    """

    `plIMM(unsigned int state_dim, unsigned int obs_dim)`  
    `plIMM(unsigned int state_dim, unsigned int obs_dim, const std::vector<
        plKalmanFilter *> &models)`  

    IMM filter.  

    Constructors
    ------------
    * `plIMM(unsigned int state_dim, unsigned int obs_dim)`  

        Constructor.  

    * `plIMM(unsigned int state_dim, unsigned int obs_dim, const std::vector<
        plKalmanFilter *> &models)`  

        Constructor.  

    C++ includes: plIMM.h

    """

    __swig_setmethods__ = {}
    for _s in [plKalmanFilter]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plIMM, name, value)
    __swig_getmethods__ = {}
    for _s in [plKalmanFilter]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plIMM, name)
    __repr__ = _swig_repr

    def __init__(self, *args):
        """
        __init__(self, state_dim, obs_dim) -> plIMM
        __init__(self, state_dim, obs_dim, models) -> plIMM


        `plIMM(unsigned int state_dim, unsigned int obs_dim)`  
        `plIMM(unsigned int state_dim, unsigned int obs_dim, const std::vector<
            plKalmanFilter *> &models)`  

        Overloaded function
        -------------------
        * `plIMM(unsigned int state_dim, unsigned int obs_dim)`  

            Constructor.  

        * `plIMM(unsigned int state_dim, unsigned int obs_dim, const std::vector<
            plKalmanFilter *> &models)`  

            Constructor.  

        """
        this = _probt_python3.new_plIMM(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def add_model(self, model: 'plKalmanFilter') -> "void":
        """
        add_model(self, model)


        `add_model(plKalmanFilter *model)`  

        Add a model.  

        """
        return _probt_python3.plIMM_add_model(self, model)


    def set_switching_prob(self, old_model: 'size_t', new_model: 'size_t', p: 'plProbValue') -> "void":
        """
        set_switching_prob(self, old_model, new_model, p)


        `set_switching_prob(size_t old_model, size_t new_model, plProbValue p)`  

        Set the probability to switch from model i to model j P(new_model | old_model)  

        """
        return _probt_python3.plIMM_set_switching_prob(self, old_model, new_model, p)


    def set_switching_probs(self, probs: 'plFloatMatrix') -> "void":
        """
        set_switching_probs(self, probs)


        `set_switching_probs(const plFloatMatrix &probs)`  

        Set the switching probabilities.  

        """
        return _probt_python3.plIMM_set_switching_probs(self, probs)


    def set_model_prob(self, model: 'size_t', p: 'plFloat') -> "void":
        """
        set_model_prob(self, model, p)


        `set_model_prob(size_t model, plFloat p)`  

        Set the current probability of a model.  

        """
        return _probt_python3.plIMM_set_model_prob(self, model, p)


    def set_model_probs(self, probs: 'plFloatVector') -> "void":
        """
        set_model_probs(self, probs)


        `set_model_probs(const plFloatVector &probs)`  

        Set the current probability of a model.  

        """
        return _probt_python3.plIMM_set_model_probs(self, probs)


    def model_probabilities(self) -> "plFloatVector":
        """
        model_probabilities(self) -> plFloatVector


        `model_probabilities() const -> plFloatVector`  

        Get the current model probabilities.  

        """
        return _probt_python3.plIMM_model_probabilities(self)


    def prediction(self) -> "void":
        """
        prediction(self)


        `prediction()`  

        Prediction step.  

        \[ \hat x^{-}_k = A \hat x_{k-1} + B u_k \]  

        \[ P^{-}_k = A P_{k-1} A^T + Q \]  

        """
        return _probt_python3.plIMM_prediction(self)


    def observation(self, zo: 'plFloatVector', Ro: 'plFloatMatrix', observation_weight: 'plFloat'=1.0) -> "void":
        """
        observation(self, zo, Ro, observation_weight=1.0)
        observation(self, zo, Ro)


        `observation(const plFloatVector &zo, const plFloatMatrix &Ro, plFloat
            observation_weight=PL_ONE)`  

        Update step using observation vector *zo* and its corresponding covariance
        matrix *Ro*.  

        Equivalent to calling (without changing *z* and *R* internally however):  

        *   set_observation_noise_cov_matrix(Ro)  
        *   set_observation(zo, observation_weight)  
        *   update()  

        """
        return _probt_python3.plIMM_observation(self, zo, Ro, observation_weight)


    def set_initial_estimation(self, x: 'plFloatVector', P: 'plFloatMatrix') -> "void":
        """
        set_initial_estimation(self, x, P)


        `set_initial_estimation(const plFloatVector &x, const plFloatMatrix &P)`  

        Set the initial estimation x0 ans P0.  

        """
        return _probt_python3.plIMM_set_initial_estimation(self, x, P)

    __swig_destroy__ = _probt_python3.delete_plIMM
    __del__ = lambda self: None
plIMM_swigregister = _probt_python3.plIMM_swigregister
plIMM_swigregister(plIMM)

class plIMM_CA_CV_2D(plIMM):
    """

    `plIMM_CA_CV_2D(plFloat var_accel_x, plFloat var_accel_y, plFloat var_jerk_x,
        plFloat var_jerk_y, plFloat dt, bool observe_velocity)`  

    2D IMM filter with Constant Veclocity and Constant Acceleration underlying
    models  

    Constructors
    ------------
    * `plIMM_CA_CV_2D(plFloat var_accel_x, plFloat var_accel_y, plFloat var_jerk_x,
        plFloat var_jerk_y, plFloat dt, bool observe_velocity)`  

    C++ includes: plIMM.h

    """

    __swig_setmethods__ = {}
    for _s in [plIMM]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plIMM_CA_CV_2D, name, value)
    __swig_getmethods__ = {}
    for _s in [plIMM]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plIMM_CA_CV_2D, name)
    __repr__ = _swig_repr

    def __init__(self, var_accel_x: 'plFloat', var_accel_y: 'plFloat', var_jerk_x: 'plFloat', var_jerk_y: 'plFloat', dt: 'plFloat', observe_velocity: 'bool'):
        """
        __init__(self, var_accel_x, var_accel_y, var_jerk_x, var_jerk_y, dt, observe_velocity) -> plIMM_CA_CV_2D


        `plIMM_CA_CV_2D(plFloat var_accel_x, plFloat var_accel_y, plFloat var_jerk_x,
            plFloat var_jerk_y, plFloat dt, bool observe_velocity)`  

        """
        this = _probt_python3.new_plIMM_CA_CV_2D(var_accel_x, var_accel_y, var_jerk_x, var_jerk_y, dt, observe_velocity)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this
    __swig_destroy__ = _probt_python3.delete_plIMM_CA_CV_2D
    __del__ = lambda self: None
plIMM_CA_CV_2D_swigregister = _probt_python3.plIMM_CA_CV_2D_swigregister
plIMM_CA_CV_2D_swigregister(plIMM_CA_CV_2D)

class plIMM_CA_CV_3D(plIMM):
    """

    `plIMM_CA_CV_3D(plFloat var_accel_x, plFloat var_accel_y, plFloat var_accel_z,
        plFloat var_jerk_x, plFloat var_jerk_y, plFloat var_jerk_z, plFloat dt, bool
        observe_velocity)`  

    3D IMM filter with Constant Veclocity and Constant Acceleration underlying
    models  

    Constructors
    ------------
    * `plIMM_CA_CV_3D(plFloat var_accel_x, plFloat var_accel_y, plFloat var_accel_z,
        plFloat var_jerk_x, plFloat var_jerk_y, plFloat var_jerk_z, plFloat dt, bool
        observe_velocity)`  

    C++ includes: plIMM.h

    """

    __swig_setmethods__ = {}
    for _s in [plIMM]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plIMM_CA_CV_3D, name, value)
    __swig_getmethods__ = {}
    for _s in [plIMM]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plIMM_CA_CV_3D, name)
    __repr__ = _swig_repr

    def __init__(self, var_accel_x: 'plFloat', var_accel_y: 'plFloat', var_accel_z: 'plFloat', var_jerk_x: 'plFloat', var_jerk_y: 'plFloat', var_jerk_z: 'plFloat', dt: 'plFloat', observe_velocity: 'bool'):
        """
        __init__(self, var_accel_x, var_accel_y, var_accel_z, var_jerk_x, var_jerk_y, var_jerk_z, dt, observe_velocity) -> plIMM_CA_CV_3D


        `plIMM_CA_CV_3D(plFloat var_accel_x, plFloat var_accel_y, plFloat var_accel_z,
            plFloat var_jerk_x, plFloat var_jerk_y, plFloat var_jerk_z, plFloat dt, bool
            observe_velocity)`  

        """
        this = _probt_python3.new_plIMM_CA_CV_3D(var_accel_x, var_accel_y, var_accel_z, var_jerk_x, var_jerk_y, var_jerk_z, dt, observe_velocity)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this
    __swig_destroy__ = _probt_python3.delete_plIMM_CA_CV_3D
    __del__ = lambda self: None
plIMM_CA_CV_3D_swigregister = _probt_python3.plIMM_CA_CV_3D_swigregister
plIMM_CA_CV_3D_swigregister(plIMM_CA_CV_3D)

class plEKF(plKalmanFilter):
    """

    `plEKF(unsigned int state_dim, unsigned int obs_dim)`  
    `plEKF(const plFloatVector &init_estimation_mean, const plFloatMatrix
        &init_estimation_cov_matrix, const plFloatMatrix
        &prediction_noise_cov_matrix, const plFloatMatrix
        &observation_noise_cov_matrix)`  

    This class implements the Extended Kalman Filter.  

    The system is defined by the two equations:  

    *   System (prediction) non-linear equation: \begin{eqnarray*} x_k = f(
        x_{k-1}, w_{k-1} ) \end{eqnarray*} with: \begin{eqnarray*} p(w) = {\cal
        N}(0, Q) \end{eqnarray*}  
    *   Observation (measurement) non-linear equation: \begin{eqnarray*} z_k = h(
        x_{k}, v_{k} ) \end{eqnarray*} with: \begin{eqnarray*} p(v) = {\cal N}(0,
        R) \end{eqnarray*}  

    Constructors
    ------------
    * `plEKF(unsigned int state_dim, unsigned int obs_dim)`  

        Constructor.  

        Parameters:  
        * `state_dim` :  
            state dimension  
        * `obs_dim` :  
            observation dimension  

    * `plEKF(const plFloatVector &init_estimation_mean, const plFloatMatrix
        &init_estimation_cov_matrix, const plFloatMatrix
        &prediction_noise_cov_matrix, const plFloatMatrix
        &observation_noise_cov_matrix)`  

        Construction and initialization.  

        Parameters:  
        * `init_estimation_mean` :  
            initial estimation mean vector (x0)  
        * `init_estimation_cov_matrix` :  
            initial estimation covariance matrix (P0)  
        * `prediction_noise_cov_matrix` :  
            prediction noise covariance matrix (Q)  
        * `observation_noise_cov_matrix` :  
            observation noise covariance matrix (R)  

    C++ includes: plEKF.h

    """

    __swig_setmethods__ = {}
    for _s in [plKalmanFilter]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plEKF, name, value)
    __swig_getmethods__ = {}
    for _s in [plKalmanFilter]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plEKF, name)
    __repr__ = _swig_repr

    def __init__(self, *args):
        """
        __init__(self, state_dim, obs_dim) -> plEKF
        __init__(self, init_estimation_mean, init_estimation_cov_matrix, prediction_noise_cov_matrix, observation_noise_cov_matrix) -> plEKF


        `plEKF(unsigned int state_dim, unsigned int obs_dim)`  
        `plEKF(const plFloatVector &init_estimation_mean, const plFloatMatrix
            &init_estimation_cov_matrix, const plFloatMatrix
            &prediction_noise_cov_matrix, const plFloatMatrix
            &observation_noise_cov_matrix)`  

        Overloaded function
        -------------------
        * `plEKF(unsigned int state_dim, unsigned int obs_dim)`  

            Constructor.  

            Parameters:  
            * `state_dim` :  
                state dimension  
            * `obs_dim` :  
                observation dimension  

        * `plEKF(const plFloatVector &init_estimation_mean, const plFloatMatrix
            &init_estimation_cov_matrix, const plFloatMatrix
            &prediction_noise_cov_matrix, const plFloatMatrix
            &observation_noise_cov_matrix)`  

            Construction and initialization.  

            Parameters:  
            * `init_estimation_mean` :  
                initial estimation mean vector (x0)  
            * `init_estimation_cov_matrix` :  
                initial estimation covariance matrix (P0)  
            * `prediction_noise_cov_matrix` :  
                prediction noise covariance matrix (Q)  
            * `observation_noise_cov_matrix` :  
                observation noise covariance matrix (R)  

        """
        if self.__class__ == plEKF:
            _self = None
        else:
            _self = self
        this = _probt_python3.new_plEKF(_self, *args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this
    __swig_destroy__ = _probt_python3.delete_plEKF
    __del__ = lambda self: None

    def prediction(self) -> "void":
        """
        prediction(self)


        `prediction()`  

        Prediction step.  

        \[ \hat x^{-}_k = f(\hat x_{k-1}, 0) \]  

        \[ P^{-}_k = A_k P_{k-1} A_k^T + W_k Q W_k^T\]  

        """
        return _probt_python3.plEKF_prediction(self)


    def observation(self, *args) -> "void":
        """
        observation(self, zo, observation_weight=1.0)
        observation(self, zo)
        observation(self, zo, Ro, observation_weight=1.0)
        observation(self, zo, Ro)


        `observation(const plFloatVector &zo, const plFloatMatrix &Ro, plFloat
            observation_weight=PL_ONE)`  

        Observation step.  

        \[ K_k = P^{-}_k H_k^T (H_k P^{-}_k H_k^T + V_k Ro V_k^T)^{-1} \]  

        \[ \hat x_k = \hat x^{-}_k + K_k (zo - h( \hat x^{-}_k, 0 ) ) \]  

        \[ P_k = (I - K_k H_k) P^{-}_k \]  

        """
        return _probt_python3.plEKF_observation(self, *args)


    def get_observation_mahalanobis_distance(self, *args) -> "plFloat":
        """
        get_observation_mahalanobis_distance(self, zo) -> plFloat
        get_observation_mahalanobis_distance(self, zo, det) -> plFloat
        get_observation_mahalanobis_distance(self, zo, Ro) -> plFloat
        get_observation_mahalanobis_distance(self, zo, Ro, det) -> plFloat


        `get_observation_mahalanobis_distance(const plFloatVector &zo, const
            plFloatMatrix &Ro) const -> plFloat`  
        `get_observation_mahalanobis_distance(const plFloatVector &zo, const
            plFloatMatrix &Ro, plFloat &det) const -> plFloat`  

        Overloaded function
        -------------------
        * `get_observation_mahalanobis_distance(const plFloatVector &zo, const
            plFloatMatrix &Ro) const -> plFloat`  

            Return the Mahalanobis distance of a given observation.  

        * `get_observation_mahalanobis_distance(const plFloatVector &zo, const
            plFloatMatrix &Ro, plFloat &det) const -> plFloat`  

            Return the Mahalanobis distance of a given observation and the determinant
            of the convariance matrix.  

        """
        return _probt_python3.plEKF_get_observation_mahalanobis_distance(self, *args)


    def get_pdf_value(self, *args) -> "plProbValue":
        """
        get_pdf_value(self, zo) -> plProbValue
        get_pdf_value(self, zo, Ro) -> plProbValue


        `get_pdf_value(const plFloatVector &zo, const plFloatMatrix &Ro) const ->
            plProbValue`  

        Return, for the observation *zo* and the corresponding variance matrix *Ro*, the
        value of the density function value according to the current gaussian estimate.  

        """
        return _probt_python3.plEKF_get_pdf_value(self, *args)


    def get_pdf_value_log(self, *args) -> "plFloat":
        """
        get_pdf_value_log(self, zo) -> plFloat
        get_pdf_value_log(self, Zo, Ro) -> plFloat


        `get_pdf_value_log(const plFloatVector &Zo, const plFloatMatrix &Ro) const ->
            plFloat`  

        Same as above but using log.  

        """
        return _probt_python3.plEKF_get_pdf_value_log(self, *args)


    def prediction_model(self, predicted_state: 'plFloatVector') -> "void":
        """prediction_model(self, predicted_state)"""
        return _probt_python3.plEKF_prediction_model(self, predicted_state)


    def observation_model(self, expected_observation: 'plFloatVector') -> "void":
        """observation_model(self, expected_observation)"""
        return _probt_python3.plEKF_observation_model(self, expected_observation)


    def prediction_model_jacobian(self, A_k: 'plFloatMatrix') -> "void":
        """prediction_model_jacobian(self, A_k)"""
        return _probt_python3.plEKF_prediction_model_jacobian(self, A_k)


    def prediction_noise_jacobian(self, W_k: 'plFloatMatrix') -> "void":
        """prediction_noise_jacobian(self, W_k)"""
        return _probt_python3.plEKF_prediction_noise_jacobian(self, W_k)


    def observation_model_jacobian(self, H_k: 'plFloatMatrix') -> "void":
        """observation_model_jacobian(self, H_k)"""
        return _probt_python3.plEKF_observation_model_jacobian(self, H_k)


    def observation_noise_jacobian(self, V_k: 'plFloatMatrix') -> "void":
        """observation_noise_jacobian(self, V_k)"""
        return _probt_python3.plEKF_observation_noise_jacobian(self, V_k)

    def __disown__(self):
        self.this.disown()
        _probt_python3.disown_plEKF(self)
        return weakref_proxy(self)

    def Output(self) -> "void":
        """Output(self)"""
        return _probt_python3.plEKF_Output(self)


    def get_Q(self) -> "plFloatMatrix":
        """get_Q(self) -> plFloatMatrix"""
        return _probt_python3.plEKF_get_Q(self)


    def get_observation_angle_indices(self) -> "std::vector< unsigned int,std::allocator< unsigned int > >":
        """get_observation_angle_indices(self) -> UnsignedIntVector"""
        return _probt_python3.plEKF_get_observation_angle_indices(self)

plEKF_swigregister = _probt_python3.plEKF_swigregister
plEKF_swigregister(plEKF)

class plUKF(plKalmanFilter):
    """

    `plUKF(size_t state_dim, size_t obs_dim, plFloat alpha=0.001, plFloat beta=2.0,
        plFloat k=0.0)`  
    `plUKF(size_t state_dim, size_t obs_dim, const plFloatVector
        &init_estimation_mean, const plFloatMatrix &init_estimation_cov_matrix,
        const plFloatMatrix &prediction_noise_cov_matrix, const plFloatMatrix
        &observation_noise_cov_matrix, bool augmented_process_noise=false, bool
        augmented_observation_noise=false, plFloat alpha=0.001, plFloat beta=2.0,
        plFloat k=0.0)`  

    This class implements the Unscented Kalman Filter.  

    The system is defined by the two equations:  

    *   System (prediction) non-linear equation: \[ x_k = f( x_{k-1} ) + w_{k-1}\]
        with: \[ p(w) = {\cal N}(0, Q) \]  
    *   Observation (measurement) non-linear equation: \[ z_k = h( x_{k}) + v_{k}
        \] with: \[ p(v) = {\cal N}(0, R) \]  

    Constructors
    ------------
    * `plUKF(size_t state_dim, size_t obs_dim, plFloat alpha=0.001, plFloat
        beta=2.0, plFloat k=0.0)`  

        Constructor.  

        Parameters:  
        * `state_dim` :  
            state dimension  
        * `obs_dim` :  
            observation dimension  
        * `alpha` :  
            ukf parameter  
        * `beta` :  
            ukf parameter  
        * `k` :  
            ukf parameter  

    * `plUKF(size_t state_dim, size_t obs_dim, const plFloatVector
        &init_estimation_mean, const plFloatMatrix &init_estimation_cov_matrix,
        const plFloatMatrix &prediction_noise_cov_matrix, const plFloatMatrix
        &observation_noise_cov_matrix, bool augmented_process_noise=false, bool
        augmented_observation_noise=false, plFloat alpha=0.001, plFloat beta=2.0,
        plFloat k=0.0)`  

        Construction and initialization.  

        Parameters:  
        * `state_dim` :  
            state dimension  
        * `obs_dim` :  
            observation dimension  
        * `init_estimation_mean` :  
            initial estimation mean vector (x0)  
        * `init_estimation_cov_matrix` :  
            initial estimation covariance matrix (P0)  
        * `prediction_noise_cov_matrix` :  
            prediction noise covariance matrix (Q)  
        * `observation_noise_cov_matrix` :  
            observation noise covariance matrix (R)  
        * `augmented_process_noise` :  
            add the process noise in the augmented state (false by default)  
        * `augmented_observation_noise` :  
            add the observation noise in the augmented state (false by default)  
        * `alpha` :  
            ukf parameter  
        * `beta` :  
            ukf parameter  
        * `k` :  
            ukf parameter  

    C++ includes: plUKF.h

    """

    __swig_setmethods__ = {}
    for _s in [plKalmanFilter]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plUKF, name, value)
    __swig_getmethods__ = {}
    for _s in [plKalmanFilter]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plUKF, name)
    __repr__ = _swig_repr

    def __init__(self, *args):
        """
        __init__(self, state_dim, obs_dim, alpha=0.001, beta=2.0, k=0.0) -> plUKF
        __init__(self, state_dim, obs_dim, alpha=0.001, beta=2.0) -> plUKF
        __init__(self, state_dim, obs_dim, alpha=0.001) -> plUKF
        __init__(self, state_dim, obs_dim) -> plUKF
        __init__(self, state_dim, obs_dim, init_estimation_mean, init_estimation_cov_matrix, prediction_noise_cov_matrix, observation_noise_cov_matrix, augmented_process_noise=False, augmented_observation_noise=False, alpha=0.001, beta=2.0, k=0.0) -> plUKF
        __init__(self, state_dim, obs_dim, init_estimation_mean, init_estimation_cov_matrix, prediction_noise_cov_matrix, observation_noise_cov_matrix, augmented_process_noise=False, augmented_observation_noise=False, alpha=0.001, beta=2.0) -> plUKF
        __init__(self, state_dim, obs_dim, init_estimation_mean, init_estimation_cov_matrix, prediction_noise_cov_matrix, observation_noise_cov_matrix, augmented_process_noise=False, augmented_observation_noise=False, alpha=0.001) -> plUKF
        __init__(self, state_dim, obs_dim, init_estimation_mean, init_estimation_cov_matrix, prediction_noise_cov_matrix, observation_noise_cov_matrix, augmented_process_noise=False, augmented_observation_noise=False) -> plUKF
        __init__(self, state_dim, obs_dim, init_estimation_mean, init_estimation_cov_matrix, prediction_noise_cov_matrix, observation_noise_cov_matrix, augmented_process_noise=False) -> plUKF
        __init__(self, state_dim, obs_dim, init_estimation_mean, init_estimation_cov_matrix, prediction_noise_cov_matrix, observation_noise_cov_matrix) -> plUKF


        `plUKF(size_t state_dim, size_t obs_dim, plFloat alpha=0.001, plFloat beta=2.0,
            plFloat k=0.0)`  
        `plUKF(size_t state_dim, size_t obs_dim, const plFloatVector
            &init_estimation_mean, const plFloatMatrix &init_estimation_cov_matrix,
            const plFloatMatrix &prediction_noise_cov_matrix, const plFloatMatrix
            &observation_noise_cov_matrix, bool augmented_process_noise=false, bool
            augmented_observation_noise=false, plFloat alpha=0.001, plFloat beta=2.0,
            plFloat k=0.0)`  

        Overloaded function
        -------------------
        * `plUKF(size_t state_dim, size_t obs_dim, plFloat alpha=0.001, plFloat
            beta=2.0, plFloat k=0.0)`  

            Constructor.  

            Parameters:  
            * `state_dim` :  
                state dimension  
            * `obs_dim` :  
                observation dimension  
            * `alpha` :  
                ukf parameter  
            * `beta` :  
                ukf parameter  
            * `k` :  
                ukf parameter  

        * `plUKF(size_t state_dim, size_t obs_dim, const plFloatVector
            &init_estimation_mean, const plFloatMatrix &init_estimation_cov_matrix,
            const plFloatMatrix &prediction_noise_cov_matrix, const plFloatMatrix
            &observation_noise_cov_matrix, bool augmented_process_noise=false, bool
            augmented_observation_noise=false, plFloat alpha=0.001, plFloat beta=2.0,
            plFloat k=0.0)`  

            Construction and initialization.  

            Parameters:  
            * `state_dim` :  
                state dimension  
            * `obs_dim` :  
                observation dimension  
            * `init_estimation_mean` :  
                initial estimation mean vector (x0)  
            * `init_estimation_cov_matrix` :  
                initial estimation covariance matrix (P0)  
            * `prediction_noise_cov_matrix` :  
                prediction noise covariance matrix (Q)  
            * `observation_noise_cov_matrix` :  
                observation noise covariance matrix (R)  
            * `augmented_process_noise` :  
                add the process noise in the augmented state (false by default)  
            * `augmented_observation_noise` :  
                add the observation noise in the augmented state (false by default)  
            * `alpha` :  
                ukf parameter  
            * `beta` :  
                ukf parameter  
            * `k` :  
                ukf parameter  

        """
        if self.__class__ == plUKF:
            _self = None
        else:
            _self = self
        this = _probt_python3.new_plUKF(_self, *args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this
    __swig_destroy__ = _probt_python3.delete_plUKF
    __del__ = lambda self: None

    def prediction(self) -> "void":
        """
        prediction(self)


        `prediction()`  

        Prediction step.  

        \[ \hat x^{-}_k = A \hat x_{k-1} + B u_k \]  

        \[ P^{-}_k = A P_{k-1} A^T + Q \]  

        """
        return _probt_python3.plUKF_prediction(self)


    def observation(self, *args) -> "void":
        """
        observation(self, zo, observation_weight=1.0)
        observation(self, zo)
        observation(self, zo, Ro, observation_weight=1.0)
        observation(self, zo, Ro)


        `observation(const plFloatVector &zo, const plFloatMatrix &Ro, plFloat
            observation_weight=PL_ONE)`  

        Update step using observation vector *zo* and its corresponding covariance
        matrix *Ro*.  

        Equivalent to calling (without changing *z* and *R* internally however):  

        *   set_observation_noise_cov_matrix(Ro)  
        *   set_observation(zo, observation_weight)  
        *   update()  

        """
        return _probt_python3.plUKF_observation(self, *args)


    def get_observation_mahalanobis_distance(self, *args) -> "plFloat":
        """
        get_observation_mahalanobis_distance(self, zo) -> plFloat
        get_observation_mahalanobis_distance(self, zo, det) -> plFloat
        get_observation_mahalanobis_distance(self, zo, Ro) -> plFloat
        get_observation_mahalanobis_distance(self, zo, Ro, det) -> plFloat


        `get_observation_mahalanobis_distance(const plFloatVector &zo, const
            plFloatMatrix &Ro) const -> plFloat`  
        `get_observation_mahalanobis_distance(const plFloatVector &zo, const
            plFloatMatrix &Ro, plFloat &det) const -> plFloat`  

        Overloaded function
        -------------------
        * `get_observation_mahalanobis_distance(const plFloatVector &zo, const
            plFloatMatrix &Ro) const -> plFloat`  

            Return the Mahalanobis distance of a given observation.  

        * `get_observation_mahalanobis_distance(const plFloatVector &zo, const
            plFloatMatrix &Ro, plFloat &det) const -> plFloat`  

            Return the Mahalanobis distance of a given observation and the determinant
            of the convariance matrix.  

        """
        return _probt_python3.plUKF_get_observation_mahalanobis_distance(self, *args)


    def get_pdf_value(self, *args) -> "plProbValue":
        """
        get_pdf_value(self, zo) -> plProbValue
        get_pdf_value(self, zo, Ro) -> plProbValue


        `get_pdf_value(const plFloatVector &zo, const plFloatMatrix &Ro) const ->
            plProbValue`  

        Return, for the observation *zo* and the corresponding variance matrix *Ro*, the
        value of the density function value according to the current gaussian estimate.  

        """
        return _probt_python3.plUKF_get_pdf_value(self, *args)


    def get_pdf_value_log(self, *args) -> "plFloat":
        """
        get_pdf_value_log(self, zo) -> plFloat
        get_pdf_value_log(self, Zo, Ro) -> plFloat


        `get_pdf_value_log(const plFloatVector &Zo, const plFloatMatrix &Ro) const ->
            plFloat`  

        Same as above but using log.  

        """
        return _probt_python3.plUKF_get_pdf_value_log(self, *args)


    def residual_state(self, x1: 'plFloatVector', x2: 'plFloatVector') -> "plFloatVector":
        """
        residual_state(self, x1, x2) -> plFloatVector


        `residual_state(const plFloatVector &x1, const plFloatVector &x2) const ->
            plFloatVector`  

        Function that computes the residual (difference) between two state vectors x1
        and x2.  

        You will have to reimplement this if your state variable cannot support
        subtraction. The case of angle variables (359-1 degrees is 2, not 358) is
        handled based on the reimplementation of the function get_state_angle_indices()  

        """
        return _probt_python3.plUKF_residual_state(self, x1, x2)


    def prediction_model(self, state: 'plFloatVector', predicted_state: 'plFloatVector') -> "void":
        """prediction_model(self, state, predicted_state)"""
        return _probt_python3.plUKF_prediction_model(self, state, predicted_state)


    def observation_model(self, state: 'plFloatVector', expected_observation: 'plFloatVector') -> "void":
        """observation_model(self, state, expected_observation)"""
        return _probt_python3.plUKF_observation_model(self, state, expected_observation)


    def compute_mean_state(self, x_points: 'plFlVectorVector', W0: 'plFloat', Wi: 'plFloat', mean: 'plFloatVector') -> "void":
        """compute_mean_state(self, x_points, W0, Wi, mean)"""
        return _probt_python3.plUKF_compute_mean_state(self, x_points, W0, Wi, mean)


    def compute_mean_observation(self, z_points: 'plFlVectorVector', W0: 'plFloat', Wi: 'plFloat', mean: 'plFloatVector') -> "void":
        """compute_mean_observation(self, z_points, W0, Wi, mean)"""
        return _probt_python3.plUKF_compute_mean_observation(self, z_points, W0, Wi, mean)


    def get_state_angle_indices(self) -> "std::vector< unsigned int,std::allocator< unsigned int > >":
        """get_state_angle_indices(self) -> UnsignedIntVector"""
        return _probt_python3.plUKF_get_state_angle_indices(self)

    def __disown__(self):
        self.this.disown()
        _probt_python3.disown_plUKF(self)
        return weakref_proxy(self)

    def Output(self) -> "void":
        """Output(self)"""
        return _probt_python3.plUKF_Output(self)


    def get_Q(self) -> "plFloatMatrix":
        """get_Q(self) -> plFloatMatrix"""
        return _probt_python3.plUKF_get_Q(self)


    def get_observation_angle_indices(self) -> "std::vector< unsigned int,std::allocator< unsigned int > >":
        """get_observation_angle_indices(self) -> UnsignedIntVector"""
        return _probt_python3.plUKF_get_observation_angle_indices(self)

plUKF_swigregister = _probt_python3.plUKF_swigregister
plUKF_swigregister(plUKF)

class plCarLikeKinematics(_object):
    """

    `plCarLikeKinematics(plFloat l, plFloat var_speed_dot, plFloat
        var_steering_dot)`  

    Constant Speed (zero-mean acceleration) Car-like kinematics.  

    $X$ (the state vector) and $Z$ (the measurement/observation vector) are defined
    as follows: \begin{eqnarray*} X &=& \left[ x, y, s, \theta, \phi \right]
    \\ Z &=& \left[ x_o, y_o, \theta_o \right] \end{eqnarray*} in which $s$ is
    vehicle's speed, $\theta$ is the heading angle, and $\phi$ is the steering
    angle.  

    The system (prediction) model is defined as follows: \begin{eqnarray*} x^{k+1}
    &=& x^k + dt \times s^k \times \cos(\theta^k) &+ w_x^k \\ y^{k+1} &=& y^k
    + dt \times s^k \times \sin(\theta^k) &+ w_y^k \\ s^{k+1} &=& s^k &+ w_s^k
    \\ \theta^{k+1} &=& \theta^k + dt \times s^k \times \frac{\tan(\phi^k)}
    {L} &+ w_\theta^k \\ \phi^{k+1} &=& \phi^k &+ w_\phi^k \end{eqnarray*} in
    which $L$ is the distance between the two axles of the vehicle, $dt$ is the
    discrete time step, and: \begin{eqnarray*} w_x^k &=& 0.5 \times dt^2 \times
    \dot{s}^k \times \cos(\theta^k) \\ w_y^k &=& 0.5 \times dt^2 \times
    \dot{s}^k \times \sin(\theta^k) \\ w_s^k &=& dt \times \dot{s}^k \\
    w_\theta^k &=& 0.5 \times dt^2 \times \dot{s}^k \times
    \frac{\tan(\phi^k)} {L} \\ w_\phi^k &=& dt \times \dot{\phi}^k
    \end{eqnarray*}  

    $\dot{s}$ is the linear acceleration assumed to have zero mean and
    $\sigma_{\dot{s}}^2$ variance.  

    $\dot{\phi}$ is the time derivative of $\phi$ and assumed to have zero mean
    and $\sigma_{\dot{\phi}}^2$ variance.  

    The observation (measurement) model is defined as follows: \begin{eqnarray*}
    x_o^k &=& x^k \\ y_o^k &=& y^k \\ \theta_o^k &=& \theta^k \end{eqnarray*}  

    The observation is assumed to be $Z = \left[ x_o, y_o \right]$ (Only the
    position is observed) when the parameter 'observe_heading' is set to 'false'.  

    See also: plCarLikeEKF  

    See also: plCarLikeUKF  

    Constructors
    ------------
    * `plCarLikeKinematics(plFloat l, plFloat var_speed_dot, plFloat
        var_steering_dot)`  

        Constructor.  

        Parameters:  
        * `l` :  
            the distance between the two axles of the vehicle  
        * `var_speed_dot` :  
            the variance of the acceleration $\sigma_{\dot{s}}^2$ (m^2/s^4)  
        * `var_steering_dot` :  
            the variance of the steering time derivative $\sigma_{\dot{\phi}}^2$
            (rad^2/s^2)  

    Attributes
    ----------
    * `L` : `plFloat`  
        The distance between the two axles of the vehicle.  

    C++ includes: plCarLikeKinematics.h

    """

    __swig_setmethods__ = {}
    __setattr__ = lambda self, name, value: _swig_setattr(self, plCarLikeKinematics, name, value)
    __swig_getmethods__ = {}
    __getattr__ = lambda self, name: _swig_getattr(self, plCarLikeKinematics, name)
    __repr__ = _swig_repr
    X = _probt_python3.plCarLikeKinematics_X
    Y = _probt_python3.plCarLikeKinematics_Y
    Speed = _probt_python3.plCarLikeKinematics_Speed
    Heading = _probt_python3.plCarLikeKinematics_Heading
    SteeringAngle = _probt_python3.plCarLikeKinematics_SteeringAngle
    NSTATES = _probt_python3.plCarLikeKinematics_NSTATES
    OX = _probt_python3.plCarLikeKinematics_OX
    OY = _probt_python3.plCarLikeKinematics_OY
    OHeading = _probt_python3.plCarLikeKinematics_OHeading

    def __init__(self, l: 'plFloat', var_speed_dot: 'plFloat', var_steering_dot: 'plFloat'):
        """
        __init__(self, l, var_speed_dot, var_steering_dot) -> plCarLikeKinematics


        `plCarLikeKinematics(plFloat l, plFloat var_speed_dot, plFloat
            var_steering_dot)`  

        Constructor.  

        Parameters
        ----------
        * `l` :  
            the distance between the two axles of the vehicle  
        * `var_speed_dot` :  
            the variance of the acceleration $\sigma_{\dot{s}}^2$ (m^2/s^4)  
        * `var_steering_dot` :  
            the variance of the steering time derivative $\sigma_{\dot{\phi}}^2$
            (rad^2/s^2)  

        """
        this = _probt_python3.new_plCarLikeKinematics(l, var_speed_dot, var_steering_dot)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this
    __swig_destroy__ = _probt_python3.delete_plCarLikeKinematics
    __del__ = lambda self: None

    def model_noise_variance(self, state: 'plFloatVector', dt: 'plFloat') -> "plFloatMatrix":
        """
        model_noise_variance(self, state, dt) -> plFloatMatrix


        `model_noise_variance(const plFloatVector &state, plFloat dt) const ->
            plFloatMatrix`  

        Return the current Q system/prediction covariance matrix based on the current
        state and the prediction error parameters $\sigma_{\dot{s}}^2$ and
        $\sigma_{\dot{\phi}}^2$.  

        """
        return _probt_python3.plCarLikeKinematics_model_noise_variance(self, state, dt)


    def evolution_model(self, state: 'plFloatVector', predicted_state: 'plFloatVector', dt: 'plFloat') -> "void":
        """
        evolution_model(self, state, predicted_state, dt)


        `evolution_model(const plFloatVector &state, plFloatVector &predicted_state,
            plFloat dt) const`  

        The evolution (prediction) model: \begin{eqnarray*} x^{k+1} &=& x^k + dt
        \times s^k \times \cos(\theta^k) \\ y^{k+1} &=& y^k + dt \times s^k
        \times \sin(\theta^k) \\ s^{k+1} &=& s^k \\ \theta^{k+1} &=& \theta^k +
        dt \times s^k \times \frac{\tan(\phi^k)} {L} \\ \phi^{k+1} &=& \phi^k
        \end{eqnarray*}.  

        """
        return _probt_python3.plCarLikeKinematics_evolution_model(self, state, predicted_state, dt)


    def evolution_model_jacobian(self, state: 'plFloatVector', A_k: 'plFloatMatrix', dt: 'plFloat') -> "void":
        """
        evolution_model_jacobian(self, state, A_k, dt)


        `evolution_model_jacobian(const plFloatVector &state, plFloatMatrix &A_k,
            plFloat dt) const`  

        Compute the jacobian of the evolution (prediction) model above.  

        """
        return _probt_python3.plCarLikeKinematics_evolution_model_jacobian(self, state, A_k, dt)


    def measurement_model(self, state: 'plFloatVector', expected_observation: 'plFloatVector', observe_heading: 'bool') -> "void":
        """
        measurement_model(self, state, expected_observation, observe_heading)


        `measurement_model(const plFloatVector &state, plFloatVector
            &expected_observation, bool observe_heading) const`  

        The measurement (observation) model: \begin{eqnarray*} x_o^k &=& x^k \\ y_o^k
        &=& y^k \\ \theta_o^k &=& \theta^k \end{eqnarray*}.  

        """
        return _probt_python3.plCarLikeKinematics_measurement_model(self, state, expected_observation, observe_heading)


    def measurement_model_jacobian(self, H_k: 'plFloatMatrix', observe_heading: 'bool') -> "void":
        """
        measurement_model_jacobian(self, H_k, observe_heading)


        `measurement_model_jacobian(plFloatMatrix &H_k, bool observe_heading) const`  

        Compute the jacobian of the measurement (observation) model above.  

        """
        return _probt_python3.plCarLikeKinematics_measurement_model_jacobian(self, H_k, observe_heading)


    def get_state_angle_indices(self) -> "std::vector< unsigned int,std::allocator< unsigned int > >":
        """
        get_state_angle_indices(self) -> UnsignedIntVector


        `get_state_angle_indices() const -> std::vector< unsigned int >`  

        Return the indices of angle variables in the state vector.  

        """
        return _probt_python3.plCarLikeKinematics_get_state_angle_indices(self)


    def get_observation_angle_indices(self, observe_heading: 'bool') -> "std::vector< unsigned int,std::allocator< unsigned int > >":
        """
        get_observation_angle_indices(self, observe_heading) -> UnsignedIntVector


        `get_observation_angle_indices(bool observe_heading) const -> std::vector<
            unsigned int >`  

        Return the indices of angle variables in the observation vector.  

        """
        return _probt_python3.plCarLikeKinematics_get_observation_angle_indices(self, observe_heading)

    __swig_setmethods__["L"] = _probt_python3.plCarLikeKinematics_L_set
    __swig_getmethods__["L"] = _probt_python3.plCarLikeKinematics_L_get
    if _newclass:
        L = _swig_property(_probt_python3.plCarLikeKinematics_L_get, _probt_python3.plCarLikeKinematics_L_set)
plCarLikeKinematics_swigregister = _probt_python3.plCarLikeKinematics_swigregister
plCarLikeKinematics_swigregister(plCarLikeKinematics)

class plCarLikeEKF(plEKF):
    """

    `plCarLikeEKF(plFloat l, plFloat var_speed_dot, plFloat var_steering_dot,
        plFloat dt, bool observe_heading)`  

    Constant Speed (zero-mean acceleration) Car-like non Linear Kalman Filter based
    on EKF.  

    $X$ (the state vector) and $Z$ (the measurement/observation vector) are defined
    as follows: \begin{eqnarray*} X &=& \left[ x, y, s, \theta, \phi \right]
    \\ Z &=& \left[ x_o, y_o, \theta_o \right] \end{eqnarray*} in which $s$ is
    vehicle's speed, $\theta$ is the heading angle, and $\phi$ is the steering
    angle.  

    The observation is assumed to be $Z = \left[ x_o, y_o \right]$ (Only the
    position is observed) when the parameter 'observe_heading' is set to 'false' in
    the constructor.  

    The kinematics are defined by the model plCarLikeKinematics  

    See also: plCarLikeKinematics  

    See also: plCarLikeUKF  

    Constructors
    ------------
    * `plCarLikeEKF(plFloat l, plFloat var_speed_dot, plFloat var_steering_dot,
        plFloat dt, bool observe_heading)`  

        Constructor.  

        Parameters:  
        * `l` :  
            the distance between the two axles of the vehicle  
        * `var_speed_dot` :  
            the variance of the acceleration (m^2/s^4)  
        * `var_steering_dot` :  
            the variance of the steering time derivative (rad^2/s^2)  
        * `dt` :  
            the time step  
        * `observe_heading` :  
            if 'false', the observation is assumed to be [X, Y]. If 'true', the
            observation is assumed to be [X, Y, Heading]  

    C++ includes: plCarLikeEKF.h

    """

    __swig_setmethods__ = {}
    for _s in [plEKF]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plCarLikeEKF, name, value)
    __swig_getmethods__ = {}
    for _s in [plEKF]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plCarLikeEKF, name)
    __repr__ = _swig_repr

    def __init__(self, l: 'plFloat', var_speed_dot: 'plFloat', var_steering_dot: 'plFloat', dt: 'plFloat', observe_heading: 'bool'):
        """
        __init__(self, l, var_speed_dot, var_steering_dot, dt, observe_heading) -> plCarLikeEKF


        `plCarLikeEKF(plFloat l, plFloat var_speed_dot, plFloat var_steering_dot,
            plFloat dt, bool observe_heading)`  

        Constructor.  

        Parameters
        ----------
        * `l` :  
            the distance between the two axles of the vehicle  
        * `var_speed_dot` :  
            the variance of the acceleration (m^2/s^4)  
        * `var_steering_dot` :  
            the variance of the steering time derivative (rad^2/s^2)  
        * `dt` :  
            the time step  
        * `observe_heading` :  
            if 'false', the observation is assumed to be [X, Y]. If 'true', the
            observation is assumed to be [X, Y, Heading]  

        """
        this = _probt_python3.new_plCarLikeEKF(l, var_speed_dot, var_steering_dot, dt, observe_heading)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this
    __swig_destroy__ = _probt_python3.delete_plCarLikeEKF
    __del__ = lambda self: None
plCarLikeEKF_swigregister = _probt_python3.plCarLikeEKF_swigregister
plCarLikeEKF_swigregister(plCarLikeEKF)

class plCarLikeUKF(plUKF):
    """

    `plCarLikeUKF(plFloat l, plFloat var_speed_dot, plFloat var_steering_dot,
        plFloat dt, bool observe_heading, plFloat ukf_alpha=0.001, plFloat
        ukf_beta=2.0, plFloat ukf_k=0.0)`  

    Constant Speed (zero-mean acceleration) Car-like non Linear Kalman Filter based
    on UKF.  

    $X$ (the state vector) and $Z$ (the measurement/observation vector) are defined
    as follows: \begin{eqnarray*} X &=& \left[ x, y, s, \theta, \phi \right]
    \\ Z &=& \left[ x_o, y_o, \theta_o \right] \end{eqnarray*} in which $s$ is
    vehicle's speed, $\theta$ is the heading angle, and $\phi$ is the steering
    angle.  

    The observation is assumed to be $Z = \left[ x_o, y_o \right]$ (Only the
    position is observed) when the parameter 'observe_heading' is set to 'false' in
    the constructor.  

    The kinematics are defined by the model plCarLikeKinematics  

    See also: plCarLikeKinematics  

    See also: plCarLikeEKF  

    Constructors
    ------------
    * `plCarLikeUKF(plFloat l, plFloat var_speed_dot, plFloat var_steering_dot,
        plFloat dt, bool observe_heading, plFloat ukf_alpha=0.001, plFloat
        ukf_beta=2.0, plFloat ukf_k=0.0)`  

        Constructor.  

        Parameters:  
        * `l` :  
            the distance between the two axles of the vehicle  
        * `var_speed_dot` :  
            the variance of the acceleration (m^2/s^4)  
        * `var_steering_dot` :  
            the variance of the steering time derivative (rad^2/s^2)  
        * `dt` :  
            the time step  
        * `observe_heading` :  
            if 'false', the observation is assumed to be [X, Y]. If 'true', the
            observation is assumed to be [X, Y, Heading]  
        * `ukf_alpha` :  
            ukf alpha parameter  
        * `ukf_beta` :  
            ukf beta parameter  
        * `ukf_k` :  
            ukf k parameter  

    C++ includes: plCarLikeUKF.h

    """

    __swig_setmethods__ = {}
    for _s in [plUKF]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plCarLikeUKF, name, value)
    __swig_getmethods__ = {}
    for _s in [plUKF]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plCarLikeUKF, name)
    __repr__ = _swig_repr

    def __init__(self, l: 'plFloat', var_speed_dot: 'plFloat', var_steering_dot: 'plFloat', dt: 'plFloat', observe_heading: 'bool', ukf_alpha: 'plFloat'=0.001, ukf_beta: 'plFloat'=2.0, ukf_k: 'plFloat'=0.0):
        """
        __init__(self, l, var_speed_dot, var_steering_dot, dt, observe_heading, ukf_alpha=0.001, ukf_beta=2.0, ukf_k=0.0) -> plCarLikeUKF
        __init__(self, l, var_speed_dot, var_steering_dot, dt, observe_heading, ukf_alpha=0.001, ukf_beta=2.0) -> plCarLikeUKF
        __init__(self, l, var_speed_dot, var_steering_dot, dt, observe_heading, ukf_alpha=0.001) -> plCarLikeUKF
        __init__(self, l, var_speed_dot, var_steering_dot, dt, observe_heading) -> plCarLikeUKF


        `plCarLikeUKF(plFloat l, plFloat var_speed_dot, plFloat var_steering_dot,
            plFloat dt, bool observe_heading, plFloat ukf_alpha=0.001, plFloat
            ukf_beta=2.0, plFloat ukf_k=0.0)`  

        Constructor.  

        Parameters
        ----------
        * `l` :  
            the distance between the two axles of the vehicle  
        * `var_speed_dot` :  
            the variance of the acceleration (m^2/s^4)  
        * `var_steering_dot` :  
            the variance of the steering time derivative (rad^2/s^2)  
        * `dt` :  
            the time step  
        * `observe_heading` :  
            if 'false', the observation is assumed to be [X, Y]. If 'true', the
            observation is assumed to be [X, Y, Heading]  
        * `ukf_alpha` :  
            ukf alpha parameter  
        * `ukf_beta` :  
            ukf beta parameter  
        * `ukf_k` :  
            ukf k parameter  

        """
        this = _probt_python3.new_plCarLikeUKF(l, var_speed_dot, var_steering_dot, dt, observe_heading, ukf_alpha, ukf_beta, ukf_k)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this
    __swig_destroy__ = _probt_python3.delete_plCarLikeUKF
    __del__ = lambda self: None
plCarLikeUKF_swigregister = _probt_python3.plCarLikeUKF_swigregister
plCarLikeUKF_swigregister(plCarLikeUKF)

class plHMM(plBuiltinModel):
    """

    `plHMM()`  
    `plHMM(const std::vector< plProbValue > &init_state_distribution, const
        std::vector< std::vector< plProbValue > > &transition_distribution, const
        std::vector< std::vector< plProbValue > > &emission_distribution)`  
    `plHMM(const plDistribution &init_state_distribution, const plCndDistribution
        &transition_distribution, const plCndDistribution &emission_distribution,
        bool tabulate_emission_distribution=false, bool
        tabulate_transition_distribution=true)`  

    This class implements Hidden Markov Model (HMM).  

    An HMM is defined as:  

    *   a discrete state space $S$,  
    *   an emission (observation) space (alphabet) $O$,  
    *   an initial state distribution $ P(S_0) $,  
    *   a transition distribution $ P(S_t | S_{t-1}) $,  
    *   an emission (observation) distribution $ P( O_t | S_t) $.  

    The state variable $S$ has to be a discrete (integer) variable taking its values
    in [0,...,nstates-1].  

    The emission (observation) variable $O$ can be discrete or continuous. It can be
    also multidimensional. Moreover, the emission (observation) distribution can be
    decomposed. Examples for a 2D observation:  

    *   $ P(O_x O_y | S) = P(O_x | S) P(O_y | S) $,  
    *   $ P(O_x O_y | S) = P(O_x | S) P(O_y | S O_x) $,  
    *   $ P(O_x O_y | S) = P(O_x | S) P(O_y | O_x) $.  

    Using ProBT, such a decomposed emission distribution can be expressed using the
    *plComputableObject* class to define the emission distribution as a product.  

    Given an already constructed HMM, this class implements:  

    *   Evaluation: Given an observation sequence (or sequences), return the
        corresponding log-likelihood.  
    *   Decoding: Given an observation sequence, return the most probable state
        sequence.  
    *   Filtering: Given an observation as input, online update of the state
        distribution.  
    *   Simulation: Generate observation/state sequences according to HMM's
        parameters.  

    It also implements HMM's distributions learning (assuming that the number of
    states and the emission space are KNOWN):  

    *   Supervised Learning: Given a set of state/observation sequences, find the
        HMM's distributions that maximize the sequences likelihood.  
    *   Unsupervised Learning: Given a set of observation sequences, find the HMM's
        distributions that maximize the sequences likelihood.  

    attention: An observation sequence is a vector of float vectors (observations).
        In each observation, order of elements matter. This order must correspond to
        the order of the emission distribution learner's left variables (as in
        `observation_variables()`). In case the orders do not match, you will get
        incorrect results, and possibly occurrence of plWarning 17 (value out of
        range).  

    attention: Furthermore, it is assumed that
        emission_distribution_learner.get_variables() returns all observation
        variables first, and the state variable in last position. You may ensure
        this when building a plLearnDistributions object by passing the list of
        variables explicitly to the constructor. The same ill effects as previously
        will be observed if this does not hold.  

    Constructors
    ------------
    * `plHMM()`  

        Default constructor.  

    * `plHMM(const std::vector< plProbValue > &init_state_distribution, const
        std::vector< std::vector< plProbValue > > &transition_distribution, const
        std::vector< std::vector< plProbValue > > &emission_distribution)`  

        Constructor using model explicit probability tables.  

        Parameters:  
        * `init_state_distribution` :  
            initial state distribution table.  
        * `transition_distribution` :  
            transition distribution matrix.  
        * `emission_distribution` :  
            emission (observation) distribution matrix.  

    * `plHMM(const plDistribution &init_state_distribution, const plCndDistribution
        &transition_distribution, const plCndDistribution &emission_distribution,
        bool tabulate_emission_distribution=false, bool
        tabulate_transition_distribution=true)`  

        Constructor using model distributions.  

        Parameters:  
        * `init_state_distribution` :  
            initial state distribution.  
        * `transition_distribution` :  
            transition distribution.  
        * `emission_distribution` :  
            emission (observation) distribution.  
        * `tabulate_emission_distribution` :  
            a parameter to say if the emission (observation) distribution should be
            tabulated or not.  
        * `tabulate_transition_distribution` :  
            a parameter to say if the transition distribution should be tabulated or
            not.  

        The emission (observation) variable can be discrete or continuous. It can be
        also multidimensional. Moreover, the emission (observation) distribution can
        be decomposed. Examples for a 2D observation:  

        *   $ P(O_x O_y | S) = P(O_x | S) P(O_y | S) $,  
        *   $ P(O_x O_y | S) = P(O_x | S) P(O_y | S O_x) $,  
        *   $ P(O_x O_y | S) = P(O_x | S) P(O_y | O_x) $.  

        Using ProBT, such a decomposed emission distribution can be expressed using
        the *plComputableObject* class to define the emission distribution as a
        product.  

    C++ includes: plHMM.h

    """

    __swig_setmethods__ = {}
    for _s in [plBuiltinModel]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plHMM, name, value)
    __swig_getmethods__ = {}
    for _s in [plBuiltinModel]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plHMM, name)
    __repr__ = _swig_repr

    def __init__(self, *args):
        """
        __init__(self) -> plHMM
        __init__(self, init_state_distribution, transition_distribution, emission_distribution) -> plHMM
        __init__(self, init_state_distribution, transition_distribution, emission_distribution, tabulate_emission_distribution=False, tabulate_transition_distribution=True) -> plHMM
        __init__(self, init_state_distribution, transition_distribution, emission_distribution, tabulate_emission_distribution=False) -> plHMM
        __init__(self, init_state_distribution, transition_distribution, emission_distribution) -> plHMM


        `plHMM()`  
        `plHMM(const std::vector< plProbValue > &init_state_distribution, const
            std::vector< std::vector< plProbValue > > &transition_distribution, const
            std::vector< std::vector< plProbValue > > &emission_distribution)`  
        `plHMM(const plDistribution &init_state_distribution, const plCndDistribution
            &transition_distribution, const plCndDistribution &emission_distribution,
            bool tabulate_emission_distribution=false, bool
            tabulate_transition_distribution=true)`  

        Overloaded function
        -------------------
        * `plHMM()`  

            Default constructor.  

        * `plHMM(const std::vector< plProbValue > &init_state_distribution, const
            std::vector< std::vector< plProbValue > > &transition_distribution, const
            std::vector< std::vector< plProbValue > > &emission_distribution)`  

            Constructor using model explicit probability tables.  

            Parameters:  
            * `init_state_distribution` :  
                initial state distribution table.  
            * `transition_distribution` :  
                transition distribution matrix.  
            * `emission_distribution` :  
                emission (observation) distribution matrix.  

        * `plHMM(const plDistribution &init_state_distribution, const plCndDistribution
            &transition_distribution, const plCndDistribution &emission_distribution,
            bool tabulate_emission_distribution=false, bool
            tabulate_transition_distribution=true)`  

            Constructor using model distributions.  

            Parameters:  
            * `init_state_distribution` :  
                initial state distribution.  
            * `transition_distribution` :  
                transition distribution.  
            * `emission_distribution` :  
                emission (observation) distribution.  
            * `tabulate_emission_distribution` :  
                a parameter to say if the emission (observation) distribution should be
                tabulated or not.  
            * `tabulate_transition_distribution` :  
                a parameter to say if the transition distribution should be tabulated or
                not.  

            The emission (observation) variable can be discrete or continuous. It can be
            also multidimensional. Moreover, the emission (observation) distribution can
            be decomposed. Examples for a 2D observation:  

            *   $ P(O_x O_y | S) = P(O_x | S) P(O_y | S) $,  
            *   $ P(O_x O_y | S) = P(O_x | S) P(O_y | S O_x) $,  
            *   $ P(O_x O_y | S) = P(O_x | S) P(O_y | O_x) $.  

            Using ProBT, such a decomposed emission distribution can be expressed using
            the *plComputableObject* class to define the emission distribution as a
            product.  

        """
        this = _probt_python3.new_plHMM(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this
    __swig_destroy__ = _probt_python3.delete_plHMM
    __del__ = lambda self: None

    def is_empty(self) -> "bool":
        """
        is_empty(self) -> bool


        `is_empty() const -> bool`  

        Return true if the distributions are empty.  

        """
        return _probt_python3.plHMM_is_empty(self)


    def set_name(self, name: 'std::string const &') -> "void":
        """
        set_name(self, name)


        `set_name(const std::string &name)`  

        Sets HMM's name.  

        Parameters
        ----------
        * `name` :  
            the new name of the HMM.  

        """
        return _probt_python3.plHMM_set_name(self, name)


    def get_name(self) -> "std::string const &":
        """
        get_name(self) -> std::string const &


        `get_name() const -> const std::string &`  

        Get HMM's name.  

        Returns
        -------
        the name of the HMM.  

        """
        return _probt_python3.plHMM_get_name(self)


    def rename_observation_variables(self, variables: 'plVariablesConjunction') -> "plHMM":
        """
        rename_observation_variables(self, variables) -> plHMM


        `rename_observation_variables(plVariablesConjunction const &variables) const ->
            plHMM`  

        Rename the observation variables of this HMM.  

        A copy of the HMM with the renamed observation variables is returned. The
        original HMM is not modified.  

        The new observation variables must have the same types as the original ones;
        they must match one to one, in order. A plError 8 will be raised if this is not
        the case.  

        """
        return _probt_python3.plHMM_rename_observation_variables(self, variables)


    def train_unsupervised_viterbi(self, *args) -> "plFloat":
        """
        train_unsupervised_viterbi(self, observation_sequences, emission_distribution_learner, init_state_distribution_learner=None, transition_distribution_learner=None, tabulate_emission_distribution=False, tabulate_transition_distribution=True, deterministic_init=False, convergence_threshold=0.0, max_iterations=200) -> plFloat
        train_unsupervised_viterbi(self, observation_sequences, emission_distribution_learner, init_state_distribution_learner=None, transition_distribution_learner=None, tabulate_emission_distribution=False, tabulate_transition_distribution=True, deterministic_init=False, convergence_threshold=0.0, max_iterations=200) -> plFloat
        train_unsupervised_viterbi(self, observation_sequences, emission_distribution_learner, init_state_distribution_learner=None, transition_distribution_learner=None, tabulate_emission_distribution=False, tabulate_transition_distribution=True, deterministic_init=False, convergence_threshold=0.0) -> plFloat
        train_unsupervised_viterbi(self, observation_sequences, emission_distribution_learner, init_state_distribution_learner=None, transition_distribution_learner=None, tabulate_emission_distribution=False, tabulate_transition_distribution=True, deterministic_init=False) -> plFloat
        train_unsupervised_viterbi(self, observation_sequences, emission_distribution_learner, init_state_distribution_learner=None, transition_distribution_learner=None, tabulate_emission_distribution=False, tabulate_transition_distribution=True) -> plFloat
        train_unsupervised_viterbi(self, observation_sequences, emission_distribution_learner, init_state_distribution_learner=None, transition_distribution_learner=None, tabulate_emission_distribution=False) -> plFloat
        train_unsupervised_viterbi(self, observation_sequences, emission_distribution_learner, init_state_distribution_learner=None, transition_distribution_learner=None) -> plFloat
        train_unsupervised_viterbi(self, observation_sequences, emission_distribution_learner, init_state_distribution_learner=None) -> plFloat
        train_unsupervised_viterbi(self, observation_sequences, emission_distribution_learner) -> plFloat
        train_unsupervised_viterbi(self, observation_sequence_gen, emission_distribution_learner, init_state_distribution_learner=None, transition_distribution_learner=None, tabulate_emission_distribution=False, tabulate_transition_distribution=True, deterministic_init=False, convergence_threshold=0.0, max_iterations=200) -> plFloat
        train_unsupervised_viterbi(self, observation_sequence_gen, emission_distribution_learner, init_state_distribution_learner=None, transition_distribution_learner=None, tabulate_emission_distribution=False, tabulate_transition_distribution=True, deterministic_init=False, convergence_threshold=0.0, max_iterations=200) -> plFloat
        train_unsupervised_viterbi(self, observation_sequence_gen, emission_distribution_learner, init_state_distribution_learner=None, transition_distribution_learner=None, tabulate_emission_distribution=False, tabulate_transition_distribution=True, deterministic_init=False, convergence_threshold=0.0) -> plFloat
        train_unsupervised_viterbi(self, observation_sequence_gen, emission_distribution_learner, init_state_distribution_learner=None, transition_distribution_learner=None, tabulate_emission_distribution=False, tabulate_transition_distribution=True, deterministic_init=False) -> plFloat
        train_unsupervised_viterbi(self, observation_sequence_gen, emission_distribution_learner, init_state_distribution_learner=None, transition_distribution_learner=None, tabulate_emission_distribution=False, tabulate_transition_distribution=True) -> plFloat
        train_unsupervised_viterbi(self, observation_sequence_gen, emission_distribution_learner, init_state_distribution_learner=None, transition_distribution_learner=None, tabulate_emission_distribution=False) -> plFloat
        train_unsupervised_viterbi(self, observation_sequence_gen, emission_distribution_learner, init_state_distribution_learner=None, transition_distribution_learner=None) -> plFloat
        train_unsupervised_viterbi(self, observation_sequence_gen, emission_distribution_learner, init_state_distribution_learner=None) -> plFloat
        train_unsupervised_viterbi(self, observation_sequence_gen, emission_distribution_learner) -> plFloat


        `train_unsupervised_viterbi(const ObservationSequenceArray_t
            &observation_sequences, plLearnObject *emission_distribution_learner,
            plLearnObject *init_state_distribution_learner=0, plLearnObject
            *transition_distribution_learner=0, bool
            tabulate_emission_distribution=false, bool
            tabulate_transition_distribution=true, bool deterministic_init=false,
            plFloat convergence_threshold=PL_ZERO, unsigned int max_iterations=200,
            std::ostream *verbose_output=0) -> plFloat`  
        `train_unsupervised_viterbi(plObservationSequenceGenerator
            &observation_sequence_gen, plLearnObject *emission_distribution_learner,
            plLearnObject *init_state_distribution_learner=0, plLearnObject
            *transition_distribution_learner=0, bool
            tabulate_emission_distribution=false, bool
            tabulate_transition_distribution=true, bool deterministic_init=false,
            plFloat convergence_threshold=PL_ZERO, unsigned int max_iterations=200,
            std::ostream *verbose_output=0) -> plFloat`  

        Overloaded function
        -------------------
        * `train_unsupervised_viterbi(const ObservationSequenceArray_t
            &observation_sequences, plLearnObject *emission_distribution_learner,
            plLearnObject *init_state_distribution_learner=0, plLearnObject
            *transition_distribution_learner=0, bool
            tabulate_emission_distribution=false, bool
            tabulate_transition_distribution=true, bool deterministic_init=false,
            plFloat convergence_threshold=PL_ZERO, unsigned int max_iterations=200,
            std::ostream *verbose_output=0) -> plFloat`  

            Unsupervised training using iterative viterbi algorithm.  

            Parameters:  
            * `observation_sequences` :  
                a vector of observation sequences.  
            * `emission_distribution_learner` :  
                an online learning object to choose the form of the emission
                (observation) distribution to be learned.  
            * `init_state_distribution_learner` :  
                an online learning object to choose the form of the initial state
                distribution to be learned.  
            * `transition_distribution_learner` :  
                an online learning object to choose the form of the transition
                distribution to be learned.  
            * `tabulate_emission_distribution` :  
                a parameter to say if the emission (observation) distribution should be
                tabulated or not.  
            * `tabulate_transition_distribution` :  
                a parameter to say if the transition distribution should be tabulated or
                not.  
            * `deterministic_init` :  
                if True, the state initialization will be deterministic "left to
                right": 0 to nstates-1 equal-length sequences. It will be random if
                False  
            * `convergence_threshold` :  
                convergence threshold of relative log-likelihood change between two
                successive iterations (smaller value means more iterations). The default
                value is set to 0.0 The convergence criterion is computed as:  
                | log-likelihood(t) - log-likelihood(t-1) | / | (log-likelihood(t) +
                log-likelihood(t-1)/2.0 | < convergence_threshold.  
            * `max_iterations` :  
                maximal number of iterations  
            * `verbose_output` :  
                the stream to be used for the verbose mode  

            Returns:
            the loglikelihood  

            Using this method, the observation dimension and type are extracted from the
            *emission_distribution_learner* object. If *init_state_distribution_learner*
            (*transition_distribution_learner*) is null, the initial state distribution
            (transition distribution) is learned as a simple histogram (s).  

            The emission (observation) variable can be discrete or continuous. It can be
            also multidimensional. Moreover, the emission (observation) distribution can
            be decomposed. Examples for a 2D observation:  

            *   $ P(O_x O_y | S) = P(O_x | S) P(O_y | S) $,  
            *   $ P(O_x O_y | S) = P(O_x | S) P(O_y | S O_x) $,  
            *   $ P(O_x O_y | S) = P(O_x | S) P(O_y | O_x) $.  

            Using ProBT, a such decomposed emission distribution can be expressed using
            the *plLearnDistributions* class to define the learner of the emission
            distribution.  

            If you want to freeze a given distribution (instead to learn it), use
            special learner plLearnFrozenDistribution.  

        * `train_unsupervised_viterbi(plObservationSequenceGenerator
            &observation_sequence_gen, plLearnObject *emission_distribution_learner,
            plLearnObject *init_state_distribution_learner=0, plLearnObject
            *transition_distribution_learner=0, bool
            tabulate_emission_distribution=false, bool
            tabulate_transition_distribution=true, bool deterministic_init=false,
            plFloat convergence_threshold=PL_ZERO, unsigned int max_iterations=200,
            std::ostream *verbose_output=0) -> plFloat`  

        """
        return _probt_python3.plHMM_train_unsupervised_viterbi(self, *args)


    def get_nstates(self) -> "unsigned int":
        """
        get_nstates(self) -> unsigned int


        `get_nstates() const -> unsigned int`  

        Returns the number of states.  

        Returns
        -------
        the number of states.  

        """
        return _probt_python3.plHMM_get_nstates(self)


    def get_init_state_distribution(self) -> "plDistribution const &":
        """
        get_init_state_distribution(self) -> plDistribution


        `get_init_state_distribution() const -> const plDistribution &`  

        Returns the initial state distribution.  

        Returns
        -------
        the initial state distribution.  

        """
        return _probt_python3.plHMM_get_init_state_distribution(self)


    def get_transition_distribution(self) -> "plCndDistribution const &":
        """
        get_transition_distribution(self) -> plCndDistribution


        `get_transition_distribution() const -> const plCndDistribution &`  

        Returns the transition distribution.  

        Returns
        -------
        the transition distribution.  

        """
        return _probt_python3.plHMM_get_transition_distribution(self)


    def get_emission_distribution(self) -> "plCndDistribution const &":
        """
        get_emission_distribution(self) -> plCndDistribution


        `get_emission_distribution() const -> const plCndDistribution &`  

        Returns the emission (observation) distribution.  

        Returns
        -------
        the emission (observation) distribution.  

        """
        return _probt_python3.plHMM_get_emission_distribution(self)


    def update_states_probabilities(self, *args) -> "plFloat":
        """
        update_states_probabilities(self, observation) -> plFloat
        update_states_probabilities(self, observation) -> plFloat


        `update_states_probabilities(const Observation_t &observation) -> plFloat`  
        `update_states_probabilities(const plValues &observation) -> plFloat`  

        Overloaded function
        -------------------
        * `update_states_probabilities(const Observation_t &observation) -> plFloat`  

            Updates the distribution on the state using a given observation and returns
            the corresponding log-likelihood.  

            Parameters:  
            * `observation` :  
                the observation vector.  

            Returns:
            the log-likelihood of the observation.  

            This method allows to use the HMM as a Bayesian filter to update, after each
            observation, the probability distribution over the states.  

            See also: get_state_distribution()  

        * `update_states_probabilities(const plValues &observation) -> plFloat`  

            Updates the distribution on the state using a given observation and returns
            the corresponding log-likelihood.  

            Parameters:  
            * `observation` :  
                the observation values.  

            Returns:
            the log-likelihood of the observation.  

            This method allows to use the HMM as a Bayesian filter to update, after each
            observation, the probability distribution over the states.  

            See also: get_state_distribution()  

        """
        return _probt_python3.plHMM_update_states_probabilities(self, *args)


    def compute_states_probabilities_log(self, *args) -> "plFloat":
        """
        compute_states_probabilities_log(self, observation, states_probabilities_log) -> plFloat
        compute_states_probabilities_log(self, observation, states_probabilities_log) -> plFloat


        `compute_states_probabilities_log(const Observation_t &observation, std::vector<
            plFloat > &states_probabilities_log) const -> plFloat`  
        `compute_states_probabilities_log(const plValues &observation, std::vector<
            plFloat > &states_probabilities_log) const -> plFloat`  

        Overloaded function
        -------------------
        * `compute_states_probabilities_log(const Observation_t &observation,
            std::vector< plFloat > &states_probabilities_log) const -> plFloat`  

            Compute the logarithm of the distribution over the states using a given
            observation and returns the corresponding log-likelihood.  

            Parameters:  
            * `observation` :  
                the observation vector.  
            * `states_probabilities_log` :  
                the computed log-distribution.  

            Returns:
            the log-likelihood of the observation.  

            This method allows to use the HMM as a Bayesian filter to update, after each
            observation, the probability distribution over the states.  

            See also: get_state_distribution()  

            See also: update_states_probabilities()  

        * `compute_states_probabilities_log(const plValues &observation, std::vector<
            plFloat > &states_probabilities_log) const -> plFloat`  

            Compute the logarithm of the distribution over the states using a given
            observation and returns the corresponding log-likelihood.  

            Parameters:  
            * `observation` :  
                the observation values.  
            * `states_probabilities_log` :  
                the computed log-distribution.  

            Returns:
            the log-likelihood of the observation.  

            This method allows to use the HMM as a Bayesian filter to update, after each
            observation, the probability distribution over the states.  

            See also: get_state_distribution()  

            See also: update_states_probabilities()  

        """
        return _probt_python3.plHMM_compute_states_probabilities_log(self, *args)


    def get_state_distribution(self, state_probabilities: 'DoubleVector') -> "void":
        """
        get_state_distribution(self, state_probabilities)


        `get_state_distribution(std::vector< plProbValue > &state_probabilities) const`  

        Returns the probability distribution over the states.  

        Parameters
        ----------
        * `state_probabilities` :  
            the returned probability table.  

        This method is to be used with the update_states_probabilities() method.  

        See also: update_states_probabilities() get_state_distribution_log()  

        """
        return _probt_python3.plHMM_get_state_distribution(self, state_probabilities)


    def get_state_distribution_log(self) -> "std::vector< plFloat,std::allocator< plFloat > > const &":
        """
        get_state_distribution_log(self) -> DoubleVector


        `get_state_distribution_log() const -> const std::vector< plFloat > &`  

        Returns the log of the probability distribution over the states.  

        Returns
        -------
        log of the probability distribution over the states.  

        This method is to be used with the update_states_probabilities() method.  

        See also: update_states_probabilities() get_state_distribution()  

        """
        return _probt_python3.plHMM_get_state_distribution_log(self)


    def get_most_probable_state_sequence(self, *args) -> "plHMM::StateSequence_t":
        """
        get_most_probable_state_sequence(self, state_sequence, observation_sequence)
        get_most_probable_state_sequence(self, observation_sequence) -> UnsignedIntVector


        `get_most_probable_state_sequence(plFloat &loglikelihood, StateSequence_t
            &state_sequence, const ObservationSequence_t &observation_sequence) const`  
        `get_most_probable_state_sequence(const ObservationSequence_t
            &observation_sequence) const -> StateSequence_t`  

        Overloaded function
        -------------------
        * `get_most_probable_state_sequence(plFloat &loglikelihood, StateSequence_t
            &state_sequence, const ObservationSequence_t &observation_sequence) const`  

            Returns the most probable state sequence given an input observation sequence
            and the corresponding log-likelihood.  

            Parameters:  
            * `loglikelihood` :  
                the log-likelihood of the observation sequence.  
            * `state_sequence` :  
                the most probable state sequence.  
            * `observation_sequence` :  
                the input observation sequence.  

        * `get_most_probable_state_sequence(const ObservationSequence_t
            &observation_sequence) const -> StateSequence_t`  

            Returns the most probable state sequence given an input observation
            sequence.  

            Parameters:  
            * `observation_sequence` :  
                the input observation sequence.  

            Returns:
            The most probable state sequence.  

        """
        return _probt_python3.plHMM_get_most_probable_state_sequence(self, *args)


    def get_observation_sequence_log_likelihood(self, observation_sequence: 'DoubleVectorVector') -> "plFloat":
        """
        get_observation_sequence_log_likelihood(self, observation_sequence) -> plFloat


        `get_observation_sequence_log_likelihood(const ObservationSequence_t
            &observation_sequence) const -> plFloat`  

        Returns the log-likelihood for a given input observation sequence.  

        Returns
        -------
        the log-likelihood for a given input observation sequence.  

        """
        return _probt_python3.plHMM_get_observation_sequence_log_likelihood(self, observation_sequence)


    def get_observation_sequences_log_likelihood(self, observation_sequences: 'DoubleVectorVectorVector') -> "plFloat":
        """
        get_observation_sequences_log_likelihood(self, observation_sequences) -> plFloat


        `get_observation_sequences_log_likelihood(const ObservationSequenceArray_t
            &observation_sequences) const -> plFloat`  

        Returns the log-likelihood for a given input set of observation sequences.  

        Returns
        -------
        the log-likelihood for a given input set of observation sequences.  

        """
        return _probt_python3.plHMM_get_observation_sequences_log_likelihood(self, observation_sequences)


    def generate_sequence(self, *args) -> "plHMM::ObservationSequence_t":
        """
        generate_sequence(self, seq_length, csv_file_name, save_state=False, separator) -> bool
        generate_sequence(self, seq_length, csv_file_name, save_state=False) -> bool
        generate_sequence(self, seq_length, csv_file_name) -> bool
        generate_sequence(self, seq_length, observation_sequence, state_sequence)
        generate_sequence(self, seq_length, observation_sequence)
        generate_sequence(self, seq_length) -> DoubleVectorVector


        `generate_sequence(unsigned int seq_length, const std::string &csv_file_name,
            bool save_state=false, char separator=';') const -> bool`  
        `generate_sequence(unsigned int seq_length, ObservationSequence_t
            &observation_sequence, StateSequence_t &state_sequence) const`  
        `generate_sequence(unsigned int seq_length, ObservationSequence_t
            &observation_sequence) const`  
        `generate_sequence(unsigned int seq_length) const -> ObservationSequence_t`  

        Overloaded function
        -------------------
        * `generate_sequence(unsigned int seq_length, const std::string &csv_file_name,
            bool save_state=false, char separator=';') const -> bool`  

            Generate a sequence in a CSV file by simulating the HMM.  

            Parameters:  
            * `seq_length` :  
                sequence's length.  
            * `csv_file_name` :  
                the name of the CSV file to be generated.  
            * `save_state` :  
                if *true* the state sequence will be also generated in the file.  
            * `separator` :  
                the separator character to be used in the CSV file.  

        * `generate_sequence(unsigned int seq_length, ObservationSequence_t
            &observation_sequence, StateSequence_t &state_sequence) const`  

            Generate an observation/state sequence by simulating the HMM.  

            Parameters:  
            * `seq_length` :  
                sequence's length.  
            * `observation_sequence` :  
                the generated observation sequence.  
            * `state_sequence` :  
                the generated state sequence.  

        * `generate_sequence(unsigned int seq_length, ObservationSequence_t
            &observation_sequence) const`  

            Generate an observation sequence by simulating the HMM.  

            Parameters:  
            * `seq_length` :  
                sequence's length.  
            * `observation_sequence` :  
                the generated observation sequence.  

        * `generate_sequence(unsigned int seq_length) const -> ObservationSequence_t`  

            Same as above but returning a fresh ObservationSequence_t.  

        """
        return _probt_python3.plHMM_generate_sequence(self, *args)


    def set_final_states(self, final_states: 'UnsignedIntVector') -> "void":
        """
        set_final_states(self, final_states)


        `set_final_states(const std::vector< State_t > &final_states)`  

        Set/change the final states.  

        Parameters
        ----------
        * `final_states` :  
            final states vector.  

        """
        return _probt_python3.plHMM_set_final_states(self, final_states)


    def get_final_states(self) -> "std::vector< plHMM::State_t,std::allocator< plHMM::State_t > > const &":
        """
        get_final_states(self) -> UnsignedIntVector


        `get_final_states() const -> const std::vector< State_t > &`  

        Return the final states.  

        Returns
        -------
        the final states  

        """
        return _probt_python3.plHMM_get_final_states(self)


    def is_final_state(self, s: 'plHMM::State_t') -> "bool":
        """
        is_final_state(self, s) -> bool


        `is_final_state(State_t s) const -> bool`  

        Return *true* if the state *s* is final.  

        Returns
        -------
        *true* if the state *s* is final.  

        """
        return _probt_python3.plHMM_is_final_state(self, s)


    def is_in_final_state(self, prob: 'plProbValue') -> "bool":
        """
        is_in_final_state(self, prob) -> bool


        `is_in_final_state(plProbValue prob) const -> bool`  

        Returns *true* iff the probability to be in a final state is greater or equal to
        *prob*.  

        """
        return _probt_python3.plHMM_is_in_final_state(self, prob)


    def set_state_distribution_log(self, state_probabilities_log: 'DoubleVector') -> "void":
        """
        set_state_distribution_log(self, state_probabilities_log)


        `set_state_distribution_log(const std::vector< plFloat >
            &state_probabilities_log)`  

        Set/Change state distribution.  

        Parameters
        ----------
        * `state_probabilities_log` :  
            the logarithm of the distribution over state values.  

        """
        return _probt_python3.plHMM_set_state_distribution_log(self, state_probabilities_log)


    def set_state_distribution(self, *args) -> "void":
        """
        set_state_distribution(self, state_probabilities)
        set_state_distribution(self, state_distribution)


        `set_state_distribution(const std::vector< plProbValue > &state_probabilities)`  
        `set_state_distribution(const plDistribution &state_distribution)`  

        Overloaded function
        -------------------
        * `set_state_distribution(const std::vector< plProbValue >
            &state_probabilities)`  

            Set/Change state distribution.  

            Parameters:  
            * `state_probabilities` :  
                distribution over state values.  

        * `set_state_distribution(const plDistribution &state_distribution)`  

            Set/Change state distribution.  

            Parameters:  
            * `state_distribution` :  
                distribution over state values.  

        """
        return _probt_python3.plHMM_set_state_distribution(self, *args)


    def reset_state_distribution(self) -> "void":
        """
        reset_state_distribution(self)


        `reset_state_distribution()`  

        Reset the state distribution to the initial one.  

        """
        return _probt_python3.plHMM_reset_state_distribution(self)


    def set_nstates(self, n: 'unsigned int') -> "void":
        """
        set_nstates(self, n)


        `set_nstates(unsigned int n)`  

        Set the number of states.  

        Parameters
        ----------
        * `n` :  
            the number of states  

        """
        return _probt_python3.plHMM_set_nstates(self, n)


    def predict_states_probabilities(self) -> "void":
        """
        predict_states_probabilities(self)


        `predict_states_probabilities()`  

        Make a prediction step.  

        """
        return _probt_python3.plHMM_predict_states_probabilities(self)


    def set_init_state_distribution(self, init_state_distribution: 'plDistribution') -> "void":
        """
        set_init_state_distribution(self, init_state_distribution)


        `set_init_state_distribution(const plDistribution &init_state_distribution)`  

        Set/change the initial distribution P(S0) over internal states.  

        """
        return _probt_python3.plHMM_set_init_state_distribution(self, init_state_distribution)


    def set_transition_distribution(self, transition_distribution: 'plCndDistribution', tabulate_transition_distribution: 'bool') -> "void":
        """
        set_transition_distribution(self, transition_distribution, tabulate_transition_distribution)


        `set_transition_distribution(const plCndDistribution &transition_distribution,
            bool tabulate_transition_distribution)`  

        Set/change the transition distribution.  

        """
        return _probt_python3.plHMM_set_transition_distribution(self, transition_distribution, tabulate_transition_distribution)


    def set_emission_distribution(self, emission_distribution: 'plCndDistribution', tabulate_emission_distribution: 'bool') -> "void":
        """
        set_emission_distribution(self, emission_distribution, tabulate_emission_distribution)


        `set_emission_distribution(const plCndDistribution &emission_distribution, bool
            tabulate_emission_distribution)`  

        Set/change the emission (observation) distribution.  

        """
        return _probt_python3.plHMM_set_emission_distribution(self, emission_distribution, tabulate_emission_distribution)


    def compute_dissimilarity_to(self, *args) -> "plFloat":
        """
        compute_dissimilarity_to(self, other, this_obs_sequences) -> plFloat
        compute_dissimilarity_to(self, other, this_obs_sequences) -> plFloat


        `compute_dissimilarity_to(const plHMM &other, const ObservationSequenceArray_t
            &this_obs_sequences) const -> plFloat`  
        `compute_dissimilarity_to(const plHMM &other, plObservationSequenceGenerator
            &this_obs_sequences) const -> plFloat`  

        Overloaded function
        -------------------
        * `compute_dissimilarity_to(const plHMM &other, const ObservationSequenceArray_t
            &this_obs_sequences) const -> plFloat`  

            Compute the dissimilarity [Rabiner 89] to another HMM using a set of
            observation sequences.  

            See also: compute_symmetric_dissimilarity  

        * `compute_dissimilarity_to(const plHMM &other, plObservationSequenceGenerator
            &this_obs_sequences) const -> plFloat`  

        """
        return _probt_python3.plHMM_compute_dissimilarity_to(self, *args)


    def compute_symmetric_dissimilarity(self, *args) -> "plFloat":
        """
        compute_symmetric_dissimilarity(self, other, this_obs_sequences, other_obs_sequences) -> plFloat
        compute_symmetric_dissimilarity(self, other, this_obs_sequences, other_obs_sequences) -> plFloat


        `compute_symmetric_dissimilarity(const plHMM &other, const
            ObservationSequenceArray_t &this_obs_sequences, const
            ObservationSequenceArray_t &other_obs_sequences) const -> plFloat`  
        `compute_symmetric_dissimilarity(const plHMM &other,
            plObservationSequenceGenerator &this_obs_sequences,
            plObservationSequenceGenerator &other_obs_sequences) const -> plFloat`  

        Overloaded function
        -------------------
        * `compute_symmetric_dissimilarity(const plHMM &other, const
            ObservationSequenceArray_t &this_obs_sequences, const
            ObservationSequenceArray_t &other_obs_sequences) const -> plFloat`  

            Compute the symmetric dissimilarity [Rabiner 89] to another HMM using a set
            of observation sequences.  

            See also: compute_dissimilarity_to  

        * `compute_symmetric_dissimilarity(const plHMM &other,
            plObservationSequenceGenerator &this_obs_sequences,
            plObservationSequenceGenerator &other_obs_sequences) const -> plFloat`  

        """
        return _probt_python3.plHMM_compute_symmetric_dissimilarity(self, *args)


    def did_tabulate_transition_distribution(self) -> "bool":
        """
        did_tabulate_transition_distribution(self) -> bool


        `did_tabulate_transition_distribution() const -> bool`  

        Get back the value of the parameter tabulate_transition_distribution that was
        given at construction time.  

        """
        return _probt_python3.plHMM_did_tabulate_transition_distribution(self)


    def did_tabulate_emission_distribution(self) -> "bool":
        """
        did_tabulate_emission_distribution(self) -> bool


        `did_tabulate_emission_distribution() const -> bool`  

        Get back the value of the parameter tabulate_emission_distribution that was
        given at construction time.  

        """
        return _probt_python3.plHMM_did_tabulate_emission_distribution(self)


    def observation_variables(self) -> "plVariablesConjunction const &":
        """
        observation_variables(self) -> plVariablesConjunction


        `observation_variables() const -> const plVariablesConjunction &`  

        Get the observation variables.  

        """
        return _probt_python3.plHMM_observation_variables(self)


    def get_joint_distribution(self) -> "plJointDistribution":
        """
        get_joint_distribution(self) -> plJointDistribution


        `get_joint_distribution() const -> plJointDistribution`  

        Get the joint distribution corresponding to this HMM model.  

        """
        return _probt_python3.plHMM_get_joint_distribution(self)


    def get_bayesian_network(self) -> "plBayesianNetwork":
        """
        get_bayesian_network(self) -> plBayesianNetwork


        `get_bayesian_network() const -> plBayesianNetwork`  

        Get the dynamic Bayesian Network corresponding to this HMM model.  

        """
        return _probt_python3.plHMM_get_bayesian_network(self)


    def unroll(self, n_time_steps: 'unsigned int', state_vars: 'plVariablesConjunction') -> "plBayesianNetwork":
        """
        unroll(self, n_time_steps, state_vars) -> plBayesianNetwork


        `unroll(unsigned int n_time_steps, plVariablesConjunction &state_vars) const ->
            plBayesianNetwork`  

        Get the static unrolled Bayesian Network corresponding to this HMM model.  

        """
        return _probt_python3.plHMM_unroll(self, n_time_steps, state_vars)


    def next_data_sequence(*args) -> "bool":
        """
        next_data_sequence(generator, seq, idx) -> bool
        next_data_sequence(data_array, seq, idx) -> bool


        `next_data_sequence(plObservationSequenceGenerator &generator, const
            plHMM::ObservationSequence_t *&seq, size_t &idx) -> bool`  
        `next_data_sequence(const plHMM::ObservationSequenceArray_t &data_array, const
            plHMM::ObservationSequence_t *&seq, size_t &idx) -> bool`  

        Overloaded function
        -------------------
        * `next_data_sequence(plObservationSequenceGenerator &generator, const
            plHMM::ObservationSequence_t *&seq, size_t &idx) -> bool`  

            Get the next data sequence from a sequence generator.  

            Parameters:  
            * `generator` :  
                The observation sequence to be used  
            * `seq` :  
                The next output sequence  
            * `idx` :  
                dummy parameter (not used)  

            Returns False iif no observation sequences are left. The call returning
            False will automatically rewinded the data generator so that the next call
            will return the first sequence  

        * `next_data_sequence(const plHMM::ObservationSequenceArray_t &data_array, const
            plHMM::ObservationSequence_t *&seq, size_t &idx) -> bool`  

            Get the next data sequence from a sequence array.  

            Parameters:  
            * `data_array` :  
                The observation sequence array to be used  
            * `seq` :  
                The next output sequence  
            * `idx` :  
                the current index for the sequence array. It must be initialized to 0
                and must not be changed by the caller  

            Returns False iif the end of the sequence array is reached. The call
            returning False will automatically put the index to 0 so that the next call
            will return the first sequence  

        """
        return _probt_python3.plHMM_next_data_sequence(*args)

    next_data_sequence = staticmethod(next_data_sequence)

    def __getstate__(self) -> "std::string":
        """__getstate__(self) -> std::string"""
        return _probt_python3.plHMM___getstate__(self)


    def __setstate_internal(self, sState: 'std::string const &') -> "void":
        """__setstate_internal(self, sState)"""
        return _probt_python3.plHMM___setstate_internal(self, sState)


    def __setstate__(self, sState):
        self.__init__()
        self.__setstate_internal(sState)

plHMM_swigregister = _probt_python3.plHMM_swigregister
plHMM_swigregister(plHMM)

def plHMM_next_data_sequence(*args) -> "bool":
    """
    next_data_sequence(generator, seq, idx) -> bool
    plHMM_next_data_sequence(data_array, seq, idx) -> bool


    `next_data_sequence(plObservationSequenceGenerator &generator, const
        plHMM::ObservationSequence_t *&seq, size_t &idx) -> bool`  
    `next_data_sequence(const plHMM::ObservationSequenceArray_t &data_array, const
        plHMM::ObservationSequence_t *&seq, size_t &idx) -> bool`  

    Overloaded function
    -------------------
    * `next_data_sequence(plObservationSequenceGenerator &generator, const
        plHMM::ObservationSequence_t *&seq, size_t &idx) -> bool`  

        Get the next data sequence from a sequence generator.  

        Parameters:  
        * `generator` :  
            The observation sequence to be used  
        * `seq` :  
            The next output sequence  
        * `idx` :  
            dummy parameter (not used)  

        Returns False iif no observation sequences are left. The call returning
        False will automatically rewinded the data generator so that the next call
        will return the first sequence  

    * `next_data_sequence(const plHMM::ObservationSequenceArray_t &data_array, const
        plHMM::ObservationSequence_t *&seq, size_t &idx) -> bool`  

        Get the next data sequence from a sequence array.  

        Parameters:  
        * `data_array` :  
            The observation sequence array to be used  
        * `seq` :  
            The next output sequence  
        * `idx` :  
            the current index for the sequence array. It must be initialized to 0
            and must not be changed by the caller  

        Returns False iif the end of the sequence array is reached. The call
        returning False will automatically put the index to 0 so that the next call
        will return the first sequence  

    """
    return _probt_python3.plHMM_next_data_sequence(*args)

class plObservationSequenceCSVParameter(_object):
    """

    `plObservationSequenceCSVParameter()`  
    `plObservationSequenceCSVParameter(const std::vector< std::string >
        &csv_files_in, bool csv_file_has_header_in, unsigned int
        csv_file_nrows_to_ignore_in, const std::vector< unsigned int >
        &csv_file_columns_to_ignore_in, const plVariablesConjunction &variables_in)`  

    Parameters for loading a set of observations sequences from csv.  

    Constructors
    ------------
    * `plObservationSequenceCSVParameter()`  

        Default constructor.  

    * `plObservationSequenceCSVParameter(const std::vector< std::string >
        &csv_files_in, bool csv_file_has_header_in, unsigned int
        csv_file_nrows_to_ignore_in, const std::vector< unsigned int >
        &csv_file_columns_to_ignore_in, const plVariablesConjunction &variables_in)`  

        Constructor using csv file parameters.  

    Attributes
    ----------
    * `csv_files` : `std::vector< std::string >`  

    * `csv_file_has_header` : `bool`  

    * `csv_file_nrows_to_ignore` : `unsigned int`  

    * `csv_file_columns_to_ignore` : `std::vector< unsigned int >`  

    * `variables` : `plVariablesConjunction`  

    C++ includes: plHMM.h

    """

    __swig_setmethods__ = {}
    __setattr__ = lambda self, name, value: _swig_setattr(self, plObservationSequenceCSVParameter, name, value)
    __swig_getmethods__ = {}
    __getattr__ = lambda self, name: _swig_getattr(self, plObservationSequenceCSVParameter, name)
    __repr__ = _swig_repr

    def __init__(self, *args):
        """
        __init__(self) -> plObservationSequenceCSVParameter
        __init__(self, csv_files_in, csv_file_has_header_in, csv_file_nrows_to_ignore_in, csv_file_columns_to_ignore_in, variables_in) -> plObservationSequenceCSVParameter


        `plObservationSequenceCSVParameter()`  
        `plObservationSequenceCSVParameter(const std::vector< std::string >
            &csv_files_in, bool csv_file_has_header_in, unsigned int
            csv_file_nrows_to_ignore_in, const std::vector< unsigned int >
            &csv_file_columns_to_ignore_in, const plVariablesConjunction &variables_in)`  

        Overloaded function
        -------------------
        * `plObservationSequenceCSVParameter()`  

            Default constructor.  

        * `plObservationSequenceCSVParameter(const std::vector< std::string >
            &csv_files_in, bool csv_file_has_header_in, unsigned int
            csv_file_nrows_to_ignore_in, const std::vector< unsigned int >
            &csv_file_columns_to_ignore_in, const plVariablesConjunction &variables_in)`  

            Constructor using csv file parameters.  

        """
        this = _probt_python3.new_plObservationSequenceCSVParameter(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this
    __swig_setmethods__["csv_files"] = _probt_python3.plObservationSequenceCSVParameter_csv_files_set
    __swig_getmethods__["csv_files"] = _probt_python3.plObservationSequenceCSVParameter_csv_files_get
    if _newclass:
        csv_files = _swig_property(_probt_python3.plObservationSequenceCSVParameter_csv_files_get, _probt_python3.plObservationSequenceCSVParameter_csv_files_set)
    __swig_setmethods__["csv_file_has_header"] = _probt_python3.plObservationSequenceCSVParameter_csv_file_has_header_set
    __swig_getmethods__["csv_file_has_header"] = _probt_python3.plObservationSequenceCSVParameter_csv_file_has_header_get
    if _newclass:
        csv_file_has_header = _swig_property(_probt_python3.plObservationSequenceCSVParameter_csv_file_has_header_get, _probt_python3.plObservationSequenceCSVParameter_csv_file_has_header_set)
    __swig_setmethods__["csv_file_nrows_to_ignore"] = _probt_python3.plObservationSequenceCSVParameter_csv_file_nrows_to_ignore_set
    __swig_getmethods__["csv_file_nrows_to_ignore"] = _probt_python3.plObservationSequenceCSVParameter_csv_file_nrows_to_ignore_get
    if _newclass:
        csv_file_nrows_to_ignore = _swig_property(_probt_python3.plObservationSequenceCSVParameter_csv_file_nrows_to_ignore_get, _probt_python3.plObservationSequenceCSVParameter_csv_file_nrows_to_ignore_set)
    __swig_setmethods__["csv_file_columns_to_ignore"] = _probt_python3.plObservationSequenceCSVParameter_csv_file_columns_to_ignore_set
    __swig_getmethods__["csv_file_columns_to_ignore"] = _probt_python3.plObservationSequenceCSVParameter_csv_file_columns_to_ignore_get
    if _newclass:
        csv_file_columns_to_ignore = _swig_property(_probt_python3.plObservationSequenceCSVParameter_csv_file_columns_to_ignore_get, _probt_python3.plObservationSequenceCSVParameter_csv_file_columns_to_ignore_set)
    __swig_setmethods__["variables"] = _probt_python3.plObservationSequenceCSVParameter_variables_set
    __swig_getmethods__["variables"] = _probt_python3.plObservationSequenceCSVParameter_variables_get
    if _newclass:
        variables = _swig_property(_probt_python3.plObservationSequenceCSVParameter_variables_get, _probt_python3.plObservationSequenceCSVParameter_variables_set)
    __swig_destroy__ = _probt_python3.delete_plObservationSequenceCSVParameter
    __del__ = lambda self: None
plObservationSequenceCSVParameter_swigregister = _probt_python3.plObservationSequenceCSVParameter_swigregister
plObservationSequenceCSVParameter_swigregister(plObservationSequenceCSVParameter)

class plObservationSequenceGenerator(_object):
    """

    `plObservationSequenceGenerator()`  

    Observation sequence generator abstract class.  

    Constructors
    ------------
    * `plObservationSequenceGenerator()`  

        Constructor.  

    C++ includes: plHMM.h

    """

    __swig_setmethods__ = {}
    __setattr__ = lambda self, name, value: _swig_setattr(self, plObservationSequenceGenerator, name, value)
    __swig_getmethods__ = {}
    __getattr__ = lambda self, name: _swig_getattr(self, plObservationSequenceGenerator, name)

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined - class is abstract")
    __repr__ = _swig_repr
    __swig_destroy__ = _probt_python3.delete_plObservationSequenceGenerator
    __del__ = lambda self: None

    def get_next_sequence(self, seq: 'plHMM::ObservationSequence_t const *&') -> "bool":
        """
        get_next_sequence(self, seq) -> bool


        `get_next_sequence(const plHMM::ObservationSequence_t *&seq)=0 -> bool`  

        Get the next observation sequence.  

        """
        return _probt_python3.plObservationSequenceGenerator_get_next_sequence(self, seq)

plObservationSequenceGenerator_swigregister = _probt_python3.plObservationSequenceGenerator_swigregister
plObservationSequenceGenerator_swigregister(plObservationSequenceGenerator)

class plObservationSequenceGeneratorFromCSV(plObservationSequenceGenerator):
    """

    `plObservationSequenceGeneratorFromCSV(const plObservationSequenceCSVParameter
        &csv_parameters)`  

    Observation sequence generator from a set of CSV files.  

    Constructors
    ------------
    * `plObservationSequenceGeneratorFromCSV(const plObservationSequenceCSVParameter
        &csv_parameters)`  

        Constructor using csv file parameters.  

    C++ includes: plHMM.h

    """

    __swig_setmethods__ = {}
    for _s in [plObservationSequenceGenerator]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plObservationSequenceGeneratorFromCSV, name, value)
    __swig_getmethods__ = {}
    for _s in [plObservationSequenceGenerator]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plObservationSequenceGeneratorFromCSV, name)
    __repr__ = _swig_repr

    def __init__(self, csv_parameters: 'plObservationSequenceCSVParameter'):
        """
        __init__(self, csv_parameters) -> plObservationSequenceGeneratorFromCSV


        `plObservationSequenceGeneratorFromCSV(const plObservationSequenceCSVParameter
            &csv_parameters)`  

        Constructor using csv file parameters.  

        """
        this = _probt_python3.new_plObservationSequenceGeneratorFromCSV(csv_parameters)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this
    __swig_destroy__ = _probt_python3.delete_plObservationSequenceGeneratorFromCSV
    __del__ = lambda self: None

    def get_next_sequence(self, seq: 'plHMM::ObservationSequence_t const *&') -> "bool":
        """
        get_next_sequence(self, seq) -> bool


        `get_next_sequence(const plHMM::ObservationSequence_t *&seq) -> bool`  

        Get the next observation sequence.  

        """
        return _probt_python3.plObservationSequenceGeneratorFromCSV_get_next_sequence(self, seq)

plObservationSequenceGeneratorFromCSV_swigregister = _probt_python3.plObservationSequenceGeneratorFromCSV_swigregister
plObservationSequenceGeneratorFromCSV_swigregister(plObservationSequenceGeneratorFromCSV)

HmmStateSequence = UnsignedIntVector 
HmmStateSequenceArray = UnsignedIntVectorVector 
HmmObservation = DoubleVector 
HmmObservationSequence = DoubleVectorVector 
HmmObservationSequenceArray = DoubleVectorVectorVector 
HmmObservationSequenceArrayVector = DoubleVectorVectorVectorVector 
class plConcurrentHmmSet(plBuiltinModel):
    """

    `plConcurrentHmmSet()`  

    This class implements a model for recognition and filtering using a set of HMMs.  

    Constructors
    ------------
    * `plConcurrentHmmSet()`  

        Default constructor.  

    C++ includes: plConcurrentHmmSet.h

    """

    __swig_setmethods__ = {}
    for _s in [plBuiltinModel]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plConcurrentHmmSet, name, value)
    __swig_getmethods__ = {}
    for _s in [plBuiltinModel]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plConcurrentHmmSet, name)
    __repr__ = _swig_repr

    def __init__(self):
        """
        __init__(self) -> plConcurrentHmmSet


        `plConcurrentHmmSet()`  

        Default constructor.  

        """
        this = _probt_python3.new_plConcurrentHmmSet()
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this
    __swig_destroy__ = _probt_python3.delete_plConcurrentHmmSet
    __del__ = lambda self: None

    def add_model(self, model: 'plHMM') -> "void":
        """
        add_model(self, model)


        `add_model(const plHMM &model)`  

        Insert a new HMM model.  

        Parameters
        ----------
        * `model` :  
            the HMM model to be inserted.  

        """
        return _probt_python3.plConcurrentHmmSet_add_model(self, model)


    def remove_model(self, *args) -> "void":
        """
        remove_model(self, index)
        remove_model(self, name)


        `remove_model(unsigned int index)`  
        `remove_model(const std::string &name)`  

        Overloaded function
        -------------------
        * `remove_model(unsigned int index)`  

            Removes the model at a given index.  

            Parameters:  
            * `index` :  
                the index of the model to be removed.  

        * `remove_model(const std::string &name)`  

            Removes the model with a given name.  

            Parameters:  
            * `name` :  
                the name of the model to be removed.  

        """
        return _probt_python3.plConcurrentHmmSet_remove_model(self, *args)


    def clear_models(self) -> "void":
        """
        clear_models(self)


        `clear_models()`  

        Clear all HMM models.  

        """
        return _probt_python3.plConcurrentHmmSet_clear_models(self)


    def set_transition_matrices(self, *args) -> "void":
        """
        set_transition_matrices(self, transition_matrix_final_states, transition_matrix_non_final_states)
        set_transition_matrices(self, mp, m, final, non_final)


        `set_transition_matrices(const std::vector< std::vector< plProbValue > >
            &transition_matrix_final_states, const std::vector< std::vector< plProbValue
            > > &transition_matrix_non_final_states)`  
        `set_transition_matrices(unsigned int mp, unsigned int m, plProbValue final,
            plProbValue non_final)`  

        Overloaded function
        -------------------
        * `set_transition_matrices(const std::vector< std::vector< plProbValue > >
            &transition_matrix_final_states, const std::vector< std::vector< plProbValue
            > > &transition_matrix_non_final_states)`  

            Set/change transition matrices between models (HMMs) i.e.  

            to pass from a class value (model) Cpred to a class value (model) Cnew.  

            Parameters:  
            * `transition_matrix_final_states` :  
                Transition matrix for final states  

            transition_matrix_final_states[p][q] should hold P([Cnew=q] | [Cpred = p]
            and Cpred was in a final state) i.e the probability, during a time step, to
            pass from the class p to the class q when assuming that the current internal
            state for classe p is a final one. For all p,
            transition_matrix_final_states[p] must be a vector of probabilities whose
            elements sum up to one.  

            Parameters:  
            * `transition_matrix_non_final_states` :  
                Transition matrix for non final states  

            transition_matrix_non_final_states[p][q] should hold P([Cnew=q] | [Cpred =
            p] and Cpred was in a NON final state) i.e the probability, during a time
            step, to pass from the class p to the class q when assuming that the current
            internal state for classe p is a final one. For all p,
            transition_matrix_non_final_states[p] must be a vector of probabilities
            whose elements sum up to one.  

        * `set_transition_matrices(unsigned int mp, unsigned int m, plProbValue final,
            plProbValue non_final)`  

            Set/change an element of the transition matrices between models (HMMs).  

        """
        return _probt_python3.plConcurrentHmmSet_set_transition_matrices(self, *args)


    def get_nmodels(self) -> "size_t":
        """
        get_nmodels(self) -> size_t


        `get_nmodels() const -> size_t`  

        Return the number of the contained HMMs.  

        Returns
        -------
        the number of the contained HMMs.  

        """
        return _probt_python3.plConcurrentHmmSet_get_nmodels(self)


    def get_best_model_most_probable_state_sequence(self, state_sequence: 'UnsignedIntVector', obs_seq: 'DoubleVectorVector', only_final_states: 'bool'=False) -> "unsigned int":
        """
        get_best_model_most_probable_state_sequence(self, state_sequence, obs_seq, only_final_states=False) -> unsigned int
        get_best_model_most_probable_state_sequence(self, state_sequence, obs_seq) -> unsigned int


        `get_best_model_most_probable_state_sequence(plHMM::StateSequence_t
            &state_sequence, const plHMM::ObservationSequence_t &obs_seq, bool
            only_final_states=false) const -> unsigned int`  

        Get, for a given observation sequence, the most probable model and the
        corresponding most probable state sequence.  

        Parameters
        ----------
        * `state_sequence` :  
            the most probable state sequence corresponding to the most probable model
            (HMM)  
        * `obs_seq` :  
            observation sequence  
        * `only_final_states` :  
            a flag to say whether the retained model must be in a final state  

        Returns
        -------
        the index of the most probable model (HMM)  

        """
        return _probt_python3.plConcurrentHmmSet_get_best_model_most_probable_state_sequence(self, state_sequence, obs_seq, only_final_states)


    def get_best_model_most_probable_state_sequence_by_name(self, state_sequence: 'UnsignedIntVector', obs_seq: 'DoubleVectorVector', only_final_states: 'bool'=False) -> "std::string const &":
        """
        get_best_model_most_probable_state_sequence_by_name(self, state_sequence, obs_seq, only_final_states=False) -> std::string const
        get_best_model_most_probable_state_sequence_by_name(self, state_sequence, obs_seq) -> std::string const &


        `get_best_model_most_probable_state_sequence_by_name(plHMM::StateSequence_t
            &state_sequence, const plHMM::ObservationSequence_t &obs_seq, bool
            only_final_states=false) const -> const std::string &`  

        Get, for a given observation sequence, the most probable model and the
        corresponding most probable state sequence.  

        Parameters
        ----------
        * `state_sequence` :  
            the most probable state sequence corresponding to the most probable model
            (HMM)  
        * `obs_seq` :  
            observation sequence  
        * `only_final_states` :  
            a flag to say whether the retained model must be in a final state  

        Returns
        -------
        the name of the most probable model (HMM)  

        """
        return _probt_python3.plConcurrentHmmSet_get_best_model_most_probable_state_sequence_by_name(self, state_sequence, obs_seq, only_final_states)


    def get_best_model(self, obs_seq: 'DoubleVectorVector') -> "unsigned int":
        """
        get_best_model(self, obs_seq) -> unsigned int


        `get_best_model(const plHMM::ObservationSequence_t &obs_seq) const -> unsigned
            int`  

        Get, for a given observation sequence, the most probable model.  

        Parameters
        ----------
        * `obs_seq` :  
            observation sequence  

        Returns
        -------
        the index of the most probable model (HMM)  

        """
        return _probt_python3.plConcurrentHmmSet_get_best_model(self, obs_seq)


    def get_best_model_log_likelihood_per_obs(self, obs_seq: 'DoubleVectorVector') -> "unsigned int":
        """
        get_best_model_log_likelihood_per_obs(self, obs_seq) -> unsigned int


        `get_best_model_log_likelihood_per_obs(const plHMM::ObservationSequence_t
            &obs_seq, plFloat &log_lk_per_obs) const -> unsigned int`  

        Get, for a given observation sequence, the most probable model.  

        Parameters
        ----------
        * `obs_seq` :  
            observation sequence  
        * `log_lk_per_obs` :  
            the minimal log-likelihood normalized by the length of each sequence  

        Returns
        -------
        the index of the most probable model (HMM)  

        In Python, the signature is changed to return its results. This can be used as
        follows: model = plConcurrentHmmSet(...) cls, log_lk_per_obs =
        model.get_best_model_log_likelihood_per_obs(obs_seq)  

        """
        return _probt_python3.plConcurrentHmmSet_get_best_model_log_likelihood_per_obs(self, obs_seq)


    def get_best_model_name(self, obs_seq: 'DoubleVectorVector') -> "std::string const &":
        """
        get_best_model_name(self, obs_seq) -> std::string const &


        `get_best_model_name(const plHMM::ObservationSequence_t &obs_seq) const -> const
            std::string &`  

        Get, for a given observation sequence, the most probable model.  

        Parameters
        ----------
        * `obs_seq` :  
            observation sequence  

        Returns
        -------
        the name of the most probable model (HMM)  

        """
        return _probt_python3.plConcurrentHmmSet_get_best_model_name(self, obs_seq)


    def get_all_models_log_probabilities(self, *args) -> "std::vector< plFloat,std::allocator< plFloat > >":
        """
        get_all_models_log_probabilities(self, models_log_probabilities, observation_sequence) -> unsigned int
        get_all_models_log_probabilities(self, observation_sequence) -> DoubleVector


        `get_all_models_log_probabilities(std::vector< plFloat >
            &models_log_probabilities, const plHMM::ObservationSequence_t
            &observation_sequence) const -> unsigned int`  
        `get_all_models_log_probabilities(const plHMM::ObservationSequence_t
            &observation_sequence) const -> std::vector< plFloat >`  

        Overloaded function
        -------------------
        * `get_all_models_log_probabilities(std::vector< plFloat >
            &models_log_probabilities, const plHMM::ObservationSequence_t
            &observation_sequence) const -> unsigned int`  

            Given an observation sequence, get for each model (HMM), the corresponding
            log-probability value.  

            Parameters:  
            * `models_log_probabilities` :  
                log probability for each model (HMM)  
            * `observation_sequence` :  
                observation sequence  

            Returns:
            the index of the most probable model (HMM)  

        * `get_all_models_log_probabilities(const plHMM::ObservationSequence_t
            &observation_sequence) const -> std::vector< plFloat >`  

            Given an observation sequence, get for each model (HMM), the corresponding
            log-probability value.  

            Parameters:  
            * `observation_sequence` :  
                observation sequence  

            Returns:
            log probability for each model (HMM)  

        """
        return _probt_python3.plConcurrentHmmSet_get_all_models_log_probabilities(self, *args)


    def get_all_models_log_probabilities_name(self, models_log_probabilities: 'DoubleVector', observation_sequence: 'DoubleVectorVector') -> "std::string const &":
        """
        get_all_models_log_probabilities_name(self, models_log_probabilities, observation_sequence) -> std::string const &


        `get_all_models_log_probabilities_name(std::vector< plFloat >
            &models_log_probabilities, const plHMM::ObservationSequence_t
            &observation_sequence) const -> const std::string &`  

        Given an observation sequence, get for each model (HMM), the corresponding log-
        probability value.  

        Parameters
        ----------
        * `models_log_probabilities` :  
            log probability for each model (HMM)  
        * `observation_sequence` :  
            observation sequence  

        Returns
        -------
        the name of the most probable model (HMM)  

        """
        return _probt_python3.plConcurrentHmmSet_get_all_models_log_probabilities_name(self, models_log_probabilities, observation_sequence)


    def get_all_models_most_probable_state_sequences(self, observation_log_likelihoods: 'DoubleVector', state_sequences: 'UnsignedIntVectorVector', observation_sequence: 'DoubleVectorVector') -> "void":
        """
        get_all_models_most_probable_state_sequences(self, observation_log_likelihoods, state_sequences, observation_sequence)


        `get_all_models_most_probable_state_sequences(std::vector< plFloat >
            &observation_log_likelihoods, std::vector< plHMM::StateSequence_t >
            &state_sequences, const plHMM::ObservationSequence_t &observation_sequence)
            const`  

        Given an observation sequence, get for each model (HMM), the most probable state
        sequence and the corresponding log-likelihood value.  

        Parameters
        ----------
        * `observation_log_likelihoods` :  
            observation log-likelihood value for each model (HMM) (i.e.,
            P(observation_sequence | HMM_i) )  
        * `state_sequences` :  
            most probable sequence for each model (HMM)  
        * `observation_sequence` :  
            observation sequence  

        """
        return _probt_python3.plConcurrentHmmSet_get_all_models_most_probable_state_sequences(self, observation_log_likelihoods, state_sequences, observation_sequence)


    def get_models_log_likelihood(self, observation_sequence: 'DoubleVectorVector') -> "std::vector< plFloat,std::allocator< plFloat > >":
        """
        get_models_log_likelihood(self, observation_sequence) -> DoubleVector


        `get_models_log_likelihood(const plHMM::ObservationSequence_t
            &observation_sequence) const -> std::vector< plFloat >`  

        Given an observation sequence, get for each model (HMM), the corresponding log-
        likelihood value.  

        Parameters
        ----------
        * `observation_sequence` :  
            observation sequence  

        Returns
        -------
        log-likelihood value for each model (HMM) (i.e., P(observation_sequence | HMM_i)
        )  

        """
        return _probt_python3.plConcurrentHmmSet_get_models_log_likelihood(self, observation_sequence)


    def update_models_states_probabilities(self, *args) -> "plFloat":
        """
        update_models_states_probabilities(self, observation) -> plFloat
        update_models_states_probabilities(self, observation) -> plFloat


        `update_models_states_probabilities(const plHMM::Observation_t &observation) ->
            plFloat`  
        `update_models_states_probabilities(const plValues &observation) -> plFloat`  

        Overloaded function
        -------------------
        * `update_models_states_probabilities(const plHMM::Observation_t &observation)
            -> plFloat`  

            Use an observation to update the probability table over the contained models
            (HMMs) and return the likelihood of the observation.  

            Parameters:  
            * `observation` :  
                the observation vector  

            Returns:
            the log-likelihood of the observation  

        * `update_models_states_probabilities(const plValues &observation) -> plFloat`  

            Use an observation to update the probability table over the contained models
            (HMMs) and return the likelihood of the observation.  

            Parameters:  
            * `observation` :  
                the observation values  

            Returns:
            the log-likelihood of the observation  

        """
        return _probt_python3.plConcurrentHmmSet_update_models_states_probabilities(self, *args)


    def get_model_probability(self, *args) -> "plProbValue":
        """
        get_model_probability(self, n) -> plProbValue
        get_model_probability(self, name) -> plProbValue


        `get_model_probability(unsigned int n) const -> plProbValue`  
        `get_model_probability(const std::string &name) const -> plProbValue`  

        Overloaded function
        -------------------
        * `get_model_probability(unsigned int n) const -> plProbValue`  

            Get the probability (belief) for a given model (HMM)  

            Parameters:  
            * `n` :  
                the index of the model  

            Returns:
            the probability (belief) for the model with index *n*  

        * `get_model_probability(const std::string &name) const -> plProbValue`  

            Get the probability (belief) for a given model (HMM)  

            Parameters:  
            * `name` :  
                the name of the model  

            Returns:
            the probability (belief) for the model with name *name*  

        """
        return _probt_python3.plConcurrentHmmSet_get_model_probability(self, *args)


    def reset_models_state_distributions(self) -> "void":
        """
        reset_models_state_distributions(self)


        `reset_models_state_distributions()`  

        Reset the state distribution to the initial one for each model (HMM).  

        ATTENTION: this function does not reset models probabilities to the initial ones  

        See also: reset()  

        """
        return _probt_python3.plConcurrentHmmSet_reset_models_state_distributions(self)


    def reset(self) -> "void":
        """
        reset(self)


        `reset()`  

        Reset the HMM set:  

        *   reset the state distribution to the initial one for each model (HMM)  
        *   reset models probabilities to the initial ones  

        """
        return _probt_python3.plConcurrentHmmSet_reset(self)


    def get_models_probabilities_log(self) -> "std::vector< plFloat,std::allocator< plFloat > > const &":
        """
        get_models_probabilities_log(self) -> DoubleVector


        `get_models_probabilities_log() const -> const std::vector< plFloat > &`  

        Get the logarithm of the probability (belief) table over all models (HMMs)  

        Returns
        -------
        the logarithm of the probability (belief) table over all models (HMMs)  

        See also: get_models_probabilities()  

        """
        return _probt_python3.plConcurrentHmmSet_get_models_probabilities_log(self)


    def get_models_probabilities(self, *args) -> "std::vector< plProbValue,std::allocator< plProbValue > >":
        """
        get_models_probabilities(self, models_probabilities)
        get_models_probabilities(self) -> DoubleVector


        `get_models_probabilities(std::vector< plProbValue > &models_probabilities)
            const`  
        `get_models_probabilities() const -> std::vector< plProbValue >`  

        Overloaded function
        -------------------
        * `get_models_probabilities(std::vector< plProbValue > &models_probabilities)
            const`  

            Get the probability (belief) table over all models (HMMs)  

            Parameters:  
            * `models_probabilities` :  
                the probability (belief) table over all models (HMMs)  

            See also: get_models_probabilities_log()  

        * `get_models_probabilities() const -> std::vector< plProbValue >`  

            Get the probability (belief) table over all models (HMMs)  

            Returns:
            the probability (belief) table over all models (HMMs)  

            See also: get_models_probabilities_log()  

        """
        return _probt_python3.plConcurrentHmmSet_get_models_probabilities(self, *args)


    def set_models_probabilities(self, models_probabilities: 'DoubleVector') -> "void":
        """
        set_models_probabilities(self, models_probabilities)


        `set_models_probabilities(const std::vector< plProbValue >
            &models_probabilities)`  

        Set the current probability (belief) table over all models (HMMs)  

        Parameters
        ----------
        * `models_probabilities` :  
            the probability (belief) table over all models (HMMs)  

        """
        return _probt_python3.plConcurrentHmmSet_set_models_probabilities(self, models_probabilities)


    def set_init_models_probabilities(self, init_models_probabilities: 'DoubleVector') -> "void":
        """
        set_init_models_probabilities(self, init_models_probabilities)


        `set_init_models_probabilities(const std::vector< plProbValue >
            &init_models_probabilities)`  

        Set the initial and the current probability (belief) table over all models
        (HMMs)  

        Parameters
        ----------
        * `init_models_probabilities` :  
            the initial probability (belief) table over all models (HMMs)  

        """
        return _probt_python3.plConcurrentHmmSet_set_init_models_probabilities(self, init_models_probabilities)


    def set_models_prior(self, models_probabilities: 'DoubleVector') -> "void":
        """
        set_models_prior(self, models_probabilities)


        `set_models_prior(const std::vector< plProbValue > &models_probabilities)`  

        Same as set_init_models_probabilities() above.  

        Kept only for backward compatibility  

        """
        return _probt_python3.plConcurrentHmmSet_set_models_prior(self, models_probabilities)


    def get_transition_matrices(self, transition_matrix_final_states: 'DoubleVectorVector', transition_matrix_non_final_states: 'DoubleVectorVector') -> "void":
        """
        get_transition_matrices(self, transition_matrix_final_states, transition_matrix_non_final_states)


        `get_transition_matrices(std::vector< std::vector< plProbValue > >
            &transition_matrix_final_states, std::vector< std::vector< plProbValue > >
            &transition_matrix_non_final_states) const`  

        Get transition matrices between models (HMMs).  

        Parameters
        ----------
        * `transition_matrix_final_states` :  
            transition matrix for final states  
        * `transition_matrix_non_final_states` :  
            transition matrix for non final states  

        """
        return _probt_python3.plConcurrentHmmSet_get_transition_matrices(self, transition_matrix_final_states, transition_matrix_non_final_states)


    def use_default_transition_matrices(self) -> "void":
        """
        use_default_transition_matrices(self)


        `use_default_transition_matrices()`  

        Set using default transition matrices.  

        """
        return _probt_python3.plConcurrentHmmSet_use_default_transition_matrices(self)


    def get_model(self, *args) -> "plHMM const &":
        """
        get_model(self, n) -> plHMM
        get_model(self, name) -> plHMM
        get_model(self, n) -> plHMM
        get_model(self, name) -> plHMM


        `get_model(unsigned int n) -> plHMM &`  
        `get_model(const std::string &name) -> plHMM &`  
        `get_model(unsigned int n) const -> const plHMM &`  
        `get_model(const std::string &name) const -> const plHMM &`  

        Overloaded function
        -------------------
        * `get_model(unsigned int n) -> plHMM &`  

            Get a reference to the nth model (HMM).  

            Parameters:  
            * `n` :  
                the number of the model (HMM)  

            Returns:
            a reference to the nth model (HMM)  

        * `get_model(const std::string &name) -> plHMM &`  

            Get a reference to the nth model (HMM).  

            Parameters:  
            * `name` :  
                the name of the model (HMM)  

            Returns:
            a reference to the nth model (HMM)  

        * `get_model(unsigned int n) const -> const plHMM &`  

            Get a const reference to the nth model (HMM) if any.  

            Parameters:  
            * `n` :  
                the number of the model (HMM)  

            Returns:
            a const reference to the nth model (HMM)  

        * `get_model(const std::string &name) const -> const plHMM &`  

            Get a const reference to the model (HMM) with a given name if any.  

            Parameters:  
            * `name` :  
                the name of the model (HMM)  

            Returns:
            a const reference to the nth model (HMM)  

        """
        return _probt_python3.plConcurrentHmmSet_get_model(self, *args)


    def predict_models_states_probabilities(self) -> "void":
        """
        predict_models_states_probabilities(self)


        `predict_models_states_probabilities()`  

        Make a pure prediction step.  

        """
        return _probt_python3.plConcurrentHmmSet_predict_models_states_probabilities(self)


    def compute_dissimilarity_matrix(self, *args) -> "plFloatMatrix":
        """
        compute_dissimilarity_matrix(self, obs_sequences) -> plFloatMatrix
        compute_dissimilarity_matrix(self, csv_observation_files, csv_file_has_header, csv_file_nrows_to_ignore, csv_file_columns_to_ignore) -> plFloatMatrix


        `compute_dissimilarity_matrix(const std::vector<
            plHMM::ObservationSequenceArray_t > &obs_sequences) const -> plFloatMatrix`  
        `compute_dissimilarity_matrix(const std::vector< std::vector< std::string > >
            &csv_observation_files, bool csv_file_has_header, unsigned int
            csv_file_nrows_to_ignore, const std::vector< unsigned int >
            &csv_file_columns_to_ignore) const -> plFloatMatrix`  

        Overloaded function
        -------------------
        * `compute_dissimilarity_matrix(const std::vector<
            plHMM::ObservationSequenceArray_t > &obs_sequences) const -> plFloatMatrix`  

            Compute the dissimilarity [Rabiner 89] of HMMi to HMMj.  

            See also: compute_symmetric_dissimilarity_matrix  

        * `compute_dissimilarity_matrix(const std::vector< std::vector< std::string > >
            &csv_observation_files, bool csv_file_has_header, unsigned int
            csv_file_nrows_to_ignore, const std::vector< unsigned int >
            &csv_file_columns_to_ignore) const -> plFloatMatrix`  

            Compute the dissimilarity [Rabiner 89] of HMMi to HMMj.  

            High dissimilarity values correspond to good offline classification
            performances  

            See also: compute_symmetric_dissimilarity_matrix()  

        """
        return _probt_python3.plConcurrentHmmSet_compute_dissimilarity_matrix(self, *args)


    def compute_symmetric_dissimilarity_matrix(self, *args) -> "plFloatMatrix":
        """
        compute_symmetric_dissimilarity_matrix(self, obs_sequences) -> plFloatMatrix
        compute_symmetric_dissimilarity_matrix(self, csv_observation_files, csv_file_has_header, csv_file_nrows_to_ignore, csv_file_columns_to_ignore) -> plFloatMatrix


        `compute_symmetric_dissimilarity_matrix(const std::vector<
            plHMM::ObservationSequenceArray_t > &obs_sequences) const -> plFloatMatrix`  
        `compute_symmetric_dissimilarity_matrix(const std::vector< std::vector<
            std::string > > &csv_observation_files, bool csv_file_has_header, unsigned
            int csv_file_nrows_to_ignore, const std::vector< unsigned int >
            &csv_file_columns_to_ignore) const -> plFloatMatrix`  

        Overloaded function
        -------------------
        * `compute_symmetric_dissimilarity_matrix(const std::vector<
            plHMM::ObservationSequenceArray_t > &obs_sequences) const -> plFloatMatrix`  

            Compute the symmetric dissimilarity [Rabiner 89] between each pair (HMMi,
            HMMj).  

            High dissimilarity values correspond to good offline classification
            performances  

            See also: compute_dissimilarity_matrix()  

        * `compute_symmetric_dissimilarity_matrix(const std::vector< std::vector<
            std::string > > &csv_observation_files, bool csv_file_has_header, unsigned
            int csv_file_nrows_to_ignore, const std::vector< unsigned int >
            &csv_file_columns_to_ignore) const -> plFloatMatrix`  

            Compute the symmetric dissimilarity [Rabiner 89] between each pair (HMMi,
            HMMj).  

            High dissimilarity values correspond to good offline classification
            performances  

            See also: compute_dissimilarity_matrix()  

        """
        return _probt_python3.plConcurrentHmmSet_compute_symmetric_dissimilarity_matrix(self, *args)


    def is_in_final_state(self, n: 'unsigned int', prob: 'plProbValue') -> "bool":
        """
        is_in_final_state(self, n, prob) -> bool


        `is_in_final_state(unsigned int n, plProbValue prob) const -> bool`  

        Returns *true* iff the nth HMM's probability to be in a final state is greater
        or equal to *prob*.  

        """
        return _probt_python3.plConcurrentHmmSet_is_in_final_state(self, n, prob)


    def get_init_models_probabilities(self) -> "std::vector< plProbValue,std::allocator< plProbValue > > const &":
        """
        get_init_models_probabilities(self) -> DoubleVector


        `get_init_models_probabilities() const -> const std::vector< plProbValue > &`  

        Get the initial probability (belief) table over all models (HMMs)  

        Returns
        -------
        the initial probability (belief) table over all models (HMMs)  

        """
        return _probt_python3.plConcurrentHmmSet_get_init_models_probabilities(self)


    def save(self, file_name: 'std::string const &') -> "void":
        """
        save(self, file_name)


        `save(const std::string &file_name) const`  

        Saves the HMM set in a file.  

        """
        return _probt_python3.plConcurrentHmmSet_save(self, file_name)


    def load(self, file_name: 'std::string const &') -> "void":
        """
        load(self, file_name)


        `load(const std::string &file_name)`  

        Loads the HMM set from a file.  

        """
        return _probt_python3.plConcurrentHmmSet_load(self, file_name)


    def evaluate_offline_classification(self, *args) -> "plPredictionPerformanceReport":
        """
        evaluate_offline_classification(self, test_obs_sequences, class_names, min_log_likelihood_per_obs) -> plPredictionPerformanceReport
        evaluate_offline_classification(self, test_obs_sequences, class_names) -> plPredictionPerformanceReport
        evaluate_offline_classification(self, csv_testing_files, csv_file_has_header, csv_file_nrows_to_ignore, csv_file_columns_to_ignore, class_names, min_log_likelihood_per_obs) -> plPredictionPerformanceReport


        `evaluate_offline_classification(const std::vector<
            plHMM::ObservationSequenceArray_t > &test_obs_sequences, const std::vector<
            std::string > &class_names, std::vector< plFloat >
            &min_log_likelihood_per_obs) const -> plPredictionPerformanceReport`  
        `evaluate_offline_classification(const std::vector<
            plHMM::ObservationSequenceArray_t > &test_obs_sequences, const std::vector<
            std::string > &class_names) const -> plPredictionPerformanceReport`  
        `evaluate_offline_classification(const std::vector< std::vector< std::string > >
            &csv_testing_files, bool csv_file_has_header, unsigned int
            csv_file_nrows_to_ignore, const std::vector< unsigned int >
            &csv_file_columns_to_ignore, const std::vector< std::string > &class_names,
            std::vector< plFloat > &min_log_likelihood_per_obs) const ->
            plPredictionPerformanceReport`  

        Overloaded function
        -------------------
        * `evaluate_offline_classification(const std::vector<
            plHMM::ObservationSequenceArray_t > &test_obs_sequences, const std::vector<
            std::string > &class_names, std::vector< plFloat >
            &min_log_likelihood_per_obs) const -> plPredictionPerformanceReport`  

            Evaluate the model regarding the offline classification (whole observation
            sequence)  

            Parameters:  
            * `test_obs_sequences` :  
                A vector of observation sequence arrays (an observation sequence array
                for each class (HMM)). An observation sequence is a vector of float
                vectors (observations). In each observation, order of elements matter.
                This order must correspond to the variables as in
                `observation_variables()` or the order defined by the parameter
                observation_variable_names. In case the orders do not match, you will
                get incorrect results, and possibly occurrence of plWarning 17 (value
                out of range).  
            * `class_names` :  
                The names of the classes (HMMs)  
            * `min_log_likelihood_per_obs` :  
                The minimal log-likelihood obtenaind on the test data for each class
                (HMM)  

            Returns:
            a plPredictionPerformanceReport instance summarizing the offline
            classification performance  

            See also: plHMM::ObservationSequenceArray_t  

            See also: plHMM::ObservationSequence_t  

            See also: plHMM::Observation_t  

        * `evaluate_offline_classification(const std::vector<
            plHMM::ObservationSequenceArray_t > &test_obs_sequences, const std::vector<
            std::string > &class_names) const -> plPredictionPerformanceReport`  

        * `evaluate_offline_classification(const std::vector< std::vector< std::string >
            > &csv_testing_files, bool csv_file_has_header, unsigned int
            csv_file_nrows_to_ignore, const std::vector< unsigned int >
            &csv_file_columns_to_ignore, const std::vector< std::string > &class_names,
            std::vector< plFloat > &min_log_likelihood_per_obs) const ->
            plPredictionPerformanceReport`  

        """
        return _probt_python3.plConcurrentHmmSet_evaluate_offline_classification(self, *args)


    def evaluate_online_classification(self, *args) -> "plPredictionPerformanceReport":
        """
        evaluate_online_classification(self, test_obs_sequences, class_names, transition_matrix_final_states, transition_matrix_non_final_states, obs_llk_threshold) -> plPredictionPerformanceReport
        evaluate_online_classification(self, test_obs_sequences, class_names, transition_matrix_final_states, transition_matrix_non_final_states) -> plPredictionPerformanceReport
        evaluate_online_classification(self, test_obs_sequences, class_names, transition_matrix_final_states) -> plPredictionPerformanceReport
        evaluate_online_classification(self, test_obs_sequences, class_names) -> plPredictionPerformanceReport
        evaluate_online_classification(self, test_obs_sequences, class_values, class_names, transition_matrix_final_states, transition_matrix_non_final_states, obs_llk_threshold) -> plPredictionPerformanceReport
        evaluate_online_classification(self, test_obs_sequences, class_values, class_names, transition_matrix_final_states, transition_matrix_non_final_states) -> plPredictionPerformanceReport
        evaluate_online_classification(self, test_obs_sequences, class_values, class_names, transition_matrix_final_states) -> plPredictionPerformanceReport
        evaluate_online_classification(self, test_obs_sequences, class_values, class_names) -> plPredictionPerformanceReport
        evaluate_online_classification(self, test_obs_sequence, class_values, class_names, transition_matrix_final_states, transition_matrix_non_final_states, obs_llk_threshold) -> plPredictionPerformanceReport
        evaluate_online_classification(self, test_obs_sequence, class_values, class_names, transition_matrix_final_states, transition_matrix_non_final_states) -> plPredictionPerformanceReport
        evaluate_online_classification(self, test_obs_sequence, class_values, class_names, transition_matrix_final_states) -> plPredictionPerformanceReport
        evaluate_online_classification(self, test_obs_sequence, class_values, class_names) -> plPredictionPerformanceReport


        `evaluate_online_classification(const std::vector<
            plHMM::ObservationSequenceArray_t > &test_obs_sequences, const std::vector<
            std::string > &class_names, const std::vector< std::vector< plProbValue > >
            &transition_matrix_final_states=std::vector< std::vector< plProbValue > >(),
            const std::vector< std::vector< plProbValue > >
            &transition_matrix_non_final_states=std::vector< std::vector< plProbValue >
            >(), plFloat obs_llk_threshold=-std::numeric_limits< plFloat >::infinity())
            -> plPredictionPerformanceReport`  
        `evaluate_online_classification(const plHMM::ObservationSequenceArray_t
            &test_obs_sequences, const std::vector< std::vector< unsigned int > >
            &class_values, const std::vector< std::string > &class_names, const
            std::vector< std::vector< plProbValue > >
            &transition_matrix_final_states=std::vector< std::vector< plProbValue > >(),
            const std::vector< std::vector< plProbValue > >
            &transition_matrix_non_final_states=std::vector< std::vector< plProbValue >
            >(), plFloat obs_llk_threshold=-std::numeric_limits< plFloat >::infinity())
            -> plPredictionPerformanceReport`  
        `evaluate_online_classification(const plHMM::ObservationSequence_t
            &test_obs_sequence, const std::vector< unsigned int > &class_values, const
            std::vector< std::string > &class_names, const std::vector< std::vector<
            plProbValue > > &transition_matrix_final_states=std::vector< std::vector<
            plProbValue > >(), const std::vector< std::vector< plProbValue > >
            &transition_matrix_non_final_states=std::vector< std::vector< plProbValue >
            >(), plFloat obs_llk_threshold=-std::numeric_limits< plFloat >::infinity())
            -> plPredictionPerformanceReport`  

        Overloaded function
        -------------------
        * `evaluate_online_classification(const std::vector<
            plHMM::ObservationSequenceArray_t > &test_obs_sequences, const std::vector<
            std::string > &class_names, const std::vector< std::vector< plProbValue > >
            &transition_matrix_final_states=std::vector< std::vector< plProbValue > >(),
            const std::vector< std::vector< plProbValue > >
            &transition_matrix_non_final_states=std::vector< std::vector< plProbValue >
            >(), plFloat obs_llk_threshold=-std::numeric_limits< plFloat >::infinity())
            -> plPredictionPerformanceReport`  

            Evaluate the model regarding the online classification (per observation)  

            Parameters:  
            * `test_obs_sequences` :  
                A vector of observation sequence arrays (an observation sequence array
                for each class (HMM)). An observation sequence is a vector of float
                vectors (observations). In each observation, order of elements matter.
                This order must correspond to the variables as in
                `observation_variables()` or the order defined by the parameter
                observation_variable_names. In case the orders do not match, you will
                get incorrect results, and possibly occurrence of plWarning 17 (value
                out of range).  
            * `class_names` :  
                The names of the classes (HMMs)  
            * `transition_matrix_final_states` :  
                Transition matrix for final states (see definition in
                set_transition_matrices())  
            * `transition_matrix_non_final_states` :  
                Transition matrix for non final states (see definition in
                set_transition_matrices())  
            * `obs_llk_threshold` :  
                The minimal log-likelihood of the observations to be accepted. If the
                log-likelihood of the observation is less than this threshold, then the
                classification will return UNKNOWN (last column in the confusion matrix)  

            Returns:
            a plPredictionPerformanceReport instance summarizing the online
            classification performance  

            See also: plHMM::ObservationSequenceArray_t  

            See also: plHMM::ObservationSequence_t  

            See also: plHMM::Observation_t  

        * `evaluate_online_classification(const plHMM::ObservationSequenceArray_t
            &test_obs_sequences, const std::vector< std::vector< unsigned int > >
            &class_values, const std::vector< std::string > &class_names, const
            std::vector< std::vector< plProbValue > >
            &transition_matrix_final_states=std::vector< std::vector< plProbValue > >(),
            const std::vector< std::vector< plProbValue > >
            &transition_matrix_non_final_states=std::vector< std::vector< plProbValue >
            >(), plFloat obs_llk_threshold=-std::numeric_limits< plFloat >::infinity())
            -> plPredictionPerformanceReport`  

            Evaluate the model regarding the online classification (per observation)  

            Parameters:  
            * `test_obs_sequences` :  
                A vector of observation sequence arrays (an observation sequence array
                for each class (HMM)). An observation sequence is a vector of float
                vectors (observations). In each observation, order of elements matter.
                This order must correspond to the variables as in
                `observation_variables()` or the order defined by the parameter
                observation_variable_names. In case the orders do not match, you will
                get incorrect results, and possibly occurrence of plWarning 17 (value
                out of range).  
            * `class_values` :  
                The class values (starting from 0) corresponding to each each time-step
                (observation) in the test_obs_sequences sequences  
            * `class_names` :  
                The names of the classes (HMMs)  
            * `transition_matrix_final_states` :  
                Transition matrix for final states (see definition in
                set_transition_matrices())  
            * `transition_matrix_non_final_states` :  
                Transition matrix for non final states (see definition in
                set_transition_matrices())  
            * `obs_llk_threshold` :  
                The minimal log-likelihood of the observations to be accepted. If the
                log-likelihood of the observation is less than this threshold, then the
                classification will return UNKNOWN (last column in the confusion matrix)  

            Returns:
            a plPredictionPerformanceReport instance summarizing the online
            classification performance  

            See also: plHMM::ObservationSequenceArray_t  

            See also: plHMM::ObservationSequence_t  

            See also: plHMM::Observation_t  

        * `evaluate_online_classification(const plHMM::ObservationSequence_t
            &test_obs_sequence, const std::vector< unsigned int > &class_values, const
            std::vector< std::string > &class_names, const std::vector< std::vector<
            plProbValue > > &transition_matrix_final_states=std::vector< std::vector<
            plProbValue > >(), const std::vector< std::vector< plProbValue > >
            &transition_matrix_non_final_states=std::vector< std::vector< plProbValue >
            >(), plFloat obs_llk_threshold=-std::numeric_limits< plFloat >::infinity())
            -> plPredictionPerformanceReport`  

            Evaluate the model regarding the online classification (per observation)  

            Parameters:  
            * `test_obs_sequence` :  
                An observation sequence array. An observation sequence is a vector of
                float vectors (observations). In each observation, order of elements
                matter. This order must correspond to the variables as in
                `observation_variable()` or the order defined by the parameter
                observation_variable_names. In case the orders do not match, you will
                get incorrect results, and possibly occurrence of plWarning 17 (value
                out of range).  
            * `class_values` :  
                The class values (starting from 0) corresponding to each each time-step
                (observation) in the test_obs_sequences sequences  
            * `class_names` :  
                The names of the classes (HMMs)  
            * `transition_matrix_final_states` :  
                Transition matrix for final states (see definition in
                set_transition_matrices())  
            * `transition_matrix_non_final_states` :  
                Transition matrix for non final states (see definition in
                set_transition_matrices())  
            * `obs_llk_threshold` :  
                The minimal log-likelihood of the observations to be accepted. If the
                log-likelihood of the observation is less than this threshold, then the
                classification will return UNKNOWN (last column in the confusion matrix)  

            Returns:
            a plPredictionPerformanceReport instance summarizing the online
            classification performance  

            See also: plHMM::ObservationSequence_t  

            See also: plHMM::Observation_t  

        """
        return _probt_python3.plConcurrentHmmSet_evaluate_online_classification(self, *args)


    def set_verbose(self, verbose: 'bool') -> "void":
        """
        set_verbose(self, verbose)


        `set_verbose(bool verbose)`  

        Set/unset verbose mode.  

        """
        return _probt_python3.plConcurrentHmmSet_set_verbose(self, verbose)


    def set_output_stream(self, *args) -> "void":
        """
        set_output_stream(self)
        set_output_stream(self, out)


        `set_output_stream(std::ostream &out)`  
        `set_output_stream(plStringStream &out)`  

        Overloaded function
        -------------------
        * `set_output_stream(std::ostream &out)`  

            Set the output stream to be used when verbose mode is enabled.  

            The default is std::cout  

        * `set_output_stream(plStringStream &out)`  

        """
        return _probt_python3.plConcurrentHmmSet_set_output_stream(self, *args)


    def observation_variables(self) -> "plVariablesConjunction":
        """
        observation_variables(self) -> plVariablesConjunction


        `observation_variables() const -> plVariablesConjunction`  

        Get the observation variables.  

        """
        return _probt_python3.plConcurrentHmmSet_observation_variables(self)


    def __getstate__(self) -> "std::string":
        """__getstate__(self) -> std::string"""
        return _probt_python3.plConcurrentHmmSet___getstate__(self)


    def __setstate_internal(self, sState: 'std::string const &') -> "void":
        """__setstate_internal(self, sState)"""
        return _probt_python3.plConcurrentHmmSet___setstate_internal(self, sState)


    def __setstate__(self, sState):
        self.__init__()
        self.__setstate_internal(sState)

plConcurrentHmmSet_swigregister = _probt_python3.plConcurrentHmmSet_swigregister
plConcurrentHmmSet_swigregister(plConcurrentHmmSet)

class plDataDescriptor(plObject):
    """

    `plDataDescriptor()`  

    This abstract class defines a sequential data container.  

    This data descriptor is intended to be used with learning functions such as
    plLearnObject::learn(), plBayesianNetwork::learn_parameters(),
    plBayesianNetwork::learn_structure(), and plEMLearner::run().  

    Constructors
    ------------
    * `plDataDescriptor()`  

        Constructor.  

    C++ includes: plDataDescriptor.h

    """

    __swig_setmethods__ = {}
    for _s in [plObject]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plDataDescriptor, name, value)
    __swig_getmethods__ = {}
    for _s in [plObject]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plDataDescriptor, name)

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined - class is abstract")
    __repr__ = _swig_repr

    def is_ok(self) -> "bool":
        """
        is_ok(self) -> bool


        `is_ok() const -> bool`  

        Returns *true* if the initialization (construction) is OK.  

        Returns
        -------
        *true* if the initialization (construction) is OK  

        """
        return _probt_python3.plDataDescriptor_is_ok(self)

    __swig_destroy__ = _probt_python3.delete_plDataDescriptor
    __del__ = lambda self: None

    def get_num_fields(self) -> "unsigned int":
        """
        get_num_fields(self) -> unsigned int


        `get_num_fields() const =0 -> unsigned int`  

        Returns the number of fields (columns).  

        Returns
        -------
        the number of fields (columns/variables).  

        """
        return _probt_python3.plDataDescriptor_get_num_fields(self)


    def rewind(self) -> "void":
        """
        rewind(self)


        `rewind()=0`  

        Rewinds the container to go back to its beginning.  

        """
        return _probt_python3.plDataDescriptor_rewind(self)


    def get_data_record(self, *args) -> "bool":
        """
        get_data_record(self) -> bool
        get_data_record(self) -> bool


        `get_data_record(const plValues *&data_values, const std::vector< bool >
            *&data_definition, plFloat &weight)=0 -> bool`  
        `get_data_record(const plValues *&data_values, const std::vector< bool >
            *&data_definition) -> bool`  

        Overloaded function
        -------------------
        * `get_data_record(const plValues *&data_values, const std::vector< bool >
            *&data_definition, plFloat &weight)=0 -> bool`  

            Get the next data record (row) and advances by one record in the data.  

            Parameters:  
            * `data_values` :  
                an array of values for all variables described in the record.  
            * `data_definition` :  
                a vector stating, for each value in *data_values*, whether it's defined
                or not.  
            * `weight` :  
                the weight of the record  

            Returns:
            *false* iif the end of the container is reached.  

            The returned pointers are managed internally: you should not attempt to
            delete them, or use them after another call to get_data_record(). Also, you
            should not use them when get_data_record() returns *false*.  

            For Python, the signature of this function is changed to return its results.
            It can be used as follows:  

                data_decriptor = ...
                not_done, data_values, data_definition, w =
            data_decriptor.get_data_record()


        * `get_data_record(const plValues *&data_values, const std::vector< bool >
            *&data_definition) -> bool`  

            Same as above but the weight is not returned (Obsolete function) This
            function is provided for backward compatibility only.  

        """
        return _probt_python3.plDataDescriptor_get_data_record(self, *args)


    def get_next_defined_value(self) -> "plValues const *":
        """
        get_next_defined_value(self) -> plValues


        `get_next_defined_value(plFloat &weight) -> const plValues *`  

        Get the defined values from the next data record (row) and advances by one
        record in the data.  

        Parameters
        ----------
        * `weight` :  
            the weight of the record  

        Returns
        -------
        a pointer to a value with the variables defined in the record or 0 if the end of
        the container is reached.  

        The returned pointers are managed internally: you should not attempt to delete
        them, or use them after another call to get_next_defined_value()  

        """
        return _probt_python3.plDataDescriptor_get_next_defined_value(self)


    def has_same_missing_variables(self) -> "bool":
        """
        has_same_missing_variables(self) -> bool


        `has_same_missing_variables() const -> bool`  

        Returns True if and only if the missing values concern the same variables
        (columns) for all data records.  

        See also: set_has_same_missing_variables()  

        """
        return _probt_python3.plDataDescriptor_has_same_missing_variables(self)


    def set_has_same_missing_variables(self, val: 'bool') -> "void":
        """
        set_has_same_missing_variables(self, val)


        `set_has_same_missing_variables(bool val)`  

        Set to True if you are sure that the missing values concern the same variables
        (columns) for all data records.  

        This information can speedup the processing using some algorithms such as EM.  

        The default value is False  

        """
        return _probt_python3.plDataDescriptor_set_has_same_missing_variables(self, val)


    def get_data_matrix(self, *args) -> "void":
        """
        get_data_matrix(self, data_matrix, undef_value, n, sampling_rate=1.0)
        get_data_matrix(self, data_matrix, undef_value, n)
        get_data_matrix(self, data_matrix, undef_value)
        get_data_matrix(self, data_matrix)
        get_data_matrix(self, data_matrix, undef_value, n, sampling_rate=1.0)
        get_data_matrix(self, data_matrix, undef_value, n)
        get_data_matrix(self, data_matrix, undef_value)
        get_data_matrix(self, data_matrix)
        get_data_matrix(self, data_matrix, undef_value, n, sampling_rate=1.0)
        get_data_matrix(self, data_matrix, undef_value, n)
        get_data_matrix(self, data_matrix, undef_value)
        get_data_matrix(self, data_matrix)
        get_data_matrix(self, data_matrix, undef_value, n, sampling_rate=1.0)
        get_data_matrix(self, data_matrix, undef_value, n)
        get_data_matrix(self, data_matrix, undef_value)
        get_data_matrix(self, data_matrix, undef_value, n, sampling_rate=1.0)
        get_data_matrix(self, data_matrix, undef_value, n)
        get_data_matrix(self, data_matrix, undef_value)
        get_data_matrix(self, data_matrix, undef_value, n, sampling_rate=1.0)
        get_data_matrix(self, data_matrix, undef_value, n)
        get_data_matrix(self, data_matrix, undef_value)
        get_data_matrix(self, data_matrix, n, sampling_rate=1.0)
        get_data_matrix(self, data_matrix, n)
        get_data_matrix(self, data_matrix)
        get_data_matrix(self, data_matrix, def_matrix, n, sampling_rate=1.0)
        get_data_matrix(self, data_matrix, def_matrix, n)
        get_data_matrix(self, data_matrix, def_matrix)
        get_data_matrix(self, data_matrix, def_matrix, n, sampling_rate=1.0)
        get_data_matrix(self, data_matrix, def_matrix, n)
        get_data_matrix(self, data_matrix, def_matrix)
        get_data_matrix(self, data_matrix, def_matrix, n, sampling_rate=1.0)
        get_data_matrix(self, data_matrix, def_matrix, n)
        get_data_matrix(self, data_matrix, def_matrix)
        get_data_matrix(self, data_matrix, def_matrix, n, sampling_rate=1.0)
        get_data_matrix(self, data_matrix, def_matrix, n)
        get_data_matrix(self, data_matrix, def_matrix)
        get_data_matrix(self, data_matrix, def_matrix, n, sampling_rate=1.0)
        get_data_matrix(self, data_matrix, def_matrix, n)
        get_data_matrix(self, data_matrix, def_matrix)
        get_data_matrix(self, data_matrix, def_matrix, n, sampling_rate=1.0)
        get_data_matrix(self, data_matrix, def_matrix, n)
        get_data_matrix(self, data_matrix, def_matrix)
        get_data_matrix(self, data_matrix, def_matrix, n, sampling_rate=1.0)
        get_data_matrix(self, data_matrix, def_matrix, n)
        get_data_matrix(self, data_matrix, def_matrix)


        `get_data_matrix(std::vector< std::vector< double > > &data_matrix, double
            undef_value=NAN, unsigned int n=std::numeric_limits< unsigned int >::max(),
            plFloat sampling_rate=PL_ONE)`  
        `get_data_matrix(std::vector< std::vector< float > > &data_matrix, float
            undef_value=NAN, unsigned int n=std::numeric_limits< unsigned int >::max(),
            plFloat sampling_rate=PL_ONE)`  
        `get_data_matrix(std::vector< std::vector< long double > > &data_matrix, long
            double undef_value=NAN, unsigned int n=std::numeric_limits< unsigned int
            >::max(), plFloat sampling_rate=PL_ONE)`  
        `get_data_matrix(std::vector< std::vector< int > > &data_matrix, int
            undef_value, unsigned int n=std::numeric_limits< unsigned int >::max(),
            plFloat sampling_rate=PL_ONE)`  
        `get_data_matrix(std::vector< std::vector< unsigned int > > &data_matrix,
            unsigned int undef_value, unsigned int n=std::numeric_limits< unsigned int
            >::max(), plFloat sampling_rate=PL_ONE)`  
        `get_data_matrix(std::vector< std::vector< long unsigned int > > &data_matrix,
            long unsigned int undef_value, unsigned int n=std::numeric_limits< unsigned
            int >::max(), plFloat sampling_rate=PL_ONE)`  
        `get_data_matrix(std::vector< plValues > &data_matrix, unsigned int
            n=std::numeric_limits< unsigned int >::max(), plFloat sampling_rate=PL_ONE)`  
        `get_data_matrix(std::vector< std::vector< double > > &data_matrix, std::vector<
            std::vector< bool > > &def_matrix, unsigned int n=std::numeric_limits<
            unsigned int >::max(), plFloat sampling_rate=PL_ONE)`  
        `get_data_matrix(std::vector< std::vector< float > > &data_matrix, std::vector<
            std::vector< bool > > &def_matrix, unsigned int n=std::numeric_limits<
            unsigned int >::max(), plFloat sampling_rate=PL_ONE)`  
        `get_data_matrix(std::vector< std::vector< long double > > &data_matrix,
            std::vector< std::vector< bool > > &def_matrix, unsigned int
            n=std::numeric_limits< unsigned int >::max(), plFloat sampling_rate=PL_ONE)`  
        `get_data_matrix(std::vector< std::vector< int > > &data_matrix, std::vector<
            std::vector< bool > > &def_matrix, unsigned int n=std::numeric_limits<
            unsigned int >::max(), plFloat sampling_rate=PL_ONE)`  
        `get_data_matrix(std::vector< std::vector< unsigned int > > &data_matrix,
            std::vector< std::vector< bool > > &def_matrix, unsigned int
            n=std::numeric_limits< unsigned int >::max(), plFloat sampling_rate=PL_ONE)`  
        `get_data_matrix(std::vector< std::vector< long unsigned int > > &data_matrix,
            std::vector< std::vector< bool > > &def_matrix, unsigned int
            n=std::numeric_limits< unsigned int >::max(), plFloat sampling_rate=PL_ONE)`  
        `get_data_matrix(std::vector< plValues > &data_matrix, std::vector< std::vector<
            bool > > &def_matrix, unsigned int n=std::numeric_limits< unsigned int
            >::max(), plFloat sampling_rate=PL_ONE)`  

        Overloaded function
        -------------------
        * `get_data_matrix(std::vector< std::vector< double > > &data_matrix, double
            undef_value=NAN, unsigned int n=std::numeric_limits< unsigned int >::max(),
            plFloat sampling_rate=PL_ONE)`  

            Fills the data matrix corresponding to the data container.  

            Parameters:  
            * `data_matrix` :  
                the returned data matrix.  
            * `undef_value` :  
                The value to be used for undefined values (missing)  
            * `n` :  
                the number of rows (data records) to be copied  
            * `sampling_rate` :  
                when sampling_rate < 1., the data descriptor is sampled and the
                parameter n above is ignored  

            This function does not rewind this data descriptor  

        * `get_data_matrix(std::vector< std::vector< float > > &data_matrix, float
            undef_value=NAN, unsigned int n=std::numeric_limits< unsigned int >::max(),
            plFloat sampling_rate=PL_ONE)`  

            Fills the data matrix corresponding to the data container.  

            Parameters:  
            * `data_matrix` :  
                the returned data matrix.  
            * `undef_value` :  
                The value to be used for undefined values (missing)  
            * `n` :  
                the number of rows (data records) to be copied  
            * `sampling_rate` :  
                when sampling_rate < 1., the data descriptor is sampled and the
                parameter n above is ignored  

            This function does not rewind this data descriptor  

        * `get_data_matrix(std::vector< std::vector< long double > > &data_matrix, long
            double undef_value=NAN, unsigned int n=std::numeric_limits< unsigned int
            >::max(), plFloat sampling_rate=PL_ONE)`  

            Fills the data matrix corresponding to the data container.  

            Parameters:  
            * `data_matrix` :  
                the returned data matrix.  
            * `undef_value` :  
                The value to be used for undefined values (missing)  
            * `n` :  
                the number of rows (data records) to be copied  
            * `sampling_rate` :  
                when sampling_rate < 1., the data descriptor is sampled and the
                parameter n above is ignored  

            This function does not rewind this data descriptor  

        * `get_data_matrix(std::vector< std::vector< int > > &data_matrix, int
            undef_value, unsigned int n=std::numeric_limits< unsigned int >::max(),
            plFloat sampling_rate=PL_ONE)`  

            Fills the data matrix corresponding to the data container.  

            Parameters:  
            * `data_matrix` :  
                the returned data matrix.  
            * `undef_value` :  
                The value to be used for undefined values (missing)  
            * `n` :  
                the number of rows (data records) to be copied  
            * `sampling_rate` :  
                when sampling_rate < 1., the data descriptor is sampled and the
                parameter n above is ignored  

            This function does not rewind this data descriptor  

        * `get_data_matrix(std::vector< std::vector< unsigned int > > &data_matrix,
            unsigned int undef_value, unsigned int n=std::numeric_limits< unsigned int
            >::max(), plFloat sampling_rate=PL_ONE)`  

            Fills the data matrix corresponding to the data container.  

            Parameters:  
            * `data_matrix` :  
                the returned data matrix.  
            * `undef_value` :  
                The value to be used for undefined values (missing)  
            * `n` :  
                the number of rows (data records) to be copied  
            * `sampling_rate` :  
                when sampling_rate < 1., the data descriptor is sampled and the
                parameter n above is ignored  

            This function does not rewind this data descriptor  

        * `get_data_matrix(std::vector< std::vector< long unsigned int > > &data_matrix,
            long unsigned int undef_value, unsigned int n=std::numeric_limits< unsigned
            int >::max(), plFloat sampling_rate=PL_ONE)`  

            Fills the data matrix corresponding to the data container.  

            Parameters:  
            * `data_matrix` :  
                the returned data matrix.  
            * `undef_value` :  
                The value to be used for undefined values (missing)  
            * `n` :  
                the number of rows (data records) to be copied  
            * `sampling_rate` :  
                when sampling_rate < 1., the data descriptor is sampled and the
                parameter n above is ignored  

            This function does not rewind this data descriptor  

        * `get_data_matrix(std::vector< plValues > &data_matrix, unsigned int
            n=std::numeric_limits< unsigned int >::max(), plFloat sampling_rate=PL_ONE)`  

            Fills the data matrix corresponding to the data container.  

            It assumes no missing data  

            Parameters:  
            * `data_matrix` :  
                the returned data matrix.  
            * `n` :  
                the number of rows (data records) to be copied  
            * `sampling_rate` :  
                when sampling_rate < 1., the data descriptor is sampled and the
                parameter n above is ignored  

            This function does not rewind this data descriptor  

        * `get_data_matrix(std::vector< std::vector< double > > &data_matrix,
            std::vector< std::vector< bool > > &def_matrix, unsigned int
            n=std::numeric_limits< unsigned int >::max(), plFloat sampling_rate=PL_ONE)`  

            Fills the data matrix (and the corresponding definition matrix)
            corresponding to the data container.  

            Parameters:  
            * `data_matrix` :  
                the returned data matrix.  
            * `def_matrix` :  
                the corresponding definition matrix.  
            * `n` :  
                the number of rows (data records) to be copied  
            * `sampling_rate` :  
                when sampling_rate < 1., the data descriptor is sampled and the
                parameter n above is ignored  

            This function does not rewind this data descriptor  

        * `get_data_matrix(std::vector< std::vector< float > > &data_matrix,
            std::vector< std::vector< bool > > &def_matrix, unsigned int
            n=std::numeric_limits< unsigned int >::max(), plFloat sampling_rate=PL_ONE)`  

            Fills the data matrix (and the corresponding definition matrix)
            corresponding to the data container.  

            Parameters:  
            * `data_matrix` :  
                the returned data matrix.  
            * `def_matrix` :  
                the corresponding definition matrix.  
            * `n` :  
                the number of rows (data records) to be copied  
            * `sampling_rate` :  
                when sampling_rate < 1., the data descriptor is sampled and the
                parameter n above is ignored  

            This function does not rewind this data descriptor  

        * `get_data_matrix(std::vector< std::vector< long double > > &data_matrix,
            std::vector< std::vector< bool > > &def_matrix, unsigned int
            n=std::numeric_limits< unsigned int >::max(), plFloat sampling_rate=PL_ONE)`  

            Fills the data matrix (and the corresponding definition matrix)
            corresponding to the data container.  

            Parameters:  
            * `data_matrix` :  
                the returned data matrix.  
            * `def_matrix` :  
                the corresponding definition matrix.  
            * `n` :  
                the number of rows (data records) to be copied  
            * `sampling_rate` :  
                when sampling_rate < 1., the data descriptor is sampled and the
                parameter n above is ignored  

            This function does not rewind this data descriptor  

        * `get_data_matrix(std::vector< std::vector< int > > &data_matrix, std::vector<
            std::vector< bool > > &def_matrix, unsigned int n=std::numeric_limits<
            unsigned int >::max(), plFloat sampling_rate=PL_ONE)`  

            Fills the data matrix (and the corresponding definition matrix)
            corresponding to the data container.  

            Parameters:  
            * `data_matrix` :  
                the returned data matrix.  
            * `def_matrix` :  
                the corresponding definition matrix.  
            * `n` :  
                the number of rows (data records) to be copied  
            * `sampling_rate` :  
                when sampling_rate < 1., the data descriptor is sampled and the
                parameter n above is ignored  

            This function does not rewind this data descriptor  

        * `get_data_matrix(std::vector< std::vector< unsigned int > > &data_matrix,
            std::vector< std::vector< bool > > &def_matrix, unsigned int
            n=std::numeric_limits< unsigned int >::max(), plFloat sampling_rate=PL_ONE)`  

            Fills the data matrix (and the corresponding definition matrix)
            corresponding to the data container.  

            Parameters:  
            * `data_matrix` :  
                the returned data matrix.  
            * `def_matrix` :  
                the corresponding definition matrix.  
            * `n` :  
                the number of rows (data records) to be copied  
            * `sampling_rate` :  
                when sampling_rate < 1., the data descriptor is sampled and the
                parameter n above is ignored  

            This function does not rewind this data descriptor  

        * `get_data_matrix(std::vector< std::vector< long unsigned int > > &data_matrix,
            std::vector< std::vector< bool > > &def_matrix, unsigned int
            n=std::numeric_limits< unsigned int >::max(), plFloat sampling_rate=PL_ONE)`  

            Fills the data matrix (and the corresponding definition matrix)
            corresponding to the data container.  

            Parameters:  
            * `data_matrix` :  
                the returned data matrix.  
            * `def_matrix` :  
                the corresponding definition matrix.  
            * `n` :  
                the number of rows (data records) to be copied  
            * `sampling_rate` :  
                when sampling_rate < 1., the data descriptor is sampled and the
                parameter n above is ignored  

            This function does not rewind this data descriptor  

        * `get_data_matrix(std::vector< plValues > &data_matrix, std::vector<
            std::vector< bool > > &def_matrix, unsigned int n=std::numeric_limits<
            unsigned int >::max(), plFloat sampling_rate=PL_ONE)`  

            Fills the data matrix (and the corresponding definition matrix)
            corresponding to the data container.  

            Parameters:  
            * `data_matrix` :  
                the returned data matrix.  
            * `def_matrix` :  
                the corresponding definition matrix.  
            * `n` :  
                the number of rows (data records) to be copied  
            * `sampling_rate` :  
                when sampling_rate < 1., the data descriptor is sampled and the
                parameter n above is ignored  

            This function does not rewind this data descriptor  

            See also: get_defined_value_array()  

        """
        return _probt_python3.plDataDescriptor_get_data_matrix(self, *args)


    def get_data_range(self, min_vals: 'DoubleVector', max_vals: 'DoubleVector') -> "void":
        """
        get_data_range(self, min_vals, max_vals)


        `get_data_range(std::vector< plFloat > &min_vals, std::vector< plFloat >
            &max_vals)`  

        Returns the range of the data.  

        Parameters
        ----------
        * `min_vals` :  
            the minimal value found in the data container for each data field (column).  
        * `max_vals` :  
            the maximal value found in the data container for each data field (column).  

        This function has as side effect the rewinding of this data descriptor  

        """
        return _probt_python3.plDataDescriptor_get_data_range(self, min_vals, max_vals)


    def get_column_values(self, *args) -> "void":
        """
        get_column_values(self, n, column_vals, undef_value)
        get_column_values(self, n, column_vals)
        get_column_values(self, n, column_vals, undef_value)
        get_column_values(self, n, column_vals)
        get_column_values(self, n, column_vals, undef_value)
        get_column_values(self, n, column_vals)
        get_column_values(self, n, column_vals, undef_value)
        get_column_values(self, n, column_vals, undef_value)
        get_column_values(self, n, column_vals, undef_value)
        get_column_values(self, n, column_vals, undef_value)
        get_column_values(self, n, column_vals, undef_value)
        get_column_values(self, n, column_vals)
        get_column_values(self, n, column_vals, column_defs)
        get_column_values(self, n, column_vals, column_defs)
        get_column_values(self, n, column_vals, column_defs)
        get_column_values(self, n, column_vals, column_defs)
        get_column_values(self, n, column_vals, column_defs)
        get_column_values(self, n, column_vals, column_defs)
        get_column_values(self, n, column_vals, column_defs)


        `get_column_values(unsigned int n, std::vector< double > &column_vals, double
            undef_value=NAN)`  
        `get_column_values(unsigned int n, std::vector< float > &column_vals, float
            undef_value=NAN)`  
        `get_column_values(unsigned int n, std::vector< long double > &column_vals, long
            double undef_value=NAN)`  
        `get_column_values(unsigned int n, std::vector< int > &column_vals, int
            undef_value)`  
        `get_column_values(unsigned int n, std::vector< long > &column_vals, long
            undef_value)`  
        `get_column_values(unsigned int n, std::vector< unsigned int > &column_vals,
            unsigned int undef_value)`  
        `get_column_values(unsigned int n, std::vector< long unsigned int >
            &column_vals, long unsigned int undef_value)`  
        `get_column_values(unsigned int n, std::vector< std::string > &column_vals,
            const std::string &undef_value="")`  
        `get_column_values(unsigned int n, std::vector< double > &column_vals,
            std::vector< bool > &column_defs)`  
        `get_column_values(unsigned int n, std::vector< float > &column_vals,
            std::vector< bool > &column_defs)`  
        `get_column_values(unsigned int n, std::vector< long double > &column_vals,
            std::vector< bool > &column_defs)`  
        `get_column_values(unsigned int n, std::vector< int > &column_vals, std::vector<
            bool > &column_defs)`  
        `get_column_values(unsigned int n, std::vector< unsigned int > &column_vals,
            std::vector< bool > &column_defs)`  
        `get_column_values(unsigned int n, std::vector< long unsigned int >
            &column_vals, std::vector< bool > &column_defs)`  
        `get_column_values(unsigned int n, std::vector< std::string > &column_vals,
            std::vector< bool > &column_defs)`  

        Overloaded function
        -------------------
        * `get_column_values(unsigned int n, std::vector< double > &column_vals, double
            undef_value=NAN)`  

            Get a column vector.  

            Parameters:  
            * `n` :  
                column number.  
            * `column_vals` :  
                the returned column vector.  
            * `undef_value` :  
                The value to be used for undefined values (missing)  

            This function has as side effect the rewinding of this data descriptor  

        * `get_column_values(unsigned int n, std::vector< float > &column_vals, float
            undef_value=NAN)`  

            Get a column vector.  

            Parameters:  
            * `n` :  
                column number.  
            * `column_vals` :  
                the returned column vector.  
            * `undef_value` :  
                The value to be used for undefined values (missing)  

            This function has as side effect the rewinding of this data descriptor  

        * `get_column_values(unsigned int n, std::vector< long double > &column_vals,
            long double undef_value=NAN)`  

            Get a column vector.  

            Parameters:  
            * `n` :  
                column number.  
            * `column_vals` :  
                the returned column vector.  
            * `undef_value` :  
                The value to be used for undefined values (missing)  

            This function has as side effect the rewinding of this data descriptor  

        * `get_column_values(unsigned int n, std::vector< int > &column_vals, int
            undef_value)`  

            Get a column vector.  

            Parameters:  
            * `n` :  
                column number.  
            * `column_vals` :  
                the returned column vector.  
            * `undef_value` :  
                The value to be used for undefined values (missing)  

            This function has as side effect the rewinding of this data descriptor  

        * `get_column_values(unsigned int n, std::vector< long > &column_vals, long
            undef_value)`  

        * `get_column_values(unsigned int n, std::vector< unsigned int > &column_vals,
            unsigned int undef_value)`  

            Get a column vector.  

            Parameters:  
            * `n` :  
                column number.  
            * `column_vals` :  
                the returned column vector.  
            * `undef_value` :  
                The value to be used for undefined values (missing)  

            This function has as side effect the rewinding of this data descriptor  

        * `get_column_values(unsigned int n, std::vector< long unsigned int >
            &column_vals, long unsigned int undef_value)`  

            Get a column vector.  

            Parameters:  
            * `n` :  
                column number.  
            * `column_vals` :  
                the returned column vector.  
            * `undef_value` :  
                The value to be used for undefined values (missing)  

            This function has as side effect the rewinding of this data descriptor  

        * `get_column_values(unsigned int n, std::vector< std::string > &column_vals,
            const std::string &undef_value="")`  

            Get a column vector.  

            Parameters:  
            * `n` :  
                column number.  
            * `column_vals` :  
                the returned column vector.  
            * `undef_value` :  
                The value to be used for undefined values (missing)  

            This function has as side effect the rewinding of this data descriptor  

        * `get_column_values(unsigned int n, std::vector< double > &column_vals,
            std::vector< bool > &column_defs)`  

            Get a column vector and the corresponding definition values.  

            Parameters:  
            * `n` :  
                column number.  
            * `column_vals` :  
                the returned column vector.  
            * `column_defs` :  
                the corresponding definition values.  

            This function has as side effect the rewinding of this data descriptor  

        * `get_column_values(unsigned int n, std::vector< float > &column_vals,
            std::vector< bool > &column_defs)`  

            Get a column vector and the corresponding definition values.  

            Parameters:  
            * `n` :  
                column number.  
            * `column_vals` :  
                the returned column vector.  
            * `column_defs` :  
                the corresponding definition values.  

        * `get_column_values(unsigned int n, std::vector< long double > &column_vals,
            std::vector< bool > &column_defs)`  

            Get a column vector and the corresponding definition values.  

            Parameters:  
            * `n` :  
                column number.  
            * `column_vals` :  
                the returned column vector.  
            * `column_defs` :  
                the corresponding definition values.  

            This function has as side effect the rewinding of this data descriptor  

        * `get_column_values(unsigned int n, std::vector< int > &column_vals,
            std::vector< bool > &column_defs)`  

            Get a column vector and the corresponding definition values.  

            Parameters:  
            * `n` :  
                column number.  
            * `column_vals` :  
                the returned column vector.  
            * `column_defs` :  
                the corresponding definition values.  

            This function has as side effect the rewinding of this data descriptor  

        * `get_column_values(unsigned int n, std::vector< unsigned int > &column_vals,
            std::vector< bool > &column_defs)`  

            Get a column vector and the corresponding definition values.  

            Parameters:  
            * `n` :  
                column number.  
            * `column_vals` :  
                the returned column vector.  
            * `column_defs` :  
                the corresponding definition values.  

            This function has as side effect the rewinding of this data descriptor  

        * `get_column_values(unsigned int n, std::vector< long unsigned int >
            &column_vals, std::vector< bool > &column_defs)`  

            Get a column vector and the corresponding definition values.  

            Parameters:  
            * `n` :  
                column number.  
            * `column_vals` :  
                the returned column vector.  
            * `column_defs` :  
                the corresponding definition values.  

            This function has as side effect the rewinding of this data descriptor  

        * `get_column_values(unsigned int n, std::vector< std::string > &column_vals,
            std::vector< bool > &column_defs)`  

            Get a column vector and the corresponding definition values.  

            Parameters:  
            * `n` :  
                column number.  
            * `column_vals` :  
                the returned column vector.  
            * `column_defs` :  
                the corresponding definition values.  

            This function has as side effect the rewinding of this data descriptor  

        """
        return _probt_python3.plDataDescriptor_get_column_values(self, *args)


    def get_variable_values(self, *args) -> "void":
        """
        get_variable_values(self, variable, column_vals, undef_value)
        get_variable_values(self, variable, column_vals)
        get_variable_values(self, variable, column_vals, undef_value)
        get_variable_values(self, variable, column_vals)
        get_variable_values(self, variable, column_vals, undef_value)
        get_variable_values(self, variable, column_vals)
        get_variable_values(self, variable, column_vals, undef_value)
        get_variable_values(self, variable, column_vals, undef_value)
        get_variable_values(self, variable, column_vals, undef_value)
        get_variable_values(self, variable, column_vals, undef_value)
        get_variable_values(self, variable, column_vals)
        get_variable_values(self, variable, column_vals, column_defs)
        get_variable_values(self, variable, column_vals, column_defs)
        get_variable_values(self, variable, column_vals, column_defs)
        get_variable_values(self, variable, column_vals, column_defs)
        get_variable_values(self, variable, column_vals, column_defs)
        get_variable_values(self, variable, column_vals, column_defs)
        get_variable_values(self, variable, column_vals, column_defs)


        `get_variable_values(const plVariable &variable, std::vector< double >
            &column_vals, double undef_value=NAN)`  
        `get_variable_values(const plVariable &variable, std::vector< float >
            &column_vals, float undef_value=NAN)`  
        `get_variable_values(const plVariable &variable, std::vector< long double >
            &column_vals, long double undef_value=NAN)`  
        `get_variable_values(const plVariable &variable, std::vector< int >
            &column_vals, int undef_value)`  
        `get_variable_values(const plVariable &variable, std::vector< unsigned int >
            &column_vals, unsigned int undef_value)`  
        `get_variable_values(const plVariable &variable, std::vector< long unsigned int
            > &column_vals, long unsigned int undef_value)`  
        `get_variable_values(const plVariable &variable, std::vector< std::string >
            &column_vals, const std::string &undef_value="")`  
        `get_variable_values(const plVariable &variable, std::vector< double >
            &column_vals, std::vector< bool > &column_defs)`  
        `get_variable_values(const plVariable &variable, std::vector< float >
            &column_vals, std::vector< bool > &column_defs)`  
        `get_variable_values(const plVariable &variable, std::vector< long double >
            &column_vals, std::vector< bool > &column_defs)`  
        `get_variable_values(const plVariable &variable, std::vector< int >
            &column_vals, std::vector< bool > &column_defs)`  
        `get_variable_values(const plVariable &variable, std::vector< unsigned int >
            &column_vals, std::vector< bool > &column_defs)`  
        `get_variable_values(const plVariable &variable, std::vector< long unsigned int
            > &column_vals, std::vector< bool > &column_defs)`  
        `get_variable_values(const plVariable &variable, std::vector< std::string >
            &column_vals, std::vector< bool > &column_defs)`  

        Overloaded function
        -------------------
        * `get_variable_values(const plVariable &variable, std::vector< double >
            &column_vals, double undef_value=NAN)`  

            Get a column vector.  

            Parameters:  
            * `variable` :  
                the variable of interest.  
            * `column_vals` :  
                the returned column vector.  
            * `undef_value` :  
                The value to be used for undefined values (missing)  

            This function has as side effect the rewinding of this data descriptor  

        * `get_variable_values(const plVariable &variable, std::vector< float >
            &column_vals, float undef_value=NAN)`  

            Get a column vector.  

            Parameters:  
            * `variable` :  
                the variable of interest.  
            * `column_vals` :  
                the returned column vector.  
            * `undef_value` :  
                The value to be used for undefined values (missing)  

            This function has as side effect the rewinding of this data descriptor  

        * `get_variable_values(const plVariable &variable, std::vector< long double >
            &column_vals, long double undef_value=NAN)`  

            Get a column vector.  

            Parameters:  
            * `variable` :  
                the variable of interest.  
            * `column_vals` :  
                the returned column vector.  
            * `undef_value` :  
                The value to be used for undefined values (missing)  

            This function has as side effect the rewinding of this data descriptor  

        * `get_variable_values(const plVariable &variable, std::vector< int >
            &column_vals, int undef_value)`  

            Get a column vector.  

            Parameters:  
            * `variable` :  
                the variable of interest.  
            * `column_vals` :  
                the returned column vector.  
            * `undef_value` :  
                The value to be used for undefined values (missing)  

            This function has as side effect the rewinding of this data descriptor  

        * `get_variable_values(const plVariable &variable, std::vector< unsigned int >
            &column_vals, unsigned int undef_value)`  

            Get a column vector.  

            Parameters:  
            * `variable` :  
                the variable of interest.  
            * `column_vals` :  
                the returned column vector.  
            * `undef_value` :  
                The value to be used for undefined values (missing)  

            This function has as side effect the rewinding of this data descriptor  

        * `get_variable_values(const plVariable &variable, std::vector< long unsigned
            int > &column_vals, long unsigned int undef_value)`  

            Get a column vector.  

            Parameters:  
            * `variable` :  
                the variable of interest.  
            * `column_vals` :  
                the returned column vector.  
            * `undef_value` :  
                The value to be used for undefined values (missing)  

            This function has as side effect the rewinding of this data descriptor  

        * `get_variable_values(const plVariable &variable, std::vector< std::string >
            &column_vals, const std::string &undef_value="")`  

            Get a column vector.  

            Parameters:  
            * `variable` :  
                the variable of interest.  
            * `column_vals` :  
                the returned column vector.  
            * `undef_value` :  
                The value to be used for undefined values (missing)  

            This function has as side effect the rewinding of this data descriptor  

        * `get_variable_values(const plVariable &variable, std::vector< double >
            &column_vals, std::vector< bool > &column_defs)`  

            Get a column vector and the corresponding definition values.  

            Parameters:  
            * `variable` :  
                the variable of interest.  
            * `column_vals` :  
                the returned column vector.  
            * `column_defs` :  
                the corresponding definition values.  

            This function has as side effect the rewinding of this data descriptor  

        * `get_variable_values(const plVariable &variable, std::vector< float >
            &column_vals, std::vector< bool > &column_defs)`  

            Get a column vector and the corresponding definition values.  

            Parameters:  
            * `variable` :  
                the variable of interest.  
            * `column_vals` :  
                the returned column vector.  
            * `column_defs` :  
                the corresponding definition values.  

            This function has as side effect the rewinding of this data descriptor  

        * `get_variable_values(const plVariable &variable, std::vector< long double >
            &column_vals, std::vector< bool > &column_defs)`  

            Get a column vector and the corresponding definition values.  

            Parameters:  
            * `variable` :  
                the variable of interest.  
            * `column_vals` :  
                the returned column vector.  
            * `column_defs` :  
                the corresponding definition values.  

            This function has as side effect the rewinding of this data descriptor  

        * `get_variable_values(const plVariable &variable, std::vector< int >
            &column_vals, std::vector< bool > &column_defs)`  

            Get a column vector and the corresponding definition values.  

            Parameters:  
            * `variable` :  
                the variable of interest.  
            * `column_vals` :  
                the returned column vector.  
            * `column_defs` :  
                the corresponding definition values.  

            This function has as side effect the rewinding of this data descriptor  

        * `get_variable_values(const plVariable &variable, std::vector< unsigned int >
            &column_vals, std::vector< bool > &column_defs)`  

            Get a column vector and the corresponding definition values.  

            Parameters:  
            * `variable` :  
                the variable of interest.  
            * `column_vals` :  
                the returned column vector.  
            * `column_defs` :  
                the corresponding definition values.  

            This function has as side effect the rewinding of this data descriptor  

        * `get_variable_values(const plVariable &variable, std::vector< long unsigned
            int > &column_vals, std::vector< bool > &column_defs)`  

            Get a column vector and the corresponding definition values.  

            Parameters:  
            * `variable` :  
                the variable of interest.  
            * `column_vals` :  
                the returned column vector.  
            * `column_defs` :  
                the corresponding definition values.  

            This function has as side effect the rewinding of this data descriptor  

        * `get_variable_values(const plVariable &variable, std::vector< std::string >
            &column_vals, std::vector< bool > &column_defs)`  

            Get a column vector and the corresponding definition values.  

            Parameters:  
            * `variable` :  
                the variable of interest.  
            * `column_vals` :  
                the returned column vector.  
            * `column_defs` :  
                the corresponding definition values.  

            This function has as side effect the rewinding of this data descriptor  

        """
        return _probt_python3.plDataDescriptor_get_variable_values(self, *args)


    def get_defined_value_array(self, *args) -> "std::vector< plValues,std::allocator< plValues > >":
        """
        get_defined_value_array(self, n, sampling_rate=1.0) -> plValuesVector
        get_defined_value_array(self, n) -> plValuesVector
        get_defined_value_array(self) -> plValuesVector


        `get_defined_value_array(unsigned int n=std::numeric_limits< unsigned int
            >::max(), plFloat sampling_rate=PL_ONE) -> std::vector< plValues >`  

        Get the defined values.  

        """
        return _probt_python3.plDataDescriptor_get_defined_value_array(self, *args)


    def validate(self, erroneous_lines: 'UnsignedIntVector') -> "bool":
        """
        validate(self, erroneous_lines) -> bool


        `validate(std::vector< unsigned int > &erroneous_lines) -> bool`  

        Validate the data set by checking that the provided values are compatible with
        the types of the given variable conjunction associaded to the data descriptor.  

        This function has as side effect the rewinding of this data descriptor  

        Parameters
        ----------
        * `erroneous_lines` :  
            line numbers (starting from 1) in which incompatible values have been found.  

        Returns
        -------
        true iff no incompatible values have been found.  

        """
        return _probt_python3.plDataDescriptor_validate(self, erroneous_lines)


    def get_n_records(self) -> "unsigned int":
        """
        get_n_records(self) -> unsigned int


        `get_n_records() -> unsigned int`  

        Get the number of records (rows) in the data set.  

        ATTENTION: For the first call, the default implementation scans the data set and
        thus has a complexity of O(n) where *n* is the size.  

        This function has as side effect the rewinding of this data descriptor  

        Returns
        -------
        the size of the data set.  

        """
        return _probt_python3.plDataDescriptor_get_n_records(self)


    def observed_variables(self) -> "plVariablesConjunction":
        """
        observed_variables(self) -> plVariablesConjunction


        `observed_variables()=0 -> plVariablesConjunction`  

        Get the variables associated to the descriptor.  

        """
        return _probt_python3.plDataDescriptor_observed_variables(self)


    def print_head(self, *args) -> "bool":
        """
        print_head(self, file, n=20, sep) -> bool
        print_head(self, file, n=20) -> bool
        print_head(self, file) -> bool


        `print_head(unsigned int n=20, std::ostream &sout=std::cout, char sep='\t') ->
            bool`  
        `print_head(const std::string &file, unsigned int n=20, char sep='\t') -> bool`  

        Overloaded function
        -------------------
        * `print_head(unsigned int n=20, std::ostream &sout=std::cout, char sep='\t')
            -> bool`  

            Prints the header and the 'n' first rows in the output stream 'sout'.  

            This function has as side effect the rewinding of this data descriptor  

            Returns:
            True if the end is reached  

        * `print_head(const std::string &file, unsigned int n=20, char sep='\t') ->
            bool`  

            Prints the header and the 'n' first rows in the file 'file'.  

            This function has as side effect the rewinding of this data descriptor  

            Returns:
            True if the end is reached  

        """
        return _probt_python3.plDataDescriptor_print_head(self, *args)


    def get_head(self, *args) -> "std::string":
        """
        get_head(self, n=20, sep) -> std::string
        get_head(self, n=20) -> std::string
        get_head(self) -> std::string


        `get_head(unsigned int n=20, char sep='\t') -> std::string`  

        """
        return _probt_python3.plDataDescriptor_get_head(self, *args)


    def print_simple_stats(self, *args) -> "void":
        """
        print_simple_stats(self, file, sep)
        print_simple_stats(self, file)


        `print_simple_stats(std::ostream &sout=std::cout, char sep='\t') ->
            std::ostream &`  
        `print_simple_stats(const std::string &file, char sep='\t')`  

        Overloaded function
        -------------------
        * `print_simple_stats(std::ostream &sout=std::cout, char sep='\t') ->
            std::ostream &`  

            Prints some simple statistic of the data.  

            This function has as side effect the rewinding of this data descriptor  

        * `print_simple_stats(const std::string &file, char sep='\t')`  

            Prints some simple statistic of the data.  

            This function has as side effect the rewinding of this data descriptor  

        """
        return _probt_python3.plDataDescriptor_print_simple_stats(self, *args)


    def get_simple_stats(self, *args) -> "std::string":
        """
        get_simple_stats(self, min_vals, max_vals, mean_vals, stdev_vals, n, ncomplete_rows) -> unsigned int
        get_simple_stats(self, sep) -> std::string
        get_simple_stats(self) -> std::string


        `get_simple_stats(std::vector< plFloat > &min_vals, std::vector< plFloat >
            &max_vals, std::vector< plFloat > &mean_vals, std::vector< plFloat >
            &stdev_vals, std::vector< unsigned int > &n, unsigned int &ncomplete_rows)
            -> unsigned int`  
        `get_simple_stats(char sep='\t') -> std::string`  

        Overloaded function
        -------------------
        * `get_simple_stats(std::vector< plFloat > &min_vals, std::vector< plFloat >
            &max_vals, std::vector< plFloat > &mean_vals, std::vector< plFloat >
            &stdev_vals, std::vector< unsigned int > &n, unsigned int &ncomplete_rows)
            -> unsigned int`  

            Computes some simple stats on the data.  

            Parameters:  
            * `min_vals` :  
                the minimal value for each data field (column).  
            * `max_vals` :  
                the maximal value for each data field (column).  
            * `mean_vals` :  
                the mean value for each data field (column).  
            * `stdev_vals` :  
                the standard deviation for each data field (column).  
            * `n` :  
                the number of defined records (rows) for each data field (column).  
            * `ncomplete_rows` :  
                the number of complete records (rows) (with no missing values)  

            Returns:
            the number of data records (rows)  

        * `get_simple_stats(char sep='\t') -> std::string`  

        """
        return _probt_python3.plDataDescriptor_get_simple_stats(self, *args)


    def use_for_discretization(self, *args) -> "std::vector< plFloat,std::allocator< plFloat > >":
        """
        use_for_discretization(self, discretizers, variable_columns) -> DoubleVectorVector
        use_for_discretization(self, discretizer, variable_column) -> DoubleVector


        `use_for_discretization(const std::vector< plVariableDiscretizer *>
            &discretizers, const std::vector< unsigned int > &variable_columns) ->
            std::vector< std::vector< plFloat > >`  
        `use_for_discretization(plVariableDiscretizer *discretizer, unsigned int
            variable_column) -> std::vector< plFloat >`  

        Overloaded function
        -------------------
        * `use_for_discretization(const std::vector< plVariableDiscretizer *>
            &discretizers, const std::vector< unsigned int > &variable_columns) ->
            std::vector< std::vector< plFloat > >`  

            Return the discretization intervals for the variables corresponding to
            columns *variable_columns* according to this data set.  

            ATTENTION: when using this function in Python, pass the parameters
            'discretizers' and 'variable_columns' as Python lists  

        * `use_for_discretization(plVariableDiscretizer *discretizer, unsigned int
            variable_column) -> std::vector< plFloat >`  

            Return the discretization intervals for the variable corresponding to column
            *variable_column* according to this data set.  

        """
        return _probt_python3.plDataDescriptor_use_for_discretization(self, *args)


    def has_observed_variables(self) -> "bool":
        """
        has_observed_variables(self) -> bool


        `has_observed_variables() const -> bool`  

        Return true iif the data descriptor has been associated to a set of variables.  

        """
        return _probt_python3.plDataDescriptor_has_observed_variables(self)


    def skip_next_lines(self, n: 'size_t') -> "void":
        """
        skip_next_lines(self, n)


        `skip_next_lines(size_t n)`  

        Skip the next n data lines.  

        """
        return _probt_python3.plDataDescriptor_skip_next_lines(self, n)


    def save_as_csv(self, csv_file: 'std::string const &', separator: 'char', undef_string: 'std::string const &') -> "void":
        """
        save_as_csv(self, csv_file, separator, undef_string)


        `save_as_csv(std::ostream &csv_stream, char separator, const std::string
            &undef_string)`  
        `save_as_csv(const std::string &csv_file, char separator, const std::string
            &undef_string)`  

        Overloaded function
        -------------------
        * `save_as_csv(std::ostream &csv_stream, char separator, const std::string
            &undef_string)`  

            Save the data descriptor as a CSV.  

            This function has as side effect the rewinding of this data descriptor  

        * `save_as_csv(const std::string &csv_file, char separator, const std::string
            &undef_string)`  

            Save the data descriptor as a CSV.  

            This function has as side effect the rewinding of this data descriptor  

        """
        return _probt_python3.plDataDescriptor_save_as_csv(self, csv_file, separator, undef_string)


    def generate_gnuplot(self, *args) -> "void":
        """
        generate_gnuplot(self, gnuplot_file, title, time_stamp_column=0, time_stamp_format, plottype=PL_DEFAULT_PLOT, plot_points=False)
        generate_gnuplot(self, gnuplot_file, title, time_stamp_column=0, time_stamp_format, plottype=PL_DEFAULT_PLOT)
        generate_gnuplot(self, gnuplot_file, title, time_stamp_column=0, time_stamp_format)
        generate_gnuplot(self, gnuplot_file, title, time_stamp_column=0)
        generate_gnuplot(self, gnuplot_file, title)


        `generate_gnuplot(const std::string &gnuplot_file, const std::string &title,
            unsigned int time_stamp_column=0, const std::string
            time_stamp_format="%m/%d/%Y:%H:%M:%S", plPlotType
            plottype=PL_DEFAULT_PLOT, bool plot_points=false)`  

        Generate gnuplot instruction for plotting the data as a time-serie.  

        'time_stamp_column' is the number, starting from 1, of the date-houre colum This
        function has as side effect the rewinding of this data descriptor  

        """
        return _probt_python3.plDataDescriptor_generate_gnuplot(self, *args)


    def generate_gnuplot_for_csv_data(csv_file: 'std::string const &', separator: 'char', used_columns_names: 'StringVector', column_is_used: 'BoolVector', n_ignored_lines: 'unsigned int', gnuplot_file: 'std::string const &', title: 'std::string const &', time_stamp_column: 'unsigned int', time_stamp_format: 'std::string const', plottype: 'plPlotType', plot_points: 'bool') -> "bool":
        """
        generate_gnuplot_for_csv_data(csv_file, separator, used_columns_names, column_is_used, n_ignored_lines, gnuplot_file, title, time_stamp_column, time_stamp_format, plottype, plot_points) -> bool


        `generate_gnuplot_for_csv_data(const std::string &csv_file, char separator,
            const std::vector< std::string > &used_columns_names, const std::vector<
            bool > &column_is_used, unsigned int n_ignored_lines, const std::string
            &gnuplot_file, const std::string &title, unsigned int time_stamp_column,
            const std::string time_stamp_format, plPlotType plottype, bool plot_points)
            -> bool`  

        """
        return _probt_python3.plDataDescriptor_generate_gnuplot_for_csv_data(csv_file, separator, used_columns_names, column_is_used, n_ignored_lines, gnuplot_file, title, time_stamp_column, time_stamp_format, plottype, plot_points)

    generate_gnuplot_for_csv_data = staticmethod(generate_gnuplot_for_csv_data)

    def head_html(self, n: 'unsigned int'=20) -> "std::string":
        """
        head_html(self, n=20) -> std::string
        head_html(self) -> std::string


        `head_html(unsigned int n=20) -> std::string`  

        Get the n head rows as an html table.  

        """
        return _probt_python3.plDataDescriptor_head_html(self, n)


    def get_undef_int() -> "long":
        """
        get_undef_int() -> long


        `get_undef_int() -> long`  

        Get the value to be used for undefined integer values in Python data (Pandas,
        Numpy)  

        """
        return _probt_python3.plDataDescriptor_get_undef_int()

    get_undef_int = staticmethod(get_undef_int)

    def set_undef_int(val: 'long') -> "void":
        """
        set_undef_int(val)


        `set_undef_int(long val)`  

        Set the value to be used for undefined integer values in Python data (Pandas,
        Numpy)  

        """
        return _probt_python3.plDataDescriptor_set_undef_int(val)

    set_undef_int = staticmethod(set_undef_int)

    def python_plot(self) -> "void":
        """
        python_plot(self)


        `python_plot()`  

        Only for Python: Plot the data.  

        """
        return _probt_python3.plDataDescriptor_python_plot(self)


    def python_as_list(self) -> "void":
        """
        python_as_list(self)


        `python_as_list()`  

        Only for Python: Return the data as a Python list.  

        """
        return _probt_python3.plDataDescriptor_python_as_list(self)


    def python_as_numpy_array(self) -> "void":
        """
        python_as_numpy_array(self)


        `python_as_numpy_array()`  

        Only for Python: Return the data as a Numpy array.  

        """
        return _probt_python3.plDataDescriptor_python_as_numpy_array(self)


    def python_as_numpy_recarray(self) -> "void":
        """
        python_as_numpy_recarray(self)


        `python_as_numpy_recarray()`  

        Only for Python: Return the data as a Numpy recarray.  

        """
        return _probt_python3.plDataDescriptor_python_as_numpy_recarray(self)


    def python_as_pandas_dataframe(self) -> "void":
        """
        python_as_pandas_dataframe(self)


        `python_as_pandas_dataframe()`  

        Only for Python: Return the data as a Pandas dataframe.  

        """
        return _probt_python3.plDataDescriptor_python_as_pandas_dataframe(self)


    def create_from_python_data() -> "void":
        """
        create_from_python_data()


        `create_from_python_data()`  

        Create a plDataDescriptor from a Python data array (Numpy, Pandas) Only for
        Python: Return the data as a plNumPyDataDescriptor.  

        """
        return _probt_python3.plDataDescriptor_create_from_python_data()

    create_from_python_data = staticmethod(create_from_python_data)
plDataDescriptor_swigregister = _probt_python3.plDataDescriptor_swigregister
plDataDescriptor_swigregister(plDataDescriptor)

def plDataDescriptor_generate_gnuplot_for_csv_data(csv_file: 'std::string const &', separator: 'char', used_columns_names: 'StringVector', column_is_used: 'BoolVector', n_ignored_lines: 'unsigned int', gnuplot_file: 'std::string const &', title: 'std::string const &', time_stamp_column: 'unsigned int', time_stamp_format: 'std::string const', plottype: 'plPlotType', plot_points: 'bool') -> "bool":
    """
    plDataDescriptor_generate_gnuplot_for_csv_data(csv_file, separator, used_columns_names, column_is_used, n_ignored_lines, gnuplot_file, title, time_stamp_column, time_stamp_format, plottype, plot_points) -> bool


    `generate_gnuplot_for_csv_data(const std::string &csv_file, char separator,
        const std::vector< std::string > &used_columns_names, const std::vector<
        bool > &column_is_used, unsigned int n_ignored_lines, const std::string
        &gnuplot_file, const std::string &title, unsigned int time_stamp_column,
        const std::string time_stamp_format, plPlotType plottype, bool plot_points)
        -> bool`  

    """
    return _probt_python3.plDataDescriptor_generate_gnuplot_for_csv_data(csv_file, separator, used_columns_names, column_is_used, n_ignored_lines, gnuplot_file, title, time_stamp_column, time_stamp_format, plottype, plot_points)

def plDataDescriptor_get_undef_int() -> "long":
    """
    plDataDescriptor_get_undef_int() -> long


    `get_undef_int() -> long`  

    Get the value to be used for undefined integer values in Python data (Pandas,
    Numpy)  

    """
    return _probt_python3.plDataDescriptor_get_undef_int()

def plDataDescriptor_set_undef_int(val: 'long') -> "void":
    """
    plDataDescriptor_set_undef_int(val)


    `set_undef_int(long val)`  

    Set the value to be used for undefined integer values in Python data (Pandas,
    Numpy)  

    """
    return _probt_python3.plDataDescriptor_set_undef_int(val)

def plDataDescriptor_create_from_python_data() -> "void":
    """
    plDataDescriptor_create_from_python_data()


    `create_from_python_data()`  

    Create a plDataDescriptor from a Python data array (Numpy, Pandas) Only for
    Python: Return the data as a plNumPyDataDescriptor.  

    """
    return _probt_python3.plDataDescriptor_create_from_python_data()

class plStringDataDescriptor(_object):
    """


    Interface for a data descriptor able to return lines of data as uninterpreted
    raw string vectors.  

    C++ includes: plDataDescriptor.h

    """

    __swig_setmethods__ = {}
    __setattr__ = lambda self, name, value: _swig_setattr(self, plStringDataDescriptor, name, value)
    __swig_getmethods__ = {}
    __getattr__ = lambda self, name: _swig_getattr(self, plStringDataDescriptor, name)

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined - class is abstract")
    __repr__ = _swig_repr
    __swig_destroy__ = _probt_python3.delete_plStringDataDescriptor
    __del__ = lambda self: None

    def get_data_record(self, data_values: 'StringVector') -> "bool":
        """
        get_data_record(self, data_values) -> bool


        `get_data_record(std::vector< std::string > &data_values)=0 -> bool`  

        Returns the raw, uninterpreted data record as a vector of strings.  

        This is a virtual method that should be filled in by implementations.  

        Parameters
        ----------
        * `data_values` :  
            Line of data split in elements, resized as needed and filled in by this
            method.  

        Returns
        -------
        false iff the end of the container is reached.  

        This method consumes one line of data descriptor input.  

        """
        return _probt_python3.plStringDataDescriptor_get_data_record(self, data_values)


    def guess_variables(self, header: 'bool', n_discretization_bins: 'int'=0) -> "plVariablesConjunction":
        """
        guess_variables(self, header, n_discretization_bins=0) -> plVariablesConjunction
        guess_variables(self, header) -> plVariablesConjunction


        `guess_variables(bool header, int n_discretization_bins=0) ->
            plVariablesConjunction`  

        Tries to guess the variables described by a string data descriptor, by examining
        its data.  

        In the current implementation, one pass is made over all data of the descriptor.  

        Parameters
        ----------
        * `header` :  
            Whether the first line of data is a header describing the variable names.  
        * `n_discretization_bins` :  
            Discretization to apply to real variables:  

            *   A null value prescribes no discretization: plRealType is used.  
            *   A positive value prescribes a plDiscreteIntervalType with
                n_discretization_bins equal length bins  
            *   A negative value prescribes a plDiscreteIntervalType with
                -n_discretization_bins equal frequency bins  

        Returns
        -------
        A conjunction of variables suitable to describe the variables in the data
        descriptor.  

        """
        return _probt_python3.plStringDataDescriptor_guess_variables(self, header, n_discretization_bins)

plStringDataDescriptor_swigregister = _probt_python3.plStringDataDescriptor_swigregister
plStringDataDescriptor_swigregister(plStringDataDescriptor)

def _get_undef(var):
    import numpy
    if var.get_var_type() == PL_LABEL:
        return ''
    elif var.get_var_type() == PL_INTEGER:
        return plDataDescriptor.get_undef_int()
    else:
        return numpy.nan

def _get_val(var, values, index):
    vtype = var.get_var_type()
    if vtype == PL_LABEL:
        return values.get_value_as_label(index)#[1:-1]
    elif vtype == PL_INTEGER:
        return values.get_value_as_int(index)
    else:
        return values.get_value_as_double(index)

def _plDataDescriptor_as_python_list(data_descriptor):
    """Get the content of the data descriptor as a Python list.
    The list will contain '' (empty string) for missing Label values, plDataDescriptor.get_undef_int() for missing Integer values, 
    and NaN for missing float values
    Attention: This conversion is computationally expensive
    """
    data = []
    data_descriptor.rewind()
    vars = data_descriptor.observed_variables()
    while True:
        not_done, data_val, data_def, _ = data_descriptor.get_data_record()
        if not not_done: break
        d = []
        for c in range(data_val.size()):
            d.append( _get_val(vars[c], data_val, c) if data_def[c] else _get_undef(vars[c]) )
        data.append(d)
    data_descriptor.rewind()
    return data
plDataDescriptor.python_as_list = _plDataDescriptor_as_python_list

def _fill_numpy_array(data_descriptor, nparray):
    data_descriptor.rewind()
    r = 0
    vars = data_descriptor.observed_variables()
    while True:
        not_done, data_val, data_def, _ = data_descriptor.get_data_record()
        if not not_done: break
        for c in range(data_val.size()):
            if data_def[c]:
                nparray[r][c] = _get_val(vars[c], data_val, c)
            else:
                nparray[r][c] = _get_undef(vars[c])
        r+=1
    data_descriptor.rewind()

def _get_column_as_int(data_desc, col, undef_int):
    """Get a given column of the data descriptor as a int"""
    vals = LongIntVector()
    data_desc.get_column_values(col, vals, undef_int)
    return vals
plDataDescriptor.get_column_as_int = _get_column_as_int

def _get_column_as_float(data_desc, col):
    """Get a given column of the data descriptor as a float"""
    vals = DoubleVector()
    data_desc.get_column_values(col, vals)
    return vals
plDataDescriptor.get_column_as_float = _get_column_as_float

def _get_column_as_string(data_desc, col):
    """Get a given column of the data descriptor as a string"""
    vals = StringVector()
    data_desc.get_column_values(col, vals, '')
#return [l[1:-1] for l in vals]
    return [l for l in vals]
plDataDescriptor.get_column_as_string = _get_column_as_string

def _get_column(data_desc, col, variable, undef_int):
    """Get a given column of the data descriptor"""
    vtype = variable.get_var_type()
    if vtype == PL_LABEL:
        return _get_column_as_string(data_desc, col)
    if vtype == PL_INTEGER:
        return _get_column_as_int(data_desc, col, undef_int)
    return _get_column_as_float(data_desc, col)
plDataDescriptor.get_column = _get_column

def _plDataDescriptor_as_numpy_array(data_descriptor, dtype=None):
    """Get the content of the data descriptor as a Numpy array.
    If dtype is None, then the type is inferred automatically: 'int' when all the variables data_descriptor.observed_variables() are Integer,
    'float' when all the variables data_descriptor.observed_variables() are numeric,
    'S' when all variables are string (plLabelType), and Object ('O') when the variables are heterogenous (string and numeric)

    The array will contain '' (empty string) for missing Label values, plDataDescriptor.get_undef_int() for missing Integer values, 
    and NaN for missing float values
    Attention: This conversion is computationally expensive
    """
    import numpy as np
    undef_int = plDataDescriptor.get_undef_int()
    vars = data_descriptor.observed_variables()
    mytype = dtype
    if dtype is None:
        all_str = True
        all_int = True
        all_num = True
        max_str_size = 0

        for v in vars:
            if v.get_var_type() == PL_LABEL:
                all_num = False
                all_int = False
                s = plLabelType(v.get_type()).get_label_max_size()
                max_str_size = max(max_str_size, s)
            elif v.get_var_type() == PL_INTEGER:
                all_str = False
            else:
                all_int = False
                all_str = False

        if all_int:
            mytype = np.int_
        elif all_num:
            mytype = np.float_
        elif all_str:
            mytype = 'S'+str(max_str_size)
        else:
            mytype = 'O'

    np_array = np.empty( (data_descriptor.get_n_records(), data_descriptor.get_num_fields()), dtype=mytype)

    rvars = range(len(vars))
    if mytype is None or mytype == 'O':
        for i, v in enumerate(vars):
            np_array[:,i] = _get_column(data_descriptor, i, v, undef_int)
    elif mytype in [np.int_, int]:
        for i in rvars:
            np_array[:,i] = _get_column_as_int(data_descriptor, i, undef_int)
    elif mytype in [np.float_, float]:
        for i in rvars:
            np_array[:,i] = _get_column_as_float(data_descriptor, i)
    elif mytype == 'S' or all_str:
        for i in rvars:
            np_array[:,i] = _get_column_as_string(data_descriptor, i)
    else:
        raise ValueError('{} is not a supported type'.format(mytype))

    return np_array
plDataDescriptor.python_as_numpy_array = _plDataDescriptor_as_numpy_array

def _plDataDescriptor_as_numpy_recarray(data_descriptor, dtypes=None):
    """Get the content of the data descriptor as a Numpy recarray.
    The array will contain '' (empty string) for missing Label values, plDataDescriptor.get_undef_int() for missing Integer values, 
    and NaN for missing float values
    Attention: This conversion is computationally expensive
    """
    import numpy as np
    vars = data_descriptor.observed_variables()
    var_types = dtypes
    if var_types is None: 
        var_types = [ 'S'+str(plLabelType(v.get_type()).get_label_max_size()) 
                      if v.get_var_type() == PL_LABEL else np.int_ if v.get_var_type() == PL_INTEGER
                      else np.float_ for v in vars]
    if not isinstance(var_types, (list, tuple)): var_types = [var_types]*vars.size()
    np_array = np.recarray(data_descriptor.get_n_records(), list(zip(vars.get_names(), var_types)))
    _fill_numpy_array(data_descriptor, np_array)
    return np_array
plDataDescriptor.python_as_numpy_recarray = _plDataDescriptor_as_numpy_recarray

def _plDataDescriptor_as_pd_df(data_descriptor):
    """Get the content of the data descriptor as a Pandas dataframe
    The array will contain '' (empty string) for missing Label values, plDataDescriptor.get_undef_int() for missing Integer values, 
    and NaN for missing float values
    """
    import pandas
    df = pandas.DataFrame()
    variables = data_descriptor.observed_variables()
    names = variables.get_names()
    for i, var in enumerate(variables):
        df[names[i]] = _get_column(data_descriptor, i, var, plDataDescriptor.get_undef_int())
    return df      
plDataDescriptor.python_as_pandas_dataframe = _plDataDescriptor_as_pd_df


def plDataDescriptorFromPandasDF(pandas_data_frame, variables, use_data_cache = False, max_string_size = 100):
    """Create a plDataDescriptor from a Pandas dataframe
    """
    import numpy as np
    assert len(pandas_data_frame.values.shape) == 2
    recarray = pandas_data_frame.to_records(index=False)
    try:
        newt = [ ( str(k[0]), k[1].replace('O', 'S'+str(max_string_size))) for k in recarray.dtype.descr]
    except:
        newt = [ ( k[0].encode('utf-8'), k[1].replace('O', 'S'+str(max_string_size))) for k in recarray.dtype.descr]

    recarray = recarray.astype(newt, copy=False)

    return plNumPyDataDescriptor(recarray, variables, use_data_cache)

def plDataDescriptorFromNumpyArray(np_array, variables, use_data_cache = False):
    """Create a plDataDescriptor from a Numpy array
    """
    import numpy as np
    assert len(np_array.shape) == 2
    ncols = min(np_array.shape[1], variables.size())
    cols = [np_array[:,c] for c in range(ncols)]
    recarray = np.rec.fromarrays(cols,
                                 dtype=list(zip(variables.get_names(), [np_array.dtype]*ncols)))
    return plNumPyDataDescriptor(recarray, variables, use_data_cache)

def plDataDescriptorFromNumpyRecArray(np_recarray, variables, use_data_cache = False):
    """Create a plDataDescriptor from a Numpy recarray
    """
    return plNumPyDataDescriptor(np_recarray, variables, use_data_cache)

def plDataDescriptorFromPython(array, variables, use_data_cache = False):
    """Create a plDataDescriptor from a Python data array (Numpy, Pandas)
    This function calls plDataDescriptorFromPandasDF, plDataDescriptorFromNumpyArray,
    or  plDataDescriptorFromNumpyRecArray based on the type the parameter 'array'
    """
    import numpy as np
    import pandas as pd
    if isinstance(array, pd.DataFrame): return plDataDescriptorFromPandasDF(array, variables, use_data_cache)
    if isinstance(array, np.recarray): return plDataDescriptorFromNumpyRecArray(array, variables, use_data_cache)
    if isinstance(array, np.ndarray): return plDataDescriptorFromNumpyArray(array, variables, use_data_cache)
    raise ValueError('{} is not a supported type'.format(array))
plDataDescriptor.create_from_python_data = staticmethod(plDataDescriptorFromPython)

plDataDescriptor._repr_html_ = plDataDescriptor.head_html
plDataDescriptor.__len__ = plDataDescriptor.get_n_records

class plCSVDataDescriptor(plDataDescriptor, plStringDataDescriptor):
    """

    `plCSVDataDescriptor(std::string const &file, plVariablesConjunction const
        &variables=plVariablesConjunction(), bool cache_data=true, bool
        header_specifies_variables=true)`  
    `plCSVDataDescriptor(std::istream &input_stream, plVariablesConjunction const
        &variables, bool cache_data=true, bool header_specifies_variables=true)`  

    A data descriptor for data in CSV (comma-separated values) format.  

    It can parse the data from a file or a file descriptor. It is slower than
    plCSVFileDataDescriptor. However, it is safer (it will detect and report parse
    errors), and may be easier to use:  

    *   by default, it allows several common CSV syntaxes  
    *   it allows to specify the variables and order of the columns inside the file  
    *   it allows using an input stream instead of a file.  

    It is based on RFC 4180: http://tools.ietf.org/html/rfc4180, with the following
    extensions:  

    *   records are ended/separated by either CR, LF, CRLF, or any sequence of mixed
        CR and LF  
    *   empty lines are skipped  
    *   leading and trailing spaces and tabulations around a quoted field are
        ignored  
    *   each field can be quoted with either " (double quote) or ' (single quote)
        (customisable using set_quotes())  
    *   fields can be separated with either , (comma) or ; (semicolon) (customisable
        using set_field_separators())  
    *   an empty field is considered undefined  
    *   additionally, a field equal to " " (one space) is also considered
        undefined (customisable using set_undefined_field()).  

    Constructors
    ------------
    * `plCSVDataDescriptor(std::string const &file, plVariablesConjunction const
        &variables=plVariablesConjunction(), bool cache_data=true, bool
        header_specifies_variables=true)`  

        Constructs a CSV data descriptor over a file containing CSV data.  

        Parameters:  
        * `file` :  
            The name of the file containing the CSV data. The file must exist and be
            readable.  
        * `variables` :  
            A conjunction describing the variables described in the file.  

            *   If header_specifies_variables is false, this should be the exact
                ordered list of variables present in the file. get_data_record()
                will return values for all these variables.  
            *   If header_specifies_variables is true, by default, this should be a
                superset of the variables announced in the file header.
                get_data_record() will return values for the variables present in
                the file header.  
            *   If header_specifies_variables is true and you called
                ignore_unknown_variables(), get_data_record() will return values for
                variables that are both in this parameter and in the file header
                (that is to say, the intersection of these two sets).  
        * `cache_data` :  
            Whether this descriptor should cache the data, in order to avoid parsing
            after the first rewind(). If memory allows it, this provides a
            significant speed boost when several passes are made over the data.  
        * `header_specifies_variables` :  
            Whether the first line of the file contains a header listing the names
            of the variables present in the file (in order). This header allows
            having superfluous values in the CSV data, and reordering the variables
            in the data.  

    * `plCSVDataDescriptor(std::istream &input_stream, plVariablesConjunction const
        &variables, bool cache_data=true, bool header_specifies_variables=true)`  

        Constructs a CSV data descriptor over an input stream containing CSV data.  

        Parameters:  
        * `input_stream` :  
            The input stream containing the CSV data.  
        * `variables` :  
            A conjunction containing a superset of the variables described in the
            stream. All variables in this conjunction must have different names. If
            header_specifies_variables is false, this must correspond exactly to the
            variables specified in the CSV data.  
        * `cache_data` :  
            Whether this descriptor should cache the data, in order to avoid parsing
            after the first rewind(). If memory allows it, this provides a
            significant speed boost when several passes are made over the data.  
        * `header_specifies_variables` :  
            Whether the first line of the file contains a header listing the names
            of the variables present in the file (in order). This header allows
            having superfluous values in the CSV data, and reordering the variables
            in the data.  

    C++ includes: plCSVDataDescriptor.h

    """

    __swig_setmethods__ = {}
    for _s in [plDataDescriptor, plStringDataDescriptor]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plCSVDataDescriptor, name, value)
    __swig_getmethods__ = {}
    for _s in [plDataDescriptor, plStringDataDescriptor]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plCSVDataDescriptor, name)
    __repr__ = _swig_repr

    def __init__(self, *args):
        """
        __init__(self, file, variables, cache_data=True, header_specifies_variables=True) -> plCSVDataDescriptor
        __init__(self, file, variables, cache_data=True) -> plCSVDataDescriptor
        __init__(self, file, variables) -> plCSVDataDescriptor
        __init__(self, file) -> plCSVDataDescriptor
        __init__(self, input_stream, variables, cache_data=True, header_specifies_variables=True) -> plCSVDataDescriptor
        __init__(self, input_stream, variables, cache_data=True) -> plCSVDataDescriptor
        __init__(self, input_stream, variables) -> plCSVDataDescriptor


        `plCSVDataDescriptor(std::string const &file, plVariablesConjunction const
            &variables=plVariablesConjunction(), bool cache_data=true, bool
            header_specifies_variables=true)`  
        `plCSVDataDescriptor(std::istream &input_stream, plVariablesConjunction const
            &variables, bool cache_data=true, bool header_specifies_variables=true)`  

        Overloaded function
        -------------------
        * `plCSVDataDescriptor(std::string const &file, plVariablesConjunction const
            &variables=plVariablesConjunction(), bool cache_data=true, bool
            header_specifies_variables=true)`  

            Constructs a CSV data descriptor over a file containing CSV data.  

            Parameters:  
            * `file` :  
                The name of the file containing the CSV data. The file must exist and be
                readable.  
            * `variables` :  
                A conjunction describing the variables described in the file.  

                *   If header_specifies_variables is false, this should be the exact
                    ordered list of variables present in the file. get_data_record()
                    will return values for all these variables.  
                *   If header_specifies_variables is true, by default, this should be a
                    superset of the variables announced in the file header.
                    get_data_record() will return values for the variables present in
                    the file header.  
                *   If header_specifies_variables is true and you called
                    ignore_unknown_variables(), get_data_record() will return values for
                    variables that are both in this parameter and in the file header
                    (that is to say, the intersection of these two sets).  
            * `cache_data` :  
                Whether this descriptor should cache the data, in order to avoid parsing
                after the first rewind(). If memory allows it, this provides a
                significant speed boost when several passes are made over the data.  
            * `header_specifies_variables` :  
                Whether the first line of the file contains a header listing the names
                of the variables present in the file (in order). This header allows
                having superfluous values in the CSV data, and reordering the variables
                in the data.  

        * `plCSVDataDescriptor(std::istream &input_stream, plVariablesConjunction const
            &variables, bool cache_data=true, bool header_specifies_variables=true)`  

            Constructs a CSV data descriptor over an input stream containing CSV data.  

            Parameters:  
            * `input_stream` :  
                The input stream containing the CSV data.  
            * `variables` :  
                A conjunction containing a superset of the variables described in the
                stream. All variables in this conjunction must have different names. If
                header_specifies_variables is false, this must correspond exactly to the
                variables specified in the CSV data.  
            * `cache_data` :  
                Whether this descriptor should cache the data, in order to avoid parsing
                after the first rewind(). If memory allows it, this provides a
                significant speed boost when several passes are made over the data.  
            * `header_specifies_variables` :  
                Whether the first line of the file contains a header listing the names
                of the variables present in the file (in order). This header allows
                having superfluous values in the CSV data, and reordering the variables
                in the data.  

        """
        this = _probt_python3.new_plCSVDataDescriptor(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def set_field_separators(self, field_separators: 'std::string const &') -> "void":
        """
        set_field_separators(self, field_separators)


        `set_field_separators(std::string const &field_separators)`  

        Sets the field separators allowed in the CSV data.  

        Any character of the passed string will be accepted as a field separator. Note
        that a field separator cannot be made of several consecutive characters.  

        The default value is ",;".  

        """
        return _probt_python3.plCSVDataDescriptor_set_field_separators(self, field_separators)


    def set_quotes(self, quotes: 'std::string const &') -> "void":
        """
        set_quotes(self, quotes)


        `set_quotes(std::string const &quotes)`  

        Sets the quotes allowed in the CSV data.  

        Any character of the passed string will be accepted as a quoting character. Note
        that there is no way to use different starting and ending characters for a
        quote, or a multi-character quote.  

        The default value is "\"'": single and double quotes.  

        """
        return _probt_python3.plCSVDataDescriptor_set_quotes(self, quotes)


    def set_undefined_field(self, undefined_field: 'std::string const &') -> "void":
        """
        set_undefined_field(self, undefined_field)


        `set_undefined_field(std::string const &undefined_field)`  

        Sets the value that will correspond to an undefined field in the CSV data.  

        Note that there is no way to specify several possible values for an undefined
        field.  

        In addition to this value, an empty field always corresponds to an undefined
        field.  

        The default value is " ": a string of exactly one space.  

        """
        return _probt_python3.plCSVDataDescriptor_set_undefined_field(self, undefined_field)


    def ignore_unknown_variables(self, ignore: 'bool'=True) -> "void":
        """
        ignore_unknown_variables(self, ignore=True)
        ignore_unknown_variables(self)


        `ignore_unknown_variables(bool ignore=true)`  

        When there is a header describing the file variables (header_specifies_variables
        = true), this lets the parser ignore the unknown variables and their
        corresponding data columns.  

        The "known" variables are those that were passed to the constructor.  

        By default, unknown variables trigger an exception when parsing the header.  

        When the file header is not used (header_specifies_variables = false), this has
        no effect.  

        Calling this method once the file header has already been parsed has no effect.  

        """
        return _probt_python3.plCSVDataDescriptor_ignore_unknown_variables(self, ignore)

    __swig_destroy__ = _probt_python3.delete_plCSVDataDescriptor
    __del__ = lambda self: None

    def get_num_fields(self) -> "unsigned int":
        """
        get_num_fields(self) -> unsigned int


        `get_num_fields() const -> unsigned int`  

        Returns the number of fields in the CSV data.  

        """
        return _probt_python3.plCSVDataDescriptor_get_num_fields(self)


    def observed_variables(self) -> "plVariablesConjunction":
        """
        observed_variables(self) -> plVariablesConjunction


        `observed_variables() -> plVariablesConjunction`  

        Returns the variables actually present in the CSV file or stream, in order.  

        If header_specifies_variables was false at construction time, this returns the
        variables passed to the constructor.  

        If header_specifies_variables was true at construction, this corresponds to the
        data header. Therefore, this triggers parsing of the file or stream. In this
        case, you should make sure to call set_quotes(), set_field_separators(),
        set_undefined_field() or ignore_unknown_variables() (if necessary) before
        calling this method.  

        """
        return _probt_python3.plCSVDataDescriptor_observed_variables(self)


    def get_data_record(self, *args) -> "bool":
        """
        get_data_record(self) -> bool
        get_data_record(self, data_values) -> bool


        `get_data_record(plValues const *&data_values, const std::vector< bool >
            *&data_definition, plFloat &weight) -> bool`  
        `get_data_record(std::vector< std::string > &data_values) -> bool`  

        Overloaded function
        -------------------
        * `get_data_record(plValues const *&data_values, const std::vector< bool >
            *&data_definition, plFloat &weight) -> bool`  

            Get the next data record (row) and advances by one record in the data.  

            Parameters:  
            * `data_values` :  
                an array of values for all variables described in the record.  
            * `data_definition` :  
                a vector stating, for each value in *data_values*, whether it's defined
                or not.  
            * `weight` :  
                the weight of the record  

            Returns:
            *false* iif the end of the container is reached.  

            The returned pointers are managed internally: you should not attempt to
            delete them, or use them after another call to get_data_record(). Also, you
            should not use them when get_data_record() returns *false*.  

            For Python, the signature of this function is changed to return its results.
            It can be used as follows:  

                data_decriptor = ...
                not_done, data_values, data_definition, w =
            data_decriptor.get_data_record()


        * `get_data_record(std::vector< std::string > &data_values) -> bool`  

            Returns the raw, uninterpreted data record as a vector of strings.  

            Parameters:  
            * `data_values` :  
                Record element, resized as needed and filled in by this method.  

            Returns:
            false iff the end of the container is reached.  

            This method consumes one line of CSV input.  

            This method triggers parsing of the file or stream. Therefore, you should
            make sure to call set_quotes() or set_field_separators() (if necessary)
            before calling this method. Methods set_undefined_field() and
            ignore_unknown_variables() have no effect on what this methods returns.  

            Warning: when the cache is enabled, there are important rules to follow to
            avoid losing data:  

            *   after calling this method, you should always call rewind() before
                calling get_data_record(plValues const * & data_values, data_definition,
                weight)  
            *   once you have called get_data_record(plValues const * & data_values,
                data_definition) once, you should not call this method anymore, even
                after doing a rewind().  

            There are no such restrictions when the descriptor's cache is disabled.  

        """
        return _probt_python3.plCSVDataDescriptor_get_data_record(self, *args)


    def rewind(self) -> "void":
        """
        rewind(self)


        `rewind()`  

        Rewinds the descriptor, by making it restart from the beginning of the data.  

        This is always possible for a descriptor attached to a file. For a descriptor
        attached to a stream, this will work if the descriptor is cached; if it is not
        cached, an error will be raised (since there is no way to rewind an input
        stream).  

        """
        return _probt_python3.plCSVDataDescriptor_rewind(self)


    def guess_variables(*args) -> "plVariablesConjunction":
        """
        guess_variables(header, n_discretization_bins=0) -> plVariablesConjunction
        guess_variables(header) -> plVariablesConjunction
        guess_variables(csv_file, header=True, n_discretization_bins=0, undef_string, field_separators) -> plVariablesConjunction
        guess_variables(csv_file, header=True, n_discretization_bins=0, undef_string) -> plVariablesConjunction
        guess_variables(csv_file, header=True, n_discretization_bins=0) -> plVariablesConjunction
        guess_variables(csv_file, header=True) -> plVariablesConjunction
        guess_variables(csv_file) -> plVariablesConjunction


        `guess_variables(std::string const &csv_file, bool header=true, int
            n_discretization_bins=0, std::string const &undef_string="", std::string
            const &field_separators="\, ") -> plVariablesConjunction`  

        Tries to guess the variables described in a CSV file, by parsing it.  

        Parameters
        ----------
        * `csv_file` :  
            Name of the CSV file.  
        * `header` :  
            Whether the CSV file contains a header describing the variable names.  
        * `n_discretization_bins` :  
            Discretization to apply to real variables:  

            *   A null value prescribes no discretization: plRealType is used.  
            *   A positive value prescribes a plDiscreteIntervalType with
                n_discretization_bins equal length bins  
            *   A negative value prescribes a plDiscreteIntervalType with
                -n_discretization_bins equal frequency bins  
        * `undef_string` :  
            The string to be used for undefined fields  
        * `field_separators` :  
            Field separators allowed in the CSV data. Any character of the passed string
            will be accepted as a field separator. Note that a field separator cannot be
            made of several consecutive characters.  

        Returns
        -------
        A conjunction of variables corresponding to the variables in the CSV file.  

        """
        return _probt_python3.plCSVDataDescriptor_guess_variables(*args)

    guess_variables = staticmethod(guess_variables)
plCSVDataDescriptor_swigregister = _probt_python3.plCSVDataDescriptor_swigregister
plCSVDataDescriptor_swigregister(plCSVDataDescriptor)

def plCSVDataDescriptor_guess_variables(*args) -> "plVariablesConjunction":
    """
    guess_variables(header, n_discretization_bins=0) -> plVariablesConjunction
    guess_variables(header) -> plVariablesConjunction
    guess_variables(csv_file, header=True, n_discretization_bins=0, undef_string, field_separators) -> plVariablesConjunction
    guess_variables(csv_file, header=True, n_discretization_bins=0, undef_string) -> plVariablesConjunction
    guess_variables(csv_file, header=True, n_discretization_bins=0) -> plVariablesConjunction
    guess_variables(csv_file, header=True) -> plVariablesConjunction
    plCSVDataDescriptor_guess_variables(csv_file) -> plVariablesConjunction


    `guess_variables(std::string const &csv_file, bool header=true, int
        n_discretization_bins=0, std::string const &undef_string="", std::string
        const &field_separators="\, ") -> plVariablesConjunction`  

    Tries to guess the variables described in a CSV file, by parsing it.  

    Parameters
    ----------
    * `csv_file` :  
        Name of the CSV file.  
    * `header` :  
        Whether the CSV file contains a header describing the variable names.  
    * `n_discretization_bins` :  
        Discretization to apply to real variables:  

        *   A null value prescribes no discretization: plRealType is used.  
        *   A positive value prescribes a plDiscreteIntervalType with
            n_discretization_bins equal length bins  
        *   A negative value prescribes a plDiscreteIntervalType with
            -n_discretization_bins equal frequency bins  
    * `undef_string` :  
        The string to be used for undefined fields  
    * `field_separators` :  
        Field separators allowed in the CSV data. Any character of the passed string
        will be accepted as a field separator. Note that a field separator cannot be
        made of several consecutive characters.  

    Returns
    -------
    A conjunction of variables corresponding to the variables in the CSV file.  

    """
    return _probt_python3.plCSVDataDescriptor_guess_variables(*args)

class plCSVFileDataDescriptor(plDataDescriptor):
    """

    `plCSVFileDataDescriptor(const std::string &file_name, const
        plVariablesConjunction &variables, bool cache_data=true, char
        field_delimiter=0, char line_delimiter='\n', const std::string
        &undefined_field="", char quote='"')`  
    `plCSVFileDataDescriptor(const std::string &file_name, unsigned int
        num_fields=0, bool cache_data=true, unsigned int ignore_lines=0, char
        field_delimiter=0, char line_delimiter='\n', const std::string
        &undefined_field="", const std::vector< unsigned int >
        &columns_to_ignore=std::vector< unsigned int >(), char quote='"')`  

    A data descriptor for data in CSV (comma-separated values) format.  

    It can parse the data from a file :  

    *   it allows to specify the variables and order of the columns inside the file  
    *   it allows parsing numeric fields (for non-label variable types) and textual
        fields (for label variable types)  
    *   it allows caching the data if several passes are needed and if the memory
        allows it  
    *   empty lines are skipped  
    *   leading and trailing spaces and tabulations around a quoted field are
        ignored  
    *   each field can be quoted. The used quote (" by default) is customisable in
        the constructor or using set_quote())  
    *   records (lines) are ended/separated by a line delimiter (its default value
        is '\n' and is customisable in the constructor or using
        set_line_delimiter())  
    *   fields are separated with a field delimiter (its default value is set
        automatically among ';' ',' , ' ', '\t' and is customisable in the
        constructor or using set_field_delimiter())  
    *   an empty field is considered undefined additionally, a field equal to
        undefined_field (its default value is 'empty string' and is customisable in
        the constructor or using set_undefined_field()).  

    Constructors
    ------------
    * `plCSVFileDataDescriptor(const std::string &file_name, const
        plVariablesConjunction &variables, bool cache_data=true, char
        field_delimiter=0, char line_delimiter='\n', const std::string
        &undefined_field="", char quote='"')`  

        Constructs a CSV data descriptor over a file containing CSV data.  

        Parameters:  
        * `file_name` :  
            The name of the file containing the CSV data. The file must exist and be
            readable.  
        * `variables` :  
            A conjunction describing the variables present in the file. This should
            be a superset of the variables announced in the file header if any. The
            other variables announced in the file header and that are not present is
            this parameter are simply ignored. This means that observed_variables()
            (and also the values returned by get_data_record() ) will return
            variables that are both in this parameter and in the file header (that
            is to say, the intersection of these two sets) but in the order
            specified by the variables announced in the file header. The special
            case corresponding to a file with no header is assumed if the
            intersection is empty. This means that observed_variables() (and also
            the values returned by get_data_record() ) will return all the variables
            in this parameter at the same order (see the example at the end of this
            documentation).  
        * `cache_data` :  
            Whether this descriptor should cache the data, in order to avoid parsing
            after the first rewind(). Its default values is 'true'. If memory allows
            it, this provides a significant speed boost when several passes are made
            over the data. ATTENTION: If cache_data is set to 'true', all the
            following parsing parameters are ignored if they are set after the first
            utilization of the descriptor.  
        * `field_delimiter` :  
            the field separator used in the CSV data. It's default value is set
            automatically among ';' ',' , ' ', '\t' and is customisable in the
            constructor or using set_field_delimiter().  
        * `line_delimiter` :  
            The line separator used in the CSV data. It's default value is '\n' and
            it can be set later using set_line_delimiter().  
        * `undefined_field` :  
            The value that will correspond to an undefined field in the CSV data.
            Its default value is "" (empty string) and it can be set later using
            set_undefined_field(). In addition to this value, an empty field always
            corresponds to an undefined field.  
        * `quote` :  
            The character to be used for quoting text fields. The default is " and
            it can be set later using set_quote().  

        Example: Let's consider the following file content:  

            "COLOR";"X";"A"
            BLUE;1.3;0
            RED;3.1;1
         and the 'variables' parameter having 4 variables with names 'A', 'COLOR',
        'B', 'C'. In this case, observed_variables() will return {COLOR, A} and the
        first data record will be {COLOR=BLUE, A=0}.  

    * `plCSVFileDataDescriptor(const std::string &file_name, unsigned int
        num_fields=0, bool cache_data=true, unsigned int ignore_lines=0, char
        field_delimiter=0, char line_delimiter='\n', const std::string
        &undefined_field="", const std::vector< unsigned int >
        &columns_to_ignore=std::vector< unsigned int >(), char quote='"')`  

        Constructs a CSV data descriptor over a file containing CSV data without
        associating it to a set of variables.  

        The actual association to a set of variables could be done later by calling
        set_variables(). If the association is not done (no call to set_variables())
        then only numeric fields are allowed (no textual fields) and textual fields
        will be considered as undefined ones.  

        Parameters:  
        * `file_name` :  
            The name of the file containing the CSV data. The file must exist and be
            readable.  
        * `num_fields` :  
            The number of columns (fields) to be read. If 0 (the default value), the
            file will be parsed in order to guess its number of columns.  
        * `cache_data` :  
            Whether this descriptor should cache the data, in order to avoid parsing
            after the first rewind(). Its default values is 'true'. If memory allows
            it, this provides a significant speed boost when several passes are made
            over the data. ATTENTION: If cache_data is set to 'true', all the
            following parsing parameters are ignored if they are set after the first
            utilization of the descriptor.  
        * `ignore_lines` :  
            The number of header lines to be ignored. Its default value is 0 and it
            can be set later using set_ignore_lines().  
        * `field_delimiter` :  
            the field separator used in the CSV data. It's default value is set
            automatically among ';' ',' , ' ', '\t' and is customisable in the
            constructor or using set_field_delimiter().  
        * `line_delimiter` :  
            The line separator used in the CSV data. It's default value is '\n' and
            it can be set later using set_line_delimiter().  
        * `undefined_field` :  
            The value that will correspond to an undefined field in the CSV data.
            Its default value is "" (empty string) and it can be set later using
            set_undefined_field(). In addition to this value, an empty field always
            corresponds to an undefined field.  
        * `columns_to_ignore` :  
            The indices (starting from 0) of the columns (fields) to be ignored in
            the file. The default value is 'empty' (no columns to ignore) and it can
            be set later using set_columns_to_ignore().  
        * `quote` :  
            The character to be used for quoting text fields. The default is " and
            it can be set later using set_quote().  

    C++ includes: plCSVFileDataDescriptor.h

    """

    __swig_setmethods__ = {}
    for _s in [plDataDescriptor]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plCSVFileDataDescriptor, name, value)
    __swig_getmethods__ = {}
    for _s in [plDataDescriptor]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plCSVFileDataDescriptor, name)
    __repr__ = _swig_repr

    def __init__(self, *args):
        """
        __init__(self, file_name, variables, cache_data=True, field_delimiter=0, line_delimiter, undefined_field, quote) -> plCSVFileDataDescriptor
        __init__(self, file_name, variables, cache_data=True, field_delimiter=0, line_delimiter, undefined_field) -> plCSVFileDataDescriptor
        __init__(self, file_name, variables, cache_data=True, field_delimiter=0, line_delimiter) -> plCSVFileDataDescriptor
        __init__(self, file_name, variables, cache_data=True, field_delimiter=0) -> plCSVFileDataDescriptor
        __init__(self, file_name, variables, cache_data=True) -> plCSVFileDataDescriptor
        __init__(self, file_name, variables) -> plCSVFileDataDescriptor
        __init__(self, file_name, num_fields=0, cache_data=True, ignore_lines=0, field_delimiter=0, line_delimiter, undefined_field, columns_to_ignore, quote) -> plCSVFileDataDescriptor
        __init__(self, file_name, num_fields=0, cache_data=True, ignore_lines=0, field_delimiter=0, line_delimiter, undefined_field, columns_to_ignore) -> plCSVFileDataDescriptor
        __init__(self, file_name, num_fields=0, cache_data=True, ignore_lines=0, field_delimiter=0, line_delimiter, undefined_field) -> plCSVFileDataDescriptor
        __init__(self, file_name, num_fields=0, cache_data=True, ignore_lines=0, field_delimiter=0, line_delimiter) -> plCSVFileDataDescriptor
        __init__(self, file_name, num_fields=0, cache_data=True, ignore_lines=0, field_delimiter=0) -> plCSVFileDataDescriptor
        __init__(self, file_name, num_fields=0, cache_data=True, ignore_lines=0) -> plCSVFileDataDescriptor
        __init__(self, file_name, num_fields=0, cache_data=True) -> plCSVFileDataDescriptor
        __init__(self, file_name, num_fields=0) -> plCSVFileDataDescriptor
        __init__(self, file_name) -> plCSVFileDataDescriptor


        `plCSVFileDataDescriptor(const std::string &file_name, const
            plVariablesConjunction &variables, bool cache_data=true, char
            field_delimiter=0, char line_delimiter='\n', const std::string
            &undefined_field="", char quote='"')`  
        `plCSVFileDataDescriptor(const std::string &file_name, unsigned int
            num_fields=0, bool cache_data=true, unsigned int ignore_lines=0, char
            field_delimiter=0, char line_delimiter='\n', const std::string
            &undefined_field="", const std::vector< unsigned int >
            &columns_to_ignore=std::vector< unsigned int >(), char quote='"')`  

        Overloaded function
        -------------------
        * `plCSVFileDataDescriptor(const std::string &file_name, const
            plVariablesConjunction &variables, bool cache_data=true, char
            field_delimiter=0, char line_delimiter='\n', const std::string
            &undefined_field="", char quote='"')`  

            Constructs a CSV data descriptor over a file containing CSV data.  

            Parameters:  
            * `file_name` :  
                The name of the file containing the CSV data. The file must exist and be
                readable.  
            * `variables` :  
                A conjunction describing the variables present in the file. This should
                be a superset of the variables announced in the file header if any. The
                other variables announced in the file header and that are not present is
                this parameter are simply ignored. This means that observed_variables()
                (and also the values returned by get_data_record() ) will return
                variables that are both in this parameter and in the file header (that
                is to say, the intersection of these two sets) but in the order
                specified by the variables announced in the file header. The special
                case corresponding to a file with no header is assumed if the
                intersection is empty. This means that observed_variables() (and also
                the values returned by get_data_record() ) will return all the variables
                in this parameter at the same order (see the example at the end of this
                documentation).  
            * `cache_data` :  
                Whether this descriptor should cache the data, in order to avoid parsing
                after the first rewind(). Its default values is 'true'. If memory allows
                it, this provides a significant speed boost when several passes are made
                over the data. ATTENTION: If cache_data is set to 'true', all the
                following parsing parameters are ignored if they are set after the first
                utilization of the descriptor.  
            * `field_delimiter` :  
                the field separator used in the CSV data. It's default value is set
                automatically among ';' ',' , ' ', '\t' and is customisable in the
                constructor or using set_field_delimiter().  
            * `line_delimiter` :  
                The line separator used in the CSV data. It's default value is '\n' and
                it can be set later using set_line_delimiter().  
            * `undefined_field` :  
                The value that will correspond to an undefined field in the CSV data.
                Its default value is "" (empty string) and it can be set later using
                set_undefined_field(). In addition to this value, an empty field always
                corresponds to an undefined field.  
            * `quote` :  
                The character to be used for quoting text fields. The default is " and
                it can be set later using set_quote().  

            Example: Let's consider the following file content:  

                "COLOR";"X";"A"
                BLUE;1.3;0
                RED;3.1;1
             and the 'variables' parameter having 4 variables with names 'A', 'COLOR',
            'B', 'C'. In this case, observed_variables() will return {COLOR, A} and the
            first data record will be {COLOR=BLUE, A=0}.  

        * `plCSVFileDataDescriptor(const std::string &file_name, unsigned int
            num_fields=0, bool cache_data=true, unsigned int ignore_lines=0, char
            field_delimiter=0, char line_delimiter='\n', const std::string
            &undefined_field="", const std::vector< unsigned int >
            &columns_to_ignore=std::vector< unsigned int >(), char quote='"')`  

            Constructs a CSV data descriptor over a file containing CSV data without
            associating it to a set of variables.  

            The actual association to a set of variables could be done later by calling
            set_variables(). If the association is not done (no call to set_variables())
            then only numeric fields are allowed (no textual fields) and textual fields
            will be considered as undefined ones.  

            Parameters:  
            * `file_name` :  
                The name of the file containing the CSV data. The file must exist and be
                readable.  
            * `num_fields` :  
                The number of columns (fields) to be read. If 0 (the default value), the
                file will be parsed in order to guess its number of columns.  
            * `cache_data` :  
                Whether this descriptor should cache the data, in order to avoid parsing
                after the first rewind(). Its default values is 'true'. If memory allows
                it, this provides a significant speed boost when several passes are made
                over the data. ATTENTION: If cache_data is set to 'true', all the
                following parsing parameters are ignored if they are set after the first
                utilization of the descriptor.  
            * `ignore_lines` :  
                The number of header lines to be ignored. Its default value is 0 and it
                can be set later using set_ignore_lines().  
            * `field_delimiter` :  
                the field separator used in the CSV data. It's default value is set
                automatically among ';' ',' , ' ', '\t' and is customisable in the
                constructor or using set_field_delimiter().  
            * `line_delimiter` :  
                The line separator used in the CSV data. It's default value is '\n' and
                it can be set later using set_line_delimiter().  
            * `undefined_field` :  
                The value that will correspond to an undefined field in the CSV data.
                Its default value is "" (empty string) and it can be set later using
                set_undefined_field(). In addition to this value, an empty field always
                corresponds to an undefined field.  
            * `columns_to_ignore` :  
                The indices (starting from 0) of the columns (fields) to be ignored in
                the file. The default value is 'empty' (no columns to ignore) and it can
                be set later using set_columns_to_ignore().  
            * `quote` :  
                The character to be used for quoting text fields. The default is " and
                it can be set later using set_quote().  

        """
        this = _probt_python3.new_plCSVFileDataDescriptor(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this
    __swig_destroy__ = _probt_python3.delete_plCSVFileDataDescriptor
    __del__ = lambda self: None

    def guess_field_delimiter(*args) -> "char":
        """
        guess_field_delimiter(file_name, delimiters, nrows=10) -> char
        guess_field_delimiter(file_name, delimiters) -> char
        guess_field_delimiter(file_name) -> char


        `guess_field_delimiter(const std::string &file_name, const std::string
            &delimiters=";, \, size_t nrows=10) -> char`  

        Guess the field delimiter among the passed ones based on statistics on the
        'nrows' first lines of the file.  

        Return 0 if no delimiter is found (one-column file)  

        """
        return _probt_python3.plCSVFileDataDescriptor_guess_field_delimiter(*args)

    guess_field_delimiter = staticmethod(guess_field_delimiter)

    def guess_number_of_fields(file_name: 'std::string const &') -> "unsigned int":
        """
        guess_number_of_fields(file_name) -> unsigned int


        `guess_number_of_fields(const std::string &file_name) -> unsigned int`  

        Guess the field of fields among of the file.  

        """
        return _probt_python3.plCSVFileDataDescriptor_guess_number_of_fields(file_name)

    guess_number_of_fields = staticmethod(guess_number_of_fields)

    def rewind(self) -> "void":
        """
        rewind(self)


        `rewind()`  

        Rewinds the container to go back to its beginning.  

        """
        return _probt_python3.plCSVFileDataDescriptor_rewind(self)


    def load_data_matrix(*args) -> "void":
        """
        load_data_matrix(csv_file_name, data_matrix, undef_value, columns_to_ignore, ignore_lines=0, n, sampling_rate=1.0)
        load_data_matrix(csv_file_name, data_matrix, undef_value, columns_to_ignore, ignore_lines=0, n)
        load_data_matrix(csv_file_name, data_matrix, undef_value, columns_to_ignore, ignore_lines=0)
        load_data_matrix(csv_file_name, data_matrix, undef_value, columns_to_ignore)
        load_data_matrix(csv_file_name, data_matrix, undef_value)
        load_data_matrix(csv_file_name, data_matrix)
        load_data_matrix(csv_file_name, data_matrix, undef_value, columns_to_ignore, ignore_lines=0, n, sampling_rate=1.0)
        load_data_matrix(csv_file_name, data_matrix, undef_value, columns_to_ignore, ignore_lines=0, n)
        load_data_matrix(csv_file_name, data_matrix, undef_value, columns_to_ignore, ignore_lines=0)
        load_data_matrix(csv_file_name, data_matrix, undef_value, columns_to_ignore)
        load_data_matrix(csv_file_name, data_matrix, undef_value)
        load_data_matrix(csv_file_name, data_matrix)
        load_data_matrix(csv_file_name, data_matrix, undef_value, columns_to_ignore, ignore_lines=0, n, sampling_rate=1.0)
        load_data_matrix(csv_file_name, data_matrix, undef_value, columns_to_ignore, ignore_lines=0, n)
        load_data_matrix(csv_file_name, data_matrix, undef_value, columns_to_ignore, ignore_lines=0)
        load_data_matrix(csv_file_name, data_matrix, undef_value, columns_to_ignore)
        load_data_matrix(csv_file_name, data_matrix, undef_value)
        load_data_matrix(csv_file_name, data_matrix)
        load_data_matrix(csv_file_name, data_matrix, undef_value, columns_to_ignore, ignore_lines=0, n, sampling_rate=1.0)
        load_data_matrix(csv_file_name, data_matrix, undef_value, columns_to_ignore, ignore_lines=0, n)
        load_data_matrix(csv_file_name, data_matrix, undef_value, columns_to_ignore, ignore_lines=0)
        load_data_matrix(csv_file_name, data_matrix, undef_value, columns_to_ignore)
        load_data_matrix(csv_file_name, data_matrix, undef_value)


        `load_data_matrix(const std::string &csv_file_name, std::vector< std::vector<
            double > > &data_matrix, double undef_value=NAN, const std::vector< unsigned
            int > &columns_to_ignore=std::vector< unsigned int >(), unsigned int
            ignore_lines=0, unsigned int n=std::numeric_limits< unsigned int >::max(),
            plFloat sampling_rate=PL_ONE)`  
        `load_data_matrix(const std::string &csv_file_name, std::vector< std::vector<
            float > > &data_matrix, float undef_value=NAN, const std::vector< unsigned
            int > &columns_to_ignore=std::vector< unsigned int >(), unsigned int
            ignore_lines=0, unsigned int n=std::numeric_limits< unsigned int >::max(),
            plFloat sampling_rate=PL_ONE)`  
        `load_data_matrix(const std::string &csv_file_name, std::vector< std::vector<
            long double > > &data_matrix, long double undef_value=NAN, const
            std::vector< unsigned int > &columns_to_ignore=std::vector< unsigned int
            >(), unsigned int ignore_lines=0, unsigned int n=std::numeric_limits<
            unsigned int >::max(), plFloat sampling_rate=PL_ONE)`  
        `load_data_matrix(const std::string &csv_file_name, std::vector< std::vector<
            int > > &data_matrix, int undef_value, const std::vector< unsigned int >
            &columns_to_ignore=std::vector< unsigned int >(), unsigned int
            ignore_lines=0, unsigned int n=std::numeric_limits< unsigned int >::max(),
            plFloat sampling_rate=PL_ONE)`  

        Overloaded function
        -------------------
        * `load_data_matrix(const std::string &csv_file_name, std::vector< std::vector<
            double > > &data_matrix, double undef_value=NAN, const std::vector< unsigned
            int > &columns_to_ignore=std::vector< unsigned int >(), unsigned int
            ignore_lines=0, unsigned int n=std::numeric_limits< unsigned int >::max(),
            plFloat sampling_rate=PL_ONE)`  

            Load a csv file into a data matrix.  

        * `load_data_matrix(const std::string &csv_file_name, std::vector< std::vector<
            float > > &data_matrix, float undef_value=NAN, const std::vector< unsigned
            int > &columns_to_ignore=std::vector< unsigned int >(), unsigned int
            ignore_lines=0, unsigned int n=std::numeric_limits< unsigned int >::max(),
            plFloat sampling_rate=PL_ONE)`  

            Load a csv file into a data matrix.  

        * `load_data_matrix(const std::string &csv_file_name, std::vector< std::vector<
            long double > > &data_matrix, long double undef_value=NAN, const
            std::vector< unsigned int > &columns_to_ignore=std::vector< unsigned int
            >(), unsigned int ignore_lines=0, unsigned int n=std::numeric_limits<
            unsigned int >::max(), plFloat sampling_rate=PL_ONE)`  

            Load a csv file into a data matrix.  

        * `load_data_matrix(const std::string &csv_file_name, std::vector< std::vector<
            int > > &data_matrix, int undef_value, const std::vector< unsigned int >
            &columns_to_ignore=std::vector< unsigned int >(), unsigned int
            ignore_lines=0, unsigned int n=std::numeric_limits< unsigned int >::max(),
            plFloat sampling_rate=PL_ONE)`  

            Load a csv file into a data matrix.  

        """
        return _probt_python3.plCSVFileDataDescriptor_load_data_matrix(*args)

    load_data_matrix = staticmethod(load_data_matrix)

    def get_data_record(self, *args) -> "bool":
        """
        get_data_record(self, records) -> bool
        get_data_record(self) -> bool


        `get_data_record(std::vector< std::string > &records) -> bool`  
        `get_data_record(const plValues *&data_values, const std::vector< bool >
            *&data_definition, plFloat &weight) -> bool`  

        Overloaded function
        -------------------
        * `get_data_record(std::vector< std::string > &records) -> bool`  

            Get the next data record (row) as a vector of strings and advances by one
            record in the data Returns false if eof.  

            ATTENTON: This should not be called using cached CSV descriptors  

        * `get_data_record(const plValues *&data_values, const std::vector< bool >
            *&data_definition, plFloat &weight) -> bool`  

            Get the next data record (row) and advances by one record in the data.  

            Parameters:  
            * `data_values` :  
                an array of values for all variables described in the record.  
            * `data_definition` :  
                a vector stating, for each value in *data_values*, whether it's defined
                or not.  
            * `weight` :  
                the weight of the record  

            Returns:
            *false* iif the end of the container is reached.  

            The returned pointers are managed internally: you should not attempt to
            delete them, or use them after another call to get_data_record(). Also, you
            should not use them when get_data_record() returns *false*.  

            For Python, the signature of this function is changed to return its results.
            It can be used as follows:  

                data_decriptor = ...
                not_done, data_values, data_definition, w =
            data_decriptor.get_data_record()


        """
        return _probt_python3.plCSVFileDataDescriptor_get_data_record(self, *args)


    def get_num_fields(self) -> "unsigned int":
        """
        get_num_fields(self) -> unsigned int


        `get_num_fields() const -> unsigned int`  

        Returns the number of fields (columns).  

        Returns
        -------
        the number of fields (columns/variables).  

        """
        return _probt_python3.plCSVFileDataDescriptor_get_num_fields(self)


    def get_n_records(self) -> "unsigned int":
        """
        get_n_records(self) -> unsigned int


        `get_n_records() -> unsigned int`  

        Get the number of records (rows) in the data set.  

        ATTENTION: if not cached, the first call scans the data set and thus has a
        complexity of O(n) where *n* is the size.  

        Returns
        -------
        the size of the data set.  

        """
        return _probt_python3.plCSVFileDataDescriptor_get_n_records(self)


    def set_variables(self, variables: 'plVariablesConjunction') -> "void":
        """
        set_variables(self, variables)


        `set_variables(const plVariablesConjunction &variables)`  

        Set the variables to be associated to the data descriptor.  

        This method is to be called when the descriptor is constructed without providing
        the variables list. After this call, observed_variables() will return the passed
        'variables' parameter.  

        Parameters
        ----------
        * `variables` :  
            The variables to be associated to the data descriptor  

        """
        return _probt_python3.plCSVFileDataDescriptor_set_variables(self, variables)


    def observed_variables(self) -> "plVariablesConjunction":
        """
        observed_variables(self) -> plVariablesConjunction


        `observed_variables() -> plVariablesConjunction`  

        Get the variables associated to the descriptor.  

        """
        return _probt_python3.plCSVFileDataDescriptor_observed_variables(self)


    def set_field_delimiter(self, field_delimiter: 'char') -> "void":
        """
        set_field_delimiter(self, field_delimiter)


        `set_field_delimiter(char field_delimiter)`  

        Set the field separator to be used in the CSV data.  

        """
        return _probt_python3.plCSVFileDataDescriptor_set_field_delimiter(self, field_delimiter)


    def set_line_delimiter(self, line_delimiter: 'char') -> "void":
        """
        set_line_delimiter(self, line_delimiter)


        `set_line_delimiter(char line_delimiter)`  

        Set the line separator to be used in the CSV data.  

        """
        return _probt_python3.plCSVFileDataDescriptor_set_line_delimiter(self, line_delimiter)


    def set_undefined_field(self, undefined_field: 'std::string const &') -> "void":
        """
        set_undefined_field(self, undefined_field)


        `set_undefined_field(const std::string &undefined_field)`  

        Set the 'undefined_field' string to be used in the CSV data.  

        """
        return _probt_python3.plCSVFileDataDescriptor_set_undefined_field(self, undefined_field)


    def set_quote(self, quote: 'char') -> "void":
        """
        set_quote(self, quote)


        `set_quote(char quote)`  

        Set the quote chracter to be used in the CSV data.  

        """
        return _probt_python3.plCSVFileDataDescriptor_set_quote(self, quote)


    def set_columns_to_ignore(self, columns_to_ignore: 'UnsignedIntVector') -> "void":
        """
        set_columns_to_ignore(self, columns_to_ignore)


        `set_columns_to_ignore(const std::vector< unsigned int > &columns_to_ignore)`  

        Set the columns (fields) to be ignored in the CSV file.  

        The passed columns are ignored only if the descriptor is constructed using
        plCSVFileDataDescriptor(const std::string &file_name, unsigned int
        num_fields,...). Otherwise, this call has no effect.  

        """
        return _probt_python3.plCSVFileDataDescriptor_set_columns_to_ignore(self, columns_to_ignore)


    def add_column_to_ignore(self, column_to_ignore: 'unsigned int') -> "void":
        """
        add_column_to_ignore(self, column_to_ignore)


        `add_column_to_ignore(unsigned int column_to_ignore)`  

        Add a column (fields) to be ignored in the CSV file.  

        The passed columns are ignored only if the descriptor is constructed using
        plCSVFileDataDescriptor(const std::string &file_name, unsigned int
        num_fields,...). Otherwise, this call has no effect.  

        """
        return _probt_python3.plCSVFileDataDescriptor_add_column_to_ignore(self, column_to_ignore)


    def set_ignore_lines(self, n: 'unsigned int') -> "void":
        """
        set_ignore_lines(self, n)


        `set_ignore_lines(unsigned int n)`  

        Set the number of lines to be ignored in the CSV file.  

        This number excludes the first header line if the descriptor is constructed
        using plCSVFileDataDescriptor(const std::string &file_name, const
        plVariablesConjunction &variables, ...) and the CSV source contains a header
        line.  

        """
        return _probt_python3.plCSVFileDataDescriptor_set_ignore_lines(self, n)


    def set_cache_data(self, cache_it: 'bool') -> "void":
        """
        set_cache_data(self, cache_it)


        `set_cache_data(bool cache_it)`  

        Set the caching flag.  

        If memory allows it, this provides a significant speed boost when several passes
        are made over the data.  

        """
        return _probt_python3.plCSVFileDataDescriptor_set_cache_data(self, cache_it)


    def set_num_fields(self, num_fields: 'unsigned int') -> "void":
        """
        set_num_fields(self, num_fields)


        `set_num_fields(unsigned int num_fields)`  

        Set the number of columns (fields) to be read.  

        If 0 (the default value), the file will be parsed in order to guess its number
        of columns.  

        """
        return _probt_python3.plCSVFileDataDescriptor_set_num_fields(self, num_fields)


    def generate_gnuplot(self, *args) -> "void":
        """
        generate_gnuplot(self, gnuplot_file, title, time_stamp_column=0, time_stamp_format, plottype=PL_DEFAULT_PLOT, plot_points=False)
        generate_gnuplot(self, gnuplot_file, title, time_stamp_column=0, time_stamp_format, plottype=PL_DEFAULT_PLOT)
        generate_gnuplot(self, gnuplot_file, title, time_stamp_column=0, time_stamp_format)
        generate_gnuplot(self, gnuplot_file, title, time_stamp_column=0)
        generate_gnuplot(self, gnuplot_file, title)


        `generate_gnuplot(const std::string &gnuplot_file, const std::string &title,
            unsigned int time_stamp_column=0, const std::string
            time_stamp_format="%m/%d/%Y:%H:%M:%S", plPlotType
            plottype=PL_DEFAULT_PLOT, bool plot_points=false)`  

        Generate gnuplot instruction for plotting the data as a time-serie.  

        'time_stamp_column' is the number, starting from 1, of the date-houre colum This
        function has as side effect the rewinding of this data descriptor  

        """
        return _probt_python3.plCSVFileDataDescriptor_generate_gnuplot(self, *args)


    def has_observed_variables(self) -> "bool":
        """
        has_observed_variables(self) -> bool


        `has_observed_variables() const -> bool`  

        Return true iif the data descriptor has been associated to a set of variables.  

        """
        return _probt_python3.plCSVFileDataDescriptor_has_observed_variables(self)

plCSVFileDataDescriptor_swigregister = _probt_python3.plCSVFileDataDescriptor_swigregister
plCSVFileDataDescriptor_swigregister(plCSVFileDataDescriptor)

def plCSVFileDataDescriptor_guess_field_delimiter(*args) -> "char":
    """
    guess_field_delimiter(file_name, delimiters, nrows=10) -> char
    guess_field_delimiter(file_name, delimiters) -> char
    plCSVFileDataDescriptor_guess_field_delimiter(file_name) -> char


    `guess_field_delimiter(const std::string &file_name, const std::string
        &delimiters=";, \, size_t nrows=10) -> char`  

    Guess the field delimiter among the passed ones based on statistics on the
    'nrows' first lines of the file.  

    Return 0 if no delimiter is found (one-column file)  

    """
    return _probt_python3.plCSVFileDataDescriptor_guess_field_delimiter(*args)

def plCSVFileDataDescriptor_guess_number_of_fields(file_name: 'std::string const &') -> "unsigned int":
    """
    plCSVFileDataDescriptor_guess_number_of_fields(file_name) -> unsigned int


    `guess_number_of_fields(const std::string &file_name) -> unsigned int`  

    Guess the field of fields among of the file.  

    """
    return _probt_python3.plCSVFileDataDescriptor_guess_number_of_fields(file_name)

def plCSVFileDataDescriptor_load_data_matrix(*args) -> "void":
    """
    load_data_matrix(csv_file_name, data_matrix, undef_value, columns_to_ignore, ignore_lines=0, n, sampling_rate=1.0)
    load_data_matrix(csv_file_name, data_matrix, undef_value, columns_to_ignore, ignore_lines=0, n)
    load_data_matrix(csv_file_name, data_matrix, undef_value, columns_to_ignore, ignore_lines=0)
    load_data_matrix(csv_file_name, data_matrix, undef_value, columns_to_ignore)
    load_data_matrix(csv_file_name, data_matrix, undef_value)
    load_data_matrix(csv_file_name, data_matrix)
    load_data_matrix(csv_file_name, data_matrix, undef_value, columns_to_ignore, ignore_lines=0, n, sampling_rate=1.0)
    load_data_matrix(csv_file_name, data_matrix, undef_value, columns_to_ignore, ignore_lines=0, n)
    load_data_matrix(csv_file_name, data_matrix, undef_value, columns_to_ignore, ignore_lines=0)
    load_data_matrix(csv_file_name, data_matrix, undef_value, columns_to_ignore)
    load_data_matrix(csv_file_name, data_matrix, undef_value)
    load_data_matrix(csv_file_name, data_matrix)
    load_data_matrix(csv_file_name, data_matrix, undef_value, columns_to_ignore, ignore_lines=0, n, sampling_rate=1.0)
    load_data_matrix(csv_file_name, data_matrix, undef_value, columns_to_ignore, ignore_lines=0, n)
    load_data_matrix(csv_file_name, data_matrix, undef_value, columns_to_ignore, ignore_lines=0)
    load_data_matrix(csv_file_name, data_matrix, undef_value, columns_to_ignore)
    load_data_matrix(csv_file_name, data_matrix, undef_value)
    load_data_matrix(csv_file_name, data_matrix)
    load_data_matrix(csv_file_name, data_matrix, undef_value, columns_to_ignore, ignore_lines=0, n, sampling_rate=1.0)
    load_data_matrix(csv_file_name, data_matrix, undef_value, columns_to_ignore, ignore_lines=0, n)
    load_data_matrix(csv_file_name, data_matrix, undef_value, columns_to_ignore, ignore_lines=0)
    load_data_matrix(csv_file_name, data_matrix, undef_value, columns_to_ignore)
    plCSVFileDataDescriptor_load_data_matrix(csv_file_name, data_matrix, undef_value)


    `load_data_matrix(const std::string &csv_file_name, std::vector< std::vector<
        double > > &data_matrix, double undef_value=NAN, const std::vector< unsigned
        int > &columns_to_ignore=std::vector< unsigned int >(), unsigned int
        ignore_lines=0, unsigned int n=std::numeric_limits< unsigned int >::max(),
        plFloat sampling_rate=PL_ONE)`  
    `load_data_matrix(const std::string &csv_file_name, std::vector< std::vector<
        float > > &data_matrix, float undef_value=NAN, const std::vector< unsigned
        int > &columns_to_ignore=std::vector< unsigned int >(), unsigned int
        ignore_lines=0, unsigned int n=std::numeric_limits< unsigned int >::max(),
        plFloat sampling_rate=PL_ONE)`  
    `load_data_matrix(const std::string &csv_file_name, std::vector< std::vector<
        long double > > &data_matrix, long double undef_value=NAN, const
        std::vector< unsigned int > &columns_to_ignore=std::vector< unsigned int
        >(), unsigned int ignore_lines=0, unsigned int n=std::numeric_limits<
        unsigned int >::max(), plFloat sampling_rate=PL_ONE)`  
    `load_data_matrix(const std::string &csv_file_name, std::vector< std::vector<
        int > > &data_matrix, int undef_value, const std::vector< unsigned int >
        &columns_to_ignore=std::vector< unsigned int >(), unsigned int
        ignore_lines=0, unsigned int n=std::numeric_limits< unsigned int >::max(),
        plFloat sampling_rate=PL_ONE)`  

    Overloaded function
    -------------------
    * `load_data_matrix(const std::string &csv_file_name, std::vector< std::vector<
        double > > &data_matrix, double undef_value=NAN, const std::vector< unsigned
        int > &columns_to_ignore=std::vector< unsigned int >(), unsigned int
        ignore_lines=0, unsigned int n=std::numeric_limits< unsigned int >::max(),
        plFloat sampling_rate=PL_ONE)`  

        Load a csv file into a data matrix.  

    * `load_data_matrix(const std::string &csv_file_name, std::vector< std::vector<
        float > > &data_matrix, float undef_value=NAN, const std::vector< unsigned
        int > &columns_to_ignore=std::vector< unsigned int >(), unsigned int
        ignore_lines=0, unsigned int n=std::numeric_limits< unsigned int >::max(),
        plFloat sampling_rate=PL_ONE)`  

        Load a csv file into a data matrix.  

    * `load_data_matrix(const std::string &csv_file_name, std::vector< std::vector<
        long double > > &data_matrix, long double undef_value=NAN, const
        std::vector< unsigned int > &columns_to_ignore=std::vector< unsigned int
        >(), unsigned int ignore_lines=0, unsigned int n=std::numeric_limits<
        unsigned int >::max(), plFloat sampling_rate=PL_ONE)`  

        Load a csv file into a data matrix.  

    * `load_data_matrix(const std::string &csv_file_name, std::vector< std::vector<
        int > > &data_matrix, int undef_value, const std::vector< unsigned int >
        &columns_to_ignore=std::vector< unsigned int >(), unsigned int
        ignore_lines=0, unsigned int n=std::numeric_limits< unsigned int >::max(),
        plFloat sampling_rate=PL_ONE)`  

        Load a csv file into a data matrix.  

    """
    return _probt_python3.plCSVFileDataDescriptor_load_data_matrix(*args)

class plMatrixDataDescriptorDoubleVector(plDataDescriptor):
    """


    This class implements a data descriptor for STL data matrices with possibly
    missing values.  

    The template parameter rowT is the type of a row of data (e.g.,
    std::vector<int>, std::vector<double>, ...).  

    In the ProBT bindings, this class is instantiated as:  

    *   plMatrixDataDescriptorDoubleVector for rowT = std::vector<double>  
    *   plMatrixDataDescriptorIntVector for rowT = std::vector<int>  

    Do not use this template with rowT = plValues. Use plValuesDataDescriptor
    instead  

    C++ includes: plMatrixDataDescriptor.h

    """

    __swig_setmethods__ = {}
    for _s in [plDataDescriptor]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plMatrixDataDescriptorDoubleVector, name, value)
    __swig_getmethods__ = {}
    for _s in [plDataDescriptor]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plMatrixDataDescriptorDoubleVector, name)
    __repr__ = _swig_repr

    def __init__(self, *args):
        """
        __init__(self, variables, data) -> plMatrixDataDescriptorDoubleVector
        __init__(self, data) -> plMatrixDataDescriptorDoubleVector


        `plMatrixDataDescriptor(const plVariablesConjunction &variables, const
            std::vector< rowT > *data, const std::vector< std::vector< bool > > *def=0,
            const std::vector< plFloat > *weight=0)`  
        `plMatrixDataDescriptor(const std::vector< rowT > *data, const std::vector<
            std::vector< bool > > *def=0, const std::vector< plFloat > *weight=0)`  
        `plMatrixDataDescriptor(const plVariablesConjunction &variables, const
            std::vector< rowT > &data)`  
        `plMatrixDataDescriptor(const std::vector< rowT > &data)`  

        Overloaded function
        -------------------
        * `plMatrixDataDescriptor(const plVariablesConjunction &variables, const
            std::vector< rowT > *data, const std::vector< std::vector< bool > > *def=0,
            const std::vector< plFloat > *weight=0)`  

            Constructor using a pointer to an STL matrix.  

            Parameters:  
            * `variables` :  
                The variables associated to the descriptor.  
            * `data` :  
                A pointer to the STL data matrix to be used.  
            * `def` :  
                A pointer to the STL data definition matrix. 0 corresponds to complete
                data (no missing values).  
            * `weight` :  
                A pointer to the STL data weight vector. If 0, then a weight of one if
                assumed  

        * `plMatrixDataDescriptor(const std::vector< rowT > *data, const std::vector<
            std::vector< bool > > *def=0, const std::vector< plFloat > *weight=0)`  

            Constructor using a pointer to an STL matrix without associating it to a set
            of variables.  

            The actual association to a set of variables could be done later by calling
            set_variables().  

            Parameters:  
            * `data` :  
                a pointer to the STL data matrix to be used.  
            * `def` :  
                a pointer to the STL data definition matrix. 0 corresponds to complete
                data (no missing values).  
            * `weight` :  
                a pointer to the STL data weight matrix. 0 corresponds to a weight of
                one.  

        * `plMatrixDataDescriptor(const plVariablesConjunction &variables, const
            std::vector< rowT > &data)`  

            Constructor using an STL matrix (with copy).  

            Parameters:  
            * `variables` :  
                The variables associated to the descriptor.  
            * `data` :  
                The STL data matrix to be used. It assumes no missing values.  

        * `plMatrixDataDescriptor(const std::vector< rowT > &data)`  

            Constructor using an STL matrix (with copy).  

            Parameters:  
            * `data` :  
                The STL data matrix to be used. It assumes no missing values.  

        """
        this = _probt_python3.new_plMatrixDataDescriptorDoubleVector(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def rewind(self) -> "void":
        """
        rewind(self)


        `rewind()`  

        Rewinds the container to go back to its beginning.  

        """
        return _probt_python3.plMatrixDataDescriptorDoubleVector_rewind(self)


    def get_data_record(self) -> "bool":
        """
        get_data_record(self) -> bool


        `get_data_record(const plValues *&data_values, const std::vector< bool >
            *&data_definition, plFloat &weight) -> bool`  

        Get the next data record (row) and advances by one record in the data.  

        Parameters
        ----------
        * `data_values` :  
            an array of values for all variables described in the record.  
        * `data_definition` :  
            a vector stating, for each value in *data_values*, whether it's defined or
            not.  
        * `weight` :  
            the weight of the record  

        Returns
        -------
        *false* iif the end of the container is reached.  

        The returned pointers are managed internally: you should not attempt to delete
        them, or use them after another call to get_data_record(). Also, you should not
        use them when get_data_record() returns *false*.  

        For Python, the signature of this function is changed to return its results. It
        can be used as follows:  

            data_decriptor = ...
            not_done, data_values, data_definition, w = data_decriptor.get_data_record()


        """
        return _probt_python3.plMatrixDataDescriptorDoubleVector_get_data_record(self)


    def get_num_fields(self) -> "unsigned int":
        """
        get_num_fields(self) -> unsigned int


        `get_num_fields() const -> unsigned int`  

        Returns the number of fields (columns).  

        Returns
        -------
        the number of fields (columns/variables).  

        """
        return _probt_python3.plMatrixDataDescriptorDoubleVector_get_num_fields(self)


    def get_n_records(self) -> "unsigned int":
        """
        get_n_records(self) -> unsigned int


        `get_n_records() -> unsigned int`  

        Get the number of records (rows) in the data set.  

        Returns
        -------
        the size of the data set.  

        """
        return _probt_python3.plMatrixDataDescriptorDoubleVector_get_n_records(self)


    def set_variables(self, variables: 'plVariablesConjunction') -> "void":
        """
        set_variables(self, variables)


        `set_variables(const plVariablesConjunction &variables)`  

        Set the variables to be associated to the data descriptor.  

        This method is to be called when the descriptor is constructed without providing
        the variables list. After this call, observed_variables() will return the passed
        'variables' parameter.  

        Parameters
        ----------
        * `variables` :  
            The variables to be associated to the data descriptor  

        """
        return _probt_python3.plMatrixDataDescriptorDoubleVector_set_variables(self, variables)


    def observed_variables(self) -> "plVariablesConjunction":
        """
        observed_variables(self) -> plVariablesConjunction


        `observed_variables() -> plVariablesConjunction`  

        Get the variables associated to the descriptor.  

        """
        return _probt_python3.plMatrixDataDescriptorDoubleVector_observed_variables(self)

    __swig_destroy__ = _probt_python3.delete_plMatrixDataDescriptorDoubleVector
    __del__ = lambda self: None
plMatrixDataDescriptorDoubleVector_swigregister = _probt_python3.plMatrixDataDescriptorDoubleVector_swigregister
plMatrixDataDescriptorDoubleVector_swigregister(plMatrixDataDescriptorDoubleVector)

class plMatrixDataDescriptorIntVector(plDataDescriptor):
    """


    This class implements a data descriptor for STL data matrices with possibly
    missing values.  

    The template parameter rowT is the type of a row of data (e.g.,
    std::vector<int>, std::vector<double>, ...).  

    In the ProBT bindings, this class is instantiated as:  

    *   plMatrixDataDescriptorDoubleVector for rowT = std::vector<double>  
    *   plMatrixDataDescriptorIntVector for rowT = std::vector<int>  

    Do not use this template with rowT = plValues. Use plValuesDataDescriptor
    instead  

    C++ includes: plMatrixDataDescriptor.h

    """

    __swig_setmethods__ = {}
    for _s in [plDataDescriptor]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plMatrixDataDescriptorIntVector, name, value)
    __swig_getmethods__ = {}
    for _s in [plDataDescriptor]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plMatrixDataDescriptorIntVector, name)
    __repr__ = _swig_repr

    def __init__(self, *args):
        """
        __init__(self, variables, data) -> plMatrixDataDescriptorIntVector
        __init__(self, data) -> plMatrixDataDescriptorIntVector


        `plMatrixDataDescriptor(const plVariablesConjunction &variables, const
            std::vector< rowT > *data, const std::vector< std::vector< bool > > *def=0,
            const std::vector< plFloat > *weight=0)`  
        `plMatrixDataDescriptor(const std::vector< rowT > *data, const std::vector<
            std::vector< bool > > *def=0, const std::vector< plFloat > *weight=0)`  
        `plMatrixDataDescriptor(const plVariablesConjunction &variables, const
            std::vector< rowT > &data)`  
        `plMatrixDataDescriptor(const std::vector< rowT > &data)`  

        Overloaded function
        -------------------
        * `plMatrixDataDescriptor(const plVariablesConjunction &variables, const
            std::vector< rowT > *data, const std::vector< std::vector< bool > > *def=0,
            const std::vector< plFloat > *weight=0)`  

            Constructor using a pointer to an STL matrix.  

            Parameters:  
            * `variables` :  
                The variables associated to the descriptor.  
            * `data` :  
                A pointer to the STL data matrix to be used.  
            * `def` :  
                A pointer to the STL data definition matrix. 0 corresponds to complete
                data (no missing values).  
            * `weight` :  
                A pointer to the STL data weight vector. If 0, then a weight of one if
                assumed  

        * `plMatrixDataDescriptor(const std::vector< rowT > *data, const std::vector<
            std::vector< bool > > *def=0, const std::vector< plFloat > *weight=0)`  

            Constructor using a pointer to an STL matrix without associating it to a set
            of variables.  

            The actual association to a set of variables could be done later by calling
            set_variables().  

            Parameters:  
            * `data` :  
                a pointer to the STL data matrix to be used.  
            * `def` :  
                a pointer to the STL data definition matrix. 0 corresponds to complete
                data (no missing values).  
            * `weight` :  
                a pointer to the STL data weight matrix. 0 corresponds to a weight of
                one.  

        * `plMatrixDataDescriptor(const plVariablesConjunction &variables, const
            std::vector< rowT > &data)`  

            Constructor using an STL matrix (with copy).  

            Parameters:  
            * `variables` :  
                The variables associated to the descriptor.  
            * `data` :  
                The STL data matrix to be used. It assumes no missing values.  

        * `plMatrixDataDescriptor(const std::vector< rowT > &data)`  

            Constructor using an STL matrix (with copy).  

            Parameters:  
            * `data` :  
                The STL data matrix to be used. It assumes no missing values.  

        """
        this = _probt_python3.new_plMatrixDataDescriptorIntVector(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def rewind(self) -> "void":
        """
        rewind(self)


        `rewind()`  

        Rewinds the container to go back to its beginning.  

        """
        return _probt_python3.plMatrixDataDescriptorIntVector_rewind(self)


    def get_data_record(self) -> "bool":
        """
        get_data_record(self) -> bool


        `get_data_record(const plValues *&data_values, const std::vector< bool >
            *&data_definition, plFloat &weight) -> bool`  

        Get the next data record (row) and advances by one record in the data.  

        Parameters
        ----------
        * `data_values` :  
            an array of values for all variables described in the record.  
        * `data_definition` :  
            a vector stating, for each value in *data_values*, whether it's defined or
            not.  
        * `weight` :  
            the weight of the record  

        Returns
        -------
        *false* iif the end of the container is reached.  

        The returned pointers are managed internally: you should not attempt to delete
        them, or use them after another call to get_data_record(). Also, you should not
        use them when get_data_record() returns *false*.  

        For Python, the signature of this function is changed to return its results. It
        can be used as follows:  

            data_decriptor = ...
            not_done, data_values, data_definition, w = data_decriptor.get_data_record()


        """
        return _probt_python3.plMatrixDataDescriptorIntVector_get_data_record(self)


    def get_num_fields(self) -> "unsigned int":
        """
        get_num_fields(self) -> unsigned int


        `get_num_fields() const -> unsigned int`  

        Returns the number of fields (columns).  

        Returns
        -------
        the number of fields (columns/variables).  

        """
        return _probt_python3.plMatrixDataDescriptorIntVector_get_num_fields(self)


    def get_n_records(self) -> "unsigned int":
        """
        get_n_records(self) -> unsigned int


        `get_n_records() -> unsigned int`  

        Get the number of records (rows) in the data set.  

        Returns
        -------
        the size of the data set.  

        """
        return _probt_python3.plMatrixDataDescriptorIntVector_get_n_records(self)


    def set_variables(self, variables: 'plVariablesConjunction') -> "void":
        """
        set_variables(self, variables)


        `set_variables(const plVariablesConjunction &variables)`  

        Set the variables to be associated to the data descriptor.  

        This method is to be called when the descriptor is constructed without providing
        the variables list. After this call, observed_variables() will return the passed
        'variables' parameter.  

        Parameters
        ----------
        * `variables` :  
            The variables to be associated to the data descriptor  

        """
        return _probt_python3.plMatrixDataDescriptorIntVector_set_variables(self, variables)


    def observed_variables(self) -> "plVariablesConjunction":
        """
        observed_variables(self) -> plVariablesConjunction


        `observed_variables() -> plVariablesConjunction`  

        Get the variables associated to the descriptor.  

        """
        return _probt_python3.plMatrixDataDescriptorIntVector_observed_variables(self)

    __swig_destroy__ = _probt_python3.delete_plMatrixDataDescriptorIntVector
    __del__ = lambda self: None
plMatrixDataDescriptorIntVector_swigregister = _probt_python3.plMatrixDataDescriptorIntVector_swigregister
plMatrixDataDescriptorIntVector_swigregister(plMatrixDataDescriptorIntVector)

class plValuesDataDescriptor(plDataDescriptor):
    """

    `plValuesDataDescriptor(const std::vector< plValues > *data_ptr, const
        std::vector< plFloat > *weight=0)`  
    `plValuesDataDescriptor(const std::vector< plValues > &data)`  

    This class implements a data descriptor from a vector of plValues.  

    Constructors
    ------------
    * `plValuesDataDescriptor(const std::vector< plValues > *data_ptr, const
        std::vector< plFloat > *weight=0)`  

        Constructor.  

    * `plValuesDataDescriptor(const std::vector< plValues > &data)`  

        Constructor with data copy.  

    C++ includes: plValuesDataDescriptor.h

    """

    __swig_setmethods__ = {}
    for _s in [plDataDescriptor]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plValuesDataDescriptor, name, value)
    __swig_getmethods__ = {}
    for _s in [plDataDescriptor]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plValuesDataDescriptor, name)
    __repr__ = _swig_repr

    def __init__(self, data: 'plValuesVector'):
        """
        __init__(self, data) -> plValuesDataDescriptor


        `plValuesDataDescriptor(const std::vector< plValues > *data_ptr, const
            std::vector< plFloat > *weight=0)`  
        `plValuesDataDescriptor(const std::vector< plValues > &data)`  

        Overloaded function
        -------------------
        * `plValuesDataDescriptor(const std::vector< plValues > *data_ptr, const
            std::vector< plFloat > *weight=0)`  

            Constructor.  

        * `plValuesDataDescriptor(const std::vector< plValues > &data)`  

            Constructor with data copy.  

        """
        this = _probt_python3.new_plValuesDataDescriptor(data)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def get_num_fields(self) -> "unsigned int":
        """
        get_num_fields(self) -> unsigned int


        `get_num_fields() const -> unsigned int`  

        Returns the number of fields (columns).  

        Returns
        -------
        the number of fields (columns/variables).  

        """
        return _probt_python3.plValuesDataDescriptor_get_num_fields(self)


    def observed_variables(self) -> "plVariablesConjunction":
        """
        observed_variables(self) -> plVariablesConjunction


        `observed_variables() -> plVariablesConjunction`  

        Get the variables associated to the descriptor.  

        """
        return _probt_python3.plValuesDataDescriptor_observed_variables(self)


    def get_n_records(self) -> "unsigned int":
        """
        get_n_records(self) -> unsigned int


        `get_n_records() -> unsigned int`  

        Get the number of records (rows) in the data set.  

        ATTENTION: For the first call, the default implementation scans the data set and
        thus has a complexity of O(n) where *n* is the size.  

        This function has as side effect the rewinding of this data descriptor  

        Returns
        -------
        the size of the data set.  

        """
        return _probt_python3.plValuesDataDescriptor_get_n_records(self)


    def rewind(self) -> "void":
        """
        rewind(self)


        `rewind()`  

        Rewinds the container to go back to its beginning.  

        """
        return _probt_python3.plValuesDataDescriptor_rewind(self)


    def get_data_record(self) -> "bool":
        """
        get_data_record(self) -> bool


        `get_data_record(const plValues *&data_values, const std::vector< bool >
            *&data_definition, plFloat &weight) -> bool`  

        Get the next data record (row) and advances by one record in the data.  

        Parameters
        ----------
        * `data_values` :  
            an array of values for all variables described in the record.  
        * `data_definition` :  
            a vector stating, for each value in *data_values*, whether it's defined or
            not.  
        * `weight` :  
            the weight of the record  

        Returns
        -------
        *false* iif the end of the container is reached.  

        The returned pointers are managed internally: you should not attempt to delete
        them, or use them after another call to get_data_record(). Also, you should not
        use them when get_data_record() returns *false*.  

        For Python, the signature of this function is changed to return its results. It
        can be used as follows:  

            data_decriptor = ...
            not_done, data_values, data_definition, w = data_decriptor.get_data_record()


        """
        return _probt_python3.plValuesDataDescriptor_get_data_record(self)

    __swig_destroy__ = _probt_python3.delete_plValuesDataDescriptor
    __del__ = lambda self: None
plValuesDataDescriptor_swigregister = _probt_python3.plValuesDataDescriptor_swigregister
plValuesDataDescriptor_swigregister(plValuesDataDescriptor)

class plNumPyDataDescriptor(plDataDescriptor):
    """

    `plNumPyDataDescriptor(PyObject *array, const plVariablesConjunction &variables,
        bool use_data_cache=false)`  

    A data descriptor for NumPy record arrays.  

    This class is intended to be used from the Python bindings only. It allows ProBT
    algorithms to access directly the content of an existing NumPy array without
    duplicating the data storage or imposing any input/output overhead. Only record
    arrays are supported, where the fields are either real-valued (double-precision
    floating-point numbers) or character-strings (labels).  

    Constructors
    ------------
    * `plNumPyDataDescriptor(PyObject *array, const plVariablesConjunction
        &variables, bool use_data_cache=false)`  

        Construct a data descriptor operating on the in-memory data storage of a
        NumPy record array.  

        The matching of the array fields and the probabilistic variables is based on
        their names. If a symbol name is not found in the array fields, then it is
        considered a latent variable (that is, it is never observed).  

        Parameters:  

        Parameters:  
        * `array` :  
            The NumPy record array;  
        * `variables` :  
            The conjunction of variables you are interested in. The plValues object
            returned in the get_data_record() method is defined using this variable
            conjunction.  
        * `use_data_cache` :  
            Whether this descriptor should cache the data, in order to avoid parsing
            after the first rewind(). If memory allows it, this provides a
            significant speed boost when several passes are made over the data.  

    C++ includes: plNumPyDataDescriptor.h

    """

    __swig_setmethods__ = {}
    for _s in [plDataDescriptor]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plNumPyDataDescriptor, name, value)
    __swig_getmethods__ = {}
    for _s in [plDataDescriptor]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plNumPyDataDescriptor, name)
    __repr__ = _swig_repr

    def __init__(self, array: 'PyObject *', variables: 'plVariablesConjunction', use_data_cache: 'bool'=False):
        """
        __init__(self, array, variables, use_data_cache=False) -> plNumPyDataDescriptor
        __init__(self, array, variables) -> plNumPyDataDescriptor


        `plNumPyDataDescriptor(PyObject *array, const plVariablesConjunction &variables,
            bool use_data_cache=false)`  

        Construct a data descriptor operating on the in-memory data storage of a NumPy
        record array.  

        The matching of the array fields and the probabilistic variables is based on
        their names. If a symbol name is not found in the array fields, then it is
        considered a latent variable (that is, it is never observed).  

        Parameters:  

        Parameters
        ----------
        * `array` :  
            The NumPy record array;  
        * `variables` :  
            The conjunction of variables you are interested in. The plValues object
            returned in the get_data_record() method is defined using this variable
            conjunction.  
        * `use_data_cache` :  
            Whether this descriptor should cache the data, in order to avoid parsing
            after the first rewind(). If memory allows it, this provides a significant
            speed boost when several passes are made over the data.  

        """
        this = _probt_python3.new_plNumPyDataDescriptor(array, variables, use_data_cache)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this
    __swig_destroy__ = _probt_python3.delete_plNumPyDataDescriptor
    __del__ = lambda self: None

    def get_num_fields(self) -> "unsigned int":
        """
        get_num_fields(self) -> unsigned int


        `get_num_fields() const -> unsigned int`  

        Returns the number of fields (columns).  

        Returns
        -------
        the number of fields (columns/variables).  

        """
        return _probt_python3.plNumPyDataDescriptor_get_num_fields(self)


    def observed_variables(self) -> "plVariablesConjunction":
        """
        observed_variables(self) -> plVariablesConjunction


        `observed_variables() -> plVariablesConjunction`  

        Get the variables associated to the descriptor.  

        """
        return _probt_python3.plNumPyDataDescriptor_observed_variables(self)


    def get_data_record(self) -> "bool":
        """
        get_data_record(self) -> bool


        `get_data_record(const plValues *&data_values, const std::vector< bool >
            *&data_definition, plFloat &weight) -> bool`  

        Get the next data record (row) and advances by one record in the data.  

        Parameters
        ----------
        * `data_values` :  
            an array of values for all variables described in the record.  
        * `data_definition` :  
            a vector stating, for each value in *data_values*, whether it's defined or
            not.  
        * `weight` :  
            the weight of the record  

        Returns
        -------
        *false* iif the end of the container is reached.  

        The returned pointers are managed internally: you should not attempt to delete
        them, or use them after another call to get_data_record(). Also, you should not
        use them when get_data_record() returns *false*.  

        For Python, the signature of this function is changed to return its results. It
        can be used as follows:  

            data_decriptor = ...
            not_done, data_values, data_definition, w = data_decriptor.get_data_record()


        """
        return _probt_python3.plNumPyDataDescriptor_get_data_record(self)


    def rewind(self) -> "void":
        """
        rewind(self)


        `rewind()`  

        Rewinds the container to go back to its beginning.  

        """
        return _probt_python3.plNumPyDataDescriptor_rewind(self)


    def get_n_records(self) -> "unsigned int":
        """
        get_n_records(self) -> unsigned int


        `get_n_records() -> unsigned int`  

        Get the number of records (rows) in the data set.  

        ATTENTION: For the first call, the default implementation scans the data set and
        thus has a complexity of O(n) where *n* is the size.  

        This function has as side effect the rewinding of this data descriptor  

        Returns
        -------
        the size of the data set.  

        """
        return _probt_python3.plNumPyDataDescriptor_get_n_records(self)

plNumPyDataDescriptor_swigregister = _probt_python3.plNumPyDataDescriptor_swigregister
plNumPyDataDescriptor_swigregister(plNumPyDataDescriptor)

class plDataDescriptorSet(plDataDescriptor):
    """

    `plDataDescriptorSet()`  
    `plDataDescriptorSet(const std::vector< plDataDescriptor *> &descriptors, const
        std::vector< plFloat > &weights)`  

    Define a sequential data container allowing the concatenation of a set of
    DataDescriptors.  

    Attention: using this container has side effects on the underlying shared
    descriptors  

    Code example:  

        plCSVFileDataDescriptor data1(...);
        plCSVFileDataDescriptor data2(...);
        plDataDescriptorSet concat;
        concat.add_descriptor(&data1, 0.6);
        concat.add_descriptor(&data2, 1.0);
        plCndLearnObject<plLearnNdNormal> cn(...);
        cn.learn(concat);


    Constructors
    ------------
    * `plDataDescriptorSet()`  

        Constructor.  

        See also: add_descriptor()  

    * `plDataDescriptorSet(const std::vector< plDataDescriptor *> &descriptors,
        const std::vector< plFloat > &weights)`  

        Construction and insertion.  

    C++ includes: plDataDescriptorSet.h

    """

    __swig_setmethods__ = {}
    for _s in [plDataDescriptor]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plDataDescriptorSet, name, value)
    __swig_getmethods__ = {}
    for _s in [plDataDescriptor]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plDataDescriptorSet, name)
    __repr__ = _swig_repr

    def __init__(self, *args):
        """
        __init__(self) -> plDataDescriptorSet
        __init__(self, descriptors, weights) -> plDataDescriptorSet


        `plDataDescriptorSet()`  
        `plDataDescriptorSet(const std::vector< plDataDescriptor *> &descriptors, const
            std::vector< plFloat > &weights)`  

        Overloaded function
        -------------------
        * `plDataDescriptorSet()`  

            Constructor.  

            See also: add_descriptor()  

        * `plDataDescriptorSet(const std::vector< plDataDescriptor *> &descriptors,
            const std::vector< plFloat > &weights)`  

            Construction and insertion.  

        """
        this = _probt_python3.new_plDataDescriptorSet(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def add_descriptor(self, desc: 'plDataDescriptor', weight: 'plFloat'=1.0) -> "void":
        """
        add_descriptor(self, desc, weight=1.0)
        add_descriptor(self, desc)


        `add_descriptor(plDataDescriptor *desc, plFloat weight=PL_ONE)`  

        Add a new descriptor with the corresponding weight.  

        The inserted descriptor has to be a valid one and must be kept by the caller  

        """
        return _probt_python3.plDataDescriptorSet_add_descriptor(self, desc, weight)


    def rescale_descriptor_weights(self, rescale_factor: 'plFloat') -> "void":
        """
        rescale_descriptor_weights(self, rescale_factor)


        `rescale_descriptor_weights(plFloat rescale_factor)`  

        Multiply the weights of the past inserted descriptors by a given factor.  

        This allows, for example, to decrease the importance of the old data points
        compared to the new ones  

        """
        return _probt_python3.plDataDescriptorSet_rescale_descriptor_weights(self, rescale_factor)

    __swig_destroy__ = _probt_python3.delete_plDataDescriptorSet
    __del__ = lambda self: None

    def get_num_fields(self) -> "unsigned int":
        """
        get_num_fields(self) -> unsigned int


        `get_num_fields() const -> unsigned int`  

        Returns the number of fields (columns).  

        Returns
        -------
        the number of fields (columns/variables).  

        """
        return _probt_python3.plDataDescriptorSet_get_num_fields(self)


    def rewind(self) -> "void":
        """
        rewind(self)


        `rewind()`  

        Rewinds the container to go back to its beginning.  

        """
        return _probt_python3.plDataDescriptorSet_rewind(self)


    def observed_variables(self) -> "plVariablesConjunction":
        """
        observed_variables(self) -> plVariablesConjunction


        `observed_variables() -> plVariablesConjunction`  

        Get the variables associated to the descriptor.  

        """
        return _probt_python3.plDataDescriptorSet_observed_variables(self)


    def get_data_record(self) -> "bool":
        """
        get_data_record(self) -> bool


        `get_data_record(const plValues *&data_values, const std::vector< bool >
            *&data_definition, plFloat &weight) -> bool`  

        Get the next data record (row) and advances by one record in the data.  

        Parameters
        ----------
        * `data_values` :  
            an array of values for all variables described in the record.  
        * `data_definition` :  
            a vector stating, for each value in *data_values*, whether it's defined or
            not.  
        * `weight` :  
            the weight of the record  

        Returns
        -------
        *false* iif the end of the container is reached.  

        The returned pointers are managed internally: you should not attempt to delete
        them, or use them after another call to get_data_record(). Also, you should not
        use them when get_data_record() returns *false*.  

        For Python, the signature of this function is changed to return its results. It
        can be used as follows:  

            data_decriptor = ...
            not_done, data_values, data_definition, w = data_decriptor.get_data_record()


        """
        return _probt_python3.plDataDescriptorSet_get_data_record(self)


    def Output(self) -> "void":
        """
        Output(self)


        `Output(std::ostream &os) const`  

        Writes the object at the *out* stream.  

        """
        return _probt_python3.plDataDescriptorSet_Output(self)

plDataDescriptorSet_swigregister = _probt_python3.plDataDescriptorSet_swigregister
plDataDescriptorSet_swigregister(plDataDescriptorSet)

class plLearner(plObject):
    """


    This is the base class of all learning objects.  

    C++ includes: plLearnObject.h

    """

    __swig_setmethods__ = {}
    for _s in [plObject]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plLearner, name, value)
    __swig_getmethods__ = {}
    for _s in [plObject]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plLearner, name)

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined - class is abstract")
    __repr__ = _swig_repr
    __swig_destroy__ = _probt_python3.delete_plLearner
    __del__ = lambda self: None
plLearner_swigregister = _probt_python3.plLearner_swigregister
plLearner_swigregister(plLearner)

class plLearnObject(plLearner):
    """

    `plLearnObject(const plVariablesConjunction &variables)`  
    `plLearnObject()`  
    `plLearnObject(const plLearnObject &obj)`  

    This is the base class of all incremental (adaptive) learning objects.  

    Constructors
    ------------
    * `plLearnObject(const plVariablesConjunction &variables)`  

        Constructor using a set of variables.  

    * `plLearnObject()`  

        Default constructor.  

    * `plLearnObject(const plLearnObject &obj)`  

        Copy constructor.  

    C++ includes: plLearnObject.h

    """

    __swig_setmethods__ = {}
    for _s in [plLearner]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plLearnObject, name, value)
    __swig_getmethods__ = {}
    for _s in [plLearner]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plLearnObject, name)

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined - class is abstract")
    __repr__ = _swig_repr
    __swig_destroy__ = _probt_python3.delete_plLearnObject
    __del__ = lambda self: None

    def get_nsamples(self) -> "unsigned int":
        """
        get_nsamples(self) -> unsigned int


        `get_nsamples() const -> unsigned int`  

        Returns the number of the points used in learning (i.e.  

        added using the *add_point* methods).  

        """
        return _probt_python3.plLearnObject_get_nsamples(self)


    def get_total_weight(self) -> "plFloat":
        """
        get_total_weight(self) -> plFloat


        `get_total_weight() const -> plFloat`  

        Returns the sum of weights of the points used in learning (i.e.  

        added using add_point()).  

        """
        return _probt_python3.plLearnObject_get_total_weight(self)


    def rescale_total_weight(self, s: 'plFloat') -> "void":
        """
        rescale_total_weight(self, s)


        `rescale_total_weight(plFloat s)=0`  

        Multiply the weight of the past inserted points by a given factor.  

        This allows, for example, to decrease the importance of the old data points
        compared to the new ones  

        """
        return _probt_python3.plLearnObject_rescale_total_weight(self, s)


    def reset(self) -> "void":
        """
        reset(self)


        `reset()`  

        Resets learning (forgets all learned data).  

        """
        return _probt_python3.plLearnObject_reset(self)


    def get_computable_object(self) -> "plComputableObject":
        """
        get_computable_object(self) -> plComputableObject


        `get_computable_object() const =0 -> plComputableObject`  

        Constructs the computable object corresponding to the learnt distribution.  

        Constructs and returns the computable object (conditional or non conditional
        distribution) corresponding to the current state of this learner  

        """
        return _probt_python3.plLearnObject_get_computable_object(self)


    def add_random_samples(self, n: 'unsigned int') -> "void":
        """
        add_random_samples(self, n)


        `add_random_samples(unsigned int n)`  

        Add random unifom samples in variable ranges.  

        """
        return _probt_python3.plLearnObject_add_random_samples(self, n)


    def add_point(self, *args) -> "bool":
        """
        add_point(self, point, weight=1.0) -> bool
        add_point(self, point) -> bool
        add_point(self, point, weight=1.0) -> bool
        add_point(self, point) -> bool
        add_point(self, point, weight=1.0) -> bool
        add_point(self, point) -> bool
        add_point(self, point, weight=1.0) -> bool
        add_point(self, point) -> bool
        add_point(self, point, weight=1.0) -> bool
        add_point(self, point) -> bool
        add_point(self, point, weight=1.0) -> bool
        add_point(self, point) -> bool
        add_point(self, point, weight=1.0) -> bool
        add_point(self, point) -> bool
        add_point(self, point, weight=1.0) -> bool
        add_point(self, point) -> bool
        add_point(self, point, weight=1.0) -> bool
        add_point(self, point) -> bool
        add_point(self, point, weight=1.0) -> bool
        add_point(self, point) -> bool
        add_point(self, point, weight=1.0) -> bool
        add_point(self, point) -> bool
        add_point(self, point, weight=1.0) -> bool
        add_point(self, point) -> bool
        add_point(self, point, weight=1.0) -> bool
        add_point(self, point) -> bool
        add_point(self, point, weight=1.0) -> bool
        add_point(self, point) -> bool
        add_point(self, point, weight=1.0) -> bool
        add_point(self, point) -> bool
        add_point(self, point, weight=1.0) -> bool
        add_point(self, point) -> bool
        add_point(self, point, is_defined, weight=1.0) -> bool
        add_point(self, point, is_defined) -> bool
        add_point(self, point, is_defined, weight=1.0) -> bool
        add_point(self, point, is_defined) -> bool
        add_point(self, point, is_defined, weight=1.0) -> bool
        add_point(self, point, is_defined) -> bool
        add_point(self, point, is_defined, weight=1.0) -> bool
        add_point(self, point, is_defined) -> bool
        add_point(self, point, is_defined, weight=1.0) -> bool
        add_point(self, point, is_defined) -> bool
        add_point(self, point, is_defined, weight=1.0) -> bool
        add_point(self, point, is_defined) -> bool
        add_point(self, point, is_defined, weight=1.0) -> bool
        add_point(self, point, is_defined) -> bool
        add_point(self, point, is_defined, weight=1.0) -> bool
        add_point(self, point, is_defined) -> bool
        add_point(self, point, is_defined, weight=1.0) -> bool
        add_point(self, point, is_defined) -> bool
        add_point(self, point, is_defined, weight=1.0) -> bool
        add_point(self, point, is_defined) -> bool
        add_point(self, point, is_defined, weight=1.0) -> bool
        add_point(self, point, is_defined) -> bool


        `add_point(const plValues &point, plFloat weight=PL_ONE) -> bool`  
        `add_point(const int *point, plFloat weight=PL_ONE) -> bool`  
        `add_point(const unsigned int *point, plFloat weight=PL_ONE) -> bool`  
        `add_point(const float *point, plFloat weight=PL_ONE) -> bool`  
        `add_point(const double *point, plFloat weight=PL_ONE) -> bool`  
        `add_point(const long double *point, plFloat weight=PL_ONE) -> bool`  
        `add_point(const std::vector< int > &point, plFloat weight=PL_ONE) -> bool`  
        `add_point(const std::vector< unsigned int > &point, plFloat weight=PL_ONE) ->
            bool`  
        `add_point(const std::vector< double > &point, plFloat weight=PL_ONE) -> bool`  
        `add_point(const std::vector< float > &point, plFloat weight=PL_ONE) -> bool`  
        `add_point(const std::vector< long double > &point, plFloat weight=PL_ONE) ->
            bool`  
        `add_point(int point, plFloat weight=PL_ONE) -> bool`  
        `add_point(unsigned int point, plFloat weight=PL_ONE) -> bool`  
        `add_point(double point, plFloat weight=PL_ONE) -> bool`  
        `add_point(float point, plFloat weight=PL_ONE) -> bool`  
        `add_point(long double point, plFloat weight=PL_ONE) -> bool`  
        `add_point(const plValues &point, const std::vector< bool > &is_defined, plFloat
            weight=PL_ONE) -> bool`  
        `add_point(const int *point, const std::vector< bool > &is_defined, plFloat
            weight=PL_ONE) -> bool`  
        `add_point(const unsigned int *point, const std::vector< bool > &is_defined,
            plFloat weight=PL_ONE) -> bool`  
        `add_point(const double *point, const std::vector< bool > &is_defined, plFloat
            weight=PL_ONE) -> bool`  
        `add_point(const float *point, const std::vector< bool > &is_defined, plFloat
            weight=PL_ONE) -> bool`  
        `add_point(const long double *point, const std::vector< bool > &is_defined,
            plFloat weight=PL_ONE) -> bool`  
        `add_point(const std::vector< int > &point, const std::vector< bool >
            &is_defined, plFloat weight=PL_ONE) -> bool`  
        `add_point(const std::vector< unsigned int > &point, const std::vector< bool >
            &is_defined, plFloat weight=PL_ONE) -> bool`  
        `add_point(const std::vector< double > &point, const std::vector< bool >
            &is_defined, plFloat weight=PL_ONE) -> bool`  
        `add_point(const std::vector< float > &point, const std::vector< bool >
            &is_defined, plFloat weight=PL_ONE) -> bool`  
        `add_point(const std::vector< long double > &point, const std::vector< bool >
            &is_defined, plFloat weight=PL_ONE) -> bool`  

        Overloaded function
        -------------------
        * `add_point(const plValues &point, plFloat weight=PL_ONE) -> bool`  

            Adds a data point with a given weight.  

            Parameters:  
            * `point` :  
                Data point to add.  
            * `weight` :  
                Weight of the added point. If *weight* is an integer, add_point(x,
                weight) is equivalent to doing *weight* times add_point(x).  

            Returns:
            True if and only if the point could be added.  

        * `add_point(const int *point, plFloat weight=PL_ONE) -> bool`  

            Adds a multidimensional data point with a given weight.  

            Parameters:  
            * `point` :  
                Data point to add, as a C array.  
            * `weight` :  
                Weight of the added point. If *weight* is an integer, add_point(x,
                weight) is equivalent to doing *weight* times add_point(x).  

            Returns:
            True if and only if the point could be added.  

        * `add_point(const unsigned int *point, plFloat weight=PL_ONE) -> bool`  

        * `add_point(const float *point, plFloat weight=PL_ONE) -> bool`  

        * `add_point(const double *point, plFloat weight=PL_ONE) -> bool`  

        * `add_point(const long double *point, plFloat weight=PL_ONE) -> bool`  

        * `add_point(const std::vector< int > &point, plFloat weight=PL_ONE) -> bool`  

            Adds a multidimensional data point with a given weight.  

            Parameters:  
            * `point` :  
                Data point to add, as an STL vector.  
            * `weight` :  
                Weight of the added point. If *weight* is an integer, add_point(x,
                weight) is equivalent to doing *weight* times add_point(x).  

            Returns:
            True if and only if the point could be added.  

        * `add_point(const std::vector< unsigned int > &point, plFloat weight=PL_ONE) ->
            bool`  

        * `add_point(const std::vector< double > &point, plFloat weight=PL_ONE) -> bool`  

        * `add_point(const std::vector< float > &point, plFloat weight=PL_ONE) -> bool`  

        * `add_point(const std::vector< long double > &point, plFloat weight=PL_ONE) ->
            bool`  

        * `add_point(int point, plFloat weight=PL_ONE) -> bool`  

            Adds a unidimensional data point with a given weight.  

            Parameters:  
            * `point` :  
                Data point to add. It must be convertible to the type of data of the
                variable.  
            * `weight` :  
                Weight of the added point. If *weight* is an integer, add_point(x,
                weight) is equivalent to doing *weight* times add_point(x).  

            Returns:
            True if and only if the point could be added.  

        * `add_point(unsigned int point, plFloat weight=PL_ONE) -> bool`  

        * `add_point(double point, plFloat weight=PL_ONE) -> bool`  

        * `add_point(float point, plFloat weight=PL_ONE) -> bool`  

        * `add_point(long double point, plFloat weight=PL_ONE) -> bool`  

        * `add_point(const plValues &point, const std::vector< bool > &is_defined,
            plFloat weight=PL_ONE) -> bool`  

            Adds a multidimensional data point with a given weight; the components of
            the point are specified in non-contiguously.  

            Parameters:  
            * `point` :  
                Data point to add, as a *plValues*.  
            * `is_defined` :  
                Indicates which components should be used for learning. is_defined[i]
                should be *true* if and only if point[i] is to be used.  
            * `weight` :  
                Weight of the added point. If *weight* is an integer, add_point(x,
                weight) is equivalent to doing *weight* times add_point(x).  

            Returns:
            True if and only if the point could be added.  

        * `add_point(const int *point, const std::vector< bool > &is_defined, plFloat
            weight=PL_ONE) -> bool`  

            Adds a multidimensional data point with a given weight; the components of
            the point are specified in order but non-contiguously.  

            Parameters:  
            * `point` :  
                Data point to add, as a C array.  
            * `is_defined` :  
                Indicates which components should be used for learning. is_defined[i]
                should be *true* if and only if point[i] is to be used.  
            * `weight` :  
                Weight of the added point. If *weight* is an integer, add_point(x,
                weight) is equivalent to doing *weight* times add_point(x).  

            Returns:
            True if and only if the point could be added.  

        * `add_point(const unsigned int *point, const std::vector< bool > &is_defined,
            plFloat weight=PL_ONE) -> bool`  

        * `add_point(const double *point, const std::vector< bool > &is_defined, plFloat
            weight=PL_ONE) -> bool`  

        * `add_point(const float *point, const std::vector< bool > &is_defined, plFloat
            weight=PL_ONE) -> bool`  

        * `add_point(const long double *point, const std::vector< bool > &is_defined,
            plFloat weight=PL_ONE) -> bool`  

        * `add_point(const std::vector< int > &point, const std::vector< bool >
            &is_defined, plFloat weight=PL_ONE) -> bool`  

            Adds a multidimensional data point with a given weight; the components of
            the point are specified in order but non-contiguously.  

            Parameters:  
            * `point` :  
                Data point to add, as an STL vector.  
            * `is_defined` :  
                Indicates which components should be used for learning. is_defined[i]
                should be *true* if and only if point[i] is to be used.  
            * `weight` :  
                Weight of the added point. If *weight* is an integer, add_point(x,
                weight) is equivalent to doing *weight* times add_point(x).  

            Returns:
            True if and only if the point could be added.  

        * `add_point(const std::vector< unsigned int > &point, const std::vector< bool >
            &is_defined, plFloat weight=PL_ONE) -> bool`  

        * `add_point(const std::vector< double > &point, const std::vector< bool >
            &is_defined, plFloat weight=PL_ONE) -> bool`  

        * `add_point(const std::vector< float > &point, const std::vector< bool >
            &is_defined, plFloat weight=PL_ONE) -> bool`  

        * `add_point(const std::vector< long double > &point, const std::vector< bool >
            &is_defined, plFloat weight=PL_ONE) -> bool`  

        """
        return _probt_python3.plLearnObject_add_point(self, *args)


    def learn_dynamic(self, *args) -> "int":
        """
        learn_dynamic(self, data_descriptor, ts_edges, n, data_weight) -> int
        learn_dynamic(self, data_set, ts_edges, n, data_weight) -> int


        `learn_dynamic(plDataDescriptor &data_descriptor, const std::vector< std::pair<
            plVariable, plVariable > > &ts_edges, unsigned int n, plFloat data_weight)
            -> int`  
        `learn_dynamic(const std::vector< plValues > &data_set, const std::vector<
            std::pair< plVariable, plVariable > > &ts_edges, unsigned int n, plFloat
            data_weight) -> int`  

        Overloaded function
        -------------------
        * `learn_dynamic(plDataDescriptor &data_descriptor, const std::vector<
            std::pair< plVariable, plVariable > > &ts_edges, unsigned int n, plFloat
            data_weight) -> int`  

        * `learn_dynamic(const std::vector< plValues > &data_set, const std::vector<
            std::pair< plVariable, plVariable > > &ts_edges, unsigned int n, plFloat
            data_weight) -> int`  

        """
        return _probt_python3.plLearnObject_learn_dynamic(self, *args)


    def learn(self, *args) -> "void":
        """
        learn(self, data_descriptor, n, data_weight=1.0) -> int
        learn(self, data_descriptor, n) -> int
        learn(self, data_descriptor) -> int
        learn(self, vals, data_weight=1.0)
        learn(self, vals)
        learn(self, vals, data_weight=1.0)
        learn(self, vals)
        learn(self, vals, data_weight=1.0)
        learn(self, vals)
        learn(self, vals, data_weight=1.0)
        learn(self, vals)
        learn(self, vals, data_weight=1.0)
        learn(self, vals)
        learn(self, vals, data_weight=1.0)
        learn(self, vals)
        learn(self, vals, arg3, data_weight)
        learn(self, vals, arg3, data_weight)
        learn(self, vals, arg3, data_weight)
        learn(self, vals, arg3, data_weight)
        learn(self, vals, arg3, data_weight)
        learn(self, vals, arg3, data_weight)


        `learn(plDataDescriptor &data_descriptor, unsigned int n=std::numeric_limits<
            unsigned int >::max(), plFloat data_weight=PL_ONE) -> int`  
        `learn(const std::vector< plValues > &vals, plFloat data_weight=PL_ONE)`  
        `learn(const std::vector< int > &vals, plFloat data_weight=PL_ONE)`  
        `learn(const std::vector< unsigned int > &vals, plFloat data_weight=PL_ONE)`  
        `learn(const std::vector< double > &vals, plFloat data_weight=PL_ONE)`  
        `learn(const std::vector< float > &vals, plFloat data_weight=PL_ONE)`  
        `learn(const std::vector< long double > &vals, plFloat data_weight=PL_ONE)`  
        `learn(const std::vector< plValues > &vals, const std::vector< bool > &def,
            plFloat data_weight)`  
        `learn(const std::vector< int > &vals, const std::vector< bool > &def, plFloat
            data_weight)`  
        `learn(const std::vector< unsigned int > &vals, const std::vector< bool > &def,
            plFloat data_weight)`  
        `learn(const std::vector< double > &vals, const std::vector< bool > &def,
            plFloat data_weight)`  
        `learn(const std::vector< float > &vals, const std::vector< bool > &def, plFloat
            data_weight)`  
        `learn(const std::vector< long double > &vals, const std::vector< bool > &def,
            plFloat data_weight)`  

        Overloaded function
        -------------------
        * `learn(plDataDescriptor &data_descriptor, unsigned int n=std::numeric_limits<
            unsigned int >::max(), plFloat data_weight=PL_ONE) -> int`  

            Learn using the data set defined by the container 'data_descriptor'.  

            Parameters:  
            * `data_descriptor` :  
                the data set to be used.  
            * `n` :  
                the number of data rows to be used.  
            * `data_weight` :  
                the weight to be applied to the data in addition to the weights provided
                for each data record  

            Returns:
            the number of the inserted points on success. Returns a negative value if
            the data descriptor is not OK (eg, CSV file does not exist, mysql server is
            not responding,...).  

            It is the responsibility of the caller to setup the data descriptor properly
            before calling this method, for instance by calling rewind() on it if
            necessary. Also, this method does not attempt to rewind() the data
            descriptor before returning.  

        * `learn(const std::vector< plValues > &vals, plFloat data_weight=PL_ONE)`  

            Learn using a set of values.  

        * `learn(const std::vector< int > &vals, plFloat data_weight=PL_ONE)`  

            Learn using a set of one-dimensional values.  

        * `learn(const std::vector< unsigned int > &vals, plFloat data_weight=PL_ONE)`  

        * `learn(const std::vector< double > &vals, plFloat data_weight=PL_ONE)`  

        * `learn(const std::vector< float > &vals, plFloat data_weight=PL_ONE)`  

        * `learn(const std::vector< long double > &vals, plFloat data_weight=PL_ONE)`  

        * `learn(const std::vector< plValues > &vals, const std::vector< bool > &def,
            plFloat data_weight)`  

            Learn using a set of one-dimensional values with their definition
            information.  

        * `learn(const std::vector< int > &vals, const std::vector< bool > &def, plFloat
            data_weight)`  

            Learn using a set of one-dimensional values with their definition
            information.  

        * `learn(const std::vector< unsigned int > &vals, const std::vector< bool >
            &def, plFloat data_weight)`  

        * `learn(const std::vector< double > &vals, const std::vector< bool > &def,
            plFloat data_weight)`  

        * `learn(const std::vector< float > &vals, const std::vector< bool > &def,
            plFloat data_weight)`  

        * `learn(const std::vector< long double > &vals, const std::vector< bool > &def,
            plFloat data_weight)`  

        """
        return _probt_python3.plLearnObject_learn(self, *args)


    def get_left_variables(self) -> "plVariablesConjunction const &":
        """
        get_left_variables(self) -> plVariablesConjunction


        `get_left_variables() const =0 -> const plVariablesConjunction &`  

        Returns the left variables.  

        """
        return _probt_python3.plLearnObject_get_left_variables(self)


    def get_right_variables(self) -> "plVariablesConjunction const &":
        """
        get_right_variables(self) -> plVariablesConjunction


        `get_right_variables() const =0 -> const plVariablesConjunction &`  

        Returns the right variables.  

        """
        return _probt_python3.plLearnObject_get_right_variables(self)


    def get_variables(self) -> "plVariablesConjunction const &":
        """
        get_variables(self) -> plVariablesConjunction


        `get_variables() const -> const plVariablesConjunction &`  

        Returns all variables.  

        """
        return _probt_python3.plLearnObject_get_variables(self)


    def get_n_parameters(self) -> "unsigned int":
        """
        get_n_parameters(self) -> unsigned int


        `get_n_parameters() const =0 -> unsigned int`  

        Returns the ACTUAL number of parameters.  

        It could be different from the number of parameters returned by get_parameters.  

        For example, the actual number of parameters of a N dimensional normal
        distribution is N + N*(N+1)/2 because the covariance matrix is symmetric.  

        """
        return _probt_python3.plLearnObject_get_n_parameters(self)


    def clone(self) -> "plLearnObject *":
        """
        clone(self) -> plLearnObject


        `clone() const =0 -> plLearnObject *`  

        Clone the learning object.  

        """
        return _probt_python3.plLearnObject_clone(self)


    def create_learnable_decomposition(*args) -> "plLearnObject *":
        """
        create_learnable_decomposition(variables, variable_group_indices, variable_group_parent_indices, n_mixtures) -> plLearnObject
        create_learnable_decomposition(variables, variable_group_indices, variable_group_parent_indices) -> plLearnObject
        create_learnable_decomposition(variables, variable_group_indices) -> plLearnObject
        create_learnable_decomposition(variables) -> plLearnObject
        create_learnable_decomposition(variables, variable_groups, variable_group_parents, n_mixtures) -> plLearnObject
        create_learnable_decomposition(variables, variable_groups, variable_group_parents) -> plLearnObject
        create_learnable_decomposition(variables, variable_groups) -> plLearnObject


        `create_learnable_decomposition(const plVariablesConjunction &variables, const
            std::vector< std::vector< unsigned int > >
            &variable_group_indices=std::vector< std::vector< unsigned int > >(), const
            std::vector< std::vector< unsigned int > >
            &variable_group_parent_indices=std::vector< std::vector< unsigned int > >(),
            const std::vector< unsigned int > &n_mixtures=std::vector< unsigned int >())
            -> plLearnObject *`  
        `create_learnable_decomposition(const plVariablesConjunction &variables, const
            std::vector< plVariablesConjunction > &variable_groups, const std::vector<
            plVariablesConjunction > &variable_group_parents=std::vector<
            plVariablesConjunction >(), const std::vector< unsigned int >
            &n_mixtures=std::vector< unsigned int >()) -> plLearnObject *`  

        Overloaded function
        -------------------
        * `create_learnable_decomposition(const plVariablesConjunction &variables, const
            std::vector< std::vector< unsigned int > >
            &variable_group_indices=std::vector< std::vector< unsigned int > >(), const
            std::vector< std::vector< unsigned int > >
            &variable_group_parent_indices=std::vector< std::vector< unsigned int > >(),
            const std::vector< unsigned int > &n_mixtures=std::vector< unsigned int >())
            -> plLearnObject *`  

            Create the learnable decomposition.  

            Parameters:  
            * `variables` :  
                observation variables  
            * `variable_group_indices` :  
                A set of indices for variable groups. For example, for variables = {X,
                A, Z}, one can use variable_group_indices = [ [0, 2], [1] ] to declare
                two groups of variables [X, Z] and [A]. This leads to the decomposition
                P(X A Z) = P(X Z) P(A)  
            * `variable_group_parent_indices` :  
                A set of indices for variable group parents. For example, for variable =
                {X, A, Z}, one can use variable_group_indices = [ [0, 2], [1] ] to
                declare two groups of variables ([X, Z], [A]) and
                variable_group_parent_indices = [ [1], [] ] to declare [1] ([A]) as the
                parents for the first group [0, 2] ([X, Z]) and no parents for the
                second group [1] ([A]). This leads to the decomposition P(X A Z) = P(X Z
                | A) P(A)  
            * `n_mixtures` :  
                The candidate number of mixtures to be used for continuous variables  

            For each distribution learner, its parametric form (type) depends of the
            type of the variable conjunctions and their parents as returned by
            create_learner()  

            See also: plLearnObject::create_learner()  

        * `create_learnable_decomposition(const plVariablesConjunction &variables, const
            std::vector< plVariablesConjunction > &variable_groups, const std::vector<
            plVariablesConjunction > &variable_group_parents=std::vector<
            plVariablesConjunction >(), const std::vector< unsigned int >
            &n_mixtures=std::vector< unsigned int >()) -> plLearnObject *`  

            Same as above.  

            However plVariablesConjunction are used instead of using indices  

        """
        return _probt_python3.plLearnObject_create_learnable_decomposition(*args)

    create_learnable_decomposition = staticmethod(create_learnable_decomposition)

    def create_learner(*args) -> "plLearnObject *":
        """
        create_learner(variables, n_mixtures) -> plLearnObject
        create_learner(variables, parents, n_mixtures) -> plLearnObject


        `create_learner(const plVariablesConjunction &variables, const std::vector<
            unsigned int > &n_mixtures) -> plLearnObject *`  
        `create_learner(const plVariablesConjunction &variables, const
            plVariablesConjunction &parents, const std::vector< unsigned int >
            &n_mixtures) -> plLearnObject *`  

        Overloaded function
        -------------------
        * `create_learner(const plVariablesConjunction &variables, const std::vector<
            unsigned int > &n_mixtures) -> plLearnObject *`  

            Creates a non-conditional distribution learner for a variable conjunction as
            follows:  

            *   if the 'variables' is discrete: plLearnLaplace(variables)  
            *   if the 'variables' is continuous and 1-dimentional:
                plLearn1dNormal(variables)  
            *   if the 'variables' is continuous and N-dimentional:
                plLearnNdNormal(variables)  
            *   if the 'variables' is mixed: a product P(discrete_variables) x
                P(continuous_variables | discrete_variables)  

            Parameters:  
            * `variables` :  
                The variables on which the learner is to be constructed  
            * `n_mixtures` :  
                The candidate number of mixtures to be used for continuous variables  

        * `create_learner(const plVariablesConjunction &variables, const
            plVariablesConjunction &parents, const std::vector< unsigned int >
            &n_mixtures) -> plLearnObject *`  

            Creates a conditional distribution learner for a variable conjunction as
            follows:  

            *   if the 'variables' is discrete and all its parents are discrete:
                plCndLearnObject<plLearnLaplace>(variables, parents)  
            *   if the 'variables' is discrete and 1-dimentional, and all its parents
                are continuous: plLearnSoftmax(variables, parents)  
            *   if the 'variables' is discrete and 1-dimentional, and its parents are
                mixed: plLearnSoftmaxFamily(variables, continuous_parents,
                discrete_parents)  
            *   if the 'variables' is continuous and 1-dimentional, and all its parents
                are discrete: plCndLearnObject<plLearn1dNormal>(variables, parents)  
            *   if the 'variables' is continuous and 1-dimentional, and all its parents
                are continuous: plLearnLinearRegression(variables, parents)  
            *   if the 'variables' is continuous and 1-dimentional, and its parents are
                mixed: plLearnLinearRegressionFamily(variables, continuous_parents,
                discrete_parents)  
            *   if the 'variables' is continuous and N-dimentional, and all its parents
                are discrete: plCndLearnObject<plLearnNdNormal>(variables, parents)  
            *   if the 'variables' is mixed: a product P(discrete_variables | parents )
                x P(continuous_variables | discrete_variables parents)  

            Throws an error otherwise  

            Parameters:  
            * `variables` :  
                The variables on which the learner is to be constructed  
            * `parents` :  
                The parents variables on which the learner is to be constructed  
            * `n_mixtures` :  
                The candidate number of mixtures to be used for continuous variables  

        """
        return _probt_python3.plLearnObject_create_learner(*args)

    create_learner = staticmethod(create_learner)
plLearnObject_swigregister = _probt_python3.plLearnObject_swigregister
plLearnObject_swigregister(plLearnObject)

def plLearnObject_create_learnable_decomposition(*args) -> "plLearnObject *":
    """
    create_learnable_decomposition(variables, variable_group_indices, variable_group_parent_indices, n_mixtures) -> plLearnObject
    create_learnable_decomposition(variables, variable_group_indices, variable_group_parent_indices) -> plLearnObject
    create_learnable_decomposition(variables, variable_group_indices) -> plLearnObject
    create_learnable_decomposition(variables) -> plLearnObject
    create_learnable_decomposition(variables, variable_groups, variable_group_parents, n_mixtures) -> plLearnObject
    create_learnable_decomposition(variables, variable_groups, variable_group_parents) -> plLearnObject
    plLearnObject_create_learnable_decomposition(variables, variable_groups) -> plLearnObject


    `create_learnable_decomposition(const plVariablesConjunction &variables, const
        std::vector< std::vector< unsigned int > >
        &variable_group_indices=std::vector< std::vector< unsigned int > >(), const
        std::vector< std::vector< unsigned int > >
        &variable_group_parent_indices=std::vector< std::vector< unsigned int > >(),
        const std::vector< unsigned int > &n_mixtures=std::vector< unsigned int >())
        -> plLearnObject *`  
    `create_learnable_decomposition(const plVariablesConjunction &variables, const
        std::vector< plVariablesConjunction > &variable_groups, const std::vector<
        plVariablesConjunction > &variable_group_parents=std::vector<
        plVariablesConjunction >(), const std::vector< unsigned int >
        &n_mixtures=std::vector< unsigned int >()) -> plLearnObject *`  

    Overloaded function
    -------------------
    * `create_learnable_decomposition(const plVariablesConjunction &variables, const
        std::vector< std::vector< unsigned int > >
        &variable_group_indices=std::vector< std::vector< unsigned int > >(), const
        std::vector< std::vector< unsigned int > >
        &variable_group_parent_indices=std::vector< std::vector< unsigned int > >(),
        const std::vector< unsigned int > &n_mixtures=std::vector< unsigned int >())
        -> plLearnObject *`  

        Create the learnable decomposition.  

        Parameters:  
        * `variables` :  
            observation variables  
        * `variable_group_indices` :  
            A set of indices for variable groups. For example, for variables = {X,
            A, Z}, one can use variable_group_indices = [ [0, 2], [1] ] to declare
            two groups of variables [X, Z] and [A]. This leads to the decomposition
            P(X A Z) = P(X Z) P(A)  
        * `variable_group_parent_indices` :  
            A set of indices for variable group parents. For example, for variable =
            {X, A, Z}, one can use variable_group_indices = [ [0, 2], [1] ] to
            declare two groups of variables ([X, Z], [A]) and
            variable_group_parent_indices = [ [1], [] ] to declare [1] ([A]) as the
            parents for the first group [0, 2] ([X, Z]) and no parents for the
            second group [1] ([A]). This leads to the decomposition P(X A Z) = P(X Z
            | A) P(A)  
        * `n_mixtures` :  
            The candidate number of mixtures to be used for continuous variables  

        For each distribution learner, its parametric form (type) depends of the
        type of the variable conjunctions and their parents as returned by
        create_learner()  

        See also: plLearnObject::create_learner()  

    * `create_learnable_decomposition(const plVariablesConjunction &variables, const
        std::vector< plVariablesConjunction > &variable_groups, const std::vector<
        plVariablesConjunction > &variable_group_parents=std::vector<
        plVariablesConjunction >(), const std::vector< unsigned int >
        &n_mixtures=std::vector< unsigned int >()) -> plLearnObject *`  

        Same as above.  

        However plVariablesConjunction are used instead of using indices  

    """
    return _probt_python3.plLearnObject_create_learnable_decomposition(*args)

def plLearnObject_create_learner(*args) -> "plLearnObject *":
    """
    create_learner(variables, n_mixtures) -> plLearnObject
    plLearnObject_create_learner(variables, parents, n_mixtures) -> plLearnObject


    `create_learner(const plVariablesConjunction &variables, const std::vector<
        unsigned int > &n_mixtures) -> plLearnObject *`  
    `create_learner(const plVariablesConjunction &variables, const
        plVariablesConjunction &parents, const std::vector< unsigned int >
        &n_mixtures) -> plLearnObject *`  

    Overloaded function
    -------------------
    * `create_learner(const plVariablesConjunction &variables, const std::vector<
        unsigned int > &n_mixtures) -> plLearnObject *`  

        Creates a non-conditional distribution learner for a variable conjunction as
        follows:  

        *   if the 'variables' is discrete: plLearnLaplace(variables)  
        *   if the 'variables' is continuous and 1-dimentional:
            plLearn1dNormal(variables)  
        *   if the 'variables' is continuous and N-dimentional:
            plLearnNdNormal(variables)  
        *   if the 'variables' is mixed: a product P(discrete_variables) x
            P(continuous_variables | discrete_variables)  

        Parameters:  
        * `variables` :  
            The variables on which the learner is to be constructed  
        * `n_mixtures` :  
            The candidate number of mixtures to be used for continuous variables  

    * `create_learner(const plVariablesConjunction &variables, const
        plVariablesConjunction &parents, const std::vector< unsigned int >
        &n_mixtures) -> plLearnObject *`  

        Creates a conditional distribution learner for a variable conjunction as
        follows:  

        *   if the 'variables' is discrete and all its parents are discrete:
            plCndLearnObject<plLearnLaplace>(variables, parents)  
        *   if the 'variables' is discrete and 1-dimentional, and all its parents
            are continuous: plLearnSoftmax(variables, parents)  
        *   if the 'variables' is discrete and 1-dimentional, and its parents are
            mixed: plLearnSoftmaxFamily(variables, continuous_parents,
            discrete_parents)  
        *   if the 'variables' is continuous and 1-dimentional, and all its parents
            are discrete: plCndLearnObject<plLearn1dNormal>(variables, parents)  
        *   if the 'variables' is continuous and 1-dimentional, and all its parents
            are continuous: plLearnLinearRegression(variables, parents)  
        *   if the 'variables' is continuous and 1-dimentional, and its parents are
            mixed: plLearnLinearRegressionFamily(variables, continuous_parents,
            discrete_parents)  
        *   if the 'variables' is continuous and N-dimentional, and all its parents
            are discrete: plCndLearnObject<plLearnNdNormal>(variables, parents)  
        *   if the 'variables' is mixed: a product P(discrete_variables | parents )
            x P(continuous_variables | discrete_variables parents)  

        Throws an error otherwise  

        Parameters:  
        * `variables` :  
            The variables on which the learner is to be constructed  
        * `parents` :  
            The parents variables on which the learner is to be constructed  
        * `n_mixtures` :  
            The candidate number of mixtures to be used for continuous variables  

    """
    return _probt_python3.plLearnObject_create_learner(*args)

class plLearnFrozenDistribution(plLearnObject):
    """

    `plLearnFrozenDistribution()`  
    `plLearnFrozenDistribution(const plComputableObject &frozen_computable_object)`  

    This class implements a learning object that learns nothing.  

    It's just a helper to provide the possibility to freeze some distributions when
    using learning algorithms. Actually, this learning object is initialized with a
    given distribution and simply returns the same distribution when the
    *get_computable_object* method is called.  

    Constructors
    ------------
    * `plLearnFrozenDistribution()`  

        Default constructor.  

    * `plLearnFrozenDistribution(const plComputableObject
        &frozen_computable_object)`  

        Constructor.  

        Parameters:  
        * `frozen_computable_object` :  
            the computable object to freeze.  

    C++ includes: plLearnObject.h

    """

    __swig_setmethods__ = {}
    for _s in [plLearnObject]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plLearnFrozenDistribution, name, value)
    __swig_getmethods__ = {}
    for _s in [plLearnObject]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plLearnFrozenDistribution, name)
    __repr__ = _swig_repr

    def __init__(self, *args):
        """
        __init__(self) -> plLearnFrozenDistribution
        __init__(self, frozen_computable_object) -> plLearnFrozenDistribution


        `plLearnFrozenDistribution()`  
        `plLearnFrozenDistribution(const plComputableObject &frozen_computable_object)`  

        Overloaded function
        -------------------
        * `plLearnFrozenDistribution()`  

            Default constructor.  

        * `plLearnFrozenDistribution(const plComputableObject
            &frozen_computable_object)`  

            Constructor.  

            Parameters:  
            * `frozen_computable_object` :  
                the computable object to freeze.  

        """
        this = _probt_python3.new_plLearnFrozenDistribution(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def get_left_variables(self) -> "plVariablesConjunction const &":
        """
        get_left_variables(self) -> plVariablesConjunction


        `get_left_variables() const -> const plVariablesConjunction &`  

        Returns the left variables.  

        """
        return _probt_python3.plLearnFrozenDistribution_get_left_variables(self)


    def get_right_variables(self) -> "plVariablesConjunction const &":
        """
        get_right_variables(self) -> plVariablesConjunction


        `get_right_variables() const -> const plVariablesConjunction &`  

        Returns the right variables.  

        """
        return _probt_python3.plLearnFrozenDistribution_get_right_variables(self)


    def get_computable_object(self) -> "plComputableObject":
        """
        get_computable_object(self) -> plComputableObject


        `get_computable_object() const -> plComputableObject`  

        Returns the frozen computable object.  

        """
        return _probt_python3.plLearnFrozenDistribution_get_computable_object(self)


    def get_n_parameters(self) -> "unsigned int":
        """
        get_n_parameters(self) -> unsigned int


        `get_n_parameters() const -> unsigned int`  

        Returns the ACTUAL number of parameters.  

        It could be different from the number of parameters returned by get_parameters.  

        For example, the actual number of parameters of a N dimensional normal
        distribution is N + N*(N+1)/2 because the covariance matrix is symmetric.  

        """
        return _probt_python3.plLearnFrozenDistribution_get_n_parameters(self)


    def clone(self) -> "plLearnObject *":
        """
        clone(self) -> plLearnObject


        `clone() const -> plLearnObject *`  

        Clone the learning object.  

        """
        return _probt_python3.plLearnFrozenDistribution_clone(self)


    def rescale_total_weight(self, arg2: 'plFloat') -> "void":
        """
        rescale_total_weight(self, arg2)


        `rescale_total_weight(plFloat)`  

        Multiply the weight of the past inserted points by a given factor.  

        This allows, for example, to decrease the importance of the old data points
        compared to the new ones  

        """
        return _probt_python3.plLearnFrozenDistribution_rescale_total_weight(self, arg2)


    def __getstate__(self) -> "std::string":
        """__getstate__(self) -> std::string"""
        return _probt_python3.plLearnFrozenDistribution___getstate__(self)


    def __setstate_internal(self, sState: 'std::string const &') -> "void":
        """__setstate_internal(self, sState)"""
        return _probt_python3.plLearnFrozenDistribution___setstate_internal(self, sState)


    def __setstate__(self, sState):
        self.__init__()
        self.__setstate_internal(sState)

    __swig_destroy__ = _probt_python3.delete_plLearnFrozenDistribution
    __del__ = lambda self: None
plLearnFrozenDistribution_swigregister = _probt_python3.plLearnFrozenDistribution_swigregister
plLearnFrozenDistribution_swigregister(plLearnFrozenDistribution)


fixup_dataframe_input(plLearnObject, 'learn', [0])
fixup_dataframe_input(plLearnObject, 'learn_dynamic', [0])

class plNonCndLearnObject(plLearnObject):
    """

    `plNonCndLearnObject()`  
    `plNonCndLearnObject(const plVariablesConjunction &variables)`  

    This is the base class of all Non-conditional incremental (adaptive) learning
    objects.  

    Constructors
    ------------
    * `plNonCndLearnObject()`  

        Void default constructor.  

    * `plNonCndLearnObject(const plVariablesConjunction &variables)`  

        Constructor using a set of variables (i.e for learning *P(variables)*.  

    C++ includes: plNonCndLearnObject.h

    """

    __swig_setmethods__ = {}
    for _s in [plLearnObject]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plNonCndLearnObject, name, value)
    __swig_getmethods__ = {}
    for _s in [plLearnObject]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plNonCndLearnObject, name)

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined - class is abstract")
    __repr__ = _swig_repr
    __swig_destroy__ = _probt_python3.delete_plNonCndLearnObject
    __del__ = lambda self: None

    def get_distribution(self) -> "plDistribution":
        """
        get_distribution(self) -> plDistribution


        `get_distribution() const =0 -> plDistribution`  

        Constructs the distribution corresponding to the learnt distribution.  

        """
        return _probt_python3.plNonCndLearnObject_get_distribution(self)


    def get_computable_object(self) -> "plComputableObject":
        """
        get_computable_object(self) -> plComputableObject


        `get_computable_object() const -> plComputableObject`  

        Constructs the computable object corresponding to the learnt distribution.  

        """
        return _probt_python3.plNonCndLearnObject_get_computable_object(self)


    def get_left_variables(self) -> "plVariablesConjunction const &":
        """
        get_left_variables(self) -> plVariablesConjunction


        `get_left_variables() const -> const plVariablesConjunction &`  

        Returns the left variables.  

        """
        return _probt_python3.plNonCndLearnObject_get_left_variables(self)


    def get_right_variables(self) -> "plVariablesConjunction const &":
        """
        get_right_variables(self) -> plVariablesConjunction


        `get_right_variables() const -> const plVariablesConjunction &`  

        Returns the right variables.  

        """
        return _probt_python3.plNonCndLearnObject_get_right_variables(self)


    def get_parameters(self, params: 'plValues') -> "void":
        """
        get_parameters(self, params)


        `get_parameters(plValues &params) const =0`  

        Returns all learnt parameters of the object (parameters passed to the
        distribution constructors when calling 'get_distribution').  

        This virtual method has to be implemented in all derived classes.  

        """
        return _probt_python3.plNonCndLearnObject_get_parameters(self, params)

plNonCndLearnObject_swigregister = _probt_python3.plNonCndLearnObject_swigregister
plNonCndLearnObject_swigregister(plNonCndLearnObject)

class plBayesLearnObject(plNonCndLearnObject):
    """

    `plBayesLearnObject()`  
    `plBayesLearnObject(const plVariablesConjunction &vars)`  

    This is the base class of all non-conditional incremental (adaptive) learning
    objects using a Bayesian criterion, by taking advantage of the conjugacy
    property.  

    We note:  

    *   a variable *X* over which we want to learn a distribution,  
    *   a set of parameters *Theta* for the distribution to learn over X,  
    *   a set of experimental data \[ \delta = x^0 .. x^n \].  

    We are interested in learning a distribution over X. Therefore we write:  

    *   P(X Theta) = P(Theta) P(delta | Theta) = P(Theta) P(x^0 | Theta) ... P(x^n |
        Theta)  
    *   P(Theta) : prior over parameters  
    *   P(x^i | Theta) = P(X | Theta) : likelihood function.  

    Given a likelihood function with a given set of parameters, there sometimes
    exist a particular form of P(Theta) that will yield a posterior P(Theta | X) of
    the same particular form. This particular form is called the conjugate prior of
    the likelihood function P(X | Theta).  

    We can then evaluate analytically P(Theta | delta). This allows to compute the
    set of parameters *theta** that either maximise P(theta | delta), or that
    correspond to the expectation of distribution P(Theta | delta).  

    See also: plBayesLearnBinomial  

    Constructors
    ------------
    * `plBayesLearnObject()`  

        Empty Constructor.  

    * `plBayesLearnObject(const plVariablesConjunction &vars)`  

        Contructor using a set of variables.  

    C++ includes: plNonCndLearnObject.h

    """

    __swig_setmethods__ = {}
    for _s in [plNonCndLearnObject]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plBayesLearnObject, name, value)
    __swig_getmethods__ = {}
    for _s in [plNonCndLearnObject]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plBayesLearnObject, name)

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined - class is abstract")
    __repr__ = _swig_repr

    def get_aposteriori_distribution(self, param_variables: 'plVariablesConjunction') -> "plDistribution":
        """
        get_aposteriori_distribution(self, param_variables) -> plDistribution


        `get_aposteriori_distribution(const plVariablesConjunction &param_variables)
            const =0 -> plDistribution`  

        Returns the posterior distribution on the learnt parameters.  

        """
        return _probt_python3.plBayesLearnObject_get_aposteriori_distribution(self, param_variables)

    __swig_destroy__ = _probt_python3.delete_plBayesLearnObject
    __del__ = lambda self: None
plBayesLearnObject_swigregister = _probt_python3.plBayesLearnObject_swigregister
plBayesLearnObject_swigregister(plBayesLearnObject)

class plMLLearnObject(plNonCndLearnObject):
    """

    `plMLLearnObject()`  
    `plMLLearnObject(const plVariablesConjunction &vars)`  

    This is the base class of all Non-conditional incremental (adaptive) learning
    objects using the Maximum Likelihood criterion.  

    Constructors
    ------------
    * `plMLLearnObject()`  

        Empty Constructor.  

    * `plMLLearnObject(const plVariablesConjunction &vars)`  

        Contructor using a set of variables.  

    C++ includes: plNonCndLearnObject.h

    """

    __swig_setmethods__ = {}
    for _s in [plNonCndLearnObject]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plMLLearnObject, name, value)
    __swig_getmethods__ = {}
    for _s in [plNonCndLearnObject]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plMLLearnObject, name)

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined - class is abstract")
    __repr__ = _swig_repr
    __swig_destroy__ = _probt_python3.delete_plMLLearnObject
    __del__ = lambda self: None
plMLLearnObject_swigregister = _probt_python3.plMLLearnObject_swigregister
plMLLearnObject_swigregister(plMLLearnObject)

class plBayesLearn1dNormalWithKnownMean(plBayesLearnObject):
    """

    `plBayesLearn1dNormalWithKnownMean()`  
    `plBayesLearn1dNormalWithKnownMean(plVariable const &variable, plFloat
        init_alpha, plFloat init_theta, plFloat mu=PL_ZERO)`  

    This class allows to make a Bayesian estimation of a one-dimensional Normal
    distribution with fixed mean when the prior distribution over the Normal
    precision (tau = 1 / sigma) is a Gamma distribution.  

    The conjugacy property of the Gamma distribution with respect to the Normal
    distribution ensures that the posterior distribution over the Normal precision
    is itself a Gamma distribution whose parameters can be computed analytically.  

    A Normal distribution with learned parameter *tau* (called *precision*) and
    fixed parameter *mu* (called *mean*) has the following probability density
    function: \[ p(x) = \frac{\tau}{\sqrt{2 \pi}} e^{-\frac{\tau^2}{2} (x -
    \mu)^2} \]  

    The parameter to learn *tau* is the inverse of the more common standard
    deviation sigma = 1 / tau.  

    A Gamma distribution with parameters *alpha* and *theta* has the following
    probability density function (for x > mu): \[ p(x) = (x - \mu)^{\alpha - 1}
    \frac{e^{-\frac{x - \mu}{\theta}}}{\theta^{\alpha} \Gamma(\alpha)} \]  

    See also: plBayesLearnObject plNormal plGamma  

    Constructors
    ------------
    * `plBayesLearn1dNormalWithKnownMean()`  

        Default constructor.  

    * `plBayesLearn1dNormalWithKnownMean(plVariable const &variable, plFloat
        init_alpha, plFloat init_theta, plFloat mu=PL_ZERO)`  

        Creates a learnable normal distribution with fixed mean, where the prior
        over the Normal precision parameter follows a Gamma distribution.  

        Parameters:  
        * `variable` :  
            the variable of the learnt distribution.  
        * `init_alpha` :  
            Initial value of the *alpha* parameter of the Gamma distribution over
            the Normal precision parameter. Must be strictly positive.  
        * `init_theta` :  
            Initial value of the *beta* parameter of the Gamma distribution over the
            Normal precision parameter. Must be strictly positive.  
        * `mu` :  
            Fixed mean of the Normal distribution.  

    C++ includes: plBayesLearn1dNormalWithKnownMean.h

    """

    __swig_setmethods__ = {}
    for _s in [plBayesLearnObject]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plBayesLearn1dNormalWithKnownMean, name, value)
    __swig_getmethods__ = {}
    for _s in [plBayesLearnObject]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plBayesLearn1dNormalWithKnownMean, name)
    __repr__ = _swig_repr

    def __init__(self, *args):
        """
        __init__(self) -> plBayesLearn1dNormalWithKnownMean
        __init__(self, variable, init_alpha, init_theta, mu=0.0) -> plBayesLearn1dNormalWithKnownMean
        __init__(self, variable, init_alpha, init_theta) -> plBayesLearn1dNormalWithKnownMean


        `plBayesLearn1dNormalWithKnownMean()`  
        `plBayesLearn1dNormalWithKnownMean(plVariable const &variable, plFloat
            init_alpha, plFloat init_theta, plFloat mu=PL_ZERO)`  

        Overloaded function
        -------------------
        * `plBayesLearn1dNormalWithKnownMean()`  

            Default constructor.  

        * `plBayesLearn1dNormalWithKnownMean(plVariable const &variable, plFloat
            init_alpha, plFloat init_theta, plFloat mu=PL_ZERO)`  

            Creates a learnable normal distribution with fixed mean, where the prior
            over the Normal precision parameter follows a Gamma distribution.  

            Parameters:  
            * `variable` :  
                the variable of the learnt distribution.  
            * `init_alpha` :  
                Initial value of the *alpha* parameter of the Gamma distribution over
                the Normal precision parameter. Must be strictly positive.  
            * `init_theta` :  
                Initial value of the *beta* parameter of the Gamma distribution over the
                Normal precision parameter. Must be strictly positive.  
            * `mu` :  
                Fixed mean of the Normal distribution.  

        """
        this = _probt_python3.new_plBayesLearn1dNormalWithKnownMean(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this
    __swig_destroy__ = _probt_python3.delete_plBayesLearn1dNormalWithKnownMean
    __del__ = lambda self: None

    def reset(self) -> "void":
        """
        reset(self)


        `reset()`  

        Resets learning (forgets all learned data).  

        """
        return _probt_python3.plBayesLearn1dNormalWithKnownMean_reset(self)


    def get_alpha(self) -> "plFloat":
        """
        get_alpha(self) -> plFloat


        `get_alpha() const -> plFloat`  

        Returns the current *alpha* parameter of the Gamma distribution over the
        Exponential parameter lambda.  

        """
        return _probt_python3.plBayesLearn1dNormalWithKnownMean_get_alpha(self)


    def get_theta(self) -> "plFloat":
        """
        get_theta(self) -> plFloat


        `get_theta() const -> plFloat`  

        Returns the current *beta* parameter of the Gamma distribution over the Normal
        precision *tau*.  

        """
        return _probt_python3.plBayesLearn1dNormalWithKnownMean_get_theta(self)


    def get_aposteriori_distribution(self, tau: 'plVariablesConjunction') -> "plDistribution":
        """
        get_aposteriori_distribution(self, tau) -> plDistribution


        `get_aposteriori_distribution(plVariablesConjunction const &tau) const ->
            plDistribution`  

        Returns the Gamma distribution corresponding to the posterior distribution over
        the Normal precision *tau* knowing all learned data.  

        Parameters
        ----------
        * `tau` :  
            Variable that corresponds to the Normal precision, on which to build the
            posterior distribution. Must be a variable with a real type.  

        """
        return _probt_python3.plBayesLearn1dNormalWithKnownMean_get_aposteriori_distribution(self, tau)


    def get_distribution(self) -> "plDistribution":
        """
        get_distribution(self) -> plDistribution


        `get_distribution() const -> plDistribution`  

        Returns the Normal distribution corresponding to the expected precision *tau*
        according to the learnt Gamma distribution on the Normal precision parameter.  

        """
        return _probt_python3.plBayesLearn1dNormalWithKnownMean_get_distribution(self)


    def get_a_posteriori_expectation(self) -> "plFloat":
        """
        get_a_posteriori_expectation(self) -> plFloat


        `get_a_posteriori_expectation() const -> plFloat`  

        Returns the expectation of the posterior distribution on the Normal precision
        given learned data.  

        """
        return _probt_python3.plBayesLearn1dNormalWithKnownMean_get_a_posteriori_expectation(self)


    def get_parameters(self, params: 'plValues') -> "void":
        """
        get_parameters(self, params)


        `get_parameters(plValues &params) const`  

        Returns all learnt parameters of the object (parameters passed to the
        distribution constructors when calling 'get_distribution').  

        This virtual method has to be implemented in all derived classes.  

        """
        return _probt_python3.plBayesLearn1dNormalWithKnownMean_get_parameters(self, params)


    def get_n_parameters(self) -> "unsigned int":
        """
        get_n_parameters(self) -> unsigned int


        `get_n_parameters() const -> unsigned int`  

        Returns the ACTUAL number of parameters.  

        It could be different from the number of parameters returned by get_parameters.  

        For example, the actual number of parameters of a N dimensional normal
        distribution is N + N*(N+1)/2 because the covariance matrix is symmetric.  

        """
        return _probt_python3.plBayesLearn1dNormalWithKnownMean_get_n_parameters(self)


    def clone(self) -> "plLearnObject *":
        """
        clone(self) -> plLearnObject


        `clone() const -> plLearnObject *`  

        Clone the learning object.  

        """
        return _probt_python3.plBayesLearn1dNormalWithKnownMean_clone(self)


    def rescale_total_weight(self, s: 'plFloat') -> "void":
        """
        rescale_total_weight(self, s)


        `rescale_total_weight(plFloat s)`  

        Multiply the weight of the past inserted points by a given factor.  

        This allows, for example, to decrease the importance of the old data points
        compared to the new ones  

        """
        return _probt_python3.plBayesLearn1dNormalWithKnownMean_rescale_total_weight(self, s)


    def __getstate__(self) -> "std::string":
        """__getstate__(self) -> std::string"""
        return _probt_python3.plBayesLearn1dNormalWithKnownMean___getstate__(self)


    def __setstate_internal(self, sState: 'std::string const &') -> "void":
        """__setstate_internal(self, sState)"""
        return _probt_python3.plBayesLearn1dNormalWithKnownMean___setstate_internal(self, sState)


    def __setstate__(self, sState):
        self.__init__()
        self.__setstate_internal(sState)

plBayesLearn1dNormalWithKnownMean_swigregister = _probt_python3.plBayesLearn1dNormalWithKnownMean_swigregister
plBayesLearn1dNormalWithKnownMean_swigregister(plBayesLearn1dNormalWithKnownMean)

class plBayesLearn1dNormalWithKnownStandardDeviation(plBayesLearnObject):
    """

    `plBayesLearn1dNormalWithKnownStandardDeviation()`  
    `plBayesLearn1dNormalWithKnownStandardDeviation(plVariable const &variable,
        plFloat init_mu, plFloat init_sigma, plFloat sigma0)`  

    This class allows to make a Bayesian estimation of a one-dimensional Normal
    distribution with fixed standard deviation *sigma0* when the prior distribution
    over the Normal mean is itself a Normal distribution.  

    The conjugacy property of the Normal distribution with respect to itself ensures
    that the posterior distribution over the Normal mean is itself a Normal
    distribution whose parameters can be computed analytically.  

    A Normal distribution with learned parameter *mu* (called *mean*) and fixed
    parameter *sigma0* (called *standard* *deviation*, square root of the *variance*
    sigma0^2) has the following probability density function: \[ P(x) =
    \frac{1}{\sigma_{0}\sqrt{2 \pi}} e^{-\frac{-(x - \mu)^2}{2 \sigma_{0}^2}
    } \]  

    See also: plBayesLearnObject plNormal  

    Constructors
    ------------
    * `plBayesLearn1dNormalWithKnownStandardDeviation()`  

        Default constructor.  

    * `plBayesLearn1dNormalWithKnownStandardDeviation(plVariable const &variable,
        plFloat init_mu, plFloat init_sigma, plFloat sigma0)`  

        Creates a learnable normal distribution with fixed standard deviation, where
        the prior over the Normal mean follows a Normal distribution.  

        Parameters:  
        * `variable` :  
            the variable of the learnt distribution.  
        * `init_mu` :  
            Initial value of the *mu* parameter of the Normal distribution over the
            learned Normal mean.  
        * `init_sigma` :  
            Initial value of the *sigma* parameter of the Normal distribution over
            the learned Normal mean. It must be strictly positive.  
        * `sigma0` :  
            Fixed standard deviation of the learned Normal distribution.  

    C++ includes: plBayesLearn1dNormalWithKnownStandardDeviation.h

    """

    __swig_setmethods__ = {}
    for _s in [plBayesLearnObject]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plBayesLearn1dNormalWithKnownStandardDeviation, name, value)
    __swig_getmethods__ = {}
    for _s in [plBayesLearnObject]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plBayesLearn1dNormalWithKnownStandardDeviation, name)
    __repr__ = _swig_repr

    def __init__(self, *args):
        """
        __init__(self) -> plBayesLearn1dNormalWithKnownStandardDeviation
        __init__(self, variable, init_mu, init_sigma, sigma0) -> plBayesLearn1dNormalWithKnownStandardDeviation


        `plBayesLearn1dNormalWithKnownStandardDeviation()`  
        `plBayesLearn1dNormalWithKnownStandardDeviation(plVariable const &variable,
            plFloat init_mu, plFloat init_sigma, plFloat sigma0)`  

        Overloaded function
        -------------------
        * `plBayesLearn1dNormalWithKnownStandardDeviation()`  

            Default constructor.  

        * `plBayesLearn1dNormalWithKnownStandardDeviation(plVariable const &variable,
            plFloat init_mu, plFloat init_sigma, plFloat sigma0)`  

            Creates a learnable normal distribution with fixed standard deviation, where
            the prior over the Normal mean follows a Normal distribution.  

            Parameters:  
            * `variable` :  
                the variable of the learnt distribution.  
            * `init_mu` :  
                Initial value of the *mu* parameter of the Normal distribution over the
                learned Normal mean.  
            * `init_sigma` :  
                Initial value of the *sigma* parameter of the Normal distribution over
                the learned Normal mean. It must be strictly positive.  
            * `sigma0` :  
                Fixed standard deviation of the learned Normal distribution.  

        """
        this = _probt_python3.new_plBayesLearn1dNormalWithKnownStandardDeviation(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this
    __swig_destroy__ = _probt_python3.delete_plBayesLearn1dNormalWithKnownStandardDeviation
    __del__ = lambda self: None

    def reset(self) -> "void":
        """
        reset(self)


        `reset()`  

        Resets learning (forgets all learned data).  

        """
        return _probt_python3.plBayesLearn1dNormalWithKnownStandardDeviation_reset(self)


    def get_mu(self) -> "plFloat":
        """
        get_mu(self) -> plFloat


        `get_mu() const -> plFloat`  

        Returns the current *mu* parameter of the Normal distribution over the learned
        Normal mean.  

        """
        return _probt_python3.plBayesLearn1dNormalWithKnownStandardDeviation_get_mu(self)


    def get_sigma(self) -> "plFloat":
        """
        get_sigma(self) -> plFloat


        `get_sigma() const -> plFloat`  

        Returns the current *sigma* parameter of the Normal distribution over the
        learned Normal mean.  

        """
        return _probt_python3.plBayesLearn1dNormalWithKnownStandardDeviation_get_sigma(self)


    def get_sigma0(self) -> "plFloat":
        """
        get_sigma0(self) -> plFloat


        `get_sigma0() const -> plFloat`  

        Returns the fixed parameter *sigma0* of the learned Normal distribution.  

        """
        return _probt_python3.plBayesLearn1dNormalWithKnownStandardDeviation_get_sigma0(self)


    def get_aposteriori_distribution(self, mu: 'plVariablesConjunction') -> "plDistribution":
        """
        get_aposteriori_distribution(self, mu) -> plDistribution


        `get_aposteriori_distribution(plVariablesConjunction const &mu) const ->
            plDistribution`  

        Returns the Normal distribution corresponding to the posterior distribution over
        the Normal mean *mu* knowing all learned data.  

        Parameters
        ----------
        * `mu` :  
            Variable that corresponds to the Normal mean, on which to build the
            posterior distribution. Must be a variable with a real type.  

        """
        return _probt_python3.plBayesLearn1dNormalWithKnownStandardDeviation_get_aposteriori_distribution(self, mu)


    def get_distribution(self) -> "plDistribution":
        """
        get_distribution(self) -> plDistribution


        `get_distribution() const -> plDistribution`  

        Returns the Normal distribution corresponding to the expected mean *mu*
        according to the learnt Normal distribution over the Normal mean, and the fixed
        standard deviation *sigma0*.  

        """
        return _probt_python3.plBayesLearn1dNormalWithKnownStandardDeviation_get_distribution(self)


    def get_a_posteriori_expectation(self) -> "plFloat":
        """
        get_a_posteriori_expectation(self) -> plFloat


        `get_a_posteriori_expectation() const -> plFloat`  

        Returns the expectation of the posterior distribution on the Normal mean given
        learned data.  

        """
        return _probt_python3.plBayesLearn1dNormalWithKnownStandardDeviation_get_a_posteriori_expectation(self)


    def get_parameters(self, params: 'plValues') -> "void":
        """
        get_parameters(self, params)


        `get_parameters(plValues &params) const`  

        Returns all learnt parameters of the object (parameters passed to the
        distribution constructors when calling 'get_distribution').  

        This virtual method has to be implemented in all derived classes.  

        """
        return _probt_python3.plBayesLearn1dNormalWithKnownStandardDeviation_get_parameters(self, params)


    def get_n_parameters(self) -> "unsigned int":
        """
        get_n_parameters(self) -> unsigned int


        `get_n_parameters() const -> unsigned int`  

        Returns the ACTUAL number of parameters.  

        It could be different from the number of parameters returned by get_parameters.  

        For example, the actual number of parameters of a N dimensional normal
        distribution is N + N*(N+1)/2 because the covariance matrix is symmetric.  

        """
        return _probt_python3.plBayesLearn1dNormalWithKnownStandardDeviation_get_n_parameters(self)


    def clone(self) -> "plLearnObject *":
        """
        clone(self) -> plLearnObject


        `clone() const -> plLearnObject *`  

        Clone the learning object.  

        """
        return _probt_python3.plBayesLearn1dNormalWithKnownStandardDeviation_clone(self)


    def rescale_total_weight(self, s: 'plFloat') -> "void":
        """
        rescale_total_weight(self, s)


        `rescale_total_weight(plFloat s)`  

        Multiply the weight of the past inserted points by a given factor.  

        This allows, for example, to decrease the importance of the old data points
        compared to the new ones  

        """
        return _probt_python3.plBayesLearn1dNormalWithKnownStandardDeviation_rescale_total_weight(self, s)


    def __getstate__(self) -> "std::string":
        """__getstate__(self) -> std::string"""
        return _probt_python3.plBayesLearn1dNormalWithKnownStandardDeviation___getstate__(self)


    def __setstate_internal(self, sState: 'std::string const &') -> "void":
        """__setstate_internal(self, sState)"""
        return _probt_python3.plBayesLearn1dNormalWithKnownStandardDeviation___setstate_internal(self, sState)


    def __setstate__(self, sState):
        self.__init__()
        self.__setstate_internal(sState)

plBayesLearn1dNormalWithKnownStandardDeviation_swigregister = _probt_python3.plBayesLearn1dNormalWithKnownStandardDeviation_swigregister
plBayesLearn1dNormalWithKnownStandardDeviation_swigregister(plBayesLearn1dNormalWithKnownStandardDeviation)

class plBayesLearnBinomial(plBayesLearnObject):
    """

    `plBayesLearnBinomial(const plVariable &variable, plFloat initp, plFloat initq)`  
    `plBayesLearnBinomial()`  

    This class allows to make a Bayesian estimation of a Binomial distribution when
    the prior distribution over the Binomial parameter is a Beta distribution.  

    The conjugacy property of the Beta distribution with respect to the Binomial
    distribution ensures that the posterior distribution over the Binomial parameter
    is itself a Beta distribution whose parameters can be computed analytically.  

    A Binomial with learned parameter *p* and fixed parameter *n* has the following
    probability distribution:  

    \[ P(k) = \frac{n!}{k! (n-k)!} p^k (1-p)^{n-k} \]  

    A Beta distribution over variable *x*, with parameters *p* and *q*, with bounds
    *a* and *b*, has the the density function (using the *Beta* function *B*): \[
    p(x) = \frac{(x-a)^{p-1} (b-x)^{q-1}}{B(p, q) (b - a)^{p+q-1}} \]  

    In this special case, the parameters *a* and *b* have values 0 and 1
    respectively because the Beta distribution is over the parameter *p*
    representing a probability value.  

    The fixed parameter *n* is extracted from the variable *variable* definition
    (the maximum value of *variable*).  

    See also: plBayesLearnObject plBeta  

    Constructors
    ------------
    * `plBayesLearnBinomial(const plVariable &variable, plFloat initp, plFloat
        initq)`  

        Constructor using given initial values for the parameters *p*, *q*, of the
        prior Beta distribution.  

        The most common case is to keep the default values for *n*, *a* and *b*.  

        Parameters:  
        * `variable` :  
            Variable of the Binomial you want to learn. The variable must be one-
            dimensional and discrete.  
        * `initp` :  
            Initial value of learned parameter *p* of the Beta distribution over the
            Binomial parameter. Must be strictly positive.  
        * `initq` :  
            Initial value of learned parameter *q* of the Beta distribution over the
            Binomial parameter. Must be strictly positive.  

    * `plBayesLearnBinomial()`  

        Empty constructor.  

    C++ includes: plBayesLearnBinomial.h

    """

    __swig_setmethods__ = {}
    for _s in [plBayesLearnObject]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plBayesLearnBinomial, name, value)
    __swig_getmethods__ = {}
    for _s in [plBayesLearnObject]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plBayesLearnBinomial, name)
    __repr__ = _swig_repr

    def __init__(self, *args):
        """
        __init__(self, variable, initp, initq) -> plBayesLearnBinomial
        __init__(self) -> plBayesLearnBinomial


        `plBayesLearnBinomial(const plVariable &variable, plFloat initp, plFloat initq)`  
        `plBayesLearnBinomial()`  

        Overloaded function
        -------------------
        * `plBayesLearnBinomial(const plVariable &variable, plFloat initp, plFloat
            initq)`  

            Constructor using given initial values for the parameters *p*, *q*, of the
            prior Beta distribution.  

            The most common case is to keep the default values for *n*, *a* and *b*.  

            Parameters:  
            * `variable` :  
                Variable of the Binomial you want to learn. The variable must be one-
                dimensional and discrete.  
            * `initp` :  
                Initial value of learned parameter *p* of the Beta distribution over the
                Binomial parameter. Must be strictly positive.  
            * `initq` :  
                Initial value of learned parameter *q* of the Beta distribution over the
                Binomial parameter. Must be strictly positive.  

        * `plBayesLearnBinomial()`  

            Empty constructor.  

        """
        this = _probt_python3.new_plBayesLearnBinomial(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this
    __swig_destroy__ = _probt_python3.delete_plBayesLearnBinomial
    __del__ = lambda self: None

    def reset(self) -> "void":
        """
        reset(self)


        `reset()`  

        Resets learning (forgets all learned data).  

        """
        return _probt_python3.plBayesLearnBinomial_reset(self)


    def get_p(self) -> "plFloat":
        """
        get_p(self) -> plFloat


        `get_p() const -> plFloat`  

        Returns the *p* parameter of the current Beta distribution on the parameter of
        the learned Binomial distribution.  

        """
        return _probt_python3.plBayesLearnBinomial_get_p(self)


    def get_q(self) -> "plFloat":
        """
        get_q(self) -> plFloat


        `get_q() const -> plFloat`  

        Returns the *q* parameter of the current Beta distribution on the parameter of
        the learned Binomial distribution.  

        """
        return _probt_python3.plBayesLearnBinomial_get_q(self)


    def get_n(self) -> "plFloat":
        """
        get_n(self) -> plFloat


        `get_n() const -> plFloat`  

        Returns the *n* parameter of the current Beta distribution on the parameter of
        the learned Binomial distribution.  

        This parameter is fixed at construction -- it is not learned.  

        """
        return _probt_python3.plBayesLearnBinomial_get_n(self)


    def get_aposteriori_distribution(self, theta: 'plVariablesConjunction') -> "plDistribution":
        """
        get_aposteriori_distribution(self, theta) -> plDistribution


        `get_aposteriori_distribution(const plVariablesConjunction &theta) const ->
            plDistribution`  

        Returns the Beta distribution corresponding to the posterior distribution over
        the Binomial parameter knowing all learned data.  

        Parameters
        ----------
        * `theta` :  
            Variable that corresponds to the Binomial parameter, on which to build the
            posterior distribution.  

        """
        return _probt_python3.plBayesLearnBinomial_get_aposteriori_distribution(self, theta)


    def get_distribution(self) -> "plDistribution":
        """
        get_distribution(self) -> plDistribution


        `get_distribution() const -> plDistribution`  

        Returns the Binomial distribution corresponding to the expected parameter
        according to the learnt Beta distribution on the Binomial parameter.  

        """
        return _probt_python3.plBayesLearnBinomial_get_distribution(self)


    def get_aposteriori_expectation(self) -> "plFloat":
        """
        get_aposteriori_expectation(self) -> plFloat


        `get_aposteriori_expectation() const -> plFloat`  

        Returns the expectation of the posterior distribution on the Binomial parameter
        given learned data.  

        """
        return _probt_python3.plBayesLearnBinomial_get_aposteriori_expectation(self)


    def get_parameters(self, params: 'plValues') -> "void":
        """
        get_parameters(self, params)


        `get_parameters(plValues &params) const`  

        Returns all learnt parameters of the object (parameters passed to the
        distribution constructors when calling 'get_distribution').  

        This virtual method has to be implemented in all derived classes.  

        """
        return _probt_python3.plBayesLearnBinomial_get_parameters(self, params)


    def get_n_parameters(self) -> "unsigned int":
        """
        get_n_parameters(self) -> unsigned int


        `get_n_parameters() const -> unsigned int`  

        Returns the ACTUAL number of parameters.  

        It could be different from the number of parameters returned by get_parameters.  

        For example, the actual number of parameters of a N dimensional normal
        distribution is N + N*(N+1)/2 because the covariance matrix is symmetric.  

        """
        return _probt_python3.plBayesLearnBinomial_get_n_parameters(self)


    def clone(self) -> "plLearnObject *":
        """
        clone(self) -> plLearnObject


        `clone() const -> plLearnObject *`  

        Clone the learning object.  

        """
        return _probt_python3.plBayesLearnBinomial_clone(self)


    def rescale_total_weight(self, s: 'plFloat') -> "void":
        """
        rescale_total_weight(self, s)


        `rescale_total_weight(plFloat s)`  

        Multiply the weight of the past inserted points by a given factor.  

        This allows, for example, to decrease the importance of the old data points
        compared to the new ones  

        """
        return _probt_python3.plBayesLearnBinomial_rescale_total_weight(self, s)


    def __getstate__(self) -> "std::string":
        """__getstate__(self) -> std::string"""
        return _probt_python3.plBayesLearnBinomial___getstate__(self)


    def __setstate_internal(self, sState: 'std::string const &') -> "void":
        """__setstate_internal(self, sState)"""
        return _probt_python3.plBayesLearnBinomial___setstate_internal(self, sState)


    def __setstate__(self, sState):
        self.__init__()
        self.__setstate_internal(sState)

plBayesLearnBinomial_swigregister = _probt_python3.plBayesLearnBinomial_swigregister
plBayesLearnBinomial_swigregister(plBayesLearnBinomial)

class plBayesLearnExponential(plBayesLearnObject):
    """

    `plBayesLearnExponential()`  
    `plBayesLearnExponential(plVariable const &variable, plFloat init_alpha, plFloat
        init_theta, plFloat mu=PL_ZERO)`  

    This class allows to make a Bayesian estimation of an Exponential distribution
    when the prior distribution of the Exponential parameter is a Gamma
    distribution.  

    The conjugacy property of the Gamma distribution with respect to the Exponential
    distribution ensures that the posterior distribution over the Exponential
    parameter is itself a Gamma distribution whose parameters can be computed
    analytically.  

    An Exponential distribution with learned parameter *beta* (called *scale*
    parameter) has the following probability density function: \[ P(x) =
    \frac{1}{\beta} e^{-\frac{x}{\beta}} \]  

    A Gamma distribution with parameters *alpha* and *theta* follows the following
    probability density function (for x > mu):  

    \[ P(x) = (x - \mu)^{\alpha - 1} \frac{e^{-\frac{x -
    \mu}{\theta}}}{\theta^{\alpha} \Gamma(\alpha)} \]  

    See also: plLearnExponential plExponential plGamma  

    Constructors
    ------------
    * `plBayesLearnExponential()`  

        Default constructor.  

    * `plBayesLearnExponential(plVariable const &variable, plFloat init_alpha,
        plFloat init_theta, plFloat mu=PL_ZERO)`  

        Creates a learnable exponential distribution, where the prior over the
        parameter follows a Gamma distribution.  

        Parameters:  
        * `variable` :  
            the variable of the learnt distribution  
        * `init_alpha` :  
            Initial value of the *alpha* parameter of the Gamma distribution over
            the exponential parameter. Must be strictly positive.  
        * `init_theta` :  
            Initial value of the *beta* parameter of the Gamma distribution over the
            exponential parameter. Must be strictly positive.  
        * `mu` :  
            The shift parameter of the exponential distribution.  

    C++ includes: plBayesLearnExponential.h

    """

    __swig_setmethods__ = {}
    for _s in [plBayesLearnObject]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plBayesLearnExponential, name, value)
    __swig_getmethods__ = {}
    for _s in [plBayesLearnObject]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plBayesLearnExponential, name)
    __repr__ = _swig_repr

    def __init__(self, *args):
        """
        __init__(self) -> plBayesLearnExponential
        __init__(self, variable, init_alpha, init_theta, mu=0.0) -> plBayesLearnExponential
        __init__(self, variable, init_alpha, init_theta) -> plBayesLearnExponential


        `plBayesLearnExponential()`  
        `plBayesLearnExponential(plVariable const &variable, plFloat init_alpha, plFloat
            init_theta, plFloat mu=PL_ZERO)`  

        Overloaded function
        -------------------
        * `plBayesLearnExponential()`  

            Default constructor.  

        * `plBayesLearnExponential(plVariable const &variable, plFloat init_alpha,
            plFloat init_theta, plFloat mu=PL_ZERO)`  

            Creates a learnable exponential distribution, where the prior over the
            parameter follows a Gamma distribution.  

            Parameters:  
            * `variable` :  
                the variable of the learnt distribution  
            * `init_alpha` :  
                Initial value of the *alpha* parameter of the Gamma distribution over
                the exponential parameter. Must be strictly positive.  
            * `init_theta` :  
                Initial value of the *beta* parameter of the Gamma distribution over the
                exponential parameter. Must be strictly positive.  
            * `mu` :  
                The shift parameter of the exponential distribution.  

        """
        this = _probt_python3.new_plBayesLearnExponential(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this
    __swig_destroy__ = _probt_python3.delete_plBayesLearnExponential
    __del__ = lambda self: None

    def reset(self) -> "void":
        """
        reset(self)


        `reset()`  

        Resets learning (forgets all learned data).  

        """
        return _probt_python3.plBayesLearnExponential_reset(self)


    def get_alpha(self) -> "plFloat":
        """
        get_alpha(self) -> plFloat


        `get_alpha() const -> plFloat`  

        Returns the current *alpha* parameter of the Gamma distribution over the
        Exponential parameter lambda.  

        """
        return _probt_python3.plBayesLearnExponential_get_alpha(self)


    def get_theta(self) -> "plFloat":
        """
        get_theta(self) -> plFloat


        `get_theta() const -> plFloat`  

        Returns the current *theta* parameter of the Gamma distribution over the
        Exponential parameter *lambda*.  

        """
        return _probt_python3.plBayesLearnExponential_get_theta(self)


    def get_aposteriori_distribution(self, beta: 'plVariablesConjunction') -> "plDistribution":
        """
        get_aposteriori_distribution(self, beta) -> plDistribution


        `get_aposteriori_distribution(plVariablesConjunction const &beta) const ->
            plDistribution`  

        Returns the Gamma distribution corresponding to the posterior distribution over
        the exponential parameter knowing all learned data.  

        Parameters
        ----------
        * `beta` :  
            Variable that corresponds to the exponential parameter, on which to build
            the posterior distribution. Must be a variable with a real type.  

        """
        return _probt_python3.plBayesLearnExponential_get_aposteriori_distribution(self, beta)


    def get_distribution(self) -> "plDistribution":
        """
        get_distribution(self) -> plDistribution


        `get_distribution() const -> plDistribution`  

        Returns the exponential distribution corresponding to the expected parameter
        according to the learnt Gamma distribution on the exponential parameter.  

        """
        return _probt_python3.plBayesLearnExponential_get_distribution(self)


    def get_a_posteriori_expectation(self) -> "plFloat":
        """
        get_a_posteriori_expectation(self) -> plFloat


        `get_a_posteriori_expectation() const -> plFloat`  

        Returns the expectation of the posterior distribution on the exponential
        parameter given learned data.  

        """
        return _probt_python3.plBayesLearnExponential_get_a_posteriori_expectation(self)


    def get_parameters(self, params: 'plValues') -> "void":
        """
        get_parameters(self, params)


        `get_parameters(plValues &params) const`  

        Returns all learnt parameters of the object (parameters passed to the
        distribution constructors when calling 'get_distribution').  

        This virtual method has to be implemented in all derived classes.  

        """
        return _probt_python3.plBayesLearnExponential_get_parameters(self, params)


    def get_n_parameters(self) -> "unsigned int":
        """
        get_n_parameters(self) -> unsigned int


        `get_n_parameters() const -> unsigned int`  

        Returns the ACTUAL number of parameters.  

        It could be different from the number of parameters returned by get_parameters.  

        For example, the actual number of parameters of a N dimensional normal
        distribution is N + N*(N+1)/2 because the covariance matrix is symmetric.  

        """
        return _probt_python3.plBayesLearnExponential_get_n_parameters(self)


    def clone(self) -> "plLearnObject *":
        """
        clone(self) -> plLearnObject


        `clone() const -> plLearnObject *`  

        Clone the learning object.  

        """
        return _probt_python3.plBayesLearnExponential_clone(self)


    def rescale_total_weight(self, s: 'plFloat') -> "void":
        """
        rescale_total_weight(self, s)


        `rescale_total_weight(plFloat s)`  

        Multiply the weight of the past inserted points by a given factor.  

        This allows, for example, to decrease the importance of the old data points
        compared to the new ones  

        """
        return _probt_python3.plBayesLearnExponential_rescale_total_weight(self, s)


    def get_init_alpha(self) -> "plFloat":
        """
        get_init_alpha(self) -> plFloat


        `get_init_alpha() const -> plFloat`  

        """
        return _probt_python3.plBayesLearnExponential_get_init_alpha(self)


    def get_init_theta(self) -> "plFloat":
        """
        get_init_theta(self) -> plFloat


        `get_init_theta() const -> plFloat`  

        """
        return _probt_python3.plBayesLearnExponential_get_init_theta(self)


    def get_sum_samples(self) -> "plFloat":
        """
        get_sum_samples(self) -> plFloat


        `get_sum_samples() const -> plFloat`  

        """
        return _probt_python3.plBayesLearnExponential_get_sum_samples(self)


    def get_mu(self) -> "plFloat":
        """
        get_mu(self) -> plFloat


        `get_mu() const -> plFloat`  

        """
        return _probt_python3.plBayesLearnExponential_get_mu(self)


    def __getstate__(self) -> "std::string":
        """__getstate__(self) -> std::string"""
        return _probt_python3.plBayesLearnExponential___getstate__(self)


    def __setstate_internal(self, sState: 'std::string const &') -> "void":
        """__setstate_internal(self, sState)"""
        return _probt_python3.plBayesLearnExponential___setstate_internal(self, sState)


    def __setstate__(self, sState):
        self.__init__()
        self.__setstate_internal(sState)

plBayesLearnExponential_swigregister = _probt_python3.plBayesLearnExponential_swigregister
plBayesLearnExponential_swigregister(plBayesLearnExponential)

class plBayesLearnGamma(plBayesLearnObject):
    """

    `plBayesLearnGamma(const plVariable &vars, plFloat v, plFloat mu, plFloat
        init_alpha, plFloat init_lambda)`  
    `plBayesLearnGamma()`  

    This class allows to make a Bayesian estimation of Gamma distributions.  

    To take advantage of the conjugacy property, the prior distribution is supposed
    to be a Gamma distribution and the a posteriori distribution is a Gamma
    distribution too.  

    Constructors
    ------------
    * `plBayesLearnGamma(const plVariable &vars, plFloat v, plFloat mu, plFloat
        init_alpha, plFloat init_lambda)`  

        Constructor using given parameters v (corresponding to the alpha parameter
        in the plGamma definition) and mu, the initial values for the 'alpha' and
        'lambda' (1/beta) parameters of the prior Gamma distribution.  


         The 'alpha' corresponds to the number of observed (supposed) number of
        events while 'lambda' corresponds on the time intervals number in which
        these events have been observed (supposed).  

    * `plBayesLearnGamma()`  

        Empty constructor.  

    C++ includes: plBayesLearnGamma.h

    """

    __swig_setmethods__ = {}
    for _s in [plBayesLearnObject]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plBayesLearnGamma, name, value)
    __swig_getmethods__ = {}
    for _s in [plBayesLearnObject]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plBayesLearnGamma, name)
    __repr__ = _swig_repr

    def __init__(self, *args):
        """
        __init__(self, vars, v, mu, init_alpha, init_lambda) -> plBayesLearnGamma
        __init__(self) -> plBayesLearnGamma


        `plBayesLearnGamma(const plVariable &vars, plFloat v, plFloat mu, plFloat
            init_alpha, plFloat init_lambda)`  
        `plBayesLearnGamma()`  

        Overloaded function
        -------------------
        * `plBayesLearnGamma(const plVariable &vars, plFloat v, plFloat mu, plFloat
            init_alpha, plFloat init_lambda)`  

            Constructor using given parameters v (corresponding to the alpha parameter
            in the plGamma definition) and mu, the initial values for the 'alpha' and
            'lambda' (1/beta) parameters of the prior Gamma distribution.  


             The 'alpha' corresponds to the number of observed (supposed) number of
            events while 'lambda' corresponds on the time intervals number in which
            these events have been observed (supposed).  

        * `plBayesLearnGamma()`  

            Empty constructor.  

        """
        this = _probt_python3.new_plBayesLearnGamma(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this
    __swig_destroy__ = _probt_python3.delete_plBayesLearnGamma
    __del__ = lambda self: None

    def reset(self) -> "void":
        """
        reset(self)


        `reset()`  

        Resets learning.  

        """
        return _probt_python3.plBayesLearnGamma_reset(self)


    def get_alpha(self) -> "plFloat":
        """
        get_alpha(self) -> plFloat


        `get_alpha() const -> plFloat`  

        Returns the 'alpha' parameter.  

        """
        return _probt_python3.plBayesLearnGamma_get_alpha(self)


    def get_lambda(self) -> "plFloat":
        """
        get_lambda(self) -> plFloat


        `get_lambda() const -> plFloat`  

        Returns the 'lambda' parameter.  

        """
        return _probt_python3.plBayesLearnGamma_get_lambda(self)


    def get_aposteriori_distribution(self, gamma_scale_variable: 'plVariablesConjunction') -> "plDistribution":
        """
        get_aposteriori_distribution(self, gamma_scale_variable) -> plDistribution


        `get_aposteriori_distribution(const plVariablesConjunction
            &gamma_scale_variable) const -> plDistribution`  

        Returns the Gamma distribution corresponding to the aposteriori distribution.  

        """
        return _probt_python3.plBayesLearnGamma_get_aposteriori_distribution(self, gamma_scale_variable)


    def get_distribution(self) -> "plDistribution":
        """
        get_distribution(self) -> plDistribution


        `get_distribution() const -> plDistribution`  

        Returns the Gamma distribution corresponding to the learnt distribution.  

        The 'mean' parameter is the expectation of the a posteriori distribution.  

        """
        return _probt_python3.plBayesLearnGamma_get_distribution(self)


    def get_a_posteriori_expectation(self) -> "plFloat":
        """
        get_a_posteriori_expectation(self) -> plFloat


        `get_a_posteriori_expectation() const -> plFloat`  

        Returns the expectation of the a posteriori distribution.  

        """
        return _probt_python3.plBayesLearnGamma_get_a_posteriori_expectation(self)


    def get_parameters(self, params: 'plValues') -> "void":
        """
        get_parameters(self, params)


        `get_parameters(plValues &params) const`  

        Returns all learnt parameters of the object (parameters passed to the
        distribution constructors when calling 'get_distribution').  

        This virtual method has to be implemented in all derived classes.  

        """
        return _probt_python3.plBayesLearnGamma_get_parameters(self, params)


    def get_n_parameters(self) -> "unsigned int":
        """
        get_n_parameters(self) -> unsigned int


        `get_n_parameters() const -> unsigned int`  

        Returns the ACTUAL number of parameters.  

        It could be different from the number of parameters returned by get_parameters.  

        For example, the actual number of parameters of a N dimensional normal
        distribution is N + N*(N+1)/2 because the covariance matrix is symmetric.  

        """
        return _probt_python3.plBayesLearnGamma_get_n_parameters(self)


    def clone(self) -> "plLearnObject *":
        """
        clone(self) -> plLearnObject


        `clone() const -> plLearnObject *`  

        Clone the learning object.  

        """
        return _probt_python3.plBayesLearnGamma_clone(self)


    def rescale_total_weight(self, s: 'plFloat') -> "void":
        """
        rescale_total_weight(self, s)


        `rescale_total_weight(plFloat s)`  

        Multiply the weight of the past inserted points by a given factor.  

        This allows, for example, to decrease the importance of the old data points
        compared to the new ones  

        """
        return _probt_python3.plBayesLearnGamma_rescale_total_weight(self, s)


    def __getstate__(self) -> "std::string":
        """__getstate__(self) -> std::string"""
        return _probt_python3.plBayesLearnGamma___getstate__(self)


    def __setstate_internal(self, sState: 'std::string const &') -> "void":
        """__setstate_internal(self, sState)"""
        return _probt_python3.plBayesLearnGamma___setstate_internal(self, sState)


    def __setstate__(self, sState):
        self.__init__()
        self.__setstate_internal(sState)

plBayesLearnGamma_swigregister = _probt_python3.plBayesLearnGamma_swigregister
plBayesLearnGamma_swigregister(plBayesLearnGamma)

class plBayesLearnLogNormalWithKnownShape(plBayesLearnObject):
    """

    `plBayesLearnLogNormalWithKnownShape()`  
    `plBayesLearnLogNormalWithKnownShape(plVariable const &variable, plFloat
        init_mu, plFloat init_sigma, plFloat s, plFloat theta)`  

    This class allows to make a Bayesian estimation of a log-normal distribution
    with fixed shape parameter *s* when the prior distribution over the natural
    logarithm of the log-normal scale *ln(m)* is a normal distribution.  

    The conjugacy property of the normal distribution with respect to the log-normal
    ensures that the posterior distribution over the natural logarithm of the log-
    normal scale parameter is a normal distribution whose parameters can be computed
    analytically.  

    A log-normal distribution with learned parameter *m* (called *scale*) and fixed
    parameters *s* (called *shape*) and *theta* (called *location*) has the
    following probability density function:  

    \[ p(x) = \frac {\exp (- (\ln( (x-\theta)/m) )^2/(2 s^2))} { (x - \theta)
    s \sqrt{2 \pi}} \hspace{2cm} x \geq \theta; m, s > 0 \]  

    A Normal distribution with parameters *mu* (called *mean*) and *sigma* (called
    *standard* *deviation*, square root of the *variance* sigma^2) has the following
    probability density function: \[ p(x) = \frac{1}{\sigma \sqrt{2 \pi}}
    e^{-\frac{-(x - \mu)^2}{2 \sigma^2} } \]  

    See also: plBayesLearnObject plLogNormal plNormal  

    Constructors
    ------------
    * `plBayesLearnLogNormalWithKnownShape()`  

        Default constructor.  

    * `plBayesLearnLogNormalWithKnownShape(plVariable const &variable, plFloat
        init_mu, plFloat init_sigma, plFloat s, plFloat theta)`  

        Creates a learnable log-normal distribution with fixed standard deviation,
        where the prior over the log-normal *mu* (*mu* = *exp(m)* ) parameter
        follows a normal distribution.  

        Parameters:  
        * `variable` :  
            the variable of the learnt distribution.  
        * `init_mu` :  
            Initial value of the *mu* parameter of the normal distribution over the
            learned log-normal mean.  
        * `init_sigma` :  
            Initial value of the *sigma* parameter of the Normal distribution over
            the learned log-normal mean. It must be strictly positive.  
        * `s` :  
            Fixed shape of the learned log-normal distribution.  
        * `theta` :  
            Fixed location parameter of the learned log-normal distribution.  

    C++ includes: plBayesLearnLogNormalWithKnownShape.h

    """

    __swig_setmethods__ = {}
    for _s in [plBayesLearnObject]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plBayesLearnLogNormalWithKnownShape, name, value)
    __swig_getmethods__ = {}
    for _s in [plBayesLearnObject]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plBayesLearnLogNormalWithKnownShape, name)
    __repr__ = _swig_repr

    def __init__(self, *args):
        """
        __init__(self) -> plBayesLearnLogNormalWithKnownShape
        __init__(self, variable, init_mu, init_sigma, s, theta) -> plBayesLearnLogNormalWithKnownShape


        `plBayesLearnLogNormalWithKnownShape()`  
        `plBayesLearnLogNormalWithKnownShape(plVariable const &variable, plFloat
            init_mu, plFloat init_sigma, plFloat s, plFloat theta)`  

        Overloaded function
        -------------------
        * `plBayesLearnLogNormalWithKnownShape()`  

            Default constructor.  

        * `plBayesLearnLogNormalWithKnownShape(plVariable const &variable, plFloat
            init_mu, plFloat init_sigma, plFloat s, plFloat theta)`  

            Creates a learnable log-normal distribution with fixed standard deviation,
            where the prior over the log-normal *mu* (*mu* = *exp(m)* ) parameter
            follows a normal distribution.  

            Parameters:  
            * `variable` :  
                the variable of the learnt distribution.  
            * `init_mu` :  
                Initial value of the *mu* parameter of the normal distribution over the
                learned log-normal mean.  
            * `init_sigma` :  
                Initial value of the *sigma* parameter of the Normal distribution over
                the learned log-normal mean. It must be strictly positive.  
            * `s` :  
                Fixed shape of the learned log-normal distribution.  
            * `theta` :  
                Fixed location parameter of the learned log-normal distribution.  

        """
        this = _probt_python3.new_plBayesLearnLogNormalWithKnownShape(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this
    __swig_destroy__ = _probt_python3.delete_plBayesLearnLogNormalWithKnownShape
    __del__ = lambda self: None

    def reset(self) -> "void":
        """
        reset(self)


        `reset()`  

        Resets learning (forgets all learned data).  

        """
        return _probt_python3.plBayesLearnLogNormalWithKnownShape_reset(self)


    def get_mu(self) -> "plFloat":
        """
        get_mu(self) -> plFloat


        `get_mu() const -> plFloat`  

        Returns the current *mu* parameter of the normal distribution over the learned
        log-normal mean.  

        """
        return _probt_python3.plBayesLearnLogNormalWithKnownShape_get_mu(self)


    def get_sigma(self) -> "plFloat":
        """
        get_sigma(self) -> plFloat


        `get_sigma() const -> plFloat`  

        Returns the current *sigma* parameter of the normal distribution over the
        learned log-normal mean.  

        """
        return _probt_python3.plBayesLearnLogNormalWithKnownShape_get_sigma(self)


    def get_s(self) -> "plFloat":
        """
        get_s(self) -> plFloat


        `get_s() const -> plFloat`  

        Returns the fixed *s* shape parameter of the learned log-normal distribution.  

        """
        return _probt_python3.plBayesLearnLogNormalWithKnownShape_get_s(self)


    def get_theta(self) -> "plFloat":
        """
        get_theta(self) -> plFloat


        `get_theta() const -> plFloat`  

        Returns the fixed *theta* location parameter of the learned log-normal
        distribution.  

        """
        return _probt_python3.plBayesLearnLogNormalWithKnownShape_get_theta(self)


    def get_aposteriori_distribution(self, mu: 'plVariablesConjunction') -> "plDistribution":
        """
        get_aposteriori_distribution(self, mu) -> plDistribution


        `get_aposteriori_distribution(plVariablesConjunction const &mu) const ->
            plDistribution`  

        Returns the normal distribution corresponding to the posterior distribution over
        the log-normal mean *mu* knowing all learned data.  

        Parameters
        ----------
        * `mu` :  
            Variable that corresponds to the log-normal mean, on which to build the
            posterior distribution. Must be a variable with a real type.  

        """
        return _probt_python3.plBayesLearnLogNormalWithKnownShape_get_aposteriori_distribution(self, mu)


    def get_distribution(self) -> "plDistribution":
        """
        get_distribution(self) -> plDistribution


        `get_distribution() const -> plDistribution`  

        Returns the log-normal distribution corresponding to the expected mean *mu*
        according to the learnt normal distribution over the log-normal mean, and the
        fixed standard deviation *sigma0*.  

        """
        return _probt_python3.plBayesLearnLogNormalWithKnownShape_get_distribution(self)


    def get_a_posteriori_expectation(self) -> "plFloat":
        """
        get_a_posteriori_expectation(self) -> plFloat


        `get_a_posteriori_expectation() const -> plFloat`  

        Returns the expectation of the posterior distribution on the log-normal mean
        given learned data.  

        """
        return _probt_python3.plBayesLearnLogNormalWithKnownShape_get_a_posteriori_expectation(self)


    def get_parameters(self, params: 'plValues') -> "void":
        """
        get_parameters(self, params)


        `get_parameters(plValues &params) const`  

        Returns all learnt parameters of the object (parameters passed to the
        distribution constructors when calling 'get_distribution').  

        This virtual method has to be implemented in all derived classes.  

        """
        return _probt_python3.plBayesLearnLogNormalWithKnownShape_get_parameters(self, params)


    def get_n_parameters(self) -> "unsigned int":
        """
        get_n_parameters(self) -> unsigned int


        `get_n_parameters() const -> unsigned int`  

        Returns the ACTUAL number of parameters.  

        It could be different from the number of parameters returned by get_parameters.  

        For example, the actual number of parameters of a N dimensional normal
        distribution is N + N*(N+1)/2 because the covariance matrix is symmetric.  

        """
        return _probt_python3.plBayesLearnLogNormalWithKnownShape_get_n_parameters(self)


    def clone(self) -> "plLearnObject *":
        """
        clone(self) -> plLearnObject


        `clone() const -> plLearnObject *`  

        Clone the learning object.  

        """
        return _probt_python3.plBayesLearnLogNormalWithKnownShape_clone(self)


    def rescale_total_weight(self, s: 'plFloat') -> "void":
        """
        rescale_total_weight(self, s)


        `rescale_total_weight(plFloat s)`  

        Multiply the weight of the past inserted points by a given factor.  

        This allows, for example, to decrease the importance of the old data points
        compared to the new ones  

        """
        return _probt_python3.plBayesLearnLogNormalWithKnownShape_rescale_total_weight(self, s)


    def __getstate__(self) -> "std::string":
        """__getstate__(self) -> std::string"""
        return _probt_python3.plBayesLearnLogNormalWithKnownShape___getstate__(self)


    def __setstate_internal(self, sState: 'std::string const &') -> "void":
        """__setstate_internal(self, sState)"""
        return _probt_python3.plBayesLearnLogNormalWithKnownShape___setstate_internal(self, sState)


    def __setstate__(self, sState):
        self.__init__()
        self.__setstate_internal(sState)

plBayesLearnLogNormalWithKnownShape_swigregister = _probt_python3.plBayesLearnLogNormalWithKnownShape_swigregister
plBayesLearnLogNormalWithKnownShape_swigregister(plBayesLearnLogNormalWithKnownShape)

class plBayesLearnNdNormalWithKnownVariance(plBayesLearnObject):
    """

    `plBayesLearnNdNormalWithKnownVariance()`  
    `plBayesLearnNdNormalWithKnownVariance(const plVariablesConjunction &variable,
        const plFloatVector &init_mu, const plFloatMatrix &init_sigma, const
        plFloatMatrix &sigma0)`  

    This class allows to make a Bayesian estimation of a n-dimensional Normal
    distribution with fixed covariance matrix *sigma0* when the prior distribution
    over the Normal mean is itself a Normal distribution.  

    The conjugacy property of the Normal distribution with respect to itself ensures
    that the posterior distribution over the Normal mean is itself a Normal
    distribution whose parameters can be computed analytically.  

    See also: plBayesLearnObject plNormal  

    Constructors
    ------------
    * `plBayesLearnNdNormalWithKnownVariance()`  

        Default constructor.  

    * `plBayesLearnNdNormalWithKnownVariance(const plVariablesConjunction &variable,
        const plFloatVector &init_mu, const plFloatMatrix &init_sigma, const
        plFloatMatrix &sigma0)`  

        Creates a learnable normal distribution with fixed covariance martrix, where
        the prior over the Normal mean follows a Normal distribution.  

        Parameters:  
        * `variable` :  
            the variable of the learnt distribution.  
        * `init_mu` :  
            Initial value of the *mu* parameter of the Normal distribution over the
            learned Normal mean.  
        * `init_sigma` :  
            Initial value of the *sigma* parameter of the Normal distribution over
            the learned Normal mean. It must be strictly positive.  
        * `sigma0` :  
            Fixed covariance matrix of the learned Normal distribution.  

    C++ includes: plBayesLearnNdNormalWithKnownVariance.h

    """

    __swig_setmethods__ = {}
    for _s in [plBayesLearnObject]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plBayesLearnNdNormalWithKnownVariance, name, value)
    __swig_getmethods__ = {}
    for _s in [plBayesLearnObject]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plBayesLearnNdNormalWithKnownVariance, name)
    __repr__ = _swig_repr

    def __init__(self, *args):
        """
        __init__(self) -> plBayesLearnNdNormalWithKnownVariance
        __init__(self, variable, init_mu, init_sigma, sigma0) -> plBayesLearnNdNormalWithKnownVariance


        `plBayesLearnNdNormalWithKnownVariance()`  
        `plBayesLearnNdNormalWithKnownVariance(const plVariablesConjunction &variable,
            const plFloatVector &init_mu, const plFloatMatrix &init_sigma, const
            plFloatMatrix &sigma0)`  

        Overloaded function
        -------------------
        * `plBayesLearnNdNormalWithKnownVariance()`  

            Default constructor.  

        * `plBayesLearnNdNormalWithKnownVariance(const plVariablesConjunction &variable,
            const plFloatVector &init_mu, const plFloatMatrix &init_sigma, const
            plFloatMatrix &sigma0)`  

            Creates a learnable normal distribution with fixed covariance martrix, where
            the prior over the Normal mean follows a Normal distribution.  

            Parameters:  
            * `variable` :  
                the variable of the learnt distribution.  
            * `init_mu` :  
                Initial value of the *mu* parameter of the Normal distribution over the
                learned Normal mean.  
            * `init_sigma` :  
                Initial value of the *sigma* parameter of the Normal distribution over
                the learned Normal mean. It must be strictly positive.  
            * `sigma0` :  
                Fixed covariance matrix of the learned Normal distribution.  

        """
        this = _probt_python3.new_plBayesLearnNdNormalWithKnownVariance(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this
    __swig_destroy__ = _probt_python3.delete_plBayesLearnNdNormalWithKnownVariance
    __del__ = lambda self: None

    def reset(self) -> "void":
        """
        reset(self)


        `reset()`  

        Resets learning (forgets all learned data).  

        """
        return _probt_python3.plBayesLearnNdNormalWithKnownVariance_reset(self)


    def get_mu(self) -> "plFloatVector const &":
        """
        get_mu(self) -> plFloatVector


        `get_mu() const -> const plFloatVector &`  

        Returns the current *mu* parameter of the Normal distribution over the learned
        Normal mean.  

        """
        return _probt_python3.plBayesLearnNdNormalWithKnownVariance_get_mu(self)


    def get_sigma(self) -> "plFloatMatrix const &":
        """
        get_sigma(self) -> plFloatMatrix


        `get_sigma() const -> const plFloatMatrix &`  

        Returns the current *sigma* parameter of the Normal distribution over the
        learned Normal mean.  

        """
        return _probt_python3.plBayesLearnNdNormalWithKnownVariance_get_sigma(self)


    def get_sigma0(self) -> "plFloatMatrix const &":
        """
        get_sigma0(self) -> plFloatMatrix


        `get_sigma0() const -> const plFloatMatrix &`  

        Returns the fixed parameter *sigma0* of the learned Normal distribution.  

        """
        return _probt_python3.plBayesLearnNdNormalWithKnownVariance_get_sigma0(self)


    def get_aposteriori_distribution(self, mu: 'plVariablesConjunction') -> "plDistribution":
        """
        get_aposteriori_distribution(self, mu) -> plDistribution


        `get_aposteriori_distribution(const plVariablesConjunction &mu) const ->
            plDistribution`  

        Returns the Normal distribution corresponding to the posterior distribution over
        the Normal mean *mu* knowing all learned data.  

        Parameters
        ----------
        * `mu` :  
            Variable that corresponds to the Normal mean, on which to build the
            posterior distribution. Must be a variable with a real type.  

        """
        return _probt_python3.plBayesLearnNdNormalWithKnownVariance_get_aposteriori_distribution(self, mu)


    def get_distribution(self) -> "plDistribution":
        """
        get_distribution(self) -> plDistribution


        `get_distribution() const -> plDistribution`  

        Returns the Normal distribution corresponding to the expected mean *mu*
        according to the learnt Normal distribution over the Normal mean, and the fixed
        covariance matrix *sigma0*.  

        """
        return _probt_python3.plBayesLearnNdNormalWithKnownVariance_get_distribution(self)


    def get_mu_sigma(self, mu: 'plFloatVector', sigma: 'plFloatMatrix') -> "void":
        """
        get_mu_sigma(self, mu, sigma)


        `get_mu_sigma(plFloatVector &mu, plFloatMatrix &sigma) const`  

        Returns the current *mu* and the *sigma* parameters of the Normal distribution
        over the learned Normal mean.  

        """
        return _probt_python3.plBayesLearnNdNormalWithKnownVariance_get_mu_sigma(self, mu, sigma)


    def add_point(self, *args) -> "bool":
        """
        add_point(self, point, weight=1.0) -> bool
        add_point(self, point) -> bool
        add_point(self, point, weight=1.0) -> bool
        add_point(self, point) -> bool
        add_point(self, point, weight=1.0) -> bool
        add_point(self, point) -> bool
        add_point(self, point, weight=1.0) -> bool
        add_point(self, point) -> bool
        add_point(self, point, weight=1.0) -> bool
        add_point(self, point) -> bool
        add_point(self, point, weight=1.0) -> bool
        add_point(self, point) -> bool
        add_point(self, point, weight=1.0) -> bool
        add_point(self, point) -> bool
        add_point(self, point, weight=1.0) -> bool
        add_point(self, point) -> bool
        add_point(self, point, weight=1.0) -> bool
        add_point(self, point) -> bool
        add_point(self, point, weight=1.0) -> bool
        add_point(self, point) -> bool
        add_point(self, point, weight=1.0) -> bool
        add_point(self, point) -> bool
        add_point(self, point, weight=1.0) -> bool
        add_point(self, point) -> bool
        add_point(self, point, weight=1.0) -> bool
        add_point(self, point) -> bool
        add_point(self, point, weight=1.0) -> bool
        add_point(self, point) -> bool
        add_point(self, point, weight=1.0) -> bool
        add_point(self, point) -> bool
        add_point(self, point, weight=1.0) -> bool
        add_point(self, point) -> bool
        add_point(self, point, is_defined, weight=1.0) -> bool
        add_point(self, point, is_defined) -> bool
        add_point(self, point, is_defined, weight=1.0) -> bool
        add_point(self, point, is_defined) -> bool
        add_point(self, point, is_defined, weight=1.0) -> bool
        add_point(self, point, is_defined) -> bool
        add_point(self, point, is_defined, weight=1.0) -> bool
        add_point(self, point, is_defined) -> bool
        add_point(self, point, is_defined, weight=1.0) -> bool
        add_point(self, point, is_defined) -> bool
        add_point(self, point, is_defined, weight=1.0) -> bool
        add_point(self, point, is_defined) -> bool
        add_point(self, point, is_defined, weight=1.0) -> bool
        add_point(self, point, is_defined) -> bool
        add_point(self, point, is_defined, weight=1.0) -> bool
        add_point(self, point, is_defined) -> bool
        add_point(self, point, is_defined, weight=1.0) -> bool
        add_point(self, point, is_defined) -> bool
        add_point(self, point, is_defined, weight=1.0) -> bool
        add_point(self, point, is_defined) -> bool
        add_point(self, point, is_defined, weight=1.0) -> bool
        add_point(self, point, is_defined) -> bool
        add_point(self, point, weight=1.0) -> bool
        add_point(self, point) -> bool


        `add_point(const plFloatVector &point, plFloat weight=PL_ONE) -> bool`  

        """
        return _probt_python3.plBayesLearnNdNormalWithKnownVariance_add_point(self, *args)


    def get_parameters(self, params: 'plValues') -> "void":
        """
        get_parameters(self, params)


        `get_parameters(plValues &params) const`  

        Returns all learnt parameters of the object (parameters passed to the
        distribution constructors when calling 'get_distribution').  

        This virtual method has to be implemented in all derived classes.  

        """
        return _probt_python3.plBayesLearnNdNormalWithKnownVariance_get_parameters(self, params)


    def get_n_parameters(self) -> "unsigned int":
        """
        get_n_parameters(self) -> unsigned int


        `get_n_parameters() const -> unsigned int`  

        Returns the ACTUAL number of parameters.  

        It could be different from the number of parameters returned by get_parameters.  

        For example, the actual number of parameters of a N dimensional normal
        distribution is N + N*(N+1)/2 because the covariance matrix is symmetric.  

        """
        return _probt_python3.plBayesLearnNdNormalWithKnownVariance_get_n_parameters(self)


    def clone(self) -> "plLearnObject *":
        """
        clone(self) -> plLearnObject


        `clone() const -> plLearnObject *`  

        Clone the learning object.  

        """
        return _probt_python3.plBayesLearnNdNormalWithKnownVariance_clone(self)


    def rescale_total_weight(self, s: 'plFloat') -> "void":
        """
        rescale_total_weight(self, s)


        `rescale_total_weight(plFloat s)`  

        Multiply the weight of the past inserted points by a given factor.  

        This allows, for example, to decrease the importance of the old data points
        compared to the new ones  

        """
        return _probt_python3.plBayesLearnNdNormalWithKnownVariance_rescale_total_weight(self, s)


    def __getstate__(self) -> "std::string":
        """__getstate__(self) -> std::string"""
        return _probt_python3.plBayesLearnNdNormalWithKnownVariance___getstate__(self)


    def __setstate_internal(self, sState: 'std::string const &') -> "void":
        """__setstate_internal(self, sState)"""
        return _probt_python3.plBayesLearnNdNormalWithKnownVariance___setstate_internal(self, sState)


    def __setstate__(self, sState):
        self.__init__()
        self.__setstate_internal(sState)

plBayesLearnNdNormalWithKnownVariance_swigregister = _probt_python3.plBayesLearnNdNormalWithKnownVariance_swigregister
plBayesLearnNdNormalWithKnownVariance_swigregister(plBayesLearnNdNormalWithKnownVariance)

class plBayesLearnPoisson(plBayesLearnObject):
    """

    `plBayesLearnPoisson(const plVariable &vars, plFloat init_alpha, plFloat
        init_lambda)`  
    `plBayesLearnPoisson()`  

    This class allows to make a Bayesian estimation of Poisson distributions.  

    To take advantage of the conjugacy property, the prior distribution is supposed
    to be a Gamma distribution and the a posteriori distribution is a Gamma
    distribution too.  

    Constructors
    ------------
    * `plBayesLearnPoisson(const plVariable &vars, plFloat init_alpha, plFloat
        init_lambda)`  

        Constructor using given initial values for the 'alpha' and 'lambda' (1/beta)
        parameters of the prior Gamma distribution.  


        The 'alpha' corresponds to the number of observed (supposed) number of
        events while 'lambda' corresponds on the time intervals number in which
        these events have been observed (supposed).  

    * `plBayesLearnPoisson()`  

        Empty constructor.  

    C++ includes: plBayesLearnPoisson.h

    """

    __swig_setmethods__ = {}
    for _s in [plBayesLearnObject]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plBayesLearnPoisson, name, value)
    __swig_getmethods__ = {}
    for _s in [plBayesLearnObject]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plBayesLearnPoisson, name)
    __repr__ = _swig_repr

    def __init__(self, *args):
        """
        __init__(self, vars, init_alpha, init_lambda) -> plBayesLearnPoisson
        __init__(self) -> plBayesLearnPoisson


        `plBayesLearnPoisson(const plVariable &vars, plFloat init_alpha, plFloat
            init_lambda)`  
        `plBayesLearnPoisson()`  

        Overloaded function
        -------------------
        * `plBayesLearnPoisson(const plVariable &vars, plFloat init_alpha, plFloat
            init_lambda)`  

            Constructor using given initial values for the 'alpha' and 'lambda' (1/beta)
            parameters of the prior Gamma distribution.  


            The 'alpha' corresponds to the number of observed (supposed) number of
            events while 'lambda' corresponds on the time intervals number in which
            these events have been observed (supposed).  

        * `plBayesLearnPoisson()`  

            Empty constructor.  

        """
        this = _probt_python3.new_plBayesLearnPoisson(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this
    __swig_destroy__ = _probt_python3.delete_plBayesLearnPoisson
    __del__ = lambda self: None

    def reset(self) -> "void":
        """
        reset(self)


        `reset()`  

        Resets learning.  

        """
        return _probt_python3.plBayesLearnPoisson_reset(self)


    def get_alpha(self) -> "plFloat":
        """
        get_alpha(self) -> plFloat


        `get_alpha() const -> plFloat`  

        Returns the 'alpha' parameter.  

        """
        return _probt_python3.plBayesLearnPoisson_get_alpha(self)


    def get_lambda(self) -> "plFloat":
        """
        get_lambda(self) -> plFloat


        `get_lambda() const -> plFloat`  

        Returns the 'lambda' parameter.  

        """
        return _probt_python3.plBayesLearnPoisson_get_lambda(self)


    def get_aposteriori_distribution(self, poisson_mean_variable: 'plVariablesConjunction') -> "plDistribution":
        """
        get_aposteriori_distribution(self, poisson_mean_variable) -> plDistribution


        `get_aposteriori_distribution(const plVariablesConjunction
            &poisson_mean_variable) const -> plDistribution`  

        Returns the Gamma distribution corresponding to the aposteriori distribution.  

        """
        return _probt_python3.plBayesLearnPoisson_get_aposteriori_distribution(self, poisson_mean_variable)


    def get_distribution(self) -> "plDistribution":
        """
        get_distribution(self) -> plDistribution


        `get_distribution() const -> plDistribution`  

        Returns the Poisson distribution corresponding to the learnt distribution.  

        The 'mean' parameter is the expectation of the a posteriori distribution.  

        """
        return _probt_python3.plBayesLearnPoisson_get_distribution(self)


    def get_a_posteriori_expectation(self) -> "plFloat":
        """
        get_a_posteriori_expectation(self) -> plFloat


        `get_a_posteriori_expectation() const -> plFloat`  

        Returns the expectation of the a posteriori distribution.  

        """
        return _probt_python3.plBayesLearnPoisson_get_a_posteriori_expectation(self)


    def get_parameters(self, params: 'plValues') -> "void":
        """
        get_parameters(self, params)


        `get_parameters(plValues &params) const`  

        Returns all learnt parameters of the object (parameters passed to the
        distribution constructors when calling 'get_distribution').  

        This virtual method has to be implemented in all derived classes.  

        """
        return _probt_python3.plBayesLearnPoisson_get_parameters(self, params)


    def get_n_parameters(self) -> "unsigned int":
        """
        get_n_parameters(self) -> unsigned int


        `get_n_parameters() const -> unsigned int`  

        Returns the ACTUAL number of parameters.  

        It could be different from the number of parameters returned by get_parameters.  

        For example, the actual number of parameters of a N dimensional normal
        distribution is N + N*(N+1)/2 because the covariance matrix is symmetric.  

        """
        return _probt_python3.plBayesLearnPoisson_get_n_parameters(self)


    def clone(self) -> "plLearnObject *":
        """
        clone(self) -> plLearnObject


        `clone() const -> plLearnObject *`  

        Clone the learning object.  

        """
        return _probt_python3.plBayesLearnPoisson_clone(self)


    def rescale_total_weight(self, s: 'plFloat') -> "void":
        """
        rescale_total_weight(self, s)


        `rescale_total_weight(plFloat s)`  

        Multiply the weight of the past inserted points by a given factor.  

        This allows, for example, to decrease the importance of the old data points
        compared to the new ones  

        """
        return _probt_python3.plBayesLearnPoisson_rescale_total_weight(self, s)


    def __getstate__(self) -> "std::string":
        """__getstate__(self) -> std::string"""
        return _probt_python3.plBayesLearnPoisson___getstate__(self)


    def __setstate_internal(self, sState: 'std::string const &') -> "void":
        """__setstate_internal(self, sState)"""
        return _probt_python3.plBayesLearnPoisson___setstate_internal(self, sState)


    def __setstate__(self, sState):
        self.__init__()
        self.__setstate_internal(sState)

plBayesLearnPoisson_swigregister = _probt_python3.plBayesLearnPoisson_swigregister
plBayesLearnPoisson_swigregister(plBayesLearnPoisson)

class plBayesLearnProbTable(plBayesLearnObject):
    """

    `plBayesLearnProbTable(const plVariablesConjunction &vars, const std::vector<
        plFloat > &init_alpha)`  
    `plBayesLearnProbTable()`  

    This class allows to make a Bayesian estimation of multinomial (ProbTable)
    distributions using Multinomial-Dirichlet conjugacy.  

    To take advantage of the conjugacy property, the prior distribution is supposed
    to be a Dirichlet distribution and the a posteriori distribution is a Dirichlet
    distribution too.  

    Constructors
    ------------
    * `plBayesLearnProbTable(const plVariablesConjunction &vars, const std::vector<
        plFloat > &init_alpha)`  

        Prepare to make a Bayesian estimation of a multinomial (ProbTable)
        distribution on variables *vars*.  

        The *init_alpha* array gives the initial values for the parameters of the
        Dirichlet prior used to estimate the multinomial (ProbTable). It represents
        the initial *virtual* numbers of observations for each possible value.  

        The a posteriori estimate is: \[ p_i = \frac {init\_alpha_i + n_i}
        {\sum_i init\_alpha_i + n_i}.\] where $ n_i $ is the number of
        observations (in the data) of the ith value.  

        Beware the dimension of *init_alpha!* See comments about Constructor2 of
        plProbTable.  

        See also: plLearnLaplace  

        See also: plLearnLidstone  

    * `plBayesLearnProbTable()`  

        Default constructor.  

    C++ includes: plBayesLearnProbTable.h

    """

    __swig_setmethods__ = {}
    for _s in [plBayesLearnObject]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plBayesLearnProbTable, name, value)
    __swig_getmethods__ = {}
    for _s in [plBayesLearnObject]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plBayesLearnProbTable, name)
    __repr__ = _swig_repr

    def __init__(self, *args):
        """
        __init__(self, vars, init_alpha) -> plBayesLearnProbTable
        __init__(self) -> plBayesLearnProbTable


        `plBayesLearnProbTable(const plVariablesConjunction &vars, const std::vector<
            plFloat > &init_alpha)`  
        `plBayesLearnProbTable()`  

        Overloaded function
        -------------------
        * `plBayesLearnProbTable(const plVariablesConjunction &vars, const std::vector<
            plFloat > &init_alpha)`  

            Prepare to make a Bayesian estimation of a multinomial (ProbTable)
            distribution on variables *vars*.  

            The *init_alpha* array gives the initial values for the parameters of the
            Dirichlet prior used to estimate the multinomial (ProbTable). It represents
            the initial *virtual* numbers of observations for each possible value.  

            The a posteriori estimate is: \[ p_i = \frac {init\_alpha_i + n_i}
            {\sum_i init\_alpha_i + n_i}.\] where $ n_i $ is the number of
            observations (in the data) of the ith value.  

            Beware the dimension of *init_alpha!* See comments about Constructor2 of
            plProbTable.  

            See also: plLearnLaplace  

            See also: plLearnLidstone  

        * `plBayesLearnProbTable()`  

            Default constructor.  

        """
        this = _probt_python3.new_plBayesLearnProbTable(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this
    __swig_destroy__ = _probt_python3.delete_plBayesLearnProbTable
    __del__ = lambda self: None

    def reset(self) -> "void":
        """
        reset(self)


        `reset()`  

        Resets learning.  

        """
        return _probt_python3.plBayesLearnProbTable_reset(self)


    def get_alpha(self) -> "std::vector< plFloat,std::allocator< plFloat > > const &":
        """
        get_alpha(self) -> DoubleVector


        `get_alpha() const -> const std::vector< plFloat > &`  

        Returns the 'alpha' parameters.  

        """
        return _probt_python3.plBayesLearnProbTable_get_alpha(self)


    def get_aposteriori_distribution(self, params_variable: 'plVariablesConjunction') -> "plDistribution":
        """
        get_aposteriori_distribution(self, params_variable) -> plDistribution


        `get_aposteriori_distribution(const plVariablesConjunction &params_variable)
            const -> plDistribution`  

        Returns the a posteriori Dirichlet distribution.  

        The *params_variable* dimension should be equal to this distribution
        cardinality.  

        """
        return _probt_python3.plBayesLearnProbTable_get_aposteriori_distribution(self, params_variable)


    def get_distribution(self) -> "plDistribution":
        """
        get_distribution(self) -> plDistribution


        `get_distribution() const -> plDistribution`  

        Returns the learnt ProbTable distribution.  

        """
        return _probt_python3.plBayesLearnProbTable_get_distribution(self)


    def get_parameters(self, params: 'plValues') -> "void":
        """
        get_parameters(self, params)


        `get_parameters(plValues &params) const`  

        Returns all learnt parameters of the object (parameters passed to the
        distribution constructors when calling 'get_distribution').  

        This virtual method has to be implemented in all derived classes.  

        """
        return _probt_python3.plBayesLearnProbTable_get_parameters(self, params)


    def get_n_parameters(self) -> "unsigned int":
        """
        get_n_parameters(self) -> unsigned int


        `get_n_parameters() const -> unsigned int`  

        Returns the ACTUAL number of parameters.  

        It could be different from the number of parameters returned by get_parameters.  

        For example, the actual number of parameters of a N dimensional normal
        distribution is N + N*(N+1)/2 because the covariance matrix is symmetric.  

        """
        return _probt_python3.plBayesLearnProbTable_get_n_parameters(self)


    def clone(self) -> "plLearnObject *":
        """
        clone(self) -> plLearnObject


        `clone() const -> plLearnObject *`  

        Clone the learning object.  

        """
        return _probt_python3.plBayesLearnProbTable_clone(self)


    def rescale_total_weight(self, s: 'plFloat') -> "void":
        """
        rescale_total_weight(self, s)


        `rescale_total_weight(plFloat s)`  

        Multiply the weight of the past inserted points by a given factor.  

        This allows, for example, to decrease the importance of the old data points
        compared to the new ones  

        """
        return _probt_python3.plBayesLearnProbTable_rescale_total_weight(self, s)


    def __getstate__(self) -> "std::string":
        """__getstate__(self) -> std::string"""
        return _probt_python3.plBayesLearnProbTable___getstate__(self)


    def __setstate_internal(self, sState: 'std::string const &') -> "void":
        """__setstate_internal(self, sState)"""
        return _probt_python3.plBayesLearnProbTable___setstate_internal(self, sState)


    def __setstate__(self, sState):
        self.__init__()
        self.__setstate_internal(sState)

plBayesLearnProbTable_swigregister = _probt_python3.plBayesLearnProbTable_swigregister
plBayesLearnProbTable_swigregister(plBayesLearnProbTable)

class plLearn1dNormal(plMLLearnObject):
    """

    `plLearn1dNormal(const plVariable &vars)`  
    `plLearn1dNormal(const plVariable &vars, plFloat init_mean, plFloat
        init_std_dev, plFloat init_weight=PL_ONE)`  
    `plLearn1dNormal()`  

    This class allows to learn one-dimensional Normal (Gaussian) distributions.  

    Constructors
    ------------
    * `plLearn1dNormal(const plVariable &vars)`  

        Constructor using a given variable.  

    * `plLearn1dNormal(const plVariable &vars, plFloat init_mean, plFloat
        init_std_dev, plFloat init_weight=PL_ONE)`  

        Constructor using a set of variables, an initial mean, initial covariance,
        and an initial weight .  

    * `plLearn1dNormal()`  

        Void default constructor.  

    C++ includes: plLearn1dNormal.h

    """

    __swig_setmethods__ = {}
    for _s in [plMLLearnObject]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plLearn1dNormal, name, value)
    __swig_getmethods__ = {}
    for _s in [plMLLearnObject]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plLearn1dNormal, name)
    __repr__ = _swig_repr

    def __init__(self, *args):
        """
        __init__(self, vars) -> plLearn1dNormal
        __init__(self, vars, init_mean, init_std_dev, init_weight=1.0) -> plLearn1dNormal
        __init__(self, vars, init_mean, init_std_dev) -> plLearn1dNormal
        __init__(self) -> plLearn1dNormal


        `plLearn1dNormal(const plVariable &vars)`  
        `plLearn1dNormal(const plVariable &vars, plFloat init_mean, plFloat
            init_std_dev, plFloat init_weight=PL_ONE)`  
        `plLearn1dNormal()`  

        Overloaded function
        -------------------
        * `plLearn1dNormal(const plVariable &vars)`  

            Constructor using a given variable.  

        * `plLearn1dNormal(const plVariable &vars, plFloat init_mean, plFloat
            init_std_dev, plFloat init_weight=PL_ONE)`  

            Constructor using a set of variables, an initial mean, initial covariance,
            and an initial weight .  

        * `plLearn1dNormal()`  

            Void default constructor.  

        """
        this = _probt_python3.new_plLearn1dNormal(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this
    __swig_destroy__ = _probt_python3.delete_plLearn1dNormal
    __del__ = lambda self: None

    def reset(self) -> "void":
        """
        reset(self)


        `reset()`  

        Resets learning.  

        """
        return _probt_python3.plLearn1dNormal_reset(self)


    def clone(self) -> "plLearnObject *":
        """
        clone(self) -> plLearnObject


        `clone() const -> plLearnObject *`  

        Clone the learning object.  

        """
        return _probt_python3.plLearn1dNormal_clone(self)


    def get_mu(self) -> "plFloat":
        """
        get_mu(self) -> plFloat


        `get_mu() const -> plFloat`  

        Returns the mean value.  

        """
        return _probt_python3.plLearn1dNormal_get_mu(self)


    def get_var(self) -> "plFloat":
        """
        get_var(self) -> plFloat


        `get_var() const -> plFloat`  

        Returns the variance value.  

        """
        return _probt_python3.plLearn1dNormal_get_var(self)


    def get_sigma(self) -> "plFloat":
        """
        get_sigma(self) -> plFloat


        `get_sigma() const -> plFloat`  

        Returns the sigma (standard deviation) value.  

        """
        return _probt_python3.plLearn1dNormal_get_sigma(self)


    def get_actual_min_max(self, min: 'plFloat &', max: 'plFloat &', cumul_prob: 'plProbValue'=0.95) -> "void":
        """
        get_actual_min_max(self, min, max, cumul_prob=0.95)
        get_actual_min_max(self, min, max)


        `get_actual_min_max(plFloat &min, plFloat &max, plProbValue cumul_prob=0.95)
            const`  

        Returns the [min, max[ range allowing to cover a total cumulated probability of
        *cumul_prob* (i.e., leaving outside the [min, max[ range a total cumulated
        probability of 1 - *cumul_pro*) according to the current estimate of the mean
        and variance.  

        """
        return _probt_python3.plLearn1dNormal_get_actual_min_max(self, min, max, cumul_prob)


    def get_distribution(self) -> "plDistribution":
        """
        get_distribution(self) -> plDistribution


        `get_distribution() const -> plDistribution`  

        Returns the normal corresponding to the learnt distribution.  

        """
        return _probt_python3.plLearn1dNormal_get_distribution(self)


    def get_parameters(self, params: 'plValues') -> "void":
        """
        get_parameters(self, params)


        `get_parameters(plValues &params) const`  

        Returns all learnt parameters of the object (parameters passed to the
        distribution constructors when calling 'get_distribution').  

        This virtual method has to be implemented in all derived classes.  

        """
        return _probt_python3.plLearn1dNormal_get_parameters(self, params)


    def get_n_parameters(self) -> "unsigned int":
        """
        get_n_parameters(self) -> unsigned int


        `get_n_parameters() const -> unsigned int`  

        Returns the ACTUAL number of parameters.  

        It could be different from the number of parameters returned by get_parameters.  

        For example, the actual number of parameters of a N dimensional normal
        distribution is N + N*(N+1)/2 because the covariance matrix is symmetric.  

        """
        return _probt_python3.plLearn1dNormal_get_n_parameters(self)


    def rescale_total_weight(self, s: 'plFloat') -> "void":
        """
        rescale_total_weight(self, s)


        `rescale_total_weight(plFloat s)`  

        Multiply the weight of the past inserted points by a given factor.  

        This allows, for example, to decrease the importance of the old data points
        compared to the new ones  

        """
        return _probt_python3.plLearn1dNormal_rescale_total_weight(self, s)


    def __getstate__(self) -> "std::string":
        """__getstate__(self) -> std::string"""
        return _probt_python3.plLearn1dNormal___getstate__(self)


    def __setstate_internal(self, sState: 'std::string const &') -> "void":
        """__setstate_internal(self, sState)"""
        return _probt_python3.plLearn1dNormal___setstate_internal(self, sState)


    def __setstate__(self, sState):
        self.__init__()
        self.__setstate_internal(sState)

plLearn1dNormal_swigregister = _probt_python3.plLearn1dNormal_swigregister
plLearn1dNormal_swigregister(plLearn1dNormal)

class plLearnBeta(plMLLearnObject):
    """

    `plLearnBeta(const plVariable &vars, plFloat a=PL_ZERO, plFloat b=PL_ONE)`  
    `plLearnBeta()`  

    This class allows to learn Beta distributions.  

    Learning concerns exclusively the *p* and *q* parameters. The *a* and *b* range
    parameters are assumed known.  

    Constructors
    ------------
    * `plLearnBeta(const plVariable &vars, plFloat a=PL_ZERO, plFloat b=PL_ONE)`  

        Constructor.  

    * `plLearnBeta()`  

        Default constructor.  

    C++ includes: plLearnBeta.h

    """

    __swig_setmethods__ = {}
    for _s in [plMLLearnObject]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plLearnBeta, name, value)
    __swig_getmethods__ = {}
    for _s in [plMLLearnObject]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plLearnBeta, name)
    __repr__ = _swig_repr

    def __init__(self, *args):
        """
        __init__(self, vars, a=0.0, b=1.0) -> plLearnBeta
        __init__(self, vars, a=0.0) -> plLearnBeta
        __init__(self, vars) -> plLearnBeta
        __init__(self) -> plLearnBeta


        `plLearnBeta(const plVariable &vars, plFloat a=PL_ZERO, plFloat b=PL_ONE)`  
        `plLearnBeta()`  

        Overloaded function
        -------------------
        * `plLearnBeta(const plVariable &vars, plFloat a=PL_ZERO, plFloat b=PL_ONE)`  

            Constructor.  

        * `plLearnBeta()`  

            Default constructor.  

        """
        this = _probt_python3.new_plLearnBeta(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this
    __swig_destroy__ = _probt_python3.delete_plLearnBeta
    __del__ = lambda self: None

    def reset(self) -> "void":
        """
        reset(self)


        `reset()`  

        Resets learning.  

        """
        return _probt_python3.plLearnBeta_reset(self)


    def set_range(self, a: 'plFloat', b: 'plFloat') -> "void":
        """
        set_range(self, a, b)


        `set_range(plFloat a, plFloat b)`  

        Sets the range parameters.  

        """
        return _probt_python3.plLearnBeta_set_range(self, a, b)


    def get_range(self, a: 'plFloat &', b: 'plFloat &') -> "void":
        """
        get_range(self, a, b)


        `get_range(plFloat &a, plFloat &b) const`  

        Returns the range parameters.  

        """
        return _probt_python3.plLearnBeta_get_range(self, a, b)


    def get_p(self) -> "plFloat":
        """
        get_p(self) -> plFloat


        `get_p() const -> plFloat`  

        Returns the 'p' parameter.  

        """
        return _probt_python3.plLearnBeta_get_p(self)


    def get_q(self) -> "plFloat":
        """
        get_q(self) -> plFloat


        `get_q() const -> plFloat`  

        Returns the 'q' parameter.  

        """
        return _probt_python3.plLearnBeta_get_q(self)


    def get_distribution(self) -> "plDistribution":
        """
        get_distribution(self) -> plDistribution


        `get_distribution() const -> plDistribution`  

        Returns the learnt Beta distribution.  

        """
        return _probt_python3.plLearnBeta_get_distribution(self)


    def get_parameters(self, params: 'plValues') -> "void":
        """
        get_parameters(self, params)


        `get_parameters(plValues &params) const`  

        Returns all learnt parameters of the object (parameters passed to the
        distribution constructors when calling 'get_distribution').  

        This virtual method has to be implemented in all derived classes.  

        """
        return _probt_python3.plLearnBeta_get_parameters(self, params)


    def get_n_parameters(self) -> "unsigned int":
        """
        get_n_parameters(self) -> unsigned int


        `get_n_parameters() const -> unsigned int`  

        Returns the ACTUAL number of parameters.  

        It could be different from the number of parameters returned by get_parameters.  

        For example, the actual number of parameters of a N dimensional normal
        distribution is N + N*(N+1)/2 because the covariance matrix is symmetric.  

        """
        return _probt_python3.plLearnBeta_get_n_parameters(self)


    def clone(self) -> "plLearnObject *":
        """
        clone(self) -> plLearnObject


        `clone() const -> plLearnObject *`  

        Clone the learning object.  

        """
        return _probt_python3.plLearnBeta_clone(self)


    def rescale_total_weight(self, s: 'plFloat') -> "void":
        """
        rescale_total_weight(self, s)


        `rescale_total_weight(plFloat s)`  

        Multiply the weight of the past inserted points by a given factor.  

        This allows, for example, to decrease the importance of the old data points
        compared to the new ones  

        """
        return _probt_python3.plLearnBeta_rescale_total_weight(self, s)


    def __getstate__(self) -> "std::string":
        """__getstate__(self) -> std::string"""
        return _probt_python3.plLearnBeta___getstate__(self)


    def __setstate_internal(self, sState: 'std::string const &') -> "void":
        """__setstate_internal(self, sState)"""
        return _probt_python3.plLearnBeta___setstate_internal(self, sState)


    def __setstate__(self, sState):
        self.__init__()
        self.__setstate_internal(sState)

plLearnBeta_swigregister = _probt_python3.plLearnBeta_swigregister
plLearnBeta_swigregister(plLearnBeta)

class plLearnExponential(plMLLearnObject):
    """

    `plLearnExponential(const plVariable &vars, plFloat min_value, plFloat
        init_mean, plFloat init_weight=PL_ONE)`  
    `plLearnExponential(const plVariable &vars)`  
    `plLearnExponential()`  

    This class allows to learn exponential distributions.  

    Constructors
    ------------
    * `plLearnExponential(const plVariable &vars, plFloat min_value, plFloat
        init_mean, plFloat init_weight=PL_ONE)`  

        Constructor using a set of variables, the min value, the initial mean, and
        the corresponding initial weight .  

    * `plLearnExponential(const plVariable &vars)`  

        Constructor using a set of variables.  

    * `plLearnExponential()`  

        Default constructor needed for deserialization.  

    C++ includes: plLearnExponential.h

    """

    __swig_setmethods__ = {}
    for _s in [plMLLearnObject]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plLearnExponential, name, value)
    __swig_getmethods__ = {}
    for _s in [plMLLearnObject]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plLearnExponential, name)
    __repr__ = _swig_repr

    def __init__(self, *args):
        """
        __init__(self, vars, min_value, init_mean, init_weight=1.0) -> plLearnExponential
        __init__(self, vars, min_value, init_mean) -> plLearnExponential
        __init__(self, vars) -> plLearnExponential
        __init__(self) -> plLearnExponential


        `plLearnExponential(const plVariable &vars, plFloat min_value, plFloat
            init_mean, plFloat init_weight=PL_ONE)`  
        `plLearnExponential(const plVariable &vars)`  
        `plLearnExponential()`  

        Overloaded function
        -------------------
        * `plLearnExponential(const plVariable &vars, plFloat min_value, plFloat
            init_mean, plFloat init_weight=PL_ONE)`  

            Constructor using a set of variables, the min value, the initial mean, and
            the corresponding initial weight .  

        * `plLearnExponential(const plVariable &vars)`  

            Constructor using a set of variables.  

        * `plLearnExponential()`  

            Default constructor needed for deserialization.  

        """
        this = _probt_python3.new_plLearnExponential(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this
    __swig_destroy__ = _probt_python3.delete_plLearnExponential
    __del__ = lambda self: None

    def reset(self) -> "void":
        """
        reset(self)


        `reset()`  

        Resets learning.  

        """
        return _probt_python3.plLearnExponential_reset(self)


    def get_mu(self) -> "plFloat":
        """
        get_mu(self) -> plFloat


        `get_mu() const -> plFloat`  

        Returns the 'mu' parameter.  

        """
        return _probt_python3.plLearnExponential_get_mu(self)


    def get_beta(self) -> "plFloat":
        """
        get_beta(self) -> plFloat


        `get_beta() const -> plFloat`  

        Returns the 'beta' parameter.  

        """
        return _probt_python3.plLearnExponential_get_beta(self)


    def get_distribution(self) -> "plDistribution":
        """
        get_distribution(self) -> plDistribution


        `get_distribution() const -> plDistribution`  

        Returns the exponential distribution corresponding to the learnt distribution.  

        """
        return _probt_python3.plLearnExponential_get_distribution(self)


    def get_parameters(self, params: 'plValues') -> "void":
        """
        get_parameters(self, params)


        `get_parameters(plValues &params) const`  

        Returns all learnt parameters of the object (parameters passed to the
        distribution constructors when calling 'get_distribution').  

        This virtual method has to be implemented in all derived classes.  

        """
        return _probt_python3.plLearnExponential_get_parameters(self, params)


    def get_n_parameters(self) -> "unsigned int":
        """
        get_n_parameters(self) -> unsigned int


        `get_n_parameters() const -> unsigned int`  

        Returns the ACTUAL number of parameters.  

        It could be different from the number of parameters returned by get_parameters.  

        For example, the actual number of parameters of a N dimensional normal
        distribution is N + N*(N+1)/2 because the covariance matrix is symmetric.  

        """
        return _probt_python3.plLearnExponential_get_n_parameters(self)


    def clone(self) -> "plLearnObject *":
        """
        clone(self) -> plLearnObject


        `clone() const -> plLearnObject *`  

        Clone the learning object.  

        """
        return _probt_python3.plLearnExponential_clone(self)


    def rescale_total_weight(self, s: 'plFloat') -> "void":
        """
        rescale_total_weight(self, s)


        `rescale_total_weight(plFloat s)`  

        Multiply the weight of the past inserted points by a given factor.  

        This allows, for example, to decrease the importance of the old data points
        compared to the new ones  

        """
        return _probt_python3.plLearnExponential_rescale_total_weight(self, s)


    def __getstate__(self) -> "std::string":
        """__getstate__(self) -> std::string"""
        return _probt_python3.plLearnExponential___getstate__(self)


    def __setstate_internal(self, sState: 'std::string const &') -> "void":
        """__setstate_internal(self, sState)"""
        return _probt_python3.plLearnExponential___setstate_internal(self, sState)


    def __setstate__(self, sState):
        self.__init__()
        self.__setstate_internal(sState)

plLearnExponential_swigregister = _probt_python3.plLearnExponential_swigregister
plLearnExponential_swigregister(plLearnExponential)

class plLearnGamma(plMLLearnObject):
    """

    `plLearnGamma(const plVariable &vars, plFloat mu=PL_ZERO)`  
    `plLearnGamma()`  

    This class implements Gamma distributions ML learning.  

    Constructors
    ------------
    * `plLearnGamma(const plVariable &vars, plFloat mu=PL_ZERO)`  

        Constructor using a given variable.  

    * `plLearnGamma()`  

        Default constructor.  

    C++ includes: plLearnGamma.h

    """

    __swig_setmethods__ = {}
    for _s in [plMLLearnObject]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plLearnGamma, name, value)
    __swig_getmethods__ = {}
    for _s in [plMLLearnObject]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plLearnGamma, name)
    __repr__ = _swig_repr

    def __init__(self, *args):
        """
        __init__(self, vars, mu=0.0) -> plLearnGamma
        __init__(self, vars) -> plLearnGamma
        __init__(self) -> plLearnGamma


        `plLearnGamma(const plVariable &vars, plFloat mu=PL_ZERO)`  
        `plLearnGamma()`  

        Overloaded function
        -------------------
        * `plLearnGamma(const plVariable &vars, plFloat mu=PL_ZERO)`  

            Constructor using a given variable.  

        * `plLearnGamma()`  

            Default constructor.  

        """
        this = _probt_python3.new_plLearnGamma(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this
    __swig_destroy__ = _probt_python3.delete_plLearnGamma
    __del__ = lambda self: None

    def reset(self) -> "void":
        """
        reset(self)


        `reset()`  

        Resets learning.  

        """
        return _probt_python3.plLearnGamma_reset(self)


    def get_a(self) -> "plFloat":
        """
        get_a(self) -> plFloat


        `get_a() const -> plFloat`  

        Returns the 'a' parameter.  

        """
        return _probt_python3.plLearnGamma_get_a(self)


    def get_b(self) -> "plFloat":
        """
        get_b(self) -> plFloat


        `get_b() const -> plFloat`  

        Returns the 'b' parameter.  

        """
        return _probt_python3.plLearnGamma_get_b(self)


    def get_distribution(self) -> "plDistribution":
        """
        get_distribution(self) -> plDistribution


        `get_distribution() const -> plDistribution`  

        Returns the the learnt Gamma distribution.  

        """
        return _probt_python3.plLearnGamma_get_distribution(self)


    def get_parameters(self, params: 'plValues') -> "void":
        """
        get_parameters(self, params)


        `get_parameters(plValues &params) const`  

        Returns all learnt parameters of the object (parameters passed to the
        distribution constructors when calling 'get_distribution').  

        This virtual method has to be implemented in all derived classes.  

        """
        return _probt_python3.plLearnGamma_get_parameters(self, params)


    def get_n_parameters(self) -> "unsigned int":
        """
        get_n_parameters(self) -> unsigned int


        `get_n_parameters() const -> unsigned int`  

        Returns the ACTUAL number of parameters.  

        It could be different from the number of parameters returned by get_parameters.  

        For example, the actual number of parameters of a N dimensional normal
        distribution is N + N*(N+1)/2 because the covariance matrix is symmetric.  

        """
        return _probt_python3.plLearnGamma_get_n_parameters(self)


    def clone(self) -> "plLearnObject *":
        """
        clone(self) -> plLearnObject


        `clone() const -> plLearnObject *`  

        Clone the learning object.  

        """
        return _probt_python3.plLearnGamma_clone(self)


    def rescale_total_weight(self, s: 'plFloat') -> "void":
        """
        rescale_total_weight(self, s)


        `rescale_total_weight(plFloat s)`  

        Multiply the weight of the past inserted points by a given factor.  

        This allows, for example, to decrease the importance of the old data points
        compared to the new ones  

        """
        return _probt_python3.plLearnGamma_rescale_total_weight(self, s)


    def __getstate__(self) -> "std::string":
        """__getstate__(self) -> std::string"""
        return _probt_python3.plLearnGamma___getstate__(self)


    def __setstate_internal(self, sState: 'std::string const &') -> "void":
        """__setstate_internal(self, sState)"""
        return _probt_python3.plLearnGamma___setstate_internal(self, sState)


    def __setstate__(self, sState):
        self.__init__()
        self.__setstate_internal(sState)

plLearnGamma_swigregister = _probt_python3.plLearnGamma_swigregister
plLearnGamma_swigregister(plLearnGamma)

class plLearnHistogram(plMLLearnObject):
    """

    `plLearnHistogram()`  
    `plLearnHistogram(const plVariablesConjunction &vars)`  
    `plLearnHistogram(const plVariablesConjunction &vars, arrayType init_freq,
        plFloat init_weight=PL_ONE)`  
    `plLearnHistogram(const plVariablesConjunction &vars, const std::vector<
        unsigned int > &init_freq, plFloat init_weight=PL_ONE)`  
    `plLearnHistogram(const plVariablesConjunction &vars, const std::vector< plFloat
        > &init_freq, plFloat init_weight=PL_ONE)`  

    The class for learning n dimensionnal histograms.  

    Constructors
    ------------
    * `plLearnHistogram()`  

        Default constructor.  

    * `plLearnHistogram(const plVariablesConjunction &vars)`  

        Constructor using a set of variables.  

    * `plLearnHistogram(const plVariablesConjunction &vars, arrayType init_freq,
        plFloat init_weight=PL_ONE)`  

        Constructor using a set of variables, initial frequencies, and an initial
        weight.  

    * `plLearnHistogram(const plVariablesConjunction &vars, const std::vector<
        unsigned int > &init_freq, plFloat init_weight=PL_ONE)`  

    * `plLearnHistogram(const plVariablesConjunction &vars, const std::vector<
        plFloat > &init_freq, plFloat init_weight=PL_ONE)`  

    C++ includes: plLearnHistogram.h

    """

    __swig_setmethods__ = {}
    for _s in [plMLLearnObject]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plLearnHistogram, name, value)
    __swig_getmethods__ = {}
    for _s in [plMLLearnObject]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plLearnHistogram, name)
    __repr__ = _swig_repr

    def __init__(self, *args):
        """
        __init__(self) -> plLearnHistogram
        __init__(self, vars) -> plLearnHistogram
        __init__(self, vars, init_freq, init_weight=1.0) -> plLearnHistogram
        __init__(self, vars, init_freq) -> plLearnHistogram
        __init__(self, vars, init_freq, init_weight=1.0) -> plLearnHistogram
        __init__(self, vars, init_freq) -> plLearnHistogram


        `plLearnHistogram()`  
        `plLearnHistogram(const plVariablesConjunction &vars)`  
        `plLearnHistogram(const plVariablesConjunction &vars, arrayType init_freq,
            plFloat init_weight=PL_ONE)`  
        `plLearnHistogram(const plVariablesConjunction &vars, const std::vector<
            unsigned int > &init_freq, plFloat init_weight=PL_ONE)`  
        `plLearnHistogram(const plVariablesConjunction &vars, const std::vector< plFloat
            > &init_freq, plFloat init_weight=PL_ONE)`  

        Overloaded function
        -------------------
        * `plLearnHistogram()`  

            Default constructor.  

        * `plLearnHistogram(const plVariablesConjunction &vars)`  

            Constructor using a set of variables.  

        * `plLearnHistogram(const plVariablesConjunction &vars, arrayType init_freq,
            plFloat init_weight=PL_ONE)`  

            Constructor using a set of variables, initial frequencies, and an initial
            weight.  

        * `plLearnHistogram(const plVariablesConjunction &vars, const std::vector<
            unsigned int > &init_freq, plFloat init_weight=PL_ONE)`  

        * `plLearnHistogram(const plVariablesConjunction &vars, const std::vector<
            plFloat > &init_freq, plFloat init_weight=PL_ONE)`  

        """
        this = _probt_python3.new_plLearnHistogram(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this
    __swig_destroy__ = _probt_python3.delete_plLearnHistogram
    __del__ = lambda self: None

    def reset(self) -> "void":
        """
        reset(self)


        `reset()`  

        Resets learning.  

        """
        return _probt_python3.plLearnHistogram_reset(self)


    def get_distribution(self) -> "plDistribution":
        """
        get_distribution(self) -> plDistribution


        `get_distribution() const -> plDistribution`  

        Returns the probability table corresponding to the learnt distribution.  

        """
        return _probt_python3.plLearnHistogram_get_distribution(self)


    def get_frequency(self) -> "std::vector< plFloat,std::allocator< plFloat > > const &":
        """
        get_frequency(self) -> DoubleVector


        `get_frequency(T *table) const`  
        `get_frequency(std::vector< T > &table) const`  
        `get_frequency() const -> const std::vector< plFloat > &`  

        Overloaded function
        -------------------
        * `get_frequency(T *table) const`  

            Returns the frequency table corresponding to the learnt distribution in the
            output parameter 'table'.  

            Supposes that 'table' has the exact size.  

        * `get_frequency(std::vector< T > &table) const`  

            Returns the frequency table corresponding to the learnt distribution in the
            output parameter 'table'.  

        * `get_frequency() const -> const std::vector< plFloat > &`  

            Returns a constant reference to the frequency table corresponding to the
            learnt distribution.  

        """
        return _probt_python3.plLearnHistogram_get_frequency(self)


    def get_actual_min_max(self, min: 'plValues', max: 'plValues') -> "void":
        """
        get_actual_min_max(self, min, max)


        `get_actual_min_max(plValues &min, plValues &max) const`  

        Returns the actual range of the head variables according to the learnt points.  

        """
        return _probt_python3.plLearnHistogram_get_actual_min_max(self, min, max)


    def size(self) -> "size_t":
        """
        size(self) -> size_t


        `size() const -> size_t`  

        Returns the size of the histogram (number of bins).  

        """
        return _probt_python3.plLearnHistogram_size(self)


    def get_parameters(self, params: 'plValues') -> "void":
        """
        get_parameters(self, params)


        `get_parameters(plValues &params) const`  

        Returns all learnt parameters of the object (parameters passed to the
        distribution constructors when calling 'get_distribution').  

        This virtual method has to be implemented in all derived classes.  

        """
        return _probt_python3.plLearnHistogram_get_parameters(self, params)


    def get_n_parameters(self) -> "unsigned int":
        """
        get_n_parameters(self) -> unsigned int


        `get_n_parameters() const -> unsigned int`  

        Returns the ACTUAL number of parameters.  

        It could be different from the number of parameters returned by get_parameters.  

        For example, the actual number of parameters of a N dimensional normal
        distribution is N + N*(N+1)/2 because the covariance matrix is symmetric.  

        """
        return _probt_python3.plLearnHistogram_get_n_parameters(self)


    def clone(self) -> "plLearnObject *":
        """
        clone(self) -> plLearnObject


        `clone() const -> plLearnObject *`  

        Clone the learning object.  

        """
        return _probt_python3.plLearnHistogram_clone(self)


    def rescale_total_weight(self, s: 'plFloat') -> "void":
        """
        rescale_total_weight(self, s)


        `rescale_total_weight(plFloat s)`  

        Multiply the weight of the past inserted points by a given factor.  

        This allows, for example, to decrease the importance of the old data points
        compared to the new ones  

        """
        return _probt_python3.plLearnHistogram_rescale_total_weight(self, s)


    def __getstate__(self) -> "std::string":
        """__getstate__(self) -> std::string"""
        return _probt_python3.plLearnHistogram___getstate__(self)


    def __setstate_internal(self, sState: 'std::string const &') -> "void":
        """__setstate_internal(self, sState)"""
        return _probt_python3.plLearnHistogram___setstate_internal(self, sState)


    def __setstate__(self, sState):
        self.__init__()
        self.__setstate_internal(sState)

plLearnHistogram_swigregister = _probt_python3.plLearnHistogram_swigregister
plLearnHistogram_swigregister(plLearnHistogram)

class plLearnLidstone(plBayesLearnProbTable):
    """

    `plLearnLidstone()`  
    `plLearnLidstone(const plVariablesConjunction &vars, plFloat alpha=PL_ONE)`  

    This class allows to make a Bayesian estimation of multinomial (ProbTable)
    distributions using Lidstone's formula.  

    This is a special case of the Multinomial-Dirichlet conjugacy in which all the
    initial values for the parameters of the Dirichlet prior are set to $ \alpha $.
    In other words, each possible value is supposed to be *virtually* observed $
    \alpha $ times (before using data).  

    The a posteriori estimate is: \[ p_i = \frac {\alpha + n_i} { \sum_i \alpha
    + n_i}.\] where $ n_i $ is the number of observations (in the data) of the ith
    value.  

    See also: plBayesLearnProbTable  

    See also: plLearnLaplace  

    Constructors
    ------------
    * `plLearnLidstone()`  

        Default constructor.  

    * `plLearnLidstone(const plVariablesConjunction &vars, plFloat alpha=PL_ONE)`  

        Constructor using a set of variables, with parameter alpha.  

    C++ includes: plLearnLidstone.h

    """

    __swig_setmethods__ = {}
    for _s in [plBayesLearnProbTable]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plLearnLidstone, name, value)
    __swig_getmethods__ = {}
    for _s in [plBayesLearnProbTable]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plLearnLidstone, name)
    __repr__ = _swig_repr

    def __init__(self, *args):
        """
        __init__(self) -> plLearnLidstone
        __init__(self, vars, alpha=1.0) -> plLearnLidstone
        __init__(self, vars) -> plLearnLidstone


        `plLearnLidstone()`  
        `plLearnLidstone(const plVariablesConjunction &vars, plFloat alpha=PL_ONE)`  

        Overloaded function
        -------------------
        * `plLearnLidstone()`  

            Default constructor.  

        * `plLearnLidstone(const plVariablesConjunction &vars, plFloat alpha=PL_ONE)`  

            Constructor using a set of variables, with parameter alpha.  

        """
        this = _probt_python3.new_plLearnLidstone(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this
    __swig_destroy__ = _probt_python3.delete_plLearnLidstone
    __del__ = lambda self: None

    def clone(self) -> "plLearnObject *":
        """
        clone(self) -> plLearnObject


        `clone() const -> plLearnObject *`  

        Clone the learning object.  

        """
        return _probt_python3.plLearnLidstone_clone(self)


    def __getstate__(self) -> "std::string":
        """__getstate__(self) -> std::string"""
        return _probt_python3.plLearnLidstone___getstate__(self)


    def __setstate_internal(self, sState: 'std::string const &') -> "void":
        """__setstate_internal(self, sState)"""
        return _probt_python3.plLearnLidstone___setstate_internal(self, sState)


    def __setstate__(self, sState):
        self.__init__()
        self.__setstate_internal(sState)

plLearnLidstone_swigregister = _probt_python3.plLearnLidstone_swigregister
plLearnLidstone_swigregister(plLearnLidstone)

class plLearnLaplace(plLearnLidstone):
    """

    `plLearnLaplace()`  
    `plLearnLaplace(const plVariablesConjunction &vars)`  

    This class allows to make a Bayesian estimation of multinomial (ProbTable)
    distributions using Laplace's formula.  

    This is a special case of the Multinomial-Dirichlet conjugacy in which all the
    initial values for the parameters of the Dirichlet prior are set to 1. In other
    words, each possible value is supposed to be *virtually* observed once (before
    using data).  

    The a posteriori estimate is: \[ p_i = \frac {1 + n_i} {\sum_i 1 + n_i}.\]
    where $ n_i $ is the number of observations (in the data) of the ith value.  

    See also: plBayesLearnProbTable  

    See also: plLearnLidstone  

    Constructors
    ------------
    * `plLearnLaplace()`  

        Default constructor.  

    * `plLearnLaplace(const plVariablesConjunction &vars)`  

        Constructor using a set of variables.  

    C++ includes: plLearnLaplace.h

    """

    __swig_setmethods__ = {}
    for _s in [plLearnLidstone]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plLearnLaplace, name, value)
    __swig_getmethods__ = {}
    for _s in [plLearnLidstone]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plLearnLaplace, name)
    __repr__ = _swig_repr

    def __init__(self, *args):
        """
        __init__(self) -> plLearnLaplace
        __init__(self, vars) -> plLearnLaplace


        `plLearnLaplace()`  
        `plLearnLaplace(const plVariablesConjunction &vars)`  

        Overloaded function
        -------------------
        * `plLearnLaplace()`  

            Default constructor.  

        * `plLearnLaplace(const plVariablesConjunction &vars)`  

            Constructor using a set of variables.  

        """
        this = _probt_python3.new_plLearnLaplace(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this
    __swig_destroy__ = _probt_python3.delete_plLearnLaplace
    __del__ = lambda self: None

    def clone(self) -> "plLearnObject *":
        """
        clone(self) -> plLearnObject


        `clone() const -> plLearnObject *`  

        Clone the learning object.  

        """
        return _probt_python3.plLearnLaplace_clone(self)


    def __getstate__(self) -> "std::string":
        """__getstate__(self) -> std::string"""
        return _probt_python3.plLearnLaplace___getstate__(self)


    def __setstate_internal(self, sState: 'std::string const &') -> "void":
        """__setstate_internal(self, sState)"""
        return _probt_python3.plLearnLaplace___setstate_internal(self, sState)


    def __setstate__(self, sState):
        self.__init__()
        self.__setstate_internal(sState)

plLearnLaplace_swigregister = _probt_python3.plLearnLaplace_swigregister
plLearnLaplace_swigregister(plLearnLaplace)

class plLearnLogNormal(plMLLearnObject):
    """

    `plLearnLogNormal(const plVariable &vars, plFloat theta=PL_ZERO)`  
    `plLearnLogNormal()`  

    This class allows to learn log-normal distributions.  

    Learning concerns exclusively the m and sigma parameters. The theta (location)
    parameter is assumed to be known.  

    Constructors
    ------------
    * `plLearnLogNormal(const plVariable &vars, plFloat theta=PL_ZERO)`  

        Constructor using a given variable and a given theta (location) parameter.  

    * `plLearnLogNormal()`  

        Void default constructor.  

    C++ includes: plLearnLogNormal.h

    """

    __swig_setmethods__ = {}
    for _s in [plMLLearnObject]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plLearnLogNormal, name, value)
    __swig_getmethods__ = {}
    for _s in [plMLLearnObject]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plLearnLogNormal, name)
    __repr__ = _swig_repr

    def __init__(self, *args):
        """
        __init__(self, vars, theta=0.0) -> plLearnLogNormal
        __init__(self, vars) -> plLearnLogNormal
        __init__(self) -> plLearnLogNormal


        `plLearnLogNormal(const plVariable &vars, plFloat theta=PL_ZERO)`  
        `plLearnLogNormal()`  

        Overloaded function
        -------------------
        * `plLearnLogNormal(const plVariable &vars, plFloat theta=PL_ZERO)`  

            Constructor using a given variable and a given theta (location) parameter.  

        * `plLearnLogNormal()`  

            Void default constructor.  

        """
        this = _probt_python3.new_plLearnLogNormal(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this
    __swig_destroy__ = _probt_python3.delete_plLearnLogNormal
    __del__ = lambda self: None

    def reset(self) -> "void":
        """
        reset(self)


        `reset()`  

        Resets learning.  

        """
        return _probt_python3.plLearnLogNormal_reset(self)


    def set_theta(self, theta: 'plFloat') -> "void":
        """
        set_theta(self, theta)


        `set_theta(plFloat theta)`  

        Sets the theta parameter.  

        """
        return _probt_python3.plLearnLogNormal_set_theta(self, theta)


    def get_theta(self) -> "plFloat":
        """
        get_theta(self) -> plFloat


        `get_theta() const -> plFloat`  

        Returns the 'theta' parameter.  

        """
        return _probt_python3.plLearnLogNormal_get_theta(self)


    def get_m(self) -> "plFloat":
        """
        get_m(self) -> plFloat


        `get_m() const -> plFloat`  

        Returns the 'm' parameter.  

        """
        return _probt_python3.plLearnLogNormal_get_m(self)


    def get_sigma(self) -> "plFloat":
        """
        get_sigma(self) -> plFloat


        `get_sigma() const -> plFloat`  

        Returns the 'sigma' parameter.  

        """
        return _probt_python3.plLearnLogNormal_get_sigma(self)


    def get_distribution(self) -> "plDistribution":
        """
        get_distribution(self) -> plDistribution


        `get_distribution() const -> plDistribution`  

        Returns the lognormal corresponding to the learnt distribution.  

        """
        return _probt_python3.plLearnLogNormal_get_distribution(self)


    def get_parameters(self, params: 'plValues') -> "void":
        """
        get_parameters(self, params)


        `get_parameters(plValues &params) const`  

        Returns all learnt parameters of the object (parameters passed to the
        distribution constructors when calling 'get_distribution').  

        This virtual method has to be implemented in all derived classes.  

        """
        return _probt_python3.plLearnLogNormal_get_parameters(self, params)


    def get_n_parameters(self) -> "unsigned int":
        """
        get_n_parameters(self) -> unsigned int


        `get_n_parameters() const -> unsigned int`  

        Returns the ACTUAL number of parameters.  

        It could be different from the number of parameters returned by get_parameters.  

        For example, the actual number of parameters of a N dimensional normal
        distribution is N + N*(N+1)/2 because the covariance matrix is symmetric.  

        """
        return _probt_python3.plLearnLogNormal_get_n_parameters(self)


    def clone(self) -> "plLearnObject *":
        """
        clone(self) -> plLearnObject


        `clone() const -> plLearnObject *`  

        Clone the learning object.  

        """
        return _probt_python3.plLearnLogNormal_clone(self)


    def rescale_total_weight(self, s: 'plFloat') -> "void":
        """
        rescale_total_weight(self, s)


        `rescale_total_weight(plFloat s)`  

        Multiply the weight of the past inserted points by a given factor.  

        This allows, for example, to decrease the importance of the old data points
        compared to the new ones  

        """
        return _probt_python3.plLearnLogNormal_rescale_total_weight(self, s)


    def __getstate__(self) -> "std::string":
        """__getstate__(self) -> std::string"""
        return _probt_python3.plLearnLogNormal___getstate__(self)


    def __setstate_internal(self, sState: 'std::string const &') -> "void":
        """__setstate_internal(self, sState)"""
        return _probt_python3.plLearnLogNormal___setstate_internal(self, sState)


    def __setstate__(self, sState):
        self.__init__()
        self.__setstate_internal(sState)

plLearnLogNormal_swigregister = _probt_python3.plLearnLogNormal_swigregister
plLearnLogNormal_swigregister(plLearnLogNormal)

class plLearnNdNormal(plMLLearnObject):
    """

    `plLearnNdNormal(const plVariablesConjunction &vars)`  
    `plLearnNdNormal(const plVariablesConjunction &vars, const plFloatVector
        &init_mean, const plFloatMatrix &init_matrix, plFloat init_weight=PL_ONE)`  
    `plLearnNdNormal()`  

    This class allows to learn multi-dimensional Normal (Gaussian) distributions.  

    Constructors
    ------------
    * `plLearnNdNormal(const plVariablesConjunction &vars)`  

        Constructor using a set of variables.  

    * `plLearnNdNormal(const plVariablesConjunction &vars, const plFloatVector
        &init_mean, const plFloatMatrix &init_matrix, plFloat init_weight=PL_ONE)`  

        Constructor using a set of variables, an initial mean, initial covariance,
        and an initial weight .  

    * `plLearnNdNormal()`  

        Void default constructor.  

    C++ includes: plLearnNdNormal.h

    """

    __swig_setmethods__ = {}
    for _s in [plMLLearnObject]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plLearnNdNormal, name, value)
    __swig_getmethods__ = {}
    for _s in [plMLLearnObject]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plLearnNdNormal, name)
    __repr__ = _swig_repr

    def __init__(self, *args):
        """
        __init__(self, vars) -> plLearnNdNormal
        __init__(self, vars, init_mean, init_matrix, init_weight=1.0) -> plLearnNdNormal
        __init__(self, vars, init_mean, init_matrix) -> plLearnNdNormal
        __init__(self) -> plLearnNdNormal


        `plLearnNdNormal(const plVariablesConjunction &vars)`  
        `plLearnNdNormal(const plVariablesConjunction &vars, const plFloatVector
            &init_mean, const plFloatMatrix &init_matrix, plFloat init_weight=PL_ONE)`  
        `plLearnNdNormal()`  

        Overloaded function
        -------------------
        * `plLearnNdNormal(const plVariablesConjunction &vars)`  

            Constructor using a set of variables.  

        * `plLearnNdNormal(const plVariablesConjunction &vars, const plFloatVector
            &init_mean, const plFloatMatrix &init_matrix, plFloat init_weight=PL_ONE)`  

            Constructor using a set of variables, an initial mean, initial covariance,
            and an initial weight .  

        * `plLearnNdNormal()`  

            Void default constructor.  

        """
        this = _probt_python3.new_plLearnNdNormal(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this
    __swig_destroy__ = _probt_python3.delete_plLearnNdNormal
    __del__ = lambda self: None

    def reset(self) -> "void":
        """
        reset(self)


        `reset()`  

        Resets learning.  

        """
        return _probt_python3.plLearnNdNormal_reset(self)


    def get_mean(self, *args) -> "plFloatVector":
        """
        get_mean(self, mean)
        get_mean(self) -> plFloatVector


        `get_mean(plFloatVector &mean) const`  
        `get_mean() const -> plFloatVector`  

        Overloaded function
        -------------------
        * `get_mean(plFloatVector &mean) const`  

            Returns the mean vector in the output parameter *mean*.  

        * `get_mean() const -> plFloatVector`  

            Returns the mean vector.  

        """
        return _probt_python3.plLearnNdNormal_get_mean(self, *args)


    def get_covariance(self, *args) -> "plFloatMatrix":
        """
        get_covariance(self, covariance)
        get_covariance(self) -> plFloatMatrix


        `get_covariance(plFloatMatrix &covariance) const`  
        `get_covariance() const -> plFloatMatrix`  

        Overloaded function
        -------------------
        * `get_covariance(plFloatMatrix &covariance) const`  

            Returns the covariance matrix in the output parameter *covariance*.  

        * `get_covariance() const -> plFloatMatrix`  

            Returns the covariance matrix.  

        """
        return _probt_python3.plLearnNdNormal_get_covariance(self, *args)


    def get_actual_min_max(self, min: 'plFloatVector', max: 'plFloatVector', cumul_prob: 'plProbValue'=0.95) -> "void":
        """
        get_actual_min_max(self, min, max, cumul_prob=0.95)
        get_actual_min_max(self, min, max)


        `get_actual_min_max(plFloatVector &min, plFloatVector &max, plProbValue
            cumul_prob=0.95) const`  

        Returns, for each dimension, the [min, max[ range allowing to cover a total
        cumulated probability of *cumul_prob* (i.e., leaving outside the [min, max[
        range a total cumulated probability of 1 - *cumul_prob*) according to the
        current estimate of the mean vector and variance matrix.  

        """
        return _probt_python3.plLearnNdNormal_get_actual_min_max(self, min, max, cumul_prob)


    def get_distribution(self) -> "plDistribution":
        """
        get_distribution(self) -> plDistribution


        `get_distribution() const -> plDistribution`  

        Returns the normal corresponding to the learnt distribution.  

        """
        return _probt_python3.plLearnNdNormal_get_distribution(self)


    def add_point(self, *args) -> "bool":
        """
        add_point(self, point, weight=1.0) -> bool
        add_point(self, point) -> bool
        add_point(self, point, weight=1.0) -> bool
        add_point(self, point) -> bool
        add_point(self, point, weight=1.0) -> bool
        add_point(self, point) -> bool
        add_point(self, point, weight=1.0) -> bool
        add_point(self, point) -> bool
        add_point(self, point, weight=1.0) -> bool
        add_point(self, point) -> bool
        add_point(self, point, weight=1.0) -> bool
        add_point(self, point) -> bool
        add_point(self, point, weight=1.0) -> bool
        add_point(self, point) -> bool
        add_point(self, point, weight=1.0) -> bool
        add_point(self, point) -> bool
        add_point(self, point, weight=1.0) -> bool
        add_point(self, point) -> bool
        add_point(self, point, weight=1.0) -> bool
        add_point(self, point) -> bool
        add_point(self, point, weight=1.0) -> bool
        add_point(self, point) -> bool
        add_point(self, point, weight=1.0) -> bool
        add_point(self, point) -> bool
        add_point(self, point, weight=1.0) -> bool
        add_point(self, point) -> bool
        add_point(self, point, weight=1.0) -> bool
        add_point(self, point) -> bool
        add_point(self, point, weight=1.0) -> bool
        add_point(self, point) -> bool
        add_point(self, point, weight=1.0) -> bool
        add_point(self, point) -> bool
        add_point(self, point, is_defined, weight=1.0) -> bool
        add_point(self, point, is_defined) -> bool
        add_point(self, point, is_defined, weight=1.0) -> bool
        add_point(self, point, is_defined) -> bool
        add_point(self, point, is_defined, weight=1.0) -> bool
        add_point(self, point, is_defined) -> bool
        add_point(self, point, is_defined, weight=1.0) -> bool
        add_point(self, point, is_defined) -> bool
        add_point(self, point, is_defined, weight=1.0) -> bool
        add_point(self, point, is_defined) -> bool
        add_point(self, point, is_defined, weight=1.0) -> bool
        add_point(self, point, is_defined) -> bool
        add_point(self, point, is_defined, weight=1.0) -> bool
        add_point(self, point, is_defined) -> bool
        add_point(self, point, is_defined, weight=1.0) -> bool
        add_point(self, point, is_defined) -> bool
        add_point(self, point, is_defined, weight=1.0) -> bool
        add_point(self, point, is_defined) -> bool
        add_point(self, point, is_defined, weight=1.0) -> bool
        add_point(self, point, is_defined) -> bool
        add_point(self, point, is_defined, weight=1.0) -> bool
        add_point(self, point, is_defined) -> bool
        add_point(self, point, weight=1.0) -> bool
        add_point(self, point) -> bool


        `add_point(const plFloatVector &point, plFloat weight=PL_ONE) -> bool`  

        """
        return _probt_python3.plLearnNdNormal_add_point(self, *args)


    def get_parameters(self, params: 'plValues') -> "void":
        """
        get_parameters(self, params)


        `get_parameters(plValues &params) const`  

        Returns all learnt parameters of the object (parameters passed to the
        distribution constructors when calling 'get_distribution').  

        This virtual method has to be implemented in all derived classes.  

        """
        return _probt_python3.plLearnNdNormal_get_parameters(self, params)


    def get_n_parameters(self) -> "unsigned int":
        """
        get_n_parameters(self) -> unsigned int


        `get_n_parameters() const -> unsigned int`  

        Returns the ACTUAL number of parameters.  

        It could be different from the number of parameters returned by get_parameters.  

        For example, the actual number of parameters of a N dimensional normal
        distribution is N + N*(N+1)/2 because the covariance matrix is symmetric.  

        """
        return _probt_python3.plLearnNdNormal_get_n_parameters(self)


    def clone(self) -> "plLearnObject *":
        """
        clone(self) -> plLearnObject


        `clone() const -> plLearnObject *`  

        Clone the learning object.  

        """
        return _probt_python3.plLearnNdNormal_clone(self)


    def rescale_total_weight(self, s: 'plFloat') -> "void":
        """
        rescale_total_weight(self, s)


        `rescale_total_weight(plFloat s)`  

        Multiply the weight of the past inserted points by a given factor.  

        This allows, for example, to decrease the importance of the old data points
        compared to the new ones  

        """
        return _probt_python3.plLearnNdNormal_rescale_total_weight(self, s)


    def __getstate__(self) -> "std::string":
        """__getstate__(self) -> std::string"""
        return _probt_python3.plLearnNdNormal___getstate__(self)


    def __setstate_internal(self, sState: 'std::string const &') -> "void":
        """__setstate_internal(self, sState)"""
        return _probt_python3.plLearnNdNormal___setstate_internal(self, sState)


    def __setstate__(self, sState):
        self.__init__()
        self.__setstate_internal(sState)

plLearnNdNormal_swigregister = _probt_python3.plLearnNdNormal_swigregister
plLearnNdNormal_swigregister(plLearnNdNormal)

class plLearnPoisson(plMLLearnObject):
    """

    `plLearnPoisson(const plVariable &vars)`  
    `plLearnPoisson(const plVariable &vars, plFloat init_mean, plFloat
        init_weight=PL_ONE)`  
    `plLearnPoisson()`  

    This class allows to learn Poisson distributions.  

    Constructors
    ------------
    * `plLearnPoisson(const plVariable &vars)`  

        Constructor using a given variable.  

    * `plLearnPoisson(const plVariable &vars, plFloat init_mean, plFloat
        init_weight=PL_ONE)`  

        Constructor using a set of variables, an initial mean and an initial weight
        .  

    * `plLearnPoisson()`  

        Void default constructor.  

    C++ includes: plLearnPoisson.h

    """

    __swig_setmethods__ = {}
    for _s in [plMLLearnObject]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plLearnPoisson, name, value)
    __swig_getmethods__ = {}
    for _s in [plMLLearnObject]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plLearnPoisson, name)
    __repr__ = _swig_repr

    def __init__(self, *args):
        """
        __init__(self, vars) -> plLearnPoisson
        __init__(self, vars, init_mean, init_weight=1.0) -> plLearnPoisson
        __init__(self, vars, init_mean) -> plLearnPoisson
        __init__(self) -> plLearnPoisson


        `plLearnPoisson(const plVariable &vars)`  
        `plLearnPoisson(const plVariable &vars, plFloat init_mean, plFloat
            init_weight=PL_ONE)`  
        `plLearnPoisson()`  

        Overloaded function
        -------------------
        * `plLearnPoisson(const plVariable &vars)`  

            Constructor using a given variable.  

        * `plLearnPoisson(const plVariable &vars, plFloat init_mean, plFloat
            init_weight=PL_ONE)`  

            Constructor using a set of variables, an initial mean and an initial weight
            .  

        * `plLearnPoisson()`  

            Void default constructor.  

        """
        this = _probt_python3.new_plLearnPoisson(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this
    __swig_destroy__ = _probt_python3.delete_plLearnPoisson
    __del__ = lambda self: None

    def reset(self) -> "void":
        """
        reset(self)


        `reset()`  

        Resets learning.  

        """
        return _probt_python3.plLearnPoisson_reset(self)


    def get_mu(self) -> "plFloat":
        """
        get_mu(self) -> plFloat


        `get_mu() const -> plFloat`  

        Returns the 'mu' parameter.  

        """
        return _probt_python3.plLearnPoisson_get_mu(self)


    def get_distribution(self) -> "plDistribution":
        """
        get_distribution(self) -> plDistribution


        `get_distribution() const -> plDistribution`  

        Returns the Poisson distribution corresponding to the learnt distribution.  

        """
        return _probt_python3.plLearnPoisson_get_distribution(self)


    def get_parameters(self, params: 'plValues') -> "void":
        """
        get_parameters(self, params)


        `get_parameters(plValues &params) const`  

        Returns all learnt parameters of the object (parameters passed to the
        distribution constructors when calling 'get_distribution').  

        This virtual method has to be implemented in all derived classes.  

        """
        return _probt_python3.plLearnPoisson_get_parameters(self, params)


    def get_n_parameters(self) -> "unsigned int":
        """
        get_n_parameters(self) -> unsigned int


        `get_n_parameters() const -> unsigned int`  

        Returns the ACTUAL number of parameters.  

        It could be different from the number of parameters returned by get_parameters.  

        For example, the actual number of parameters of a N dimensional normal
        distribution is N + N*(N+1)/2 because the covariance matrix is symmetric.  

        """
        return _probt_python3.plLearnPoisson_get_n_parameters(self)


    def clone(self) -> "plLearnObject *":
        """
        clone(self) -> plLearnObject


        `clone() const -> plLearnObject *`  

        Clone the learning object.  

        """
        return _probt_python3.plLearnPoisson_clone(self)


    def rescale_total_weight(self, s: 'plFloat') -> "void":
        """
        rescale_total_weight(self, s)


        `rescale_total_weight(plFloat s)`  

        Multiply the weight of the past inserted points by a given factor.  

        This allows, for example, to decrease the importance of the old data points
        compared to the new ones  

        """
        return _probt_python3.plLearnPoisson_rescale_total_weight(self, s)


    def __getstate__(self) -> "std::string":
        """__getstate__(self) -> std::string"""
        return _probt_python3.plLearnPoisson___getstate__(self)


    def __setstate_internal(self, sState: 'std::string const &') -> "void":
        """__setstate_internal(self, sState)"""
        return _probt_python3.plLearnPoisson___setstate_internal(self, sState)


    def __setstate__(self, sState):
        self.__init__()
        self.__setstate_internal(sState)

plLearnPoisson_swigregister = _probt_python3.plLearnPoisson_swigregister
plLearnPoisson_swigregister(plLearnPoisson)

class plLearnSparseHistogram(plMLLearnObject):
    """

    `plLearnSparseHistogram()`  
    `plLearnSparseHistogram(const plLearnSparseHistogram &histo)`  
    `plLearnSparseHistogram(const plVariablesConjunction &vars)`  

    A class for learning sparse histograms.  

    Constructors
    ------------
    * `plLearnSparseHistogram()`  

        Default constructor.  

    * `plLearnSparseHistogram(const plLearnSparseHistogram &histo)`  

        Copy constructor.  

    * `plLearnSparseHistogram(const plVariablesConjunction &vars)`  

        Constructor using a set of variables.  

    C++ includes: plLearnSparseHistogram.h

    """

    __swig_setmethods__ = {}
    for _s in [plMLLearnObject]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plLearnSparseHistogram, name, value)
    __swig_getmethods__ = {}
    for _s in [plMLLearnObject]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plLearnSparseHistogram, name)
    __repr__ = _swig_repr

    def __init__(self, *args):
        """
        __init__(self) -> plLearnSparseHistogram
        __init__(self, histo) -> plLearnSparseHistogram
        __init__(self, vars) -> plLearnSparseHistogram


        `plLearnSparseHistogram()`  
        `plLearnSparseHistogram(const plLearnSparseHistogram &histo)`  
        `plLearnSparseHistogram(const plVariablesConjunction &vars)`  

        Overloaded function
        -------------------
        * `plLearnSparseHistogram()`  

            Default constructor.  

        * `plLearnSparseHistogram(const plLearnSparseHistogram &histo)`  

            Copy constructor.  

        * `plLearnSparseHistogram(const plVariablesConjunction &vars)`  

            Constructor using a set of variables.  

        """
        this = _probt_python3.new_plLearnSparseHistogram(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this
    __swig_destroy__ = _probt_python3.delete_plLearnSparseHistogram
    __del__ = lambda self: None

    def get_distribution(self) -> "plDistribution":
        """
        get_distribution(self) -> plDistribution


        `get_distribution() const -> plDistribution`  

        Returns the probability table corresponding to the learnt distribution.  

        """
        return _probt_python3.plLearnSparseHistogram_get_distribution(self)


    def reset(self) -> "void":
        """
        reset(self)


        `reset()`  

        Resets learning.  

        """
        return _probt_python3.plLearnSparseHistogram_reset(self)


    def get_probability(self, *args) -> "void":
        """
        get_probability(self, table)
        get_probability(self, table)


        `get_probability(std::vector< plProbValue > &table) const`  
        `get_probability(plProbValue *table) const`  

        Overloaded function
        -------------------
        * `get_probability(std::vector< plProbValue > &table) const`  

            Returns the probability table corresponding to the learnt distribution in
            the output parameter 'table'.  

        * `get_probability(plProbValue *table) const`  

            Returns the probability table corresponding to the learnt distribution in
            the output parameter 'table'.  

            Assumes that 'table' has the exact size.  

        """
        return _probt_python3.plLearnSparseHistogram_get_probability(self, *args)


    def get_parameters(self, params: 'plValues') -> "void":
        """
        get_parameters(self, params)


        `get_parameters(plValues &params) const`  

        Returns all learnt parameters of the object (parameters passed to the
        distribution constructors when calling 'get_distribution').  

        This virtual method has to be implemented in all derived classes.  

        """
        return _probt_python3.plLearnSparseHistogram_get_parameters(self, params)


    def get_n_parameters(self) -> "unsigned int":
        """
        get_n_parameters(self) -> unsigned int


        `get_n_parameters() const -> unsigned int`  

        Returns the ACTUAL number of parameters.  

        It could be different from the number of parameters returned by get_parameters.  

        For example, the actual number of parameters of a N dimensional normal
        distribution is N + N*(N+1)/2 because the covariance matrix is symmetric.  

        """
        return _probt_python3.plLearnSparseHistogram_get_n_parameters(self)


    def clone(self) -> "plLearnObject *":
        """
        clone(self) -> plLearnObject


        `clone() const -> plLearnObject *`  

        Clone the learning object.  

        """
        return _probt_python3.plLearnSparseHistogram_clone(self)


    def rescale_total_weight(self, s: 'plFloat') -> "void":
        """
        rescale_total_weight(self, s)


        `rescale_total_weight(plFloat s)`  

        Multiply the weight of the past inserted points by a given factor.  

        This allows, for example, to decrease the importance of the old data points
        compared to the new ones  

        """
        return _probt_python3.plLearnSparseHistogram_rescale_total_weight(self, s)


    def __getstate__(self) -> "std::string":
        """__getstate__(self) -> std::string"""
        return _probt_python3.plLearnSparseHistogram___getstate__(self)


    def __setstate_internal(self, sState: 'std::string const &') -> "void":
        """__setstate_internal(self, sState)"""
        return _probt_python3.plLearnSparseHistogram___setstate_internal(self, sState)


    def __setstate__(self, sState):
        self.__init__()
        self.__setstate_internal(sState)

plLearnSparseHistogram_swigregister = _probt_python3.plLearnSparseHistogram_swigregister
plLearnSparseHistogram_swigregister(plLearnSparseHistogram)

class plLearnMixtureModel(plNonCndLearnObject):
    """

    `plLearnMixtureModel()`  
    `plLearnMixtureModel(const plVariablesConjunction &ObsVars, size_t n_mixture)`  
    `plLearnMixtureModel(const plVariablesConjunction &ObsVars, const std::vector<
        unsigned int > &n_mixture_candidates)`  

    This class implements the Mixture Model unsupervised learning.  

    Children classes have to implement the pure virtual functions
    get_initialization_cluster() and create_cluster_learn_object().  

    It uses the EM learning algorithm and is based on the plEMLearner class.  

    See also: plLearnGMM  

    Constructors
    ------------
    * `plLearnMixtureModel()`  

        Default constructor.  

    * `plLearnMixtureModel(const plVariablesConjunction &ObsVars, size_t n_mixture)`  

        Constructor.  

        Parameters:  
        * `ObsVars` :  
            The variables on which the mixture model will be learned  
        * `n_mixture` :  
            The number of components (kernels) of the mixture  

    * `plLearnMixtureModel(const plVariablesConjunction &ObsVars, const std::vector<
        unsigned int > &n_mixture_candidates)`  

        Constructor.  

        Parameters:  
        * `ObsVars` :  
            The variables on which the mixture model will be learned  
        * `n_mixture_candidates` :  
            The candidate number of components (kernels) of the mixture. Choosing
            among this candidates will be based on the optimality score (as defined
            by set_optimality_score() among BIC, AIC, ...)  

    C++ includes: plLearnMixtureModel.h

    """

    __swig_setmethods__ = {}
    for _s in [plNonCndLearnObject]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plLearnMixtureModel, name, value)
    __swig_getmethods__ = {}
    for _s in [plNonCndLearnObject]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plLearnMixtureModel, name)

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined - class is abstract")
    __repr__ = _swig_repr
    AIC = _probt_python3.plLearnMixtureModel_AIC
    BIC = _probt_python3.plLearnMixtureModel_BIC
    N_SCORES = _probt_python3.plLearnMixtureModel_N_SCORES
    __swig_destroy__ = _probt_python3.delete_plLearnMixtureModel
    __del__ = lambda self: None

    def get_distribution(self) -> "plDistribution":
        """
        get_distribution(self) -> plDistribution


        `get_distribution() const -> plDistribution`  

        Return the mixture corresponding to the best optimality score.  

        """
        return _probt_python3.plLearnMixtureModel_get_distribution(self)


    def get_parameters(self, params: 'plValues') -> "void":
        """
        get_parameters(self, params)


        `get_parameters(plValues &params) const`  

        Returns all learnt parameters of the object (parameters passed to the
        distribution constructors when calling 'get_distribution').  

        This virtual method has to be implemented in all derived classes.  

        """
        return _probt_python3.plLearnMixtureModel_get_parameters(self, params)


    def reset(self) -> "void":
        """
        reset(self)


        `reset()`  

        Resets learning (forgets all learned data).  

        """
        return _probt_python3.plLearnMixtureModel_reset(self)


    def get_n_parameters(self) -> "unsigned int":
        """
        get_n_parameters(self) -> unsigned int


        `get_n_parameters() const -> unsigned int`  

        Returns the ACTUAL number of parameters.  

        It could be different from the number of parameters returned by get_parameters.  

        For example, the actual number of parameters of a N dimensional normal
        distribution is N + N*(N+1)/2 because the covariance matrix is symmetric.  

        """
        return _probt_python3.plLearnMixtureModel_get_n_parameters(self)


    def get_model_n_learn_parameters(self, i: 'size_t') -> "size_t":
        """
        get_model_n_learn_parameters(self, i) -> size_t


        `get_model_n_learn_parameters(size_t i) const -> size_t`  

        Get the number of parameters to be learned of the model learned using the ith
        candidate for the number of components.  

        """
        return _probt_python3.plLearnMixtureModel_get_model_n_learn_parameters(self, i)


    def get_model_log_likelihood(self, i: 'size_t') -> "plFloat":
        """
        get_model_log_likelihood(self, i) -> plFloat


        `get_model_log_likelihood(size_t i) const -> plFloat`  

        Get the log-likelihood value of the model learned using the ith candidate for
        the number of components.  

        """
        return _probt_python3.plLearnMixtureModel_get_model_log_likelihood(self, i)


    def get_model_optimality_score(self, score: 'plLearnMixtureModel::OptimalityCriterion', i: 'size_t') -> "plFloat":
        """
        get_model_optimality_score(self, score, i) -> plFloat


        `get_model_optimality_score(OptimalityCriterion score, size_t i) const ->
            plFloat`  

        Get the optimality score among BIC, AIC, ...  

        of the model learned using the ith candidate for the number of components  

        """
        return _probt_python3.plLearnMixtureModel_get_model_optimality_score(self, score, i)


    def get_optimality_criterion_name(i: 'unsigned int') -> "std::string":
        """
        get_optimality_criterion_name(i) -> std::string


        `get_optimality_criterion_name(unsigned int i) -> std::string`  

        Return a human-readable name for optimality criterion number i.  

        An exception is raised if i is not in [0; N_SCORES-1].  

        """
        return _probt_python3.plLearnMixtureModel_get_optimality_criterion_name(i)

    get_optimality_criterion_name = staticmethod(get_optimality_criterion_name)

    def get_model_joint(self, i: 'size_t') -> "plJointDistribution const &":
        """
        get_model_joint(self, i) -> plJointDistribution


        `get_model_joint(size_t i) const -> const plJointDistribution &`  

        Get the joint distribution 'P(X C) = P(C) P(X | C)' corresponding to the model
        learned using the ith candidate for the number of components.  

        """
        return _probt_python3.plLearnMixtureModel_get_model_joint(self, i)


    def get_best_model_index(self, score: 'plLearnMixtureModel::OptimalityCriterion') -> "size_t":
        """
        get_best_model_index(self, score) -> size_t


        `get_best_model_index(OptimalityCriterion score) const -> size_t`  

        Get the best candidate index, based on the the optimality score among BIC, AIC,
        ...  

        """
        return _probt_python3.plLearnMixtureModel_get_best_model_index(self, score)


    def get_n_mixture_candidates(self) -> "std::vector< unsigned int,std::allocator< unsigned int > > const &":
        """
        get_n_mixture_candidates(self) -> UnsignedIntVector


        `get_n_mixture_candidates() const -> const std::vector< unsigned int > &`  

        Get the list of candidates of the number of components passed to the
        constructor.  

        """
        return _probt_python3.plLearnMixtureModel_get_n_mixture_candidates(self)


    def get_n_mixture_candidate(self, i: 'size_t') -> "size_t":
        """
        get_n_mixture_candidate(self, i) -> size_t


        `get_n_mixture_candidate(size_t i) const -> size_t`  

        Get the ith candidate of the number of components passed to the constructor.  

        """
        return _probt_python3.plLearnMixtureModel_get_n_mixture_candidate(self, i)


    def set_em_n_trials(self, ntrials: 'size_t') -> "void":
        """
        set_em_n_trials(self, ntrials)


        `set_em_n_trials(size_t ntrials)`  

        Set the number of EM trials with random starting points (the default is 1)  

        """
        return _probt_python3.plLearnMixtureModel_set_em_n_trials(self, ntrials)


    def optimality_score(self) -> "plLearnMixtureModel::OptimalityCriterion":
        """
        optimality_score(self) -> plLearnMixtureModel::OptimalityCriterion


        `optimality_score() const -> OptimalityCriterion`  

        Return the used optimality score (among BIC and AIC)  

        """
        return _probt_python3.plLearnMixtureModel_optimality_score(self)


    def set_optimality_score(self, score: 'plLearnMixtureModel::OptimalityCriterion') -> "void":
        """
        set_optimality_score(self, score)


        `set_optimality_score(OptimalityCriterion score)`  

        Set the optimality score allowing to choose the best number of components
        (clusters) among BIC and AIC.  

        """
        return _probt_python3.plLearnMixtureModel_set_optimality_score(self, score)


    def print_mixture_solutions(self, *args) -> "void":
        """
        print_mixture_solutions(self)
        print_mixture_solutions(self)


        `print_mixture_solutions(std::ostream &os=std::cout) const`  

        Print all mixture solutions corresponding to the provided list of components
        number.  

        """
        return _probt_python3.plLearnMixtureModel_print_mixture_solutions(self, *args)


    def enable_multi_threading(self, enable_it: 'bool'=True) -> "void":
        """
        enable_multi_threading(self, enable_it=True)
        enable_multi_threading(self)


        `enable_multi_threading(bool enable_it=true)`  

        Enable/disable multi-threading.  

        """
        return _probt_python3.plLearnMixtureModel_enable_multi_threading(self, enable_it)


    def set_no_missing_data_values(self, nomissing: 'bool') -> "void":
        """
        set_no_missing_data_values(self, nomissing)


        `set_no_missing_data_values(bool nomissing)`  

        Set/unset the "no missing data values" flag allowing to speedup the EM
        algorithm.  

        Set it to 'true' if you are sure that the data set to be used does not contain
        missing values (only mixture latent variables)  

        """
        return _probt_python3.plLearnMixtureModel_set_no_missing_data_values(self, nomissing)


    def set_em_convergence_threshold(self, em_convergence_threshold: 'plFloat') -> "void":
        """
        set_em_convergence_threshold(self, em_convergence_threshold)


        `set_em_convergence_threshold(plFloat em_convergence_threshold)`  

        Set the convergence_threshold for the EM algorithm The default value is 0.0001.  

        """
        return _probt_python3.plLearnMixtureModel_set_em_convergence_threshold(self, em_convergence_threshold)


    def rescale_total_weight(self, s: 'plFloat') -> "void":
        """
        rescale_total_weight(self, s)


        `rescale_total_weight(plFloat s)`  

        Multiply the weight of the past inserted points by a given factor.  

        This allows, for example, to decrease the importance of the old data points
        compared to the new ones  

        """
        return _probt_python3.plLearnMixtureModel_rescale_total_weight(self, s)


    def python_plot_results(self) -> "void":
        """
        python_plot_results(self)


        `python_plot_results()`  

        Only for Python: Plot the log-likelihood, BIC, and AIC scores.  

        """
        return _probt_python3.plLearnMixtureModel_python_plot_results(self)

plLearnMixtureModel_swigregister = _probt_python3.plLearnMixtureModel_swigregister
plLearnMixtureModel_swigregister(plLearnMixtureModel)

def plLearnMixtureModel_get_optimality_criterion_name(i: 'unsigned int') -> "std::string":
    """
    plLearnMixtureModel_get_optimality_criterion_name(i) -> std::string


    `get_optimality_criterion_name(unsigned int i) -> std::string`  

    Return a human-readable name for optimality criterion number i.  

    An exception is raised if i is not in [0; N_SCORES-1].  

    """
    return _probt_python3.plLearnMixtureModel_get_optimality_criterion_name(i)

class plLearnGMM(plLearnMixtureModel):
    """

    `plLearnGMM()`  
    `plLearnGMM(const plVariablesConjunction &ObsVars, size_t n_mixture, bool
        independent_dimensions=false)`  
    `plLearnGMM(const plVariablesConjunction &ObsVars, const std::vector< unsigned
        int > &n_mixture_candidates, bool independent_dimensions=false)`  

    This class implements the Gaussian Mixture Model unsupervised learning.  

    It uses the EM learning algorithm and is based on the plEMLearner class.  

    See also: plLearnMixtureModel  

    Constructors
    ------------
    * `plLearnGMM()`  

        Default constructor.  

    * `plLearnGMM(const plVariablesConjunction &ObsVars, size_t n_mixture, bool
        independent_dimensions=false)`  

        Constructor.  

        Parameters:  
        * `ObsVars` :  
            The variables on which the GMM will be learned  
        * `n_mixture` :  
            The number of components (kernels) of the mixture  
        * `independent_dimensions` :  
            If 'true', ObsVars are assumed to be independent (i.e., diagnonal
            conarianace matrix)  

    * `plLearnGMM(const plVariablesConjunction &ObsVars, const std::vector< unsigned
        int > &n_mixture_candidates, bool independent_dimensions=false)`  

        Constructor.  

        Parameters:  
        * `ObsVars` :  
            The variables on which the GMM will be learned  
        * `n_mixture_candidates` :  
            The candidate number of components (kernels) of the mixture. Choosing
            among this candidates will be based on the optimality score (as defined
            by set_optimality_score() among BIC, AIC, ...)  
        * `independent_dimensions` :  
            If 'true', ObsVars are assumed to be independent (i.e., diagnonal
            covariance matrix)  

    C++ includes: plLearnGMM.h

    """

    __swig_setmethods__ = {}
    for _s in [plLearnMixtureModel]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plLearnGMM, name, value)
    __swig_getmethods__ = {}
    for _s in [plLearnMixtureModel]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plLearnGMM, name)
    __repr__ = _swig_repr
    GMM_RANDOM_INIT = _probt_python3.plLearnGMM_GMM_RANDOM_INIT
    GMM_KMEANS_INIT = _probt_python3.plLearnGMM_GMM_KMEANS_INIT

    def __init__(self, *args):
        """
        __init__(self) -> plLearnGMM
        __init__(self, ObsVars, n_mixture, independent_dimensions=False) -> plLearnGMM
        __init__(self, ObsVars, n_mixture) -> plLearnGMM
        __init__(self, ObsVars, n_mixture_candidates, independent_dimensions=False) -> plLearnGMM
        __init__(self, ObsVars, n_mixture_candidates) -> plLearnGMM


        `plLearnGMM()`  
        `plLearnGMM(const plVariablesConjunction &ObsVars, size_t n_mixture, bool
            independent_dimensions=false)`  
        `plLearnGMM(const plVariablesConjunction &ObsVars, const std::vector< unsigned
            int > &n_mixture_candidates, bool independent_dimensions=false)`  

        Overloaded function
        -------------------
        * `plLearnGMM()`  

            Default constructor.  

        * `plLearnGMM(const plVariablesConjunction &ObsVars, size_t n_mixture, bool
            independent_dimensions=false)`  

            Constructor.  

            Parameters:  
            * `ObsVars` :  
                The variables on which the GMM will be learned  
            * `n_mixture` :  
                The number of components (kernels) of the mixture  
            * `independent_dimensions` :  
                If 'true', ObsVars are assumed to be independent (i.e., diagnonal
                conarianace matrix)  

        * `plLearnGMM(const plVariablesConjunction &ObsVars, const std::vector< unsigned
            int > &n_mixture_candidates, bool independent_dimensions=false)`  

            Constructor.  

            Parameters:  
            * `ObsVars` :  
                The variables on which the GMM will be learned  
            * `n_mixture_candidates` :  
                The candidate number of components (kernels) of the mixture. Choosing
                among this candidates will be based on the optimality score (as defined
                by set_optimality_score() among BIC, AIC, ...)  
            * `independent_dimensions` :  
                If 'true', ObsVars are assumed to be independent (i.e., diagnonal
                covariance matrix)  

        """
        this = _probt_python3.new_plLearnGMM(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def clone(self) -> "plLearnObject *":
        """
        clone(self) -> plLearnObject


        `clone() const -> plLearnObject *`  

        Clone the learning object.  

        """
        return _probt_python3.plLearnGMM_clone(self)


    def set_initialization_parameters(self, variable: 'size_t', min_val: 'plFloat', max_val: 'plFloat', variance: 'plFloat') -> "void":
        """
        set_initialization_parameters(self, variable, min_val, max_val, variance)


        `set_initialization_parameters(size_t variable, plFloat min_val, plFloat
            max_val, plFloat variance)`  

        Set components (clusters) initialization parameters for each dimension.  

        Parameters
        ----------
        * `variable` :  
            the variable (dimension) for which the parameters are set  
        * `min_val` :  
            The minimal value of the range  
        * `max_val` :  
            The maximal value of the range  
        * `variance` :  
            The variance  

        These parameters will be used by the default get_initialization_cluster()
        function  

        See also: get_initialization_cluster()  

        """
        return _probt_python3.plLearnGMM_set_initialization_parameters(self, variable, min_val, max_val, variance)


    def set_diagonal_covariance(self, diagonal_covariance: 'bool'=True) -> "void":
        """
        set_diagonal_covariance(self, diagonal_covariance=True)
        set_diagonal_covariance(self)


        `set_diagonal_covariance(bool diagonal_covariance=true)`  

        Set/unset independent variables hypothesis (i.e., diagonal covariance matrix)  

        Has no effect in one-dimensional case  

        """
        return _probt_python3.plLearnGMM_set_diagonal_covariance(self, diagonal_covariance)


    def set_initialization_method(self, init_method: 'plLearnGMM::InitializationMethod') -> "void":
        """
        set_initialization_method(self, init_method)


        `set_initialization_method(InitializationMethod init_method)`  

        Change initialization method.  

        """
        return _probt_python3.plLearnGMM_set_initialization_method(self, init_method)


    def __getstate__(self) -> "std::string":
        """__getstate__(self) -> std::string"""
        return _probt_python3.plLearnGMM___getstate__(self)


    def __setstate_internal(self, sState: 'std::string const &') -> "void":
        """__setstate_internal(self, sState)"""
        return _probt_python3.plLearnGMM___setstate_internal(self, sState)


    def __setstate__(self, sState):
        self.__init__()
        self.__setstate_internal(sState)

    __swig_destroy__ = _probt_python3.delete_plLearnGMM
    __del__ = lambda self: None
plLearnGMM_swigregister = _probt_python3.plLearnGMM_swigregister
plLearnGMM_swigregister(plLearnGMM)

class plLearnCndObject(plLearnObject):
    """

    `plLearnCndObject()`  
    `plLearnCndObject(const plVariablesConjunction &left_vars, const
        plVariablesConjunction &right_vars)`  

    This is an abstract class for all conditional learning objects.  

    Constructors
    ------------
    * `plLearnCndObject()`  

        Default constructor.  

    * `plLearnCndObject(const plVariablesConjunction &left_vars, const
        plVariablesConjunction &right_vars)`  

        Constructor.  

    C++ includes: plLearnCndObject.h

    """

    __swig_setmethods__ = {}
    for _s in [plLearnObject]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plLearnCndObject, name, value)
    __swig_getmethods__ = {}
    for _s in [plLearnObject]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plLearnCndObject, name)

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined - class is abstract")
    __repr__ = _swig_repr

    def get_left_variables(self) -> "plVariablesConjunction const &":
        """
        get_left_variables(self) -> plVariablesConjunction


        `get_left_variables() const -> const plVariablesConjunction &`  

        Returns the left variables of this conditional learning object.  

        """
        return _probt_python3.plLearnCndObject_get_left_variables(self)


    def get_right_variables(self) -> "plVariablesConjunction const &":
        """
        get_right_variables(self) -> plVariablesConjunction


        `get_right_variables() const -> const plVariablesConjunction &`  

        Returns the right variables of this conditional learning object.  

        """
        return _probt_python3.plLearnCndObject_get_right_variables(self)


    def get_cnd_distribution(self) -> "plCndDistribution":
        """
        get_cnd_distribution(self) -> plCndDistribution


        `get_cnd_distribution() const =0 -> plCndDistribution`  

        Constructs and returns the conditional ditribution corresponding to the current
        state of this learner.  

        """
        return _probt_python3.plLearnCndObject_get_cnd_distribution(self)


    def get_computable_object(self) -> "plComputableObject":
        """
        get_computable_object(self) -> plComputableObject


        `get_computable_object() const -> plComputableObject`  

        Constructs the computable object corresponding to the learnt distribution.  

        Constructs and returns the computable object (conditional or non conditional
        distribution) corresponding to the current state of this learner  

        """
        return _probt_python3.plLearnCndObject_get_computable_object(self)


    def add_point(self, *args) -> "bool":
        """
        add_point(self, point, weight=1.0) -> bool
        add_point(self, point) -> bool
        add_point(self, point, weight=1.0) -> bool
        add_point(self, point) -> bool
        add_point(self, point, weight=1.0) -> bool
        add_point(self, point) -> bool
        add_point(self, point, weight=1.0) -> bool
        add_point(self, point) -> bool
        add_point(self, point, weight=1.0) -> bool
        add_point(self, point) -> bool
        add_point(self, point, weight=1.0) -> bool
        add_point(self, point) -> bool
        add_point(self, point, weight=1.0) -> bool
        add_point(self, point) -> bool
        add_point(self, point, weight=1.0) -> bool
        add_point(self, point) -> bool
        add_point(self, point, weight=1.0) -> bool
        add_point(self, point) -> bool
        add_point(self, point, weight=1.0) -> bool
        add_point(self, point) -> bool
        add_point(self, point, weight=1.0) -> bool
        add_point(self, point) -> bool
        add_point(self, point, weight=1.0) -> bool
        add_point(self, point) -> bool
        add_point(self, point, weight=1.0) -> bool
        add_point(self, point) -> bool
        add_point(self, point, weight=1.0) -> bool
        add_point(self, point) -> bool
        add_point(self, point, weight=1.0) -> bool
        add_point(self, point) -> bool
        add_point(self, point, weight=1.0) -> bool
        add_point(self, point) -> bool
        add_point(self, point, is_defined, weight=1.0) -> bool
        add_point(self, point, is_defined) -> bool
        add_point(self, point, is_defined, weight=1.0) -> bool
        add_point(self, point, is_defined) -> bool
        add_point(self, point, is_defined, weight=1.0) -> bool
        add_point(self, point, is_defined) -> bool
        add_point(self, point, is_defined, weight=1.0) -> bool
        add_point(self, point, is_defined) -> bool
        add_point(self, point, is_defined, weight=1.0) -> bool
        add_point(self, point, is_defined) -> bool
        add_point(self, point, is_defined, weight=1.0) -> bool
        add_point(self, point, is_defined) -> bool
        add_point(self, point, is_defined, weight=1.0) -> bool
        add_point(self, point, is_defined) -> bool
        add_point(self, point, is_defined, weight=1.0) -> bool
        add_point(self, point, is_defined) -> bool
        add_point(self, point, is_defined, weight=1.0) -> bool
        add_point(self, point, is_defined) -> bool
        add_point(self, point, is_defined, weight=1.0) -> bool
        add_point(self, point, is_defined) -> bool
        add_point(self, point, is_defined, weight=1.0) -> bool
        add_point(self, point, is_defined) -> bool
        add_point(self, left_point, right_point, weight=1.0) -> bool
        add_point(self, left_point, right_point) -> bool
        add_point(self, left_point, right_point, weight=1.0) -> bool
        add_point(self, left_point, right_point) -> bool
        add_point(self, left_point, right_point, weight=1.0) -> bool
        add_point(self, left_point, right_point) -> bool
        add_point(self, left_point, right_point, weight=1.0) -> bool
        add_point(self, left_point, right_point) -> bool
        add_point(self, left_point, right_point, weight=1.0) -> bool
        add_point(self, left_point, right_point) -> bool


        `add_point(const int *left_point, const int *right_point, plFloat weight=PL_ONE)
            -> bool`  
        `add_point(const unsigned int *left_point, const unsigned int *right_point,
            plFloat weight=PL_ONE) -> bool`  
        `add_point(const float *left_point, const float *right_point, plFloat
            weight=PL_ONE) -> bool`  
        `add_point(const double *left_point, const double *right_point, plFloat
            weight=PL_ONE) -> bool`  
        `add_point(const long double *left_point, const long double *right_point,
            plFloat weight=PL_ONE) -> bool`  

        Overloaded function
        -------------------
        * `add_point(const int *left_point, const int *right_point, plFloat
            weight=PL_ONE) -> bool`  

            Adds a multidimensional data point with a given weight to learn (left |
            righ).  

            Parameters:  
            * `left_point` :  
                Data point for left variables to add, as a C array.  
            * `right_point` :  
                Data point for right variables to add, as a C array.  
            * `weight` :  
                Weight of the added point. If *weight* is an integer, add_point(x, y,
                weight) is equivalent to doing *weight* times add_point(x, y).  

            Returns:
            True if and only if the point could be added (i.e. is valid).  

        * `add_point(const unsigned int *left_point, const unsigned int *right_point,
            plFloat weight=PL_ONE) -> bool`  

        * `add_point(const float *left_point, const float *right_point, plFloat
            weight=PL_ONE) -> bool`  

        * `add_point(const double *left_point, const double *right_point, plFloat
            weight=PL_ONE) -> bool`  

        * `add_point(const long double *left_point, const long double *right_point,
            plFloat weight=PL_ONE) -> bool`  

        """
        return _probt_python3.plLearnCndObject_add_point(self, *args)

    __swig_destroy__ = _probt_python3.delete_plLearnCndObject
    __del__ = lambda self: None
plLearnCndObject_swigregister = _probt_python3.plLearnCndObject_swigregister
plLearnCndObject_swigregister(plLearnCndObject)

class plLearnLinearRegression(plLearnCndObject):
    """

    `plLearnLinearRegression(const plVariable &left_var, const
        plVariablesConjunction &right_vars, plFloat
        regression_std_deviation=-PL_ONE, plFloat inv_threshold=0.001)`  
    `plLearnLinearRegression()`  

    This implements the learning part of the linear regression model (aka Linear
    Gaussian).  

    Given a continuous variable $Y$, and a set of $ n $ quantitative attribute
    variables $X_1, \cdots,X_n $, the probability density function over $Y$ is
    defined as: \[ p(Y~|~X_1=x_1,\cdots,X_n=x_n) = Normal(y, mean(x_1, ...,x_n),
    \sigma),\] in which \[ mean(x_1, \cdots,x_n) = \sum_{i=1}^n \beta_i
    \times x_i + \beta_{n+1},\] and $ \sigma $ is either a user-provided
    constant or computed as the residual error of the regression.  

    The learning algorithm computes the parameter vector $\beta$ as a solution for
    a linear problem. Thus, unlike the other learning objects,
    plLearnLinearRegression is not incremental and needs to store all the data
    points added using plLearnObject::add_point().  

    See also: plLinearRegression  

    Constructors
    ------------
    * `plLearnLinearRegression(const plVariable &left_var, const
        plVariablesConjunction &right_vars, plFloat
        regression_std_deviation=-PL_ONE, plFloat inv_threshold=0.001)`  

        Constructor.  

        Parameters:  
        * `left_var` :  
            The regression output variables  
        * `right_vars` :  
            The regression input variables  
        * `regression_std_deviation` :  
            the standart deviation to be used around the regression value. If -1,
            the residual error will be used.  
        * `inv_threshold` :  
            The threshold used for *Greville's* algorithm used for matrix inversion  

    * `plLearnLinearRegression()`  

        Default constructor to be used for serialisation.  

    C++ includes: plLearnLinearRegression.h

    """

    __swig_setmethods__ = {}
    for _s in [plLearnCndObject]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plLearnLinearRegression, name, value)
    __swig_getmethods__ = {}
    for _s in [plLearnCndObject]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plLearnLinearRegression, name)
    __repr__ = _swig_repr

    def __init__(self, *args):
        """
        __init__(self, left_var, right_vars, regression_std_deviation=-1.0, inv_threshold=0.001) -> plLearnLinearRegression
        __init__(self, left_var, right_vars, regression_std_deviation=-1.0) -> plLearnLinearRegression
        __init__(self, left_var, right_vars) -> plLearnLinearRegression
        __init__(self) -> plLearnLinearRegression


        `plLearnLinearRegression(const plVariable &left_var, const
            plVariablesConjunction &right_vars, plFloat
            regression_std_deviation=-PL_ONE, plFloat inv_threshold=0.001)`  
        `plLearnLinearRegression()`  

        Overloaded function
        -------------------
        * `plLearnLinearRegression(const plVariable &left_var, const
            plVariablesConjunction &right_vars, plFloat
            regression_std_deviation=-PL_ONE, plFloat inv_threshold=0.001)`  

            Constructor.  

            Parameters:  
            * `left_var` :  
                The regression output variables  
            * `right_vars` :  
                The regression input variables  
            * `regression_std_deviation` :  
                the standart deviation to be used around the regression value. If -1,
                the residual error will be used.  
            * `inv_threshold` :  
                The threshold used for *Greville's* algorithm used for matrix inversion  

        * `plLearnLinearRegression()`  

            Default constructor to be used for serialisation.  

        """
        this = _probt_python3.new_plLearnLinearRegression(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this
    __swig_destroy__ = _probt_python3.delete_plLearnLinearRegression
    __del__ = lambda self: None

    def reset(self) -> "void":
        """
        reset(self)


        `reset()`  

        Resets learning to its initial state.  

        """
        return _probt_python3.plLearnLinearRegression_reset(self)


    def get_cnd_distribution(self) -> "plCndDistribution":
        """
        get_cnd_distribution(self) -> plCndDistribution


        `get_cnd_distribution() const -> plCndDistribution`  

        Constructs the corresponding learnt conditional distribution.  

        It computes the $\beta$ vector and returns a plLinearRegression with the
        computed $\beta$.  

        """
        return _probt_python3.plLearnLinearRegression_get_cnd_distribution(self)


    def get_n_parameters(self) -> "unsigned int":
        """
        get_n_parameters(self) -> unsigned int


        `get_n_parameters() const -> unsigned int`  

        Returns the ACTUAL number of parameters.  

        It could be different from the number of parameters returned by get_parameters.  

        For example, the actual number of parameters of a N dimensional normal
        distribution is N + N*(N+1)/2 because the covariance matrix is symmetric.  

        """
        return _probt_python3.plLearnLinearRegression_get_n_parameters(self)


    def clone(self) -> "plLearnObject *":
        """
        clone(self) -> plLearnObject


        `clone() const -> plLearnObject *`  

        Clone the learning object.  

        """
        return _probt_python3.plLearnLinearRegression_clone(self)


    def get_beta(self) -> "plFloatVector const &":
        """
        get_beta(self) -> plFloatVector


        `get_beta() const -> const plFloatVector &`  

        Get the current learnt beta.  

        """
        return _probt_python3.plLearnLinearRegression_get_beta(self)


    def get_regression_std_deviation(self) -> "plFloat":
        """
        get_regression_std_deviation(self) -> plFloat


        `get_regression_std_deviation() const -> plFloat`  

        Get the regression standard deviation.  

        """
        return _probt_python3.plLearnLinearRegression_get_regression_std_deviation(self)


    def rescale_total_weight(self, s: 'plFloat') -> "void":
        """
        rescale_total_weight(self, s)


        `rescale_total_weight(plFloat s)`  

        Multiply the weight of the past inserted points by a given factor.  

        This allows, for example, to decrease the importance of the old data points
        compared to the new ones  

        """
        return _probt_python3.plLearnLinearRegression_rescale_total_weight(self, s)


    def __getstate__(self) -> "std::string":
        """__getstate__(self) -> std::string"""
        return _probt_python3.plLearnLinearRegression___getstate__(self)


    def __setstate_internal(self, sState: 'std::string const &') -> "void":
        """__setstate_internal(self, sState)"""
        return _probt_python3.plLearnLinearRegression___setstate_internal(self, sState)


    def __setstate__(self, sState):
        self.__init__()
        self.__setstate_internal(sState)

plLearnLinearRegression_swigregister = _probt_python3.plLearnLinearRegression_swigregister
plLearnLinearRegression_swigregister(plLearnLinearRegression)

class plLearnLinearRegressionFamily(plLearnCndObject):
    """

    `plLearnLinearRegressionFamily(const plVariable &left_var, const
        plVariablesConjunction &quantitative_right_vars, const
        plVariablesConjunction &categorical_right_vars, plFloat
        regression_std_deviation=-PL_ONE, plFloat inv_threshold=0.001)`  
    `plLearnLinearRegressionFamily()`  

    Implements a family of linear regressions (over a set of quantitative
    variables), indexed by a set of categorical variables.  

    Actually, given a categorical variable (or conjunction of variables) $ A $ with
    a cardinality of $ N_A $, this class constructs and learns a set of $ N_A $
    linear regressions (see plLearnLinearRegression).  

    See also: plLearnLinearRegression  

    Constructors
    ------------
    * `plLearnLinearRegressionFamily(const plVariable &left_var, const
        plVariablesConjunction &quantitative_right_vars, const
        plVariablesConjunction &categorical_right_vars, plFloat
        regression_std_deviation=-PL_ONE, plFloat inv_threshold=0.001)`  

        Constructor.  

        Parameters:  
        * `left_var` :  
            The regression quantitative output variable  
        * `quantitative_right_vars` :  
            The right (parent) quantitative variables on which the regression is
            computed  
        * `categorical_right_vars` :  
            The right (parent) categorical variables for which we have a regression
            for each modality  
        * `regression_std_deviation` :  
            the standart deviation to be used around the regression value. If -1,
            the residual error will be used.  
        * `inv_threshold` :  
            The threshold used for *Greville's* algorithm used for matrix inversion  

    * `plLearnLinearRegressionFamily()`  

        Default constructor to be used for serialisation.  

    C++ includes: plLearnLinearRegressionFamily.h

    """

    __swig_setmethods__ = {}
    for _s in [plLearnCndObject]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plLearnLinearRegressionFamily, name, value)
    __swig_getmethods__ = {}
    for _s in [plLearnCndObject]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plLearnLinearRegressionFamily, name)
    __repr__ = _swig_repr

    def __init__(self, *args):
        """
        __init__(self, left_var, quantitative_right_vars, categorical_right_vars, regression_std_deviation=-1.0, inv_threshold=0.001) -> plLearnLinearRegressionFamily
        __init__(self, left_var, quantitative_right_vars, categorical_right_vars, regression_std_deviation=-1.0) -> plLearnLinearRegressionFamily
        __init__(self, left_var, quantitative_right_vars, categorical_right_vars) -> plLearnLinearRegressionFamily
        __init__(self) -> plLearnLinearRegressionFamily


        `plLearnLinearRegressionFamily(const plVariable &left_var, const
            plVariablesConjunction &quantitative_right_vars, const
            plVariablesConjunction &categorical_right_vars, plFloat
            regression_std_deviation=-PL_ONE, plFloat inv_threshold=0.001)`  
        `plLearnLinearRegressionFamily()`  

        Overloaded function
        -------------------
        * `plLearnLinearRegressionFamily(const plVariable &left_var, const
            plVariablesConjunction &quantitative_right_vars, const
            plVariablesConjunction &categorical_right_vars, plFloat
            regression_std_deviation=-PL_ONE, plFloat inv_threshold=0.001)`  

            Constructor.  

            Parameters:  
            * `left_var` :  
                The regression quantitative output variable  
            * `quantitative_right_vars` :  
                The right (parent) quantitative variables on which the regression is
                computed  
            * `categorical_right_vars` :  
                The right (parent) categorical variables for which we have a regression
                for each modality  
            * `regression_std_deviation` :  
                the standart deviation to be used around the regression value. If -1,
                the residual error will be used.  
            * `inv_threshold` :  
                The threshold used for *Greville's* algorithm used for matrix inversion  

        * `plLearnLinearRegressionFamily()`  

            Default constructor to be used for serialisation.  

        """
        this = _probt_python3.new_plLearnLinearRegressionFamily(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this
    __swig_destroy__ = _probt_python3.delete_plLearnLinearRegressionFamily
    __del__ = lambda self: None

    def reset(self) -> "void":
        """
        reset(self)


        `reset()`  

        Resets learning to its initial state.  

        """
        return _probt_python3.plLearnLinearRegressionFamily_reset(self)


    def get_cnd_distribution(self) -> "plCndDistribution":
        """
        get_cnd_distribution(self) -> plCndDistribution


        `get_cnd_distribution() const -> plCndDistribution`  

        Constructs the corresponding learnt conditional distribution.  

        It computes the $\beta$ vector for each regression and returns a
        plDistributionTable of plLinearRegression.  

        """
        return _probt_python3.plLearnLinearRegressionFamily_get_cnd_distribution(self)


    def get_n_parameters(self) -> "unsigned int":
        """
        get_n_parameters(self) -> unsigned int


        `get_n_parameters() const -> unsigned int`  

        Returns the ACTUAL number of parameters.  

        It could be different from the number of parameters returned by get_parameters.  

        For example, the actual number of parameters of a N dimensional normal
        distribution is N + N*(N+1)/2 because the covariance matrix is symmetric.  

        """
        return _probt_python3.plLearnLinearRegressionFamily_get_n_parameters(self)


    def clone(self) -> "plLearnObject *":
        """
        clone(self) -> plLearnObject


        `clone() const -> plLearnObject *`  

        Clone the learning object.  

        """
        return _probt_python3.plLearnLinearRegressionFamily_clone(self)


    def rescale_total_weight(self, s: 'plFloat') -> "void":
        """
        rescale_total_weight(self, s)


        `rescale_total_weight(plFloat s)`  

        Multiply the weight of the past inserted points by a given factor.  

        This allows, for example, to decrease the importance of the old data points
        compared to the new ones  

        """
        return _probt_python3.plLearnLinearRegressionFamily_rescale_total_weight(self, s)


    def __getstate__(self) -> "std::string":
        """__getstate__(self) -> std::string"""
        return _probt_python3.plLearnLinearRegressionFamily___getstate__(self)


    def __setstate_internal(self, sState: 'std::string const &') -> "void":
        """__setstate_internal(self, sState)"""
        return _probt_python3.plLearnLinearRegressionFamily___setstate_internal(self, sState)


    def __setstate__(self, sState):
        self.__init__()
        self.__setstate_internal(sState)

plLearnLinearRegressionFamily_swigregister = _probt_python3.plLearnLinearRegressionFamily_swigregister
plLearnLinearRegressionFamily_swigregister(plLearnLinearRegressionFamily)

class plLearnNoisyOR(plLearnCndObject):
    """

    `plLearnNoisyOR(const plVariable &left_binary_var, const plVariablesConjunction
        &right_vars, unsigned int n_em_it)`  
    `plLearnNoisyOR()`  

    This class implements the learning part of the NoisyOR discrimination model.  

    Given a binary class variable $C$, and a set of $ n $ discrete attribute
    variables $A_1, \cdots,A_n $, the idea of the NoisyOR model is to assume that
    the value of the binary class variable $C$ is the deterministic result of the OR
    operator on another set of $ n $ intermediate (latent) binary variables $B_1,
    \cdots,B_n $. The parameters of the $ n $ distributions $ P(B_i~|~ A_i)$ are
    computed using an EM algorithm (see the corresponding initial and transformed
    graphs at the end of this section).  

    This leads to the formula: \[ P(C=0~|~A_1=a_1,\cdots,A_n=a_n) =
    \prod_{i=1}^{n} P(B_i=0~|~A_i=a_i). \]  

    The learning algorithm computes the parameter matrix $ P(B_i = 0~|~A_i = a_i^j)$
    for $ i = 1,\cdots,n; j = 1,\cdots,card(A_i) $ using an iterative algorithm
    (EM). Thus, unlike the other learning objects, plLearnNoisyOR is not incremental
    and needs to store all the data points added using plLearnObject::add_point().  

                     C

                  ^    ^
                 /      \
                /        \
               /          \
              /            \
             /              \

            A1                An

              INITIAL MODEL



                    |
                    |
                    |
                    |
                    |
                    V



                    C

                  ^    ^
                 /      \
                /        \
               /          \
              /            \
             /              \

            B1  .........    Bn

            ^                 ^
            |                 |
            |   .........     |
            |                 |
            |                 |
            |                 |

            A1                An

              TRANSFORMED MODEL  

    See also: plNoisyOR  

    See also: plLearnSoftmax  

    Constructors
    ------------
    * `plLearnNoisyOR(const plVariable &left_binary_var, const
        plVariablesConjunction &right_vars, unsigned int n_em_it)`  

        Constructor.  

        Parameters:  
        * `left_binary_var` :  
            The binary class variable  
        * `right_vars` :  
            The $ n $ attribute variables $ A_i, i=1,\cdots,n$  
        * `n_em_it` :  
            The number of iterations for the EM algorithm  

    * `plLearnNoisyOR()`  

        Default constructor to be used for serialisation.  

    C++ includes: plLearnNoisyOR.h

    """

    __swig_setmethods__ = {}
    for _s in [plLearnCndObject]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plLearnNoisyOR, name, value)
    __swig_getmethods__ = {}
    for _s in [plLearnCndObject]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plLearnNoisyOR, name)
    __repr__ = _swig_repr

    def __init__(self, *args):
        """
        __init__(self, left_binary_var, right_vars, n_em_it) -> plLearnNoisyOR
        __init__(self) -> plLearnNoisyOR


        `plLearnNoisyOR(const plVariable &left_binary_var, const plVariablesConjunction
            &right_vars, unsigned int n_em_it)`  
        `plLearnNoisyOR()`  

        Overloaded function
        -------------------
        * `plLearnNoisyOR(const plVariable &left_binary_var, const
            plVariablesConjunction &right_vars, unsigned int n_em_it)`  

            Constructor.  

            Parameters:  
            * `left_binary_var` :  
                The binary class variable  
            * `right_vars` :  
                The $ n $ attribute variables $ A_i, i=1,\cdots,n$  
            * `n_em_it` :  
                The number of iterations for the EM algorithm  

        * `plLearnNoisyOR()`  

            Default constructor to be used for serialisation.  

        """
        this = _probt_python3.new_plLearnNoisyOR(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this
    __swig_destroy__ = _probt_python3.delete_plLearnNoisyOR
    __del__ = lambda self: None

    def reset(self) -> "void":
        """
        reset(self)


        `reset()`  

        Resets learning to its initial state.  

        """
        return _probt_python3.plLearnNoisyOR_reset(self)


    def get_cnd_distribution(self) -> "plCndDistribution":
        """
        get_cnd_distribution(self) -> plCndDistribution


        `get_cnd_distribution() const -> plCndDistribution`  

        Constructs the conditional distribution corresponding to the learnt conditional
        distribution.  

        It computes the parameter matrix $ P(B_i = 0~|~A_i = a_i^j)$ for $ i =
        1,\cdots,n; j = 1,\cdots,card(A_i) $ using an EM algorithm and returns a
        plNoisyOR with the computed parameters.  

        """
        return _probt_python3.plLearnNoisyOR_get_cnd_distribution(self)


    def get_n_parameters(self) -> "unsigned int":
        """
        get_n_parameters(self) -> unsigned int


        `get_n_parameters() const -> unsigned int`  

        Returns the ACTUAL number of parameters.  

        It could be different from the number of parameters returned by get_parameters.  

        For example, the actual number of parameters of a N dimensional normal
        distribution is N + N*(N+1)/2 because the covariance matrix is symmetric.  

        """
        return _probt_python3.plLearnNoisyOR_get_n_parameters(self)


    def clone(self) -> "plLearnObject *":
        """
        clone(self) -> plLearnObject


        `clone() const -> plLearnObject *`  

        Clone the learning object.  

        """
        return _probt_python3.plLearnNoisyOR_clone(self)


    def rescale_total_weight(self, s: 'plFloat') -> "void":
        """
        rescale_total_weight(self, s)


        `rescale_total_weight(plFloat s)`  

        Multiply the weight of the past inserted points by a given factor.  

        This allows, for example, to decrease the importance of the old data points
        compared to the new ones  

        """
        return _probt_python3.plLearnNoisyOR_rescale_total_weight(self, s)


    def __getstate__(self) -> "std::string":
        """__getstate__(self) -> std::string"""
        return _probt_python3.plLearnNoisyOR___getstate__(self)


    def __setstate_internal(self, sState: 'std::string const &') -> "void":
        """__setstate_internal(self, sState)"""
        return _probt_python3.plLearnNoisyOR___setstate_internal(self, sState)


    def __setstate__(self, sState):
        self.__init__()
        self.__setstate_internal(sState)

plLearnNoisyOR_swigregister = _probt_python3.plLearnNoisyOR_swigregister
plLearnNoisyOR_swigregister(plLearnNoisyOR)

class plLearnSoftmax(plLearnCndObject):
    """

    `plLearnSoftmax(const plVariable &left_var, const plVariablesConjunction
        &right_vars)`  
    `plLearnSoftmax()`  

    This implements the learning part of the Softmax (aka multinomial logistic or
    multinomial logit) regression.  

    It's a generalization of the binary Sigmoid regression for multiclass cases.  

    Given a discrete class variable $C$ with $m$ modalities, and a set of $ n $
    quantitative attribute variables $A_1, \cdots,A_n $, the Softmax regression
    assumes that \[ \log \frac {P(C=k~|~A_1=a_1,\cdots,A_n=a_n)}
    {P(C>k~|~A_1=a_1,\cdots,A_n=a_n)} = \sum_{i=1}^n \beta_i^k \times a_i +
    \beta_{n+1}^k, k=0,\cdots, m-2,\] and \[P(C=m-1~|~A_1=a_1,\cdots,A_n=a_n) =
    1 - \sum_{k=0}^{m-2} P(C=k~|~A_1=a_1,\cdots,A_n=a_n). \]  

    This leads to the recursive formula: \[ P(C=0~|~A_1=a_1,\cdots,A_n=a_n) =
    P_0(A) = Sigmoid( z\left(A, \beta^0 ) \right),\] \[
    P(C=k~|~A_1=a_1,\cdots,A_n=a_n) = P_k(A) = \left[ 1 - \sum_{i=0}^{k-1} P_i(A)
    \right] \times Sigmoid( z\left(A, \beta^k ) \right), k=0,\cdots, m-2,\]
    \[ P(C=m-1~|~A_1=a_1,\cdots,A_n=a_n) = P_{m-1}(A) = 1 - \sum_{i=0}^{m-2}
    P_i(A), \] in which \[ z(A, \beta^k) = \sum_{i=1}^n \beta_i^k \times a_i +
    \beta_{n+1}^k, \] \[ Sigmoid(t) = \frac {1} {1+\exp(-t)}. \]  

    The learning algorithm computes the parameter matrix $\beta$ using an iterative
    algorithm (gradient descent/newton-raphson). Thus, unlike the other learning
    objects, plLearnSoftmax is not incremental and needs to store all the data
    points added using plLearnObject::add_point().  

    See also: plSoftmax  

    See also: plLearnNoisyOR  

    Constructors
    ------------
    * `plLearnSoftmax(const plVariable &left_var, const plVariablesConjunction
        &right_vars)`  

        Constructor.  

        Parameters:  
        * `left_var` :  
            The class variable  
        * `right_vars` :  
            The quantitative attribute variables  

    * `plLearnSoftmax()`  

        Default constructor to be used for serialisation.  

    C++ includes: plLearnSoftmax.h

    """

    __swig_setmethods__ = {}
    for _s in [plLearnCndObject]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plLearnSoftmax, name, value)
    __swig_getmethods__ = {}
    for _s in [plLearnCndObject]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plLearnSoftmax, name)
    __repr__ = _swig_repr

    def __init__(self, *args):
        """
        __init__(self, left_var, right_vars) -> plLearnSoftmax
        __init__(self) -> plLearnSoftmax


        `plLearnSoftmax(const plVariable &left_var, const plVariablesConjunction
            &right_vars)`  
        `plLearnSoftmax()`  

        Overloaded function
        -------------------
        * `plLearnSoftmax(const plVariable &left_var, const plVariablesConjunction
            &right_vars)`  

            Constructor.  

            Parameters:  
            * `left_var` :  
                The class variable  
            * `right_vars` :  
                The quantitative attribute variables  

        * `plLearnSoftmax()`  

            Default constructor to be used for serialisation.  

        """
        this = _probt_python3.new_plLearnSoftmax(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def set_solver_parameters(self, solver_conv_threshold: 'plFloat', solver_hessian_inv_threshold: 'plFloat', solver_use_hessian: 'bool', solver_learning_rate: 'plFloat', solver_sampling_rate: 'plFloat', solver_max_iterations: 'unsigned int') -> "void":
        """
        set_solver_parameters(self, solver_conv_threshold, solver_hessian_inv_threshold, solver_use_hessian, solver_learning_rate, solver_sampling_rate, solver_max_iterations)


        `set_solver_parameters(plFloat solver_conv_threshold, plFloat
            solver_hessian_inv_threshold, bool solver_use_hessian, plFloat
            solver_learning_rate, plFloat solver_sampling_rate, unsigned int
            solver_max_iterations)`  

        Set/change the parameters for the optimizer.  

        Parameters
        ----------
        * `solver_conv_threshold` :  
            The convergence threshold to be used for the gradient descent algorithm  
        * `solver_hessian_inv_threshold` :  
            The threshold to be used for *Greville's* algorithm used for the Hessian
            matrix inversion  
        * `solver_use_hessian` :  
            Use second order derivative iif solver_use_hessian is true  
        * `solver_learning_rate` :  
            The gradient descent step  
        * `solver_sampling_rate` :  
            The data sampling rate (for stochastic gradient descent)  
        * `solver_max_iterations` :  
            The maximum number of iterations  

        The default values, corresponding to a Newton-Raphson resolution, are:  

        *   solver_conv_threshold: 0.00001  
        *   solver_hessian_inv_threshold: 0.001  
        *   solver_use_hessian: true  
        *   solver_learning_rate: 1.0  
        *   solver_sampling_rate: 1.0 (use all the data)  
        *   solver_max_iterations: 500  

        Do not change these values unless you know what you are doing.  

        For Newton-Raphson, set for example:  

        *   solver_use_hessian: true  
        *   solver_learning_rate: 1.0  

        For Gradient Descent, set for example:  

        *   solver_use_hessian: false  
        *   solver_learning_rate: 0.01  

        For Stochastic Gradient Descent, set for example:  

        *   solver_use_hessian: false  
        *   solver_learning_rate: 0.01  
        *   solver_sampling_rate: 0.2 (use 20% of the data samples for estimating the
            derivatives for each iteration)  

        """
        return _probt_python3.plLearnSoftmax_set_solver_parameters(self, solver_conv_threshold, solver_hessian_inv_threshold, solver_use_hessian, solver_learning_rate, solver_sampling_rate, solver_max_iterations)

    __swig_destroy__ = _probt_python3.delete_plLearnSoftmax
    __del__ = lambda self: None

    def reset(self) -> "void":
        """
        reset(self)


        `reset()`  

        Resets learning to its initial state.  

        """
        return _probt_python3.plLearnSoftmax_reset(self)


    def get_cnd_distribution(self) -> "plCndDistribution":
        """
        get_cnd_distribution(self) -> plCndDistribution


        `get_cnd_distribution() const -> plCndDistribution`  

        Constructs the corresponding learnt distribution.  

        It computes the $\beta$ matrix using an iterative algorithm (gradient
        descent/newton-raphson) and returns a plSoftmax with the computed $\beta$.  

        """
        return _probt_python3.plLearnSoftmax_get_cnd_distribution(self)


    def get_n_parameters(self) -> "unsigned int":
        """
        get_n_parameters(self) -> unsigned int


        `get_n_parameters() const -> unsigned int`  

        Returns the ACTUAL number of parameters.  

        It could be different from the number of parameters returned by get_parameters.  

        For example, the actual number of parameters of a N dimensional normal
        distribution is N + N*(N+1)/2 because the covariance matrix is symmetric.  

        """
        return _probt_python3.plLearnSoftmax_get_n_parameters(self)


    def clone(self) -> "plLearnObject *":
        """
        clone(self) -> plLearnObject


        `clone() const -> plLearnObject *`  

        Clone the learning object.  

        """
        return _probt_python3.plLearnSoftmax_clone(self)


    def rescale_total_weight(self, s: 'plFloat') -> "void":
        """
        rescale_total_weight(self, s)


        `rescale_total_weight(plFloat s)`  

        Multiply the weight of the past inserted points by a given factor.  

        This allows, for example, to decrease the importance of the old data points
        compared to the new ones  

        """
        return _probt_python3.plLearnSoftmax_rescale_total_weight(self, s)


    def __getstate__(self) -> "std::string":
        """__getstate__(self) -> std::string"""
        return _probt_python3.plLearnSoftmax___getstate__(self)


    def __setstate_internal(self, sState: 'std::string const &') -> "void":
        """__setstate_internal(self, sState)"""
        return _probt_python3.plLearnSoftmax___setstate_internal(self, sState)


    def __setstate__(self, sState):
        self.__init__()
        self.__setstate_internal(sState)

plLearnSoftmax_swigregister = _probt_python3.plLearnSoftmax_swigregister
plLearnSoftmax_swigregister(plLearnSoftmax)

class plLearnSoftmaxFamily(plLearnCndObject):
    """

    `plLearnSoftmaxFamily(const plVariable &left_var, const plVariablesConjunction
        &quantitative_right_vars, const plVariablesConjunction
        &categorical_right_vars)`  
    `plLearnSoftmaxFamily()`  

    Implements a family of softmax regressions (over a set of quantitative
    variables), indexed by a set of categorical variables.  

    Actually, given a categorical variable (or conjunction of variables) $ A $ with
    a cardinality of $ N_A $, this class constructs and learns a set of $ N_A $
    softmax regressions (see plLearnSoftmax).  

    See also: plLearnSoftmax  

    Constructors
    ------------
    * `plLearnSoftmaxFamily(const plVariable &left_var, const plVariablesConjunction
        &quantitative_right_vars, const plVariablesConjunction
        &categorical_right_vars)`  

        Constructor.  

        Parameters:  
        * `left_var` :  
            The class variable  
        * `quantitative_right_vars` :  
            The right (parent) quantitative variables on which the regression is
            computed  
        * `categorical_right_vars` :  
            The right (parent) categorical variables for which we have a regression
            for each modality  

    * `plLearnSoftmaxFamily()`  

        Default constructor to be used for serialisation.  

    C++ includes: plLearnSoftmaxFamily.h

    """

    __swig_setmethods__ = {}
    for _s in [plLearnCndObject]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plLearnSoftmaxFamily, name, value)
    __swig_getmethods__ = {}
    for _s in [plLearnCndObject]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plLearnSoftmaxFamily, name)
    __repr__ = _swig_repr

    def __init__(self, *args):
        """
        __init__(self, left_var, quantitative_right_vars, categorical_right_vars) -> plLearnSoftmaxFamily
        __init__(self) -> plLearnSoftmaxFamily


        `plLearnSoftmaxFamily(const plVariable &left_var, const plVariablesConjunction
            &quantitative_right_vars, const plVariablesConjunction
            &categorical_right_vars)`  
        `plLearnSoftmaxFamily()`  

        Overloaded function
        -------------------
        * `plLearnSoftmaxFamily(const plVariable &left_var, const plVariablesConjunction
            &quantitative_right_vars, const plVariablesConjunction
            &categorical_right_vars)`  

            Constructor.  

            Parameters:  
            * `left_var` :  
                The class variable  
            * `quantitative_right_vars` :  
                The right (parent) quantitative variables on which the regression is
                computed  
            * `categorical_right_vars` :  
                The right (parent) categorical variables for which we have a regression
                for each modality  

        * `plLearnSoftmaxFamily()`  

            Default constructor to be used for serialisation.  

        """
        this = _probt_python3.new_plLearnSoftmaxFamily(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this
    __swig_destroy__ = _probt_python3.delete_plLearnSoftmaxFamily
    __del__ = lambda self: None

    def reset(self) -> "void":
        """
        reset(self)


        `reset()`  

        Resets learning to its initial state.  

        """
        return _probt_python3.plLearnSoftmaxFamily_reset(self)


    def get_cnd_distribution(self) -> "plCndDistribution":
        """
        get_cnd_distribution(self) -> plCndDistribution


        `get_cnd_distribution() const -> plCndDistribution`  

        Constructs the corresponding learnt conditional distribution.  

        It computes the $\beta$ vector for each regression and returns a
        plDistributionTable of plSoftmax.  

        """
        return _probt_python3.plLearnSoftmaxFamily_get_cnd_distribution(self)


    def get_n_parameters(self) -> "unsigned int":
        """
        get_n_parameters(self) -> unsigned int


        `get_n_parameters() const -> unsigned int`  

        Returns the ACTUAL number of parameters.  

        It could be different from the number of parameters returned by get_parameters.  

        For example, the actual number of parameters of a N dimensional normal
        distribution is N + N*(N+1)/2 because the covariance matrix is symmetric.  

        """
        return _probt_python3.plLearnSoftmaxFamily_get_n_parameters(self)


    def clone(self) -> "plLearnObject *":
        """
        clone(self) -> plLearnObject


        `clone() const -> plLearnObject *`  

        Clone the learning object.  

        """
        return _probt_python3.plLearnSoftmaxFamily_clone(self)


    def set_solver_parameters(self, solver_conv_threshold: 'plFloat', solver_hessian_inv_threshold: 'plFloat', solver_use_hessian: 'bool', solver_learning_rate: 'plFloat', solver_sampling_rate: 'plFloat', solver_max_iterations: 'unsigned int') -> "void":
        """
        set_solver_parameters(self, solver_conv_threshold, solver_hessian_inv_threshold, solver_use_hessian, solver_learning_rate, solver_sampling_rate, solver_max_iterations)


        `set_solver_parameters(plFloat solver_conv_threshold, plFloat
            solver_hessian_inv_threshold, bool solver_use_hessian, plFloat
            solver_learning_rate, plFloat solver_sampling_rate, unsigned int
            solver_max_iterations)`  

        Set/change the parameters for the optimizer.  

        See also: plLearnSoftmax::set_solver_parameters()  

        Do not change the default values unless you know what you are doing.  

        """
        return _probt_python3.plLearnSoftmaxFamily_set_solver_parameters(self, solver_conv_threshold, solver_hessian_inv_threshold, solver_use_hessian, solver_learning_rate, solver_sampling_rate, solver_max_iterations)


    def rescale_total_weight(self, s: 'plFloat') -> "void":
        """
        rescale_total_weight(self, s)


        `rescale_total_weight(plFloat s)`  

        Multiply the weight of the past inserted points by a given factor.  

        This allows, for example, to decrease the importance of the old data points
        compared to the new ones  

        """
        return _probt_python3.plLearnSoftmaxFamily_rescale_total_weight(self, s)


    def __getstate__(self) -> "std::string":
        """__getstate__(self) -> std::string"""
        return _probt_python3.plLearnSoftmaxFamily___getstate__(self)


    def __setstate_internal(self, sState: 'std::string const &') -> "void":
        """__setstate_internal(self, sState)"""
        return _probt_python3.plLearnSoftmaxFamily___setstate_internal(self, sState)


    def __setstate__(self, sState):
        self.__init__()
        self.__setstate_internal(sState)

plLearnSoftmaxFamily_swigregister = _probt_python3.plLearnSoftmaxFamily_swigregister
plLearnSoftmaxFamily_swigregister(plLearnSoftmaxFamily)

class plLearnDistributionTable(plLearnCndObject):
    """

    `plLearnDistributionTable(const plVariablesConjunction &left_vars, const
        plVariablesConjunction &right_vars)`  
    `plLearnDistributionTable(const plVariablesConjunction &left_vars, const
        plVariablesConjunction &right_vars, const plLearnObject &init_object)`  
    `plLearnDistributionTable()`  
    `plLearnDistributionTable(const plLearnDistributionTable &other)`  

    This class implements conditional learning objects as a map.  

    Learning a conditional distribution P(X | Y) consists in using a map of non-
    conditional learning objects. This map contains, for each possible value of Y a
    non-conditional learning object on X. These non-conditional learning objects are
    added using the plLearnDistributionTable::push() and
    plLearnDistributionTable::push_default() methods.  

    See also: plCndLearnObject  

    Constructors
    ------------
    * `plLearnDistributionTable(const plVariablesConjunction &left_vars, const
        plVariablesConjunction &right_vars)`  

        Constructor.  

    * `plLearnDistributionTable(const plVariablesConjunction &left_vars, const
        plVariablesConjunction &right_vars, const plLearnObject &init_object)`  

        Constructor when using the same type for non conditional learning objects
        for all the values of the right variables.  

        *init_object* will be used as initilization even after calling reset()
        function  

    * `plLearnDistributionTable()`  

        Default constructor to be used for serialisation.  

    * `plLearnDistributionTable(const plLearnDistributionTable &other)`  

        Copy constructor.  

    C++ includes: plLearnDistributionTable.h

    """

    __swig_setmethods__ = {}
    for _s in [plLearnCndObject]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plLearnDistributionTable, name, value)
    __swig_getmethods__ = {}
    for _s in [plLearnCndObject]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plLearnDistributionTable, name)
    __repr__ = _swig_repr

    def __init__(self, *args):
        """
        __init__(self, left_vars, right_vars) -> plLearnDistributionTable
        __init__(self, left_vars, right_vars, init_object) -> plLearnDistributionTable
        __init__(self) -> plLearnDistributionTable
        __init__(self, other) -> plLearnDistributionTable


        `plLearnDistributionTable(const plVariablesConjunction &left_vars, const
            plVariablesConjunction &right_vars)`  
        `plLearnDistributionTable(const plVariablesConjunction &left_vars, const
            plVariablesConjunction &right_vars, const plLearnObject &init_object)`  
        `plLearnDistributionTable()`  
        `plLearnDistributionTable(const plLearnDistributionTable &other)`  

        Overloaded function
        -------------------
        * `plLearnDistributionTable(const plVariablesConjunction &left_vars, const
            plVariablesConjunction &right_vars)`  

            Constructor.  

        * `plLearnDistributionTable(const plVariablesConjunction &left_vars, const
            plVariablesConjunction &right_vars, const plLearnObject &init_object)`  

            Constructor when using the same type for non conditional learning objects
            for all the values of the right variables.  

            *init_object* will be used as initilization even after calling reset()
            function  

        * `plLearnDistributionTable()`  

            Default constructor to be used for serialisation.  

        * `plLearnDistributionTable(const plLearnDistributionTable &other)`  

            Copy constructor.  

        """
        this = _probt_python3.new_plLearnDistributionTable(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this
    __swig_destroy__ = _probt_python3.delete_plLearnDistributionTable
    __del__ = lambda self: None

    def push(self, *args) -> "void":
        """
        push(self, learn_object, value)
        push(self, learn_object, value)
        push(self, learn_object, value)


        `push(const plLearnObject &learn_object, const plValues &value)`  
        `push(const plLearnObject &learn_object, int value)`  
        `push(const plLearnObject &learn_object, plFloat value)`  

        Overloaded function
        -------------------
        * `push(const plLearnObject &learn_object, const plValues &value)`  

            Inserts a new non-conditional learning object with a given right value.  

            A clone of the passed *learn_object* is created and stored internally (i.e.
            with no side-effect on the passed *learn_object*).  

        * `push(const plLearnObject &learn_object, int value)`  

            Inserts a new non-conditional learning object with a given right value.  

            A clone of the passed *learn_object* is created and stored internally (i.e.
            with no side-effect on the passed *learn_object*).  

        * `push(const plLearnObject &learn_object, plFloat value)`  

            Inserts a new non-conditional learning object with a given right value.  

            A clone of the passed *learn_object* is created and stored internally (i.e.
            with no side-effect on the passed *learn_object*).  

        """
        return _probt_python3.plLearnDistributionTable_push(self, *args)


    def push_default(self, default_learn_object: 'plLearnObject') -> "void":
        """
        push_default(self, default_learn_object)


        `push_default(const plLearnObject &default_learn_object)`  

        Inserts a new non-conditional learning object as a default one for all the right
        values that have not been inserted using push().  

        A clone of the passed *default_learn_object* is created and stored internally
        (i.e. with no side-effect on the passed *default_learn_object*).  

        """
        return _probt_python3.plLearnDistributionTable_push_default(self, default_learn_object)


    def reset(self) -> "void":
        """
        reset(self)


        `reset()`  

        Resets learning to its initial state.  

        """
        return _probt_python3.plLearnDistributionTable_reset(self)


    def get_distribution_table(self) -> "plDistributionTable":
        """
        get_distribution_table(self) -> plDistributionTable


        `get_distribution_table() const -> plDistributionTable`  

        Creates the distribution table corresponding to the learnt conditional
        distribution.  

        Consider calling the more efficient get_cnd_distribution() if you do not need to
        change the returned conditional distribution later.  

        If no default learning object is provided using push_default(), then the
        returned distribution table does not contain a default function for the right
        values that have never been inserted. Consider calling push_default() on the
        returned distribution table in order to customize it.  

        See also: get_cnd_distribution()  

        """
        return _probt_python3.plLearnDistributionTable_get_distribution_table(self)


    def get_cnd_distribution(self) -> "plCndDistribution":
        """
        get_cnd_distribution(self) -> plCndDistribution


        `get_cnd_distribution() const -> plCndDistribution`  

        Constructs the corresponding learnt conditional distribution.  

        It's equivalent to calling get_distribution_table() but the returned
        distribution is read-only and thus is more efficient. Moreover, if no default
        learning object is inserted (no call to push_default()), then the returned
        conditional distribution will contain a uniform distribution for the right
        values that have never been inserted.  

        """
        return _probt_python3.plLearnDistributionTable_get_cnd_distribution(self)


    def get_total_weights(self, w: 'DoubleVector') -> "void":
        """
        get_total_weights(self, w)


        `get_total_weights(std::vector< plFloat > &w) const`  

        Returns, for each right value, the total weight of the inserted points.  

        """
        return _probt_python3.plLearnDistributionTable_get_total_weights(self, w)


    def rescale_total_weight(self, s: 'plFloat') -> "void":
        """
        rescale_total_weight(self, s)


        `rescale_total_weight(plFloat s)`  

        Multiply the weight of the past inserted points by a given factor.  

        This allows, for example, to decrease the importance of the old data points
        compared to the new ones  

        """
        return _probt_python3.plLearnDistributionTable_rescale_total_weight(self, s)


    def get_all_nsamples(self, n: 'UnsignedIntVector') -> "void":
        """
        get_all_nsamples(self, n)


        `get_all_nsamples(std::vector< unsigned int > &n) const`  

        Returns, for each right value, the corresponding number of the inserted points.  

        """
        return _probt_python3.plLearnDistributionTable_get_all_nsamples(self, n)


    def get_nsamples_for_value(self, right_value: 'plValues') -> "unsigned int":
        """
        get_nsamples_for_value(self, right_value) -> unsigned int


        `get_nsamples_for_value(const plValues &right_value) const -> unsigned int`  

        Get the number of the inserted points for given right value.  

        """
        return _probt_python3.plLearnDistributionTable_get_nsamples_for_value(self, right_value)


    def get_learnt_object_for_value(self, right_value: 'plValues') -> "plLearnObject const *":
        """
        get_learnt_object_for_value(self, right_value) -> plLearnObject


        `get_learnt_object_for_value(const plValues &right_value) const -> const
            plLearnObject *`  

        Returns a pointer to the non conditional learning object corresponding to the
        *right_value* value of the right variables.  

        Returns 0 if *right_value* has never been seen.  

        """
        return _probt_python3.plLearnDistributionTable_get_learnt_object_for_value(self, right_value)


    def get_n_parameters(self) -> "unsigned int":
        """
        get_n_parameters(self) -> unsigned int


        `get_n_parameters() const -> unsigned int`  

        Returns the ACTUAL number of parameters.  

        It could be different from the number of parameters returned by get_parameters.  

        For example, the actual number of parameters of a N dimensional normal
        distribution is N + N*(N+1)/2 because the covariance matrix is symmetric.  

        """
        return _probt_python3.plLearnDistributionTable_get_n_parameters(self)


    def clone(self) -> "plLearnObject *":
        """
        clone(self) -> plLearnObject


        `clone() const -> plLearnObject *`  

        Clone the learning object.  

        """
        return _probt_python3.plLearnDistributionTable_clone(self)


    def __getstate__(self) -> "std::string":
        """__getstate__(self) -> std::string"""
        return _probt_python3.plLearnDistributionTable___getstate__(self)


    def __setstate_internal(self, sState: 'std::string const &') -> "void":
        """__setstate_internal(self, sState)"""
        return _probt_python3.plLearnDistributionTable___setstate_internal(self, sState)


    def __setstate__(self, sState):
        self.__init__()
        self.__setstate_internal(sState)

plLearnDistributionTable_swigregister = _probt_python3.plLearnDistributionTable_swigregister
plLearnDistributionTable_swigregister(plLearnDistributionTable)

class plCndBayesLearn1dNormalWithKnownMean(plLearnDistributionTable):
    """


    This template class implements conditional learning objects.  

    Learning a conditional distribution P(X | Y) for a given learning object type
    (template parameter) T, consists in building a map of non-conditional learning
    objects of type T. This map will contain, for each possible value of Y a non-
    conditional learning object of type T on X. The learning objects are assumed to
    be of the same type T. Consider using plLearnDistributionTable if you want to
    use different types depending on the right variable (Y) values.  

    This template class is instantiated for all plNonCndLearnObject subclasses.  

    See also: plLearnDistributionTable  

    C++ includes: plCndLearnObject.h

    """

    __swig_setmethods__ = {}
    for _s in [plLearnDistributionTable]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plCndBayesLearn1dNormalWithKnownMean, name, value)
    __swig_getmethods__ = {}
    for _s in [plLearnDistributionTable]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plCndBayesLearn1dNormalWithKnownMean, name)
    __repr__ = _swig_repr

    def __init__(self, *args):
        """
        __init__(self) -> plCndBayesLearn1dNormalWithKnownMean
        __init__(self, left_vars, right_vars, init_object) -> plCndBayesLearn1dNormalWithKnownMean
        __init__(self, left_vars, right_vars) -> plCndBayesLearn1dNormalWithKnownMean


        `plCndLearnObject()`  
        `plCndLearnObject(const plVariablesConjunction &left_vars, const
            plVariablesConjunction &right_vars, const T &init_object=T())`  

        Overloaded function
        -------------------
        * `plCndLearnObject()`  

            Empty constructor used for serialization.  

        * `plCndLearnObject(const plVariablesConjunction &left_vars, const
            plVariablesConjunction &right_vars, const T &init_object=T())`  

            Constructor to learn the conditional distribution P(left_vars | right_vars).  

            If *init_object* is not empty (the default value), then learning for each
            right value is initialized by *init_object* and the returned distribution
            when get_distribution_table() (or get_computable_object()) is called will
            contain a default function obtained by calling get_distribution() on
            *init_object*.  

        """
        this = _probt_python3.new_plCndBayesLearn1dNormalWithKnownMean(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def get_learnt_object_for_value(self, right_value: 'plValues') -> "plBayesLearn1dNormalWithKnownMean const *":
        """
        get_learnt_object_for_value(self, right_value) -> plBayesLearn1dNormalWithKnownMean


        `get_learnt_object_for_value(const plValues &right_value) const -> const T *`  

        Returns a pointer to the T learning object corresponding to the *right_value*
        value of the right variables.  

        Returns 0 if *right_value* has never been seen.  

        """
        return _probt_python3.plCndBayesLearn1dNormalWithKnownMean_get_learnt_object_for_value(self, right_value)


    def clone(self) -> "plLearnObject *":
        """
        clone(self) -> plLearnObject


        `clone() const -> plLearnObject *`  

        Clone the learning object.  

        """
        return _probt_python3.plCndBayesLearn1dNormalWithKnownMean_clone(self)


    def get_cnd_distribution(self) -> "plCndDistribution":
        """
        get_cnd_distribution(self) -> plCndDistribution


        `get_cnd_distribution() const -> plCndDistribution`  

        Constructs and returns the conditional ditribution corresponding to the current
        state of this learner.  

        """
        return _probt_python3.plCndBayesLearn1dNormalWithKnownMean_get_cnd_distribution(self)

    __swig_destroy__ = _probt_python3.delete_plCndBayesLearn1dNormalWithKnownMean
    __del__ = lambda self: None
plCndBayesLearn1dNormalWithKnownMean_swigregister = _probt_python3.plCndBayesLearn1dNormalWithKnownMean_swigregister
plCndBayesLearn1dNormalWithKnownMean_swigregister(plCndBayesLearn1dNormalWithKnownMean)

class plCndBayesLearn1dNormalWithKnownStandardDeviation(plLearnDistributionTable):
    """


    This template class implements conditional learning objects.  

    Learning a conditional distribution P(X | Y) for a given learning object type
    (template parameter) T, consists in building a map of non-conditional learning
    objects of type T. This map will contain, for each possible value of Y a non-
    conditional learning object of type T on X. The learning objects are assumed to
    be of the same type T. Consider using plLearnDistributionTable if you want to
    use different types depending on the right variable (Y) values.  

    This template class is instantiated for all plNonCndLearnObject subclasses.  

    See also: plLearnDistributionTable  

    C++ includes: plCndLearnObject.h

    """

    __swig_setmethods__ = {}
    for _s in [plLearnDistributionTable]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plCndBayesLearn1dNormalWithKnownStandardDeviation, name, value)
    __swig_getmethods__ = {}
    for _s in [plLearnDistributionTable]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plCndBayesLearn1dNormalWithKnownStandardDeviation, name)
    __repr__ = _swig_repr

    def __init__(self, *args):
        """
        __init__(self) -> plCndBayesLearn1dNormalWithKnownStandardDeviation
        __init__(self, left_vars, right_vars, init_object) -> plCndBayesLearn1dNormalWithKnownStandardDeviation
        __init__(self, left_vars, right_vars) -> plCndBayesLearn1dNormalWithKnownStandardDeviation


        `plCndLearnObject()`  
        `plCndLearnObject(const plVariablesConjunction &left_vars, const
            plVariablesConjunction &right_vars, const T &init_object=T())`  

        Overloaded function
        -------------------
        * `plCndLearnObject()`  

            Empty constructor used for serialization.  

        * `plCndLearnObject(const plVariablesConjunction &left_vars, const
            plVariablesConjunction &right_vars, const T &init_object=T())`  

            Constructor to learn the conditional distribution P(left_vars | right_vars).  

            If *init_object* is not empty (the default value), then learning for each
            right value is initialized by *init_object* and the returned distribution
            when get_distribution_table() (or get_computable_object()) is called will
            contain a default function obtained by calling get_distribution() on
            *init_object*.  

        """
        this = _probt_python3.new_plCndBayesLearn1dNormalWithKnownStandardDeviation(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def get_learnt_object_for_value(self, right_value: 'plValues') -> "plBayesLearn1dNormalWithKnownStandardDeviation const *":
        """
        get_learnt_object_for_value(self, right_value) -> plBayesLearn1dNormalWithKnownStandardDeviation


        `get_learnt_object_for_value(const plValues &right_value) const -> const T *`  

        Returns a pointer to the T learning object corresponding to the *right_value*
        value of the right variables.  

        Returns 0 if *right_value* has never been seen.  

        """
        return _probt_python3.plCndBayesLearn1dNormalWithKnownStandardDeviation_get_learnt_object_for_value(self, right_value)


    def clone(self) -> "plLearnObject *":
        """
        clone(self) -> plLearnObject


        `clone() const -> plLearnObject *`  

        Clone the learning object.  

        """
        return _probt_python3.plCndBayesLearn1dNormalWithKnownStandardDeviation_clone(self)


    def get_cnd_distribution(self) -> "plCndDistribution":
        """
        get_cnd_distribution(self) -> plCndDistribution


        `get_cnd_distribution() const -> plCndDistribution`  

        Constructs and returns the conditional ditribution corresponding to the current
        state of this learner.  

        """
        return _probt_python3.plCndBayesLearn1dNormalWithKnownStandardDeviation_get_cnd_distribution(self)

    __swig_destroy__ = _probt_python3.delete_plCndBayesLearn1dNormalWithKnownStandardDeviation
    __del__ = lambda self: None
plCndBayesLearn1dNormalWithKnownStandardDeviation_swigregister = _probt_python3.plCndBayesLearn1dNormalWithKnownStandardDeviation_swigregister
plCndBayesLearn1dNormalWithKnownStandardDeviation_swigregister(plCndBayesLearn1dNormalWithKnownStandardDeviation)

class plCndBayesLearnBinomial(plLearnDistributionTable):
    """


    This template class implements conditional learning objects.  

    Learning a conditional distribution P(X | Y) for a given learning object type
    (template parameter) T, consists in building a map of non-conditional learning
    objects of type T. This map will contain, for each possible value of Y a non-
    conditional learning object of type T on X. The learning objects are assumed to
    be of the same type T. Consider using plLearnDistributionTable if you want to
    use different types depending on the right variable (Y) values.  

    This template class is instantiated for all plNonCndLearnObject subclasses.  

    See also: plLearnDistributionTable  

    C++ includes: plCndLearnObject.h

    """

    __swig_setmethods__ = {}
    for _s in [plLearnDistributionTable]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plCndBayesLearnBinomial, name, value)
    __swig_getmethods__ = {}
    for _s in [plLearnDistributionTable]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plCndBayesLearnBinomial, name)
    __repr__ = _swig_repr

    def __init__(self, *args):
        """
        __init__(self) -> plCndBayesLearnBinomial
        __init__(self, left_vars, right_vars, init_object) -> plCndBayesLearnBinomial
        __init__(self, left_vars, right_vars) -> plCndBayesLearnBinomial


        `plCndLearnObject()`  
        `plCndLearnObject(const plVariablesConjunction &left_vars, const
            plVariablesConjunction &right_vars, const T &init_object=T())`  

        Overloaded function
        -------------------
        * `plCndLearnObject()`  

            Empty constructor used for serialization.  

        * `plCndLearnObject(const plVariablesConjunction &left_vars, const
            plVariablesConjunction &right_vars, const T &init_object=T())`  

            Constructor to learn the conditional distribution P(left_vars | right_vars).  

            If *init_object* is not empty (the default value), then learning for each
            right value is initialized by *init_object* and the returned distribution
            when get_distribution_table() (or get_computable_object()) is called will
            contain a default function obtained by calling get_distribution() on
            *init_object*.  

        """
        this = _probt_python3.new_plCndBayesLearnBinomial(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def get_learnt_object_for_value(self, right_value: 'plValues') -> "plBayesLearnBinomial const *":
        """
        get_learnt_object_for_value(self, right_value) -> plBayesLearnBinomial


        `get_learnt_object_for_value(const plValues &right_value) const -> const T *`  

        Returns a pointer to the T learning object corresponding to the *right_value*
        value of the right variables.  

        Returns 0 if *right_value* has never been seen.  

        """
        return _probt_python3.plCndBayesLearnBinomial_get_learnt_object_for_value(self, right_value)


    def clone(self) -> "plLearnObject *":
        """
        clone(self) -> plLearnObject


        `clone() const -> plLearnObject *`  

        Clone the learning object.  

        """
        return _probt_python3.plCndBayesLearnBinomial_clone(self)


    def get_cnd_distribution(self) -> "plCndDistribution":
        """
        get_cnd_distribution(self) -> plCndDistribution


        `get_cnd_distribution() const -> plCndDistribution`  

        Constructs and returns the conditional ditribution corresponding to the current
        state of this learner.  

        """
        return _probt_python3.plCndBayesLearnBinomial_get_cnd_distribution(self)

    __swig_destroy__ = _probt_python3.delete_plCndBayesLearnBinomial
    __del__ = lambda self: None
plCndBayesLearnBinomial_swigregister = _probt_python3.plCndBayesLearnBinomial_swigregister
plCndBayesLearnBinomial_swigregister(plCndBayesLearnBinomial)

class plCndBayesLearnExponential(plLearnDistributionTable):
    """


    This template class implements conditional learning objects.  

    Learning a conditional distribution P(X | Y) for a given learning object type
    (template parameter) T, consists in building a map of non-conditional learning
    objects of type T. This map will contain, for each possible value of Y a non-
    conditional learning object of type T on X. The learning objects are assumed to
    be of the same type T. Consider using plLearnDistributionTable if you want to
    use different types depending on the right variable (Y) values.  

    This template class is instantiated for all plNonCndLearnObject subclasses.  

    See also: plLearnDistributionTable  

    C++ includes: plCndLearnObject.h

    """

    __swig_setmethods__ = {}
    for _s in [plLearnDistributionTable]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plCndBayesLearnExponential, name, value)
    __swig_getmethods__ = {}
    for _s in [plLearnDistributionTable]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plCndBayesLearnExponential, name)
    __repr__ = _swig_repr

    def __init__(self, *args):
        """
        __init__(self) -> plCndBayesLearnExponential
        __init__(self, left_vars, right_vars, init_object) -> plCndBayesLearnExponential
        __init__(self, left_vars, right_vars) -> plCndBayesLearnExponential


        `plCndLearnObject()`  
        `plCndLearnObject(const plVariablesConjunction &left_vars, const
            plVariablesConjunction &right_vars, const T &init_object=T())`  

        Overloaded function
        -------------------
        * `plCndLearnObject()`  

            Empty constructor used for serialization.  

        * `plCndLearnObject(const plVariablesConjunction &left_vars, const
            plVariablesConjunction &right_vars, const T &init_object=T())`  

            Constructor to learn the conditional distribution P(left_vars | right_vars).  

            If *init_object* is not empty (the default value), then learning for each
            right value is initialized by *init_object* and the returned distribution
            when get_distribution_table() (or get_computable_object()) is called will
            contain a default function obtained by calling get_distribution() on
            *init_object*.  

        """
        this = _probt_python3.new_plCndBayesLearnExponential(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def get_learnt_object_for_value(self, right_value: 'plValues') -> "plBayesLearnExponential const *":
        """
        get_learnt_object_for_value(self, right_value) -> plBayesLearnExponential


        `get_learnt_object_for_value(const plValues &right_value) const -> const T *`  

        Returns a pointer to the T learning object corresponding to the *right_value*
        value of the right variables.  

        Returns 0 if *right_value* has never been seen.  

        """
        return _probt_python3.plCndBayesLearnExponential_get_learnt_object_for_value(self, right_value)


    def clone(self) -> "plLearnObject *":
        """
        clone(self) -> plLearnObject


        `clone() const -> plLearnObject *`  

        Clone the learning object.  

        """
        return _probt_python3.plCndBayesLearnExponential_clone(self)


    def get_cnd_distribution(self) -> "plCndDistribution":
        """
        get_cnd_distribution(self) -> plCndDistribution


        `get_cnd_distribution() const -> plCndDistribution`  

        Constructs and returns the conditional ditribution corresponding to the current
        state of this learner.  

        """
        return _probt_python3.plCndBayesLearnExponential_get_cnd_distribution(self)

    __swig_destroy__ = _probt_python3.delete_plCndBayesLearnExponential
    __del__ = lambda self: None
plCndBayesLearnExponential_swigregister = _probt_python3.plCndBayesLearnExponential_swigregister
plCndBayesLearnExponential_swigregister(plCndBayesLearnExponential)

class plCndBayesLearnGamma(plLearnDistributionTable):
    """


    This template class implements conditional learning objects.  

    Learning a conditional distribution P(X | Y) for a given learning object type
    (template parameter) T, consists in building a map of non-conditional learning
    objects of type T. This map will contain, for each possible value of Y a non-
    conditional learning object of type T on X. The learning objects are assumed to
    be of the same type T. Consider using plLearnDistributionTable if you want to
    use different types depending on the right variable (Y) values.  

    This template class is instantiated for all plNonCndLearnObject subclasses.  

    See also: plLearnDistributionTable  

    C++ includes: plCndLearnObject.h

    """

    __swig_setmethods__ = {}
    for _s in [plLearnDistributionTable]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plCndBayesLearnGamma, name, value)
    __swig_getmethods__ = {}
    for _s in [plLearnDistributionTable]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plCndBayesLearnGamma, name)
    __repr__ = _swig_repr

    def __init__(self, *args):
        """
        __init__(self) -> plCndBayesLearnGamma
        __init__(self, left_vars, right_vars, init_object) -> plCndBayesLearnGamma
        __init__(self, left_vars, right_vars) -> plCndBayesLearnGamma


        `plCndLearnObject()`  
        `plCndLearnObject(const plVariablesConjunction &left_vars, const
            plVariablesConjunction &right_vars, const T &init_object=T())`  

        Overloaded function
        -------------------
        * `plCndLearnObject()`  

            Empty constructor used for serialization.  

        * `plCndLearnObject(const plVariablesConjunction &left_vars, const
            plVariablesConjunction &right_vars, const T &init_object=T())`  

            Constructor to learn the conditional distribution P(left_vars | right_vars).  

            If *init_object* is not empty (the default value), then learning for each
            right value is initialized by *init_object* and the returned distribution
            when get_distribution_table() (or get_computable_object()) is called will
            contain a default function obtained by calling get_distribution() on
            *init_object*.  

        """
        this = _probt_python3.new_plCndBayesLearnGamma(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def get_learnt_object_for_value(self, right_value: 'plValues') -> "plBayesLearnGamma const *":
        """
        get_learnt_object_for_value(self, right_value) -> plBayesLearnGamma


        `get_learnt_object_for_value(const plValues &right_value) const -> const T *`  

        Returns a pointer to the T learning object corresponding to the *right_value*
        value of the right variables.  

        Returns 0 if *right_value* has never been seen.  

        """
        return _probt_python3.plCndBayesLearnGamma_get_learnt_object_for_value(self, right_value)


    def clone(self) -> "plLearnObject *":
        """
        clone(self) -> plLearnObject


        `clone() const -> plLearnObject *`  

        Clone the learning object.  

        """
        return _probt_python3.plCndBayesLearnGamma_clone(self)


    def get_cnd_distribution(self) -> "plCndDistribution":
        """
        get_cnd_distribution(self) -> plCndDistribution


        `get_cnd_distribution() const -> plCndDistribution`  

        Constructs and returns the conditional ditribution corresponding to the current
        state of this learner.  

        """
        return _probt_python3.plCndBayesLearnGamma_get_cnd_distribution(self)

    __swig_destroy__ = _probt_python3.delete_plCndBayesLearnGamma
    __del__ = lambda self: None
plCndBayesLearnGamma_swigregister = _probt_python3.plCndBayesLearnGamma_swigregister
plCndBayesLearnGamma_swigregister(plCndBayesLearnGamma)

class plCndBayesLearnLogNormalWithKnownShape(plLearnDistributionTable):
    """


    This template class implements conditional learning objects.  

    Learning a conditional distribution P(X | Y) for a given learning object type
    (template parameter) T, consists in building a map of non-conditional learning
    objects of type T. This map will contain, for each possible value of Y a non-
    conditional learning object of type T on X. The learning objects are assumed to
    be of the same type T. Consider using plLearnDistributionTable if you want to
    use different types depending on the right variable (Y) values.  

    This template class is instantiated for all plNonCndLearnObject subclasses.  

    See also: plLearnDistributionTable  

    C++ includes: plCndLearnObject.h

    """

    __swig_setmethods__ = {}
    for _s in [plLearnDistributionTable]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plCndBayesLearnLogNormalWithKnownShape, name, value)
    __swig_getmethods__ = {}
    for _s in [plLearnDistributionTable]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plCndBayesLearnLogNormalWithKnownShape, name)
    __repr__ = _swig_repr

    def __init__(self, *args):
        """
        __init__(self) -> plCndBayesLearnLogNormalWithKnownShape
        __init__(self, left_vars, right_vars, init_object) -> plCndBayesLearnLogNormalWithKnownShape
        __init__(self, left_vars, right_vars) -> plCndBayesLearnLogNormalWithKnownShape


        `plCndLearnObject()`  
        `plCndLearnObject(const plVariablesConjunction &left_vars, const
            plVariablesConjunction &right_vars, const T &init_object=T())`  

        Overloaded function
        -------------------
        * `plCndLearnObject()`  

            Empty constructor used for serialization.  

        * `plCndLearnObject(const plVariablesConjunction &left_vars, const
            plVariablesConjunction &right_vars, const T &init_object=T())`  

            Constructor to learn the conditional distribution P(left_vars | right_vars).  

            If *init_object* is not empty (the default value), then learning for each
            right value is initialized by *init_object* and the returned distribution
            when get_distribution_table() (or get_computable_object()) is called will
            contain a default function obtained by calling get_distribution() on
            *init_object*.  

        """
        this = _probt_python3.new_plCndBayesLearnLogNormalWithKnownShape(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def get_learnt_object_for_value(self, right_value: 'plValues') -> "plBayesLearnLogNormalWithKnownShape const *":
        """
        get_learnt_object_for_value(self, right_value) -> plBayesLearnLogNormalWithKnownShape


        `get_learnt_object_for_value(const plValues &right_value) const -> const T *`  

        Returns a pointer to the T learning object corresponding to the *right_value*
        value of the right variables.  

        Returns 0 if *right_value* has never been seen.  

        """
        return _probt_python3.plCndBayesLearnLogNormalWithKnownShape_get_learnt_object_for_value(self, right_value)


    def clone(self) -> "plLearnObject *":
        """
        clone(self) -> plLearnObject


        `clone() const -> plLearnObject *`  

        Clone the learning object.  

        """
        return _probt_python3.plCndBayesLearnLogNormalWithKnownShape_clone(self)


    def get_cnd_distribution(self) -> "plCndDistribution":
        """
        get_cnd_distribution(self) -> plCndDistribution


        `get_cnd_distribution() const -> plCndDistribution`  

        Constructs and returns the conditional ditribution corresponding to the current
        state of this learner.  

        """
        return _probt_python3.plCndBayesLearnLogNormalWithKnownShape_get_cnd_distribution(self)

    __swig_destroy__ = _probt_python3.delete_plCndBayesLearnLogNormalWithKnownShape
    __del__ = lambda self: None
plCndBayesLearnLogNormalWithKnownShape_swigregister = _probt_python3.plCndBayesLearnLogNormalWithKnownShape_swigregister
plCndBayesLearnLogNormalWithKnownShape_swigregister(plCndBayesLearnLogNormalWithKnownShape)

class plCndBayesLearnNdNormalWithKnownVariance(plLearnDistributionTable):
    """


    This template class implements conditional learning objects.  

    Learning a conditional distribution P(X | Y) for a given learning object type
    (template parameter) T, consists in building a map of non-conditional learning
    objects of type T. This map will contain, for each possible value of Y a non-
    conditional learning object of type T on X. The learning objects are assumed to
    be of the same type T. Consider using plLearnDistributionTable if you want to
    use different types depending on the right variable (Y) values.  

    This template class is instantiated for all plNonCndLearnObject subclasses.  

    See also: plLearnDistributionTable  

    C++ includes: plCndLearnObject.h

    """

    __swig_setmethods__ = {}
    for _s in [plLearnDistributionTable]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plCndBayesLearnNdNormalWithKnownVariance, name, value)
    __swig_getmethods__ = {}
    for _s in [plLearnDistributionTable]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plCndBayesLearnNdNormalWithKnownVariance, name)
    __repr__ = _swig_repr

    def __init__(self, *args):
        """
        __init__(self) -> plCndBayesLearnNdNormalWithKnownVariance
        __init__(self, left_vars, right_vars, init_object) -> plCndBayesLearnNdNormalWithKnownVariance
        __init__(self, left_vars, right_vars) -> plCndBayesLearnNdNormalWithKnownVariance


        `plCndLearnObject()`  
        `plCndLearnObject(const plVariablesConjunction &left_vars, const
            plVariablesConjunction &right_vars, const T &init_object=T())`  

        Overloaded function
        -------------------
        * `plCndLearnObject()`  

            Empty constructor used for serialization.  

        * `plCndLearnObject(const plVariablesConjunction &left_vars, const
            plVariablesConjunction &right_vars, const T &init_object=T())`  

            Constructor to learn the conditional distribution P(left_vars | right_vars).  

            If *init_object* is not empty (the default value), then learning for each
            right value is initialized by *init_object* and the returned distribution
            when get_distribution_table() (or get_computable_object()) is called will
            contain a default function obtained by calling get_distribution() on
            *init_object*.  

        """
        this = _probt_python3.new_plCndBayesLearnNdNormalWithKnownVariance(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def get_learnt_object_for_value(self, right_value: 'plValues') -> "plBayesLearnNdNormalWithKnownVariance const *":
        """
        get_learnt_object_for_value(self, right_value) -> plBayesLearnNdNormalWithKnownVariance


        `get_learnt_object_for_value(const plValues &right_value) const -> const T *`  

        Returns a pointer to the T learning object corresponding to the *right_value*
        value of the right variables.  

        Returns 0 if *right_value* has never been seen.  

        """
        return _probt_python3.plCndBayesLearnNdNormalWithKnownVariance_get_learnt_object_for_value(self, right_value)


    def clone(self) -> "plLearnObject *":
        """
        clone(self) -> plLearnObject


        `clone() const -> plLearnObject *`  

        Clone the learning object.  

        """
        return _probt_python3.plCndBayesLearnNdNormalWithKnownVariance_clone(self)


    def get_cnd_distribution(self) -> "plCndDistribution":
        """
        get_cnd_distribution(self) -> plCndDistribution


        `get_cnd_distribution() const -> plCndDistribution`  

        Constructs and returns the conditional ditribution corresponding to the current
        state of this learner.  

        """
        return _probt_python3.plCndBayesLearnNdNormalWithKnownVariance_get_cnd_distribution(self)

    __swig_destroy__ = _probt_python3.delete_plCndBayesLearnNdNormalWithKnownVariance
    __del__ = lambda self: None
plCndBayesLearnNdNormalWithKnownVariance_swigregister = _probt_python3.plCndBayesLearnNdNormalWithKnownVariance_swigregister
plCndBayesLearnNdNormalWithKnownVariance_swigregister(plCndBayesLearnNdNormalWithKnownVariance)

class plCndBayesLearnPoisson(plLearnDistributionTable):
    """


    This template class implements conditional learning objects.  

    Learning a conditional distribution P(X | Y) for a given learning object type
    (template parameter) T, consists in building a map of non-conditional learning
    objects of type T. This map will contain, for each possible value of Y a non-
    conditional learning object of type T on X. The learning objects are assumed to
    be of the same type T. Consider using plLearnDistributionTable if you want to
    use different types depending on the right variable (Y) values.  

    This template class is instantiated for all plNonCndLearnObject subclasses.  

    See also: plLearnDistributionTable  

    C++ includes: plCndLearnObject.h

    """

    __swig_setmethods__ = {}
    for _s in [plLearnDistributionTable]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plCndBayesLearnPoisson, name, value)
    __swig_getmethods__ = {}
    for _s in [plLearnDistributionTable]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plCndBayesLearnPoisson, name)
    __repr__ = _swig_repr

    def __init__(self, *args):
        """
        __init__(self) -> plCndBayesLearnPoisson
        __init__(self, left_vars, right_vars, init_object) -> plCndBayesLearnPoisson
        __init__(self, left_vars, right_vars) -> plCndBayesLearnPoisson


        `plCndLearnObject()`  
        `plCndLearnObject(const plVariablesConjunction &left_vars, const
            plVariablesConjunction &right_vars, const T &init_object=T())`  

        Overloaded function
        -------------------
        * `plCndLearnObject()`  

            Empty constructor used for serialization.  

        * `plCndLearnObject(const plVariablesConjunction &left_vars, const
            plVariablesConjunction &right_vars, const T &init_object=T())`  

            Constructor to learn the conditional distribution P(left_vars | right_vars).  

            If *init_object* is not empty (the default value), then learning for each
            right value is initialized by *init_object* and the returned distribution
            when get_distribution_table() (or get_computable_object()) is called will
            contain a default function obtained by calling get_distribution() on
            *init_object*.  

        """
        this = _probt_python3.new_plCndBayesLearnPoisson(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def get_learnt_object_for_value(self, right_value: 'plValues') -> "plBayesLearnPoisson const *":
        """
        get_learnt_object_for_value(self, right_value) -> plBayesLearnPoisson


        `get_learnt_object_for_value(const plValues &right_value) const -> const T *`  

        Returns a pointer to the T learning object corresponding to the *right_value*
        value of the right variables.  

        Returns 0 if *right_value* has never been seen.  

        """
        return _probt_python3.plCndBayesLearnPoisson_get_learnt_object_for_value(self, right_value)


    def clone(self) -> "plLearnObject *":
        """
        clone(self) -> plLearnObject


        `clone() const -> plLearnObject *`  

        Clone the learning object.  

        """
        return _probt_python3.plCndBayesLearnPoisson_clone(self)


    def get_cnd_distribution(self) -> "plCndDistribution":
        """
        get_cnd_distribution(self) -> plCndDistribution


        `get_cnd_distribution() const -> plCndDistribution`  

        Constructs and returns the conditional ditribution corresponding to the current
        state of this learner.  

        """
        return _probt_python3.plCndBayesLearnPoisson_get_cnd_distribution(self)

    __swig_destroy__ = _probt_python3.delete_plCndBayesLearnPoisson
    __del__ = lambda self: None
plCndBayesLearnPoisson_swigregister = _probt_python3.plCndBayesLearnPoisson_swigregister
plCndBayesLearnPoisson_swigregister(plCndBayesLearnPoisson)

class plCndBayesLearnProbTable(plLearnDistributionTable):
    """


    This template class implements conditional learning objects.  

    Learning a conditional distribution P(X | Y) for a given learning object type
    (template parameter) T, consists in building a map of non-conditional learning
    objects of type T. This map will contain, for each possible value of Y a non-
    conditional learning object of type T on X. The learning objects are assumed to
    be of the same type T. Consider using plLearnDistributionTable if you want to
    use different types depending on the right variable (Y) values.  

    This template class is instantiated for all plNonCndLearnObject subclasses.  

    See also: plLearnDistributionTable  

    C++ includes: plCndLearnObject.h

    """

    __swig_setmethods__ = {}
    for _s in [plLearnDistributionTable]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plCndBayesLearnProbTable, name, value)
    __swig_getmethods__ = {}
    for _s in [plLearnDistributionTable]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plCndBayesLearnProbTable, name)
    __repr__ = _swig_repr

    def __init__(self, *args):
        """
        __init__(self) -> plCndBayesLearnProbTable
        __init__(self, left_vars, right_vars, init_object) -> plCndBayesLearnProbTable
        __init__(self, left_vars, right_vars) -> plCndBayesLearnProbTable


        `plCndLearnObject()`  
        `plCndLearnObject(const plVariablesConjunction &left_vars, const
            plVariablesConjunction &right_vars, const T &init_object=T())`  

        Overloaded function
        -------------------
        * `plCndLearnObject()`  

            Empty constructor used for serialization.  

        * `plCndLearnObject(const plVariablesConjunction &left_vars, const
            plVariablesConjunction &right_vars, const T &init_object=T())`  

            Constructor to learn the conditional distribution P(left_vars | right_vars).  

            If *init_object* is not empty (the default value), then learning for each
            right value is initialized by *init_object* and the returned distribution
            when get_distribution_table() (or get_computable_object()) is called will
            contain a default function obtained by calling get_distribution() on
            *init_object*.  

        """
        this = _probt_python3.new_plCndBayesLearnProbTable(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def get_learnt_object_for_value(self, right_value: 'plValues') -> "plBayesLearnProbTable const *":
        """
        get_learnt_object_for_value(self, right_value) -> plBayesLearnProbTable


        `get_learnt_object_for_value(const plValues &right_value) const -> const T *`  

        Returns a pointer to the T learning object corresponding to the *right_value*
        value of the right variables.  

        Returns 0 if *right_value* has never been seen.  

        """
        return _probt_python3.plCndBayesLearnProbTable_get_learnt_object_for_value(self, right_value)


    def clone(self) -> "plLearnObject *":
        """
        clone(self) -> plLearnObject


        `clone() const -> plLearnObject *`  

        Clone the learning object.  

        """
        return _probt_python3.plCndBayesLearnProbTable_clone(self)


    def get_cnd_distribution(self) -> "plCndDistribution":
        """
        get_cnd_distribution(self) -> plCndDistribution


        `get_cnd_distribution() const -> plCndDistribution`  

        Constructs and returns the conditional ditribution corresponding to the current
        state of this learner.  

        """
        return _probt_python3.plCndBayesLearnProbTable_get_cnd_distribution(self)

    __swig_destroy__ = _probt_python3.delete_plCndBayesLearnProbTable
    __del__ = lambda self: None
plCndBayesLearnProbTable_swigregister = _probt_python3.plCndBayesLearnProbTable_swigregister
plCndBayesLearnProbTable_swigregister(plCndBayesLearnProbTable)

class plCndLearn1dNormal(plLearnDistributionTable):
    """


    This template class implements conditional learning objects.  

    Learning a conditional distribution P(X | Y) for a given learning object type
    (template parameter) T, consists in building a map of non-conditional learning
    objects of type T. This map will contain, for each possible value of Y a non-
    conditional learning object of type T on X. The learning objects are assumed to
    be of the same type T. Consider using plLearnDistributionTable if you want to
    use different types depending on the right variable (Y) values.  

    This template class is instantiated for all plNonCndLearnObject subclasses.  

    See also: plLearnDistributionTable  

    C++ includes: plCndLearnObject.h

    """

    __swig_setmethods__ = {}
    for _s in [plLearnDistributionTable]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plCndLearn1dNormal, name, value)
    __swig_getmethods__ = {}
    for _s in [plLearnDistributionTable]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plCndLearn1dNormal, name)
    __repr__ = _swig_repr

    def __init__(self, *args):
        """
        __init__(self) -> plCndLearn1dNormal
        __init__(self, left_vars, right_vars, init_object) -> plCndLearn1dNormal
        __init__(self, left_vars, right_vars) -> plCndLearn1dNormal


        `plCndLearnObject()`  
        `plCndLearnObject(const plVariablesConjunction &left_vars, const
            plVariablesConjunction &right_vars, const T &init_object=T())`  

        Overloaded function
        -------------------
        * `plCndLearnObject()`  

            Empty constructor used for serialization.  

        * `plCndLearnObject(const plVariablesConjunction &left_vars, const
            plVariablesConjunction &right_vars, const T &init_object=T())`  

            Constructor to learn the conditional distribution P(left_vars | right_vars).  

            If *init_object* is not empty (the default value), then learning for each
            right value is initialized by *init_object* and the returned distribution
            when get_distribution_table() (or get_computable_object()) is called will
            contain a default function obtained by calling get_distribution() on
            *init_object*.  

        """
        this = _probt_python3.new_plCndLearn1dNormal(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def get_learnt_object_for_value(self, right_value: 'plValues') -> "plLearn1dNormal const *":
        """
        get_learnt_object_for_value(self, right_value) -> plLearn1dNormal


        `get_learnt_object_for_value(const plValues &right_value) const -> const T *`  

        Returns a pointer to the T learning object corresponding to the *right_value*
        value of the right variables.  

        Returns 0 if *right_value* has never been seen.  

        """
        return _probt_python3.plCndLearn1dNormal_get_learnt_object_for_value(self, right_value)


    def clone(self) -> "plLearnObject *":
        """
        clone(self) -> plLearnObject


        `clone() const -> plLearnObject *`  

        Clone the learning object.  

        """
        return _probt_python3.plCndLearn1dNormal_clone(self)


    def get_cnd_distribution(self) -> "plCndDistribution":
        """
        get_cnd_distribution(self) -> plCndDistribution


        `get_cnd_distribution() const -> plCndDistribution`  

        Constructs and returns the conditional ditribution corresponding to the current
        state of this learner.  

        """
        return _probt_python3.plCndLearn1dNormal_get_cnd_distribution(self)

    __swig_destroy__ = _probt_python3.delete_plCndLearn1dNormal
    __del__ = lambda self: None
plCndLearn1dNormal_swigregister = _probt_python3.plCndLearn1dNormal_swigregister
plCndLearn1dNormal_swigregister(plCndLearn1dNormal)

class plCndLearnBeta(plLearnDistributionTable):
    """


    This template class implements conditional learning objects.  

    Learning a conditional distribution P(X | Y) for a given learning object type
    (template parameter) T, consists in building a map of non-conditional learning
    objects of type T. This map will contain, for each possible value of Y a non-
    conditional learning object of type T on X. The learning objects are assumed to
    be of the same type T. Consider using plLearnDistributionTable if you want to
    use different types depending on the right variable (Y) values.  

    This template class is instantiated for all plNonCndLearnObject subclasses.  

    See also: plLearnDistributionTable  

    C++ includes: plCndLearnObject.h

    """

    __swig_setmethods__ = {}
    for _s in [plLearnDistributionTable]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plCndLearnBeta, name, value)
    __swig_getmethods__ = {}
    for _s in [plLearnDistributionTable]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plCndLearnBeta, name)
    __repr__ = _swig_repr

    def __init__(self, *args):
        """
        __init__(self) -> plCndLearnBeta
        __init__(self, left_vars, right_vars, init_object) -> plCndLearnBeta
        __init__(self, left_vars, right_vars) -> plCndLearnBeta


        `plCndLearnObject()`  
        `plCndLearnObject(const plVariablesConjunction &left_vars, const
            plVariablesConjunction &right_vars, const T &init_object=T())`  

        Overloaded function
        -------------------
        * `plCndLearnObject()`  

            Empty constructor used for serialization.  

        * `plCndLearnObject(const plVariablesConjunction &left_vars, const
            plVariablesConjunction &right_vars, const T &init_object=T())`  

            Constructor to learn the conditional distribution P(left_vars | right_vars).  

            If *init_object* is not empty (the default value), then learning for each
            right value is initialized by *init_object* and the returned distribution
            when get_distribution_table() (or get_computable_object()) is called will
            contain a default function obtained by calling get_distribution() on
            *init_object*.  

        """
        this = _probt_python3.new_plCndLearnBeta(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def get_learnt_object_for_value(self, right_value: 'plValues') -> "plLearnBeta const *":
        """
        get_learnt_object_for_value(self, right_value) -> plLearnBeta


        `get_learnt_object_for_value(const plValues &right_value) const -> const T *`  

        Returns a pointer to the T learning object corresponding to the *right_value*
        value of the right variables.  

        Returns 0 if *right_value* has never been seen.  

        """
        return _probt_python3.plCndLearnBeta_get_learnt_object_for_value(self, right_value)


    def clone(self) -> "plLearnObject *":
        """
        clone(self) -> plLearnObject


        `clone() const -> plLearnObject *`  

        Clone the learning object.  

        """
        return _probt_python3.plCndLearnBeta_clone(self)


    def get_cnd_distribution(self) -> "plCndDistribution":
        """
        get_cnd_distribution(self) -> plCndDistribution


        `get_cnd_distribution() const -> plCndDistribution`  

        Constructs and returns the conditional ditribution corresponding to the current
        state of this learner.  

        """
        return _probt_python3.plCndLearnBeta_get_cnd_distribution(self)

    __swig_destroy__ = _probt_python3.delete_plCndLearnBeta
    __del__ = lambda self: None
plCndLearnBeta_swigregister = _probt_python3.plCndLearnBeta_swigregister
plCndLearnBeta_swigregister(plCndLearnBeta)

class plCndLearnExponential(plLearnDistributionTable):
    """


    This template class implements conditional learning objects.  

    Learning a conditional distribution P(X | Y) for a given learning object type
    (template parameter) T, consists in building a map of non-conditional learning
    objects of type T. This map will contain, for each possible value of Y a non-
    conditional learning object of type T on X. The learning objects are assumed to
    be of the same type T. Consider using plLearnDistributionTable if you want to
    use different types depending on the right variable (Y) values.  

    This template class is instantiated for all plNonCndLearnObject subclasses.  

    See also: plLearnDistributionTable  

    C++ includes: plCndLearnObject.h

    """

    __swig_setmethods__ = {}
    for _s in [plLearnDistributionTable]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plCndLearnExponential, name, value)
    __swig_getmethods__ = {}
    for _s in [plLearnDistributionTable]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plCndLearnExponential, name)
    __repr__ = _swig_repr

    def __init__(self, *args):
        """
        __init__(self) -> plCndLearnExponential
        __init__(self, left_vars, right_vars, init_object) -> plCndLearnExponential
        __init__(self, left_vars, right_vars) -> plCndLearnExponential


        `plCndLearnObject()`  
        `plCndLearnObject(const plVariablesConjunction &left_vars, const
            plVariablesConjunction &right_vars, const T &init_object=T())`  

        Overloaded function
        -------------------
        * `plCndLearnObject()`  

            Empty constructor used for serialization.  

        * `plCndLearnObject(const plVariablesConjunction &left_vars, const
            plVariablesConjunction &right_vars, const T &init_object=T())`  

            Constructor to learn the conditional distribution P(left_vars | right_vars).  

            If *init_object* is not empty (the default value), then learning for each
            right value is initialized by *init_object* and the returned distribution
            when get_distribution_table() (or get_computable_object()) is called will
            contain a default function obtained by calling get_distribution() on
            *init_object*.  

        """
        this = _probt_python3.new_plCndLearnExponential(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def get_learnt_object_for_value(self, right_value: 'plValues') -> "plLearnExponential const *":
        """
        get_learnt_object_for_value(self, right_value) -> plLearnExponential


        `get_learnt_object_for_value(const plValues &right_value) const -> const T *`  

        Returns a pointer to the T learning object corresponding to the *right_value*
        value of the right variables.  

        Returns 0 if *right_value* has never been seen.  

        """
        return _probt_python3.plCndLearnExponential_get_learnt_object_for_value(self, right_value)


    def clone(self) -> "plLearnObject *":
        """
        clone(self) -> plLearnObject


        `clone() const -> plLearnObject *`  

        Clone the learning object.  

        """
        return _probt_python3.plCndLearnExponential_clone(self)


    def get_cnd_distribution(self) -> "plCndDistribution":
        """
        get_cnd_distribution(self) -> plCndDistribution


        `get_cnd_distribution() const -> plCndDistribution`  

        Constructs and returns the conditional ditribution corresponding to the current
        state of this learner.  

        """
        return _probt_python3.plCndLearnExponential_get_cnd_distribution(self)

    __swig_destroy__ = _probt_python3.delete_plCndLearnExponential
    __del__ = lambda self: None
plCndLearnExponential_swigregister = _probt_python3.plCndLearnExponential_swigregister
plCndLearnExponential_swigregister(plCndLearnExponential)

class plCndLearnGMM(plLearnDistributionTable):
    """


    This template class implements conditional learning objects.  

    Learning a conditional distribution P(X | Y) for a given learning object type
    (template parameter) T, consists in building a map of non-conditional learning
    objects of type T. This map will contain, for each possible value of Y a non-
    conditional learning object of type T on X. The learning objects are assumed to
    be of the same type T. Consider using plLearnDistributionTable if you want to
    use different types depending on the right variable (Y) values.  

    This template class is instantiated for all plNonCndLearnObject subclasses.  

    See also: plLearnDistributionTable  

    C++ includes: plCndLearnObject.h

    """

    __swig_setmethods__ = {}
    for _s in [plLearnDistributionTable]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plCndLearnGMM, name, value)
    __swig_getmethods__ = {}
    for _s in [plLearnDistributionTable]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plCndLearnGMM, name)
    __repr__ = _swig_repr

    def __init__(self, *args):
        """
        __init__(self) -> plCndLearnGMM
        __init__(self, left_vars, right_vars, init_object) -> plCndLearnGMM
        __init__(self, left_vars, right_vars) -> plCndLearnGMM


        `plCndLearnObject()`  
        `plCndLearnObject(const plVariablesConjunction &left_vars, const
            plVariablesConjunction &right_vars, const T &init_object=T())`  

        Overloaded function
        -------------------
        * `plCndLearnObject()`  

            Empty constructor used for serialization.  

        * `plCndLearnObject(const plVariablesConjunction &left_vars, const
            plVariablesConjunction &right_vars, const T &init_object=T())`  

            Constructor to learn the conditional distribution P(left_vars | right_vars).  

            If *init_object* is not empty (the default value), then learning for each
            right value is initialized by *init_object* and the returned distribution
            when get_distribution_table() (or get_computable_object()) is called will
            contain a default function obtained by calling get_distribution() on
            *init_object*.  

        """
        this = _probt_python3.new_plCndLearnGMM(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def get_learnt_object_for_value(self, right_value: 'plValues') -> "plLearnGMM const *":
        """
        get_learnt_object_for_value(self, right_value) -> plLearnGMM


        `get_learnt_object_for_value(const plValues &right_value) const -> const T *`  

        Returns a pointer to the T learning object corresponding to the *right_value*
        value of the right variables.  

        Returns 0 if *right_value* has never been seen.  

        """
        return _probt_python3.plCndLearnGMM_get_learnt_object_for_value(self, right_value)


    def clone(self) -> "plLearnObject *":
        """
        clone(self) -> plLearnObject


        `clone() const -> plLearnObject *`  

        Clone the learning object.  

        """
        return _probt_python3.plCndLearnGMM_clone(self)


    def get_cnd_distribution(self) -> "plCndDistribution":
        """
        get_cnd_distribution(self) -> plCndDistribution


        `get_cnd_distribution() const -> plCndDistribution`  

        Constructs and returns the conditional ditribution corresponding to the current
        state of this learner.  

        """
        return _probt_python3.plCndLearnGMM_get_cnd_distribution(self)

    __swig_destroy__ = _probt_python3.delete_plCndLearnGMM
    __del__ = lambda self: None
plCndLearnGMM_swigregister = _probt_python3.plCndLearnGMM_swigregister
plCndLearnGMM_swigregister(plCndLearnGMM)

class plCndLearnGamma(plLearnDistributionTable):
    """


    This template class implements conditional learning objects.  

    Learning a conditional distribution P(X | Y) for a given learning object type
    (template parameter) T, consists in building a map of non-conditional learning
    objects of type T. This map will contain, for each possible value of Y a non-
    conditional learning object of type T on X. The learning objects are assumed to
    be of the same type T. Consider using plLearnDistributionTable if you want to
    use different types depending on the right variable (Y) values.  

    This template class is instantiated for all plNonCndLearnObject subclasses.  

    See also: plLearnDistributionTable  

    C++ includes: plCndLearnObject.h

    """

    __swig_setmethods__ = {}
    for _s in [plLearnDistributionTable]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plCndLearnGamma, name, value)
    __swig_getmethods__ = {}
    for _s in [plLearnDistributionTable]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plCndLearnGamma, name)
    __repr__ = _swig_repr

    def __init__(self, *args):
        """
        __init__(self) -> plCndLearnGamma
        __init__(self, left_vars, right_vars, init_object) -> plCndLearnGamma
        __init__(self, left_vars, right_vars) -> plCndLearnGamma


        `plCndLearnObject()`  
        `plCndLearnObject(const plVariablesConjunction &left_vars, const
            plVariablesConjunction &right_vars, const T &init_object=T())`  

        Overloaded function
        -------------------
        * `plCndLearnObject()`  

            Empty constructor used for serialization.  

        * `plCndLearnObject(const plVariablesConjunction &left_vars, const
            plVariablesConjunction &right_vars, const T &init_object=T())`  

            Constructor to learn the conditional distribution P(left_vars | right_vars).  

            If *init_object* is not empty (the default value), then learning for each
            right value is initialized by *init_object* and the returned distribution
            when get_distribution_table() (or get_computable_object()) is called will
            contain a default function obtained by calling get_distribution() on
            *init_object*.  

        """
        this = _probt_python3.new_plCndLearnGamma(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def get_learnt_object_for_value(self, right_value: 'plValues') -> "plLearnGamma const *":
        """
        get_learnt_object_for_value(self, right_value) -> plLearnGamma


        `get_learnt_object_for_value(const plValues &right_value) const -> const T *`  

        Returns a pointer to the T learning object corresponding to the *right_value*
        value of the right variables.  

        Returns 0 if *right_value* has never been seen.  

        """
        return _probt_python3.plCndLearnGamma_get_learnt_object_for_value(self, right_value)


    def clone(self) -> "plLearnObject *":
        """
        clone(self) -> plLearnObject


        `clone() const -> plLearnObject *`  

        Clone the learning object.  

        """
        return _probt_python3.plCndLearnGamma_clone(self)


    def get_cnd_distribution(self) -> "plCndDistribution":
        """
        get_cnd_distribution(self) -> plCndDistribution


        `get_cnd_distribution() const -> plCndDistribution`  

        Constructs and returns the conditional ditribution corresponding to the current
        state of this learner.  

        """
        return _probt_python3.plCndLearnGamma_get_cnd_distribution(self)

    __swig_destroy__ = _probt_python3.delete_plCndLearnGamma
    __del__ = lambda self: None
plCndLearnGamma_swigregister = _probt_python3.plCndLearnGamma_swigregister
plCndLearnGamma_swigregister(plCndLearnGamma)

class plCndLearnHistogram(plLearnDistributionTable):
    """


    This template class implements conditional learning objects.  

    Learning a conditional distribution P(X | Y) for a given learning object type
    (template parameter) T, consists in building a map of non-conditional learning
    objects of type T. This map will contain, for each possible value of Y a non-
    conditional learning object of type T on X. The learning objects are assumed to
    be of the same type T. Consider using plLearnDistributionTable if you want to
    use different types depending on the right variable (Y) values.  

    This template class is instantiated for all plNonCndLearnObject subclasses.  

    See also: plLearnDistributionTable  

    C++ includes: plCndLearnObject.h

    """

    __swig_setmethods__ = {}
    for _s in [plLearnDistributionTable]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plCndLearnHistogram, name, value)
    __swig_getmethods__ = {}
    for _s in [plLearnDistributionTable]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plCndLearnHistogram, name)
    __repr__ = _swig_repr

    def __init__(self, *args):
        """
        __init__(self) -> plCndLearnHistogram
        __init__(self, left_vars, right_vars, init_object) -> plCndLearnHistogram
        __init__(self, left_vars, right_vars) -> plCndLearnHistogram


        `plCndLearnObject()`  
        `plCndLearnObject(const plVariablesConjunction &left_vars, const
            plVariablesConjunction &right_vars, const T &init_object=T())`  

        Overloaded function
        -------------------
        * `plCndLearnObject()`  

            Empty constructor used for serialization.  

        * `plCndLearnObject(const plVariablesConjunction &left_vars, const
            plVariablesConjunction &right_vars, const T &init_object=T())`  

            Constructor to learn the conditional distribution P(left_vars | right_vars).  

            If *init_object* is not empty (the default value), then learning for each
            right value is initialized by *init_object* and the returned distribution
            when get_distribution_table() (or get_computable_object()) is called will
            contain a default function obtained by calling get_distribution() on
            *init_object*.  

        """
        this = _probt_python3.new_plCndLearnHistogram(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def get_learnt_object_for_value(self, right_value: 'plValues') -> "plLearnHistogram const *":
        """
        get_learnt_object_for_value(self, right_value) -> plLearnHistogram


        `get_learnt_object_for_value(const plValues &right_value) const -> const T *`  

        Returns a pointer to the T learning object corresponding to the *right_value*
        value of the right variables.  

        Returns 0 if *right_value* has never been seen.  

        """
        return _probt_python3.plCndLearnHistogram_get_learnt_object_for_value(self, right_value)


    def clone(self) -> "plLearnObject *":
        """
        clone(self) -> plLearnObject


        `clone() const -> plLearnObject *`  

        Clone the learning object.  

        """
        return _probt_python3.plCndLearnHistogram_clone(self)


    def get_cnd_distribution(self) -> "plCndDistribution":
        """
        get_cnd_distribution(self) -> plCndDistribution


        `get_cnd_distribution() const -> plCndDistribution`  

        Constructs and returns the conditional ditribution corresponding to the current
        state of this learner.  

        """
        return _probt_python3.plCndLearnHistogram_get_cnd_distribution(self)

    __swig_destroy__ = _probt_python3.delete_plCndLearnHistogram
    __del__ = lambda self: None
plCndLearnHistogram_swigregister = _probt_python3.plCndLearnHistogram_swigregister
plCndLearnHistogram_swigregister(plCndLearnHistogram)

class plCndLearnLaplace(plLearnDistributionTable):
    """


    This template class implements conditional learning objects.  

    Learning a conditional distribution P(X | Y) for a given learning object type
    (template parameter) T, consists in building a map of non-conditional learning
    objects of type T. This map will contain, for each possible value of Y a non-
    conditional learning object of type T on X. The learning objects are assumed to
    be of the same type T. Consider using plLearnDistributionTable if you want to
    use different types depending on the right variable (Y) values.  

    This template class is instantiated for all plNonCndLearnObject subclasses.  

    See also: plLearnDistributionTable  

    C++ includes: plCndLearnObject.h

    """

    __swig_setmethods__ = {}
    for _s in [plLearnDistributionTable]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plCndLearnLaplace, name, value)
    __swig_getmethods__ = {}
    for _s in [plLearnDistributionTable]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plCndLearnLaplace, name)
    __repr__ = _swig_repr

    def __init__(self, *args):
        """
        __init__(self) -> plCndLearnLaplace
        __init__(self, left_vars, right_vars, init_object) -> plCndLearnLaplace
        __init__(self, left_vars, right_vars) -> plCndLearnLaplace


        `plCndLearnObject()`  
        `plCndLearnObject(const plVariablesConjunction &left_vars, const
            plVariablesConjunction &right_vars, const T &init_object=T())`  

        Overloaded function
        -------------------
        * `plCndLearnObject()`  

            Empty constructor used for serialization.  

        * `plCndLearnObject(const plVariablesConjunction &left_vars, const
            plVariablesConjunction &right_vars, const T &init_object=T())`  

            Constructor to learn the conditional distribution P(left_vars | right_vars).  

            If *init_object* is not empty (the default value), then learning for each
            right value is initialized by *init_object* and the returned distribution
            when get_distribution_table() (or get_computable_object()) is called will
            contain a default function obtained by calling get_distribution() on
            *init_object*.  

        """
        this = _probt_python3.new_plCndLearnLaplace(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def get_learnt_object_for_value(self, right_value: 'plValues') -> "plLearnLaplace const *":
        """
        get_learnt_object_for_value(self, right_value) -> plLearnLaplace


        `get_learnt_object_for_value(const plValues &right_value) const -> const T *`  

        Returns a pointer to the T learning object corresponding to the *right_value*
        value of the right variables.  

        Returns 0 if *right_value* has never been seen.  

        """
        return _probt_python3.plCndLearnLaplace_get_learnt_object_for_value(self, right_value)


    def clone(self) -> "plLearnObject *":
        """
        clone(self) -> plLearnObject


        `clone() const -> plLearnObject *`  

        Clone the learning object.  

        """
        return _probt_python3.plCndLearnLaplace_clone(self)


    def get_cnd_distribution(self) -> "plCndDistribution":
        """
        get_cnd_distribution(self) -> plCndDistribution


        `get_cnd_distribution() const -> plCndDistribution`  

        Constructs and returns the conditional ditribution corresponding to the current
        state of this learner.  

        """
        return _probt_python3.plCndLearnLaplace_get_cnd_distribution(self)

    __swig_destroy__ = _probt_python3.delete_plCndLearnLaplace
    __del__ = lambda self: None
plCndLearnLaplace_swigregister = _probt_python3.plCndLearnLaplace_swigregister
plCndLearnLaplace_swigregister(plCndLearnLaplace)

class plCndLearnLidstone(plLearnDistributionTable):
    """


    This template class implements conditional learning objects.  

    Learning a conditional distribution P(X | Y) for a given learning object type
    (template parameter) T, consists in building a map of non-conditional learning
    objects of type T. This map will contain, for each possible value of Y a non-
    conditional learning object of type T on X. The learning objects are assumed to
    be of the same type T. Consider using plLearnDistributionTable if you want to
    use different types depending on the right variable (Y) values.  

    This template class is instantiated for all plNonCndLearnObject subclasses.  

    See also: plLearnDistributionTable  

    C++ includes: plCndLearnObject.h

    """

    __swig_setmethods__ = {}
    for _s in [plLearnDistributionTable]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plCndLearnLidstone, name, value)
    __swig_getmethods__ = {}
    for _s in [plLearnDistributionTable]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plCndLearnLidstone, name)
    __repr__ = _swig_repr

    def __init__(self, *args):
        """
        __init__(self) -> plCndLearnLidstone
        __init__(self, left_vars, right_vars, init_object) -> plCndLearnLidstone
        __init__(self, left_vars, right_vars) -> plCndLearnLidstone


        `plCndLearnObject()`  
        `plCndLearnObject(const plVariablesConjunction &left_vars, const
            plVariablesConjunction &right_vars, const T &init_object=T())`  

        Overloaded function
        -------------------
        * `plCndLearnObject()`  

            Empty constructor used for serialization.  

        * `plCndLearnObject(const plVariablesConjunction &left_vars, const
            plVariablesConjunction &right_vars, const T &init_object=T())`  

            Constructor to learn the conditional distribution P(left_vars | right_vars).  

            If *init_object* is not empty (the default value), then learning for each
            right value is initialized by *init_object* and the returned distribution
            when get_distribution_table() (or get_computable_object()) is called will
            contain a default function obtained by calling get_distribution() on
            *init_object*.  

        """
        this = _probt_python3.new_plCndLearnLidstone(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def get_learnt_object_for_value(self, right_value: 'plValues') -> "plLearnLidstone const *":
        """
        get_learnt_object_for_value(self, right_value) -> plLearnLidstone


        `get_learnt_object_for_value(const plValues &right_value) const -> const T *`  

        Returns a pointer to the T learning object corresponding to the *right_value*
        value of the right variables.  

        Returns 0 if *right_value* has never been seen.  

        """
        return _probt_python3.plCndLearnLidstone_get_learnt_object_for_value(self, right_value)


    def clone(self) -> "plLearnObject *":
        """
        clone(self) -> plLearnObject


        `clone() const -> plLearnObject *`  

        Clone the learning object.  

        """
        return _probt_python3.plCndLearnLidstone_clone(self)


    def get_cnd_distribution(self) -> "plCndDistribution":
        """
        get_cnd_distribution(self) -> plCndDistribution


        `get_cnd_distribution() const -> plCndDistribution`  

        Constructs and returns the conditional ditribution corresponding to the current
        state of this learner.  

        """
        return _probt_python3.plCndLearnLidstone_get_cnd_distribution(self)

    __swig_destroy__ = _probt_python3.delete_plCndLearnLidstone
    __del__ = lambda self: None
plCndLearnLidstone_swigregister = _probt_python3.plCndLearnLidstone_swigregister
plCndLearnLidstone_swigregister(plCndLearnLidstone)

class plCndLearnLogNormal(plLearnDistributionTable):
    """


    This template class implements conditional learning objects.  

    Learning a conditional distribution P(X | Y) for a given learning object type
    (template parameter) T, consists in building a map of non-conditional learning
    objects of type T. This map will contain, for each possible value of Y a non-
    conditional learning object of type T on X. The learning objects are assumed to
    be of the same type T. Consider using plLearnDistributionTable if you want to
    use different types depending on the right variable (Y) values.  

    This template class is instantiated for all plNonCndLearnObject subclasses.  

    See also: plLearnDistributionTable  

    C++ includes: plCndLearnObject.h

    """

    __swig_setmethods__ = {}
    for _s in [plLearnDistributionTable]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plCndLearnLogNormal, name, value)
    __swig_getmethods__ = {}
    for _s in [plLearnDistributionTable]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plCndLearnLogNormal, name)
    __repr__ = _swig_repr

    def __init__(self, *args):
        """
        __init__(self) -> plCndLearnLogNormal
        __init__(self, left_vars, right_vars, init_object) -> plCndLearnLogNormal
        __init__(self, left_vars, right_vars) -> plCndLearnLogNormal


        `plCndLearnObject()`  
        `plCndLearnObject(const plVariablesConjunction &left_vars, const
            plVariablesConjunction &right_vars, const T &init_object=T())`  

        Overloaded function
        -------------------
        * `plCndLearnObject()`  

            Empty constructor used for serialization.  

        * `plCndLearnObject(const plVariablesConjunction &left_vars, const
            plVariablesConjunction &right_vars, const T &init_object=T())`  

            Constructor to learn the conditional distribution P(left_vars | right_vars).  

            If *init_object* is not empty (the default value), then learning for each
            right value is initialized by *init_object* and the returned distribution
            when get_distribution_table() (or get_computable_object()) is called will
            contain a default function obtained by calling get_distribution() on
            *init_object*.  

        """
        this = _probt_python3.new_plCndLearnLogNormal(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def get_learnt_object_for_value(self, right_value: 'plValues') -> "plLearnLogNormal const *":
        """
        get_learnt_object_for_value(self, right_value) -> plLearnLogNormal


        `get_learnt_object_for_value(const plValues &right_value) const -> const T *`  

        Returns a pointer to the T learning object corresponding to the *right_value*
        value of the right variables.  

        Returns 0 if *right_value* has never been seen.  

        """
        return _probt_python3.plCndLearnLogNormal_get_learnt_object_for_value(self, right_value)


    def clone(self) -> "plLearnObject *":
        """
        clone(self) -> plLearnObject


        `clone() const -> plLearnObject *`  

        Clone the learning object.  

        """
        return _probt_python3.plCndLearnLogNormal_clone(self)


    def get_cnd_distribution(self) -> "plCndDistribution":
        """
        get_cnd_distribution(self) -> plCndDistribution


        `get_cnd_distribution() const -> plCndDistribution`  

        Constructs and returns the conditional ditribution corresponding to the current
        state of this learner.  

        """
        return _probt_python3.plCndLearnLogNormal_get_cnd_distribution(self)

    __swig_destroy__ = _probt_python3.delete_plCndLearnLogNormal
    __del__ = lambda self: None
plCndLearnLogNormal_swigregister = _probt_python3.plCndLearnLogNormal_swigregister
plCndLearnLogNormal_swigregister(plCndLearnLogNormal)

class plCndLearnNdNormal(plLearnDistributionTable):
    """


    This template class implements conditional learning objects.  

    Learning a conditional distribution P(X | Y) for a given learning object type
    (template parameter) T, consists in building a map of non-conditional learning
    objects of type T. This map will contain, for each possible value of Y a non-
    conditional learning object of type T on X. The learning objects are assumed to
    be of the same type T. Consider using plLearnDistributionTable if you want to
    use different types depending on the right variable (Y) values.  

    This template class is instantiated for all plNonCndLearnObject subclasses.  

    See also: plLearnDistributionTable  

    C++ includes: plCndLearnObject.h

    """

    __swig_setmethods__ = {}
    for _s in [plLearnDistributionTable]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plCndLearnNdNormal, name, value)
    __swig_getmethods__ = {}
    for _s in [plLearnDistributionTable]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plCndLearnNdNormal, name)
    __repr__ = _swig_repr

    def __init__(self, *args):
        """
        __init__(self) -> plCndLearnNdNormal
        __init__(self, left_vars, right_vars, init_object) -> plCndLearnNdNormal
        __init__(self, left_vars, right_vars) -> plCndLearnNdNormal


        `plCndLearnObject()`  
        `plCndLearnObject(const plVariablesConjunction &left_vars, const
            plVariablesConjunction &right_vars, const T &init_object=T())`  

        Overloaded function
        -------------------
        * `plCndLearnObject()`  

            Empty constructor used for serialization.  

        * `plCndLearnObject(const plVariablesConjunction &left_vars, const
            plVariablesConjunction &right_vars, const T &init_object=T())`  

            Constructor to learn the conditional distribution P(left_vars | right_vars).  

            If *init_object* is not empty (the default value), then learning for each
            right value is initialized by *init_object* and the returned distribution
            when get_distribution_table() (or get_computable_object()) is called will
            contain a default function obtained by calling get_distribution() on
            *init_object*.  

        """
        this = _probt_python3.new_plCndLearnNdNormal(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def get_learnt_object_for_value(self, right_value: 'plValues') -> "plLearnNdNormal const *":
        """
        get_learnt_object_for_value(self, right_value) -> plLearnNdNormal


        `get_learnt_object_for_value(const plValues &right_value) const -> const T *`  

        Returns a pointer to the T learning object corresponding to the *right_value*
        value of the right variables.  

        Returns 0 if *right_value* has never been seen.  

        """
        return _probt_python3.plCndLearnNdNormal_get_learnt_object_for_value(self, right_value)


    def clone(self) -> "plLearnObject *":
        """
        clone(self) -> plLearnObject


        `clone() const -> plLearnObject *`  

        Clone the learning object.  

        """
        return _probt_python3.plCndLearnNdNormal_clone(self)


    def get_cnd_distribution(self) -> "plCndDistribution":
        """
        get_cnd_distribution(self) -> plCndDistribution


        `get_cnd_distribution() const -> plCndDistribution`  

        Constructs and returns the conditional ditribution corresponding to the current
        state of this learner.  

        """
        return _probt_python3.plCndLearnNdNormal_get_cnd_distribution(self)

    __swig_destroy__ = _probt_python3.delete_plCndLearnNdNormal
    __del__ = lambda self: None
plCndLearnNdNormal_swigregister = _probt_python3.plCndLearnNdNormal_swigregister
plCndLearnNdNormal_swigregister(plCndLearnNdNormal)

class plCndLearnPoisson(plLearnDistributionTable):
    """


    This template class implements conditional learning objects.  

    Learning a conditional distribution P(X | Y) for a given learning object type
    (template parameter) T, consists in building a map of non-conditional learning
    objects of type T. This map will contain, for each possible value of Y a non-
    conditional learning object of type T on X. The learning objects are assumed to
    be of the same type T. Consider using plLearnDistributionTable if you want to
    use different types depending on the right variable (Y) values.  

    This template class is instantiated for all plNonCndLearnObject subclasses.  

    See also: plLearnDistributionTable  

    C++ includes: plCndLearnObject.h

    """

    __swig_setmethods__ = {}
    for _s in [plLearnDistributionTable]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plCndLearnPoisson, name, value)
    __swig_getmethods__ = {}
    for _s in [plLearnDistributionTable]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plCndLearnPoisson, name)
    __repr__ = _swig_repr

    def __init__(self, *args):
        """
        __init__(self) -> plCndLearnPoisson
        __init__(self, left_vars, right_vars, init_object) -> plCndLearnPoisson
        __init__(self, left_vars, right_vars) -> plCndLearnPoisson


        `plCndLearnObject()`  
        `plCndLearnObject(const plVariablesConjunction &left_vars, const
            plVariablesConjunction &right_vars, const T &init_object=T())`  

        Overloaded function
        -------------------
        * `plCndLearnObject()`  

            Empty constructor used for serialization.  

        * `plCndLearnObject(const plVariablesConjunction &left_vars, const
            plVariablesConjunction &right_vars, const T &init_object=T())`  

            Constructor to learn the conditional distribution P(left_vars | right_vars).  

            If *init_object* is not empty (the default value), then learning for each
            right value is initialized by *init_object* and the returned distribution
            when get_distribution_table() (or get_computable_object()) is called will
            contain a default function obtained by calling get_distribution() on
            *init_object*.  

        """
        this = _probt_python3.new_plCndLearnPoisson(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def get_learnt_object_for_value(self, right_value: 'plValues') -> "plLearnPoisson const *":
        """
        get_learnt_object_for_value(self, right_value) -> plLearnPoisson


        `get_learnt_object_for_value(const plValues &right_value) const -> const T *`  

        Returns a pointer to the T learning object corresponding to the *right_value*
        value of the right variables.  

        Returns 0 if *right_value* has never been seen.  

        """
        return _probt_python3.plCndLearnPoisson_get_learnt_object_for_value(self, right_value)


    def clone(self) -> "plLearnObject *":
        """
        clone(self) -> plLearnObject


        `clone() const -> plLearnObject *`  

        Clone the learning object.  

        """
        return _probt_python3.plCndLearnPoisson_clone(self)


    def get_cnd_distribution(self) -> "plCndDistribution":
        """
        get_cnd_distribution(self) -> plCndDistribution


        `get_cnd_distribution() const -> plCndDistribution`  

        Constructs and returns the conditional ditribution corresponding to the current
        state of this learner.  

        """
        return _probt_python3.plCndLearnPoisson_get_cnd_distribution(self)

    __swig_destroy__ = _probt_python3.delete_plCndLearnPoisson
    __del__ = lambda self: None
plCndLearnPoisson_swigregister = _probt_python3.plCndLearnPoisson_swigregister
plCndLearnPoisson_swigregister(plCndLearnPoisson)

class plCndLearnSparseHistogram(plLearnDistributionTable):
    """


    This template class implements conditional learning objects.  

    Learning a conditional distribution P(X | Y) for a given learning object type
    (template parameter) T, consists in building a map of non-conditional learning
    objects of type T. This map will contain, for each possible value of Y a non-
    conditional learning object of type T on X. The learning objects are assumed to
    be of the same type T. Consider using plLearnDistributionTable if you want to
    use different types depending on the right variable (Y) values.  

    This template class is instantiated for all plNonCndLearnObject subclasses.  

    See also: plLearnDistributionTable  

    C++ includes: plCndLearnObject.h

    """

    __swig_setmethods__ = {}
    for _s in [plLearnDistributionTable]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plCndLearnSparseHistogram, name, value)
    __swig_getmethods__ = {}
    for _s in [plLearnDistributionTable]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plCndLearnSparseHistogram, name)
    __repr__ = _swig_repr

    def __init__(self, *args):
        """
        __init__(self) -> plCndLearnSparseHistogram
        __init__(self, left_vars, right_vars, init_object) -> plCndLearnSparseHistogram
        __init__(self, left_vars, right_vars) -> plCndLearnSparseHistogram


        `plCndLearnObject()`  
        `plCndLearnObject(const plVariablesConjunction &left_vars, const
            plVariablesConjunction &right_vars, const T &init_object=T())`  

        Overloaded function
        -------------------
        * `plCndLearnObject()`  

            Empty constructor used for serialization.  

        * `plCndLearnObject(const plVariablesConjunction &left_vars, const
            plVariablesConjunction &right_vars, const T &init_object=T())`  

            Constructor to learn the conditional distribution P(left_vars | right_vars).  

            If *init_object* is not empty (the default value), then learning for each
            right value is initialized by *init_object* and the returned distribution
            when get_distribution_table() (or get_computable_object()) is called will
            contain a default function obtained by calling get_distribution() on
            *init_object*.  

        """
        this = _probt_python3.new_plCndLearnSparseHistogram(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def get_learnt_object_for_value(self, right_value: 'plValues') -> "plLearnSparseHistogram const *":
        """
        get_learnt_object_for_value(self, right_value) -> plLearnSparseHistogram


        `get_learnt_object_for_value(const plValues &right_value) const -> const T *`  

        Returns a pointer to the T learning object corresponding to the *right_value*
        value of the right variables.  

        Returns 0 if *right_value* has never been seen.  

        """
        return _probt_python3.plCndLearnSparseHistogram_get_learnt_object_for_value(self, right_value)


    def clone(self) -> "plLearnObject *":
        """
        clone(self) -> plLearnObject


        `clone() const -> plLearnObject *`  

        Clone the learning object.  

        """
        return _probt_python3.plCndLearnSparseHistogram_clone(self)


    def get_cnd_distribution(self) -> "plCndDistribution":
        """
        get_cnd_distribution(self) -> plCndDistribution


        `get_cnd_distribution() const -> plCndDistribution`  

        Constructs and returns the conditional ditribution corresponding to the current
        state of this learner.  

        """
        return _probt_python3.plCndLearnSparseHistogram_get_cnd_distribution(self)

    __swig_destroy__ = _probt_python3.delete_plCndLearnSparseHistogram
    __del__ = lambda self: None
plCndLearnSparseHistogram_swigregister = _probt_python3.plCndLearnSparseHistogram_swigregister
plCndLearnSparseHistogram_swigregister(plCndLearnSparseHistogram)

class plLearnObjectVector(_object):
    """Proxy of C++ std::vector<(p.plLearnObject)> class."""

    __swig_setmethods__ = {}
    __setattr__ = lambda self, name, value: _swig_setattr(self, plLearnObjectVector, name, value)
    __swig_getmethods__ = {}
    __getattr__ = lambda self, name: _swig_getattr(self, plLearnObjectVector, name)
    __repr__ = _swig_repr

    def iterator(self) -> "swig::SwigPyIterator *":
        """iterator(self) -> SwigPyIterator"""
        return _probt_python3.plLearnObjectVector_iterator(self)

    def __iter__(self):
        return self.iterator()

    def __nonzero__(self) -> "bool":
        """__nonzero__(self) -> bool"""
        return _probt_python3.plLearnObjectVector___nonzero__(self)


    def __bool__(self) -> "bool":
        """__bool__(self) -> bool"""
        return _probt_python3.plLearnObjectVector___bool__(self)


    def __len__(self) -> "std::vector< plLearnObject * >::size_type":
        """__len__(self) -> std::vector< plLearnObject * >::size_type"""
        return _probt_python3.plLearnObjectVector___len__(self)


    def __getslice__(self, i: 'std::vector< plLearnObject * >::difference_type', j: 'std::vector< plLearnObject * >::difference_type') -> "std::vector< plLearnObject *,std::allocator< plLearnObject * > > *":
        """__getslice__(self, i, j) -> plLearnObjectVector"""
        return _probt_python3.plLearnObjectVector___getslice__(self, i, j)


    def __setslice__(self, *args) -> "void":
        """
        __setslice__(self, i, j)
        __setslice__(self, i, j, v)
        """
        return _probt_python3.plLearnObjectVector___setslice__(self, *args)


    def __delslice__(self, i: 'std::vector< plLearnObject * >::difference_type', j: 'std::vector< plLearnObject * >::difference_type') -> "void":
        """__delslice__(self, i, j)"""
        return _probt_python3.plLearnObjectVector___delslice__(self, i, j)


    def __delitem__(self, *args) -> "void":
        """
        __delitem__(self, i)
        __delitem__(self, slice)
        """
        return _probt_python3.plLearnObjectVector___delitem__(self, *args)


    def __getitem__(self, *args) -> "std::vector< plLearnObject * >::value_type":
        """
        __getitem__(self, slice) -> plLearnObjectVector
        __getitem__(self, i) -> plLearnObject
        """
        return _probt_python3.plLearnObjectVector___getitem__(self, *args)


    def __setitem__(self, *args) -> "void":
        """
        __setitem__(self, slice, v)
        __setitem__(self, slice)
        __setitem__(self, i, x)
        """
        return _probt_python3.plLearnObjectVector___setitem__(self, *args)


    def pop(self) -> "std::vector< plLearnObject * >::value_type":
        """pop(self) -> plLearnObject"""
        return _probt_python3.plLearnObjectVector_pop(self)


    def append(self, x: 'plLearnObject') -> "void":
        """append(self, x)"""
        return _probt_python3.plLearnObjectVector_append(self, x)


    def empty(self) -> "bool":
        """empty(self) -> bool"""
        return _probt_python3.plLearnObjectVector_empty(self)


    def size(self) -> "std::vector< plLearnObject * >::size_type":
        """size(self) -> std::vector< plLearnObject * >::size_type"""
        return _probt_python3.plLearnObjectVector_size(self)


    def swap(self, v: 'plLearnObjectVector') -> "void":
        """swap(self, v)"""
        return _probt_python3.plLearnObjectVector_swap(self, v)


    def begin(self) -> "std::vector< plLearnObject * >::iterator":
        """begin(self) -> std::vector< plLearnObject * >::iterator"""
        return _probt_python3.plLearnObjectVector_begin(self)


    def end(self) -> "std::vector< plLearnObject * >::iterator":
        """end(self) -> std::vector< plLearnObject * >::iterator"""
        return _probt_python3.plLearnObjectVector_end(self)


    def rbegin(self) -> "std::vector< plLearnObject * >::reverse_iterator":
        """rbegin(self) -> std::vector< plLearnObject * >::reverse_iterator"""
        return _probt_python3.plLearnObjectVector_rbegin(self)


    def rend(self) -> "std::vector< plLearnObject * >::reverse_iterator":
        """rend(self) -> std::vector< plLearnObject * >::reverse_iterator"""
        return _probt_python3.plLearnObjectVector_rend(self)


    def clear(self) -> "void":
        """clear(self)"""
        return _probt_python3.plLearnObjectVector_clear(self)


    def get_allocator(self) -> "std::vector< plLearnObject * >::allocator_type":
        """get_allocator(self) -> std::vector< plLearnObject * >::allocator_type"""
        return _probt_python3.plLearnObjectVector_get_allocator(self)


    def pop_back(self) -> "void":
        """pop_back(self)"""
        return _probt_python3.plLearnObjectVector_pop_back(self)


    def erase(self, *args) -> "std::vector< plLearnObject * >::iterator":
        """
        erase(self, pos) -> std::vector< plLearnObject * >::iterator
        erase(self, first, last) -> std::vector< plLearnObject * >::iterator
        """
        return _probt_python3.plLearnObjectVector_erase(self, *args)


    def __init__(self, *args):
        """
        __init__(self) -> plLearnObjectVector
        __init__(self, arg2) -> plLearnObjectVector
        __init__(self, size) -> plLearnObjectVector
        __init__(self, size, value) -> plLearnObjectVector
        """
        this = _probt_python3.new_plLearnObjectVector(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def push_back(self, x: 'plLearnObject') -> "void":
        """push_back(self, x)"""
        return _probt_python3.plLearnObjectVector_push_back(self, x)


    def front(self) -> "std::vector< plLearnObject * >::value_type":
        """front(self) -> plLearnObject"""
        return _probt_python3.plLearnObjectVector_front(self)


    def back(self) -> "std::vector< plLearnObject * >::value_type":
        """back(self) -> plLearnObject"""
        return _probt_python3.plLearnObjectVector_back(self)


    def assign(self, n: 'std::vector< plLearnObject * >::size_type', x: 'plLearnObject') -> "void":
        """assign(self, n, x)"""
        return _probt_python3.plLearnObjectVector_assign(self, n, x)


    def resize(self, *args) -> "void":
        """
        resize(self, new_size)
        resize(self, new_size, x)
        """
        return _probt_python3.plLearnObjectVector_resize(self, *args)


    def insert(self, *args) -> "void":
        """
        insert(self, pos, x) -> std::vector< plLearnObject * >::iterator
        insert(self, pos, n, x)
        """
        return _probt_python3.plLearnObjectVector_insert(self, *args)


    def reserve(self, n: 'std::vector< plLearnObject * >::size_type') -> "void":
        """reserve(self, n)"""
        return _probt_python3.plLearnObjectVector_reserve(self, n)


    def capacity(self) -> "std::vector< plLearnObject * >::size_type":
        """capacity(self) -> std::vector< plLearnObject * >::size_type"""
        return _probt_python3.plLearnObjectVector_capacity(self)

    __swig_destroy__ = _probt_python3.delete_plLearnObjectVector
    __del__ = lambda self: None
plLearnObjectVector_swigregister = _probt_python3.plLearnObjectVector_swigregister
plLearnObjectVector_swigregister(plLearnObjectVector)

class plLearnDistributions(plLearnObject):
    """

    `plLearnDistributions()`  
    `plLearnDistributions(const std::vector< plLearnObject *> &learn_objects, const
        plVariablesConjunction &vars, bool do_not_clone_learners=false)`  
    `plLearnDistributions(const std::vector< plLearnObject *> &learn_objects, bool
        do_not_clone_learners=false)`  
    `plLearnDistributions(const plLearnDistributions &other)`  

    This class allows to learn a set of conditional and non-conditional
    distributions in the same time.  

    Constructors
    ------------
    * `plLearnDistributions()`  

        Default constructor.  

        To be used especially with add_object() to insert objects  

    * `plLearnDistributions(const std::vector< plLearnObject *> &learn_objects,
        const plVariablesConjunction &vars, bool do_not_clone_learners=false)`  

        Construct an object allowing to jointly learn a set of distributions
        corresponding to the learning object vector *learn_objects*.  

        *vars* represents the order of data values when inserted without using a
        plValues container (i.e., using stl vectors and pointers).  

        The constructor clones the passed *learn_objects* and stores them internally
        (i.e. with no side-effect on the passed *learn_objects*) unless
        *do_not_clone_learners* is set to *true*  

        ATTENTION: when using this function in Python, pass the parameter
        'learn_objects' as a Python list  

    * `plLearnDistributions(const std::vector< plLearnObject *> &learn_objects, bool
        do_not_clone_learners=false)`  

        Construct an object allowing to jointly learn a set of distributions
        corresponding to the learning object vector *learn_objects*.  

        The constructor clones the passed *learn_objects* and stores them internally
        (i.e. with no side-effect on the passed *learn_objects*) unless
        *do_not_clone_learners* is set to *true*  

        ATTENTION: using this constructor, you have to:  

        *   use *plValues* when using *add_point*, or  
        *   ensure that the order of the learning data corresponds to the order
            defined by variables apparition in the concatenation of the variables of
            all elements of *learn_objects*.  

        ATTENTION: when using this function in Python, pass the parameter
        'learn_objects' as a Python list  

    * `plLearnDistributions(const plLearnDistributions &other)`  

        Copy constructor.  

    C++ includes: plLearnDistributions.h

    """

    __swig_setmethods__ = {}
    for _s in [plLearnObject]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plLearnDistributions, name, value)
    __swig_getmethods__ = {}
    for _s in [plLearnObject]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plLearnDistributions, name)
    __repr__ = _swig_repr

    def add_object(self, object: 'plLearnObject') -> "void":
        """
        add_object(self, object)


        `add_object(const plLearnObject &object)`  

        Insert an object to be be learnt This function may be used with a default
        constructed plLearnDistributions.  

        """
        return _probt_python3.plLearnDistributions_add_object(self, object)


    def set_from_adopted_learners(self, learn_objects: 'plLearnObjectVector', vars: 'plVariablesConjunction') -> "void":
        """
        set_from_adopted_learners(self, learn_objects, vars)


        `set_from_adopted_learners(const std::vector< plLearnObject *> &learn_objects,
            const plVariablesConjunction &vars)`  

        Set the passed a plLearnDistributions while adpting the passed *learn_objects*.  

        """
        return _probt_python3.plLearnDistributions_set_from_adopted_learners(self, learn_objects, vars)


    def create_from_adopted_learners(*args) -> "plLearnDistributions *":
        """
        create_from_adopted_learners(learn_objects, vars) -> plLearnDistributions
        create_from_adopted_learners(learn_objects) -> plLearnDistributions


        `create_from_adopted_learners(const std::vector< plLearnObject *>
            &learn_objects, const plVariablesConjunction &vars) -> plLearnDistributions
            *`  
        `create_from_adopted_learners(const std::vector< plLearnObject *>
            &learn_objects) -> plLearnDistributions *`  

        Overloaded function
        -------------------
        * `create_from_adopted_learners(const std::vector< plLearnObject *>
            &learn_objects, const plVariablesConjunction &vars) -> plLearnDistributions
            *`  

            Create a plLearnDistributions while adpting the passed *learn_objects*.  

            See also: plLearnDistributions()  

        * `create_from_adopted_learners(const std::vector< plLearnObject *>
            &learn_objects) -> plLearnDistributions *`  

            Create a plLearnDistributions while adpting the passed *learn_objects*.  

            See also: plLearnDistributions()  

        """
        return _probt_python3.plLearnDistributions_create_from_adopted_learners(*args)

    create_from_adopted_learners = staticmethod(create_from_adopted_learners)

    def __init__(self, *args):
        """
        __init__(self) -> plLearnDistributions
        __init__(self, learn_objects, vars, do_not_clone_learners=False) -> plLearnDistributions
        __init__(self, learn_objects, vars) -> plLearnDistributions
        __init__(self, learn_objects, do_not_clone_learners=False) -> plLearnDistributions
        __init__(self, learn_objects) -> plLearnDistributions
        __init__(self, other) -> plLearnDistributions


        `plLearnDistributions()`  
        `plLearnDistributions(const std::vector< plLearnObject *> &learn_objects, const
            plVariablesConjunction &vars, bool do_not_clone_learners=false)`  
        `plLearnDistributions(const std::vector< plLearnObject *> &learn_objects, bool
            do_not_clone_learners=false)`  
        `plLearnDistributions(const plLearnDistributions &other)`  

        Overloaded function
        -------------------
        * `plLearnDistributions()`  

            Default constructor.  

            To be used especially with add_object() to insert objects  

        * `plLearnDistributions(const std::vector< plLearnObject *> &learn_objects,
            const plVariablesConjunction &vars, bool do_not_clone_learners=false)`  

            Construct an object allowing to jointly learn a set of distributions
            corresponding to the learning object vector *learn_objects*.  

            *vars* represents the order of data values when inserted without using a
            plValues container (i.e., using stl vectors and pointers).  

            The constructor clones the passed *learn_objects* and stores them internally
            (i.e. with no side-effect on the passed *learn_objects*) unless
            *do_not_clone_learners* is set to *true*  

            ATTENTION: when using this function in Python, pass the parameter
            'learn_objects' as a Python list  

        * `plLearnDistributions(const std::vector< plLearnObject *> &learn_objects, bool
            do_not_clone_learners=false)`  

            Construct an object allowing to jointly learn a set of distributions
            corresponding to the learning object vector *learn_objects*.  

            The constructor clones the passed *learn_objects* and stores them internally
            (i.e. with no side-effect on the passed *learn_objects*) unless
            *do_not_clone_learners* is set to *true*  

            ATTENTION: using this constructor, you have to:  

            *   use *plValues* when using *add_point*, or  
            *   ensure that the order of the learning data corresponds to the order
                defined by variables apparition in the concatenation of the variables of
                all elements of *learn_objects*.  

            ATTENTION: when using this function in Python, pass the parameter
            'learn_objects' as a Python list  

        * `plLearnDistributions(const plLearnDistributions &other)`  

            Copy constructor.  

        """
        this = _probt_python3.new_plLearnDistributions(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this
    __swig_destroy__ = _probt_python3.delete_plLearnDistributions
    __del__ = lambda self: None

    def reset(self) -> "void":
        """
        reset(self)


        `reset()`  

        Resets all learning objects.  

        """
        return _probt_python3.plLearnDistributions_reset(self)


    def get_computable_object(self) -> "plComputableObject":
        """
        get_computable_object(self) -> plComputableObject


        `get_computable_object() const -> plComputableObject`  

        Constructs the computable object corresponding to the learnt distribution.  

        Actually, the returned object is a product plComputableObject (that can be
        conditional or not).  

        When no variable order is given to the constructor (ie, using
        plLearnDistributions(const std::vector <plLearnObject*> &)), the left variables
        of the constructed computable object are the concatenation, in the apparition
        order, of the left variables of all elements of the vector *learn_objects*
        passed to the constructor. Its right variables are the concatenation of the
        right variables of all elements of *learn_objects* and that are not in left one
        above.  

        When an order is provided (ie, using plLearnDistributions(const std::vector
        <plLearnObject*> &learn_objects, const plVariablesConjunction &vars)), the left
        variables of the constructed computable object are the concatenation, respecting
        the order 'vars', of the left variables of all elements of the vector
        *learn_objects* passed to the constructor. Its right variables are the
        concatenation, respecting the order 'vars', of the right variables of all
        elements of *learn_objects* and that are not in left one above.  

        If the learnt set of distributions contains a given variable on the left side
        several times (ie, not a valid decomposition), calling this method will throw an
        error when creating the plComputableObject instance.  

        """
        return _probt_python3.plLearnDistributions_get_computable_object(self)


    def get_computable_object_list(self) -> "plComputableObjectList":
        """
        get_computable_object_list(self) -> plComputableObjectList


        `get_computable_object_list() const -> plComputableObjectList`  

        Returns the list of all learnt computable objects.  

        """
        return _probt_python3.plLearnDistributions_get_computable_object_list(self)


    def add_point_if_not_frozen(self, *args) -> "bool":
        """
        add_point_if_not_frozen(self, point, is_not_frozen_learner, weight=1.0) -> bool
        add_point_if_not_frozen(self, point, is_not_frozen_learner) -> bool
        add_point_if_not_frozen(self, point, is_not_frozen_learner, weight=1.0) -> bool
        add_point_if_not_frozen(self, point, is_not_frozen_learner) -> bool
        add_point_if_not_frozen(self, point, is_not_frozen_learner, weight=1.0) -> bool
        add_point_if_not_frozen(self, point, is_not_frozen_learner) -> bool
        add_point_if_not_frozen(self, point, is_not_frozen_learner, weight=1.0) -> bool
        add_point_if_not_frozen(self, point, is_not_frozen_learner) -> bool
        add_point_if_not_frozen(self, point, is_not_frozen_learner, weight=1.0) -> bool
        add_point_if_not_frozen(self, point, is_not_frozen_learner) -> bool
        add_point_if_not_frozen(self, point, is_not_frozen_learner, weight=1.0) -> bool
        add_point_if_not_frozen(self, point, is_not_frozen_learner) -> bool
        add_point_if_not_frozen(self, point, is_not_frozen_learner, weight=1.0) -> bool
        add_point_if_not_frozen(self, point, is_not_frozen_learner) -> bool
        add_point_if_not_frozen(self, point, is_not_frozen_learner, weight=1.0) -> bool
        add_point_if_not_frozen(self, point, is_not_frozen_learner) -> bool
        add_point_if_not_frozen(self, point, is_not_frozen_learner, weight=1.0) -> bool
        add_point_if_not_frozen(self, point, is_not_frozen_learner) -> bool
        add_point_if_not_frozen(self, point, is_not_frozen_learner, weight=1.0) -> bool
        add_point_if_not_frozen(self, point, is_not_frozen_learner) -> bool
        add_point_if_not_frozen(self, point, is_not_frozen_learner, weight=1.0) -> bool
        add_point_if_not_frozen(self, point, is_not_frozen_learner) -> bool
        add_point_if_not_frozen(self, point, is_not_frozen_learner, weight=1.0) -> bool
        add_point_if_not_frozen(self, point, is_not_frozen_learner) -> bool
        add_point_if_not_frozen(self, point, is_not_frozen_learner, weight=1.0) -> bool
        add_point_if_not_frozen(self, point, is_not_frozen_learner) -> bool
        add_point_if_not_frozen(self, point, is_not_frozen_learner, weight=1.0) -> bool
        add_point_if_not_frozen(self, point, is_not_frozen_learner) -> bool
        add_point_if_not_frozen(self, point, is_not_frozen_learner, weight=1.0) -> bool
        add_point_if_not_frozen(self, point, is_not_frozen_learner) -> bool
        add_point_if_not_frozen(self, point, is_not_frozen_learner, weight=1.0) -> bool
        add_point_if_not_frozen(self, point, is_not_frozen_learner) -> bool


        `add_point_if_not_frozen(const plValues &point, const std::vector< bool >
            &is_not_frozen_learner, plFloat weight=PL_ONE) -> bool`  
        `add_point_if_not_frozen(const float *point, const std::vector< bool >
            &is_not_frozen_learner, plFloat weight=PL_ONE) -> bool`  
        `add_point_if_not_frozen(const double *point, const std::vector< bool >
            &is_not_frozen_learner, plFloat weight=PL_ONE) -> bool`  
        `add_point_if_not_frozen(const long double *point, const std::vector< bool >
            &is_not_frozen_learner, plFloat weight=PL_ONE) -> bool`  
        `add_point_if_not_frozen(const int *point, const std::vector< bool >
            &is_not_frozen_learner, plFloat weight=PL_ONE) -> bool`  
        `add_point_if_not_frozen(const size_t *point, const std::vector< bool >
            &is_not_frozen_learner, plFloat weight=PL_ONE) -> bool`  
        `add_point_if_not_frozen(const std::vector< float > &point, const std::vector<
            bool > &is_not_frozen_learner, plFloat weight=PL_ONE) -> bool`  
        `add_point_if_not_frozen(const std::vector< double > &point, const std::vector<
            bool > &is_not_frozen_learner, plFloat weight=PL_ONE) -> bool`  
        `add_point_if_not_frozen(const std::vector< long double > &point, const
            std::vector< bool > &is_not_frozen_learner, plFloat weight=PL_ONE) -> bool`  
        `add_point_if_not_frozen(const std::vector< int > &point, const std::vector<
            bool > &is_not_frozen_learner, plFloat weight=PL_ONE) -> bool`  
        `add_point_if_not_frozen(const std::vector< unsigned int > &point, const
            std::vector< bool > &is_not_frozen_learner, plFloat weight=PL_ONE) -> bool`  
        `add_point_if_not_frozen(float point, const std::vector< bool >
            &is_not_frozen_learner, plFloat weight=PL_ONE) -> bool`  
        `add_point_if_not_frozen(double point, const std::vector< bool >
            &is_not_frozen_learner, plFloat weight=PL_ONE) -> bool`  
        `add_point_if_not_frozen(long double point, const std::vector< bool >
            &is_not_frozen_learner, plFloat weight=PL_ONE) -> bool`  
        `add_point_if_not_frozen(int point, const std::vector< bool >
            &is_not_frozen_learner, plFloat weight=PL_ONE) -> bool`  
        `add_point_if_not_frozen(size_t point, const std::vector< bool >
            &is_not_frozen_learner, plFloat weight=PL_ONE) -> bool`  

        Overloaded function
        -------------------
        * `add_point_if_not_frozen(const plValues &point, const std::vector< bool >
            &is_not_frozen_learner, plFloat weight=PL_ONE) -> bool`  

            Adds a point *point* (represented as a *plValues*) with a given weight
            *weight* and updates the statistics.  

            *is_not_frozen_learner* is an array of boolean values to say, for each
            learning object, if it has to be updated or not.  

        * `add_point_if_not_frozen(const float *point, const std::vector< bool >
            &is_not_frozen_learner, plFloat weight=PL_ONE) -> bool`  

            Same as above, but *point* is a C array.  

        * `add_point_if_not_frozen(const double *point, const std::vector< bool >
            &is_not_frozen_learner, plFloat weight=PL_ONE) -> bool`  

        * `add_point_if_not_frozen(const long double *point, const std::vector< bool >
            &is_not_frozen_learner, plFloat weight=PL_ONE) -> bool`  

        * `add_point_if_not_frozen(const int *point, const std::vector< bool >
            &is_not_frozen_learner, plFloat weight=PL_ONE) -> bool`  

        * `add_point_if_not_frozen(const size_t *point, const std::vector< bool >
            &is_not_frozen_learner, plFloat weight=PL_ONE) -> bool`  

        * `add_point_if_not_frozen(const std::vector< float > &point, const std::vector<
            bool > &is_not_frozen_learner, plFloat weight=PL_ONE) -> bool`  

            Same as above, but *point* is an STL array.  

        * `add_point_if_not_frozen(const std::vector< double > &point, const
            std::vector< bool > &is_not_frozen_learner, plFloat weight=PL_ONE) -> bool`  

        * `add_point_if_not_frozen(const std::vector< long double > &point, const
            std::vector< bool > &is_not_frozen_learner, plFloat weight=PL_ONE) -> bool`  

        * `add_point_if_not_frozen(const std::vector< int > &point, const std::vector<
            bool > &is_not_frozen_learner, plFloat weight=PL_ONE) -> bool`  

        * `add_point_if_not_frozen(const std::vector< unsigned int > &point, const
            std::vector< bool > &is_not_frozen_learner, plFloat weight=PL_ONE) -> bool`  

        * `add_point_if_not_frozen(float point, const std::vector< bool >
            &is_not_frozen_learner, plFloat weight=PL_ONE) -> bool`  

            Same as above, but *point* is an unidimensional value.  

            ATTENTION: this method can only be used for one-dimensional cases.  

        * `add_point_if_not_frozen(double point, const std::vector< bool >
            &is_not_frozen_learner, plFloat weight=PL_ONE) -> bool`  

        * `add_point_if_not_frozen(long double point, const std::vector< bool >
            &is_not_frozen_learner, plFloat weight=PL_ONE) -> bool`  

        * `add_point_if_not_frozen(int point, const std::vector< bool >
            &is_not_frozen_learner, plFloat weight=PL_ONE) -> bool`  

        * `add_point_if_not_frozen(size_t point, const std::vector< bool >
            &is_not_frozen_learner, plFloat weight=PL_ONE) -> bool`  

        """
        return _probt_python3.plLearnDistributions_add_point_if_not_frozen(self, *args)


    def get_left_variables(self) -> "plVariablesConjunction const &":
        """
        get_left_variables(self) -> plVariablesConjunction


        `get_left_variables() const -> const plVariablesConjunction &`  

        Returns the left variables.  

        ATTENTION: when using the constructor plLearnDistributions(const std::vector
        <plLearnObject*> &learn_objects, const plVariablesConjunction &vars),
        get_variables() is not necessary equivalent to the concatenation of
        get_left_variables() and get_right_variables().  

        """
        return _probt_python3.plLearnDistributions_get_left_variables(self)


    def get_right_variables(self) -> "plVariablesConjunction const &":
        """
        get_right_variables(self) -> plVariablesConjunction


        `get_right_variables() const -> const plVariablesConjunction &`  

        Returns the right variables.  

        """
        return _probt_python3.plLearnDistributions_get_right_variables(self)


    def get_n_parameters(self) -> "unsigned int":
        """
        get_n_parameters(self) -> unsigned int


        `get_n_parameters() const -> unsigned int`  

        Returns the ACTUAL number of parameters.  

        It could be different from the number of parameters returned by get_parameters.
        For example, the actual number of parameters of a N dimensional normal
        distribution is N + N*(N+1)/2 because the covariance matrix is symmetric.  

        The number of parameters of *plLearnDistributions* instance is the sum of the
        number of parameters of each containd *plLearnObject*.  

        """
        return _probt_python3.plLearnDistributions_get_n_parameters(self)


    def get_all_nsamples(self, n: 'UnsignedIntVector') -> "void":
        """
        get_all_nsamples(self, n)


        `get_all_nsamples(std::vector< unsigned int > &n) const`  

        Return *nsamples* for each learned distribution.  

        """
        return _probt_python3.plLearnDistributions_get_all_nsamples(self, n)


    def get_total_weights(self, w: 'DoubleVector') -> "void":
        """
        get_total_weights(self, w)


        `get_total_weights(std::vector< plFloat > &w) const`  

        Return *total_weight* for each learned distribution.  

        """
        return _probt_python3.plLearnDistributions_get_total_weights(self, w)


    def rescale_total_weight(self, s: 'plFloat') -> "void":
        """
        rescale_total_weight(self, s)


        `rescale_total_weight(plFloat s)`  

        Multiply the weight of the past inserted points by a given factor.  

        This allows, for example, to decrease the importance of the old data points
        compared to the new ones  

        """
        return _probt_python3.plLearnDistributions_rescale_total_weight(self, s)


    def clone(self) -> "plLearnObject *":
        """
        clone(self) -> plLearnObject


        `clone() const -> plLearnObject *`  

        Clone the learning object.  

        """
        return _probt_python3.plLearnDistributions_clone(self)


    def get_learn_objects(self) -> "std::vector< plLearnObject *,std::allocator< plLearnObject * > > const &":
        """
        get_learn_objects(self) -> plLearnObjectVector


        `get_learn_objects() const -> const std::vector< plLearnObject * > &`  

        Return the vector of the stored learn objects.  

        """
        return _probt_python3.plLearnDistributions_get_learn_objects(self)


    def get_learn_objects_number(self) -> "size_t":
        """
        get_learn_objects_number(self) -> size_t


        `get_learn_objects_number() const -> size_t`  

        Get the number of learn objects.  

        """
        return _probt_python3.plLearnDistributions_get_learn_objects_number(self)


    def get_learn_object(self, n: 'size_t') -> "plLearnObject *":
        """
        get_learn_object(self, n) -> plLearnObject


        `get_learn_object(size_t n) const -> plLearnObject *`  

        Get the learn object at a quiven position.  

        Return 0 if the position is out-of-range  

        """
        return _probt_python3.plLearnDistributions_get_learn_object(self, n)


    def __getstate__(self) -> "std::string":
        """__getstate__(self) -> std::string"""
        return _probt_python3.plLearnDistributions___getstate__(self)


    def __setstate_internal(self, sState: 'std::string const &') -> "void":
        """__setstate_internal(self, sState)"""
        return _probt_python3.plLearnDistributions___setstate_internal(self, sState)


    def __setstate__(self, sState):
        self.__init__()
        self.__setstate_internal(sState)

plLearnDistributions_swigregister = _probt_python3.plLearnDistributions_swigregister
plLearnDistributions_swigregister(plLearnDistributions)

def plLearnDistributions_create_from_adopted_learners(*args) -> "plLearnDistributions *":
    """
    create_from_adopted_learners(learn_objects, vars) -> plLearnDistributions
    plLearnDistributions_create_from_adopted_learners(learn_objects) -> plLearnDistributions


    `create_from_adopted_learners(const std::vector< plLearnObject *>
        &learn_objects, const plVariablesConjunction &vars) -> plLearnDistributions
        *`  
    `create_from_adopted_learners(const std::vector< plLearnObject *>
        &learn_objects) -> plLearnDistributions *`  

    Overloaded function
    -------------------
    * `create_from_adopted_learners(const std::vector< plLearnObject *>
        &learn_objects, const plVariablesConjunction &vars) -> plLearnDistributions
        *`  

        Create a plLearnDistributions while adpting the passed *learn_objects*.  

        See also: plLearnDistributions()  

    * `create_from_adopted_learners(const std::vector< plLearnObject *>
        &learn_objects) -> plLearnDistributions *`  

        Create a plLearnDistributions while adpting the passed *learn_objects*.  

        See also: plLearnDistributions()  

    """
    return _probt_python3.plLearnDistributions_create_from_adopted_learners(*args)

class plEMLearner(plLearner):
    """

    `plEMLearner()`  
    `plEMLearner(const plComputableObjectList &init_distribs, const std::vector<
        plLearnObject *> &learn_objects)`  
    `plEMLearner(const std::vector< plLearnObject *> &learn_objects)`  
    `plEMLearner(const plEMLearner &other)`  

    This class implements a generic EM (Expectation-Maximization) learning algorithm
    (using incomplete data sets).  

    There can be arbitrary missing data in the learning observations provided to the
    EM algorithm by a data descriptor.  

    An example of estimating a Gaussian mixture using the EM algorithm with a BIC
    (Bayesian Information Criterion) score is as follows:  

        #include <pl.h>

        #include <fstream>
        #include <iostream>

        // Output a given mixture
        //========================================================
        void output_mixture(const plJointDistribution &mixture)
        {
        std::cout << mixture.get_computable_object_list()[0] << std::endl;
        std::cout << mixture.get_computable_object_list()[1] << std::endl;
        }

        // Simulate and generate a 2-components (kernels) Gaussian mixture data.
    This data will be used for learning using EM based on a BIC score
        //========================================================
        void generate_data(const std::string &file,
        unsigned int ndata)
        {
        std::ofstream data(file.c_str());
        if(!data) {
        std::cerr << "failed to open '" << file << "' for output" << std::endl;
        exit(-1);
        }

        // Class latent variable (actual number of classes = 2)
        const unsigned int nc = 2;
        const plVariable C("C", plIntegerType(0, nc-1));

        // X observed variable
        const plVariable X("X", plRealType(-100.0, 100.0));

        // Actual (PC) table
        const plProbValue pr[] = {0.3, 0.7};
        const plProbTable PC(C, pr);

        // Actual P(X | C) distributions
        plDistributionTable PX(X, C);
        const plFloat mean[] = {-10.0, 10.0};
        const plFloat sd[] = {1.0, 3.0};
        for(unsigned int i = 0; i < nc; ++i) {
        PX.push( plNormal(X, mean[i], sd[i]), int(i));
        }

        // Constructing the model
        const plJointDistribution mixture(C^X, PC*PX);

        // Simulating data by drawing from P(X)
        data << "C;X" << std::endl;
        plValues val_CX(C^X);
        for(unsigned int i = 0; i < ndata; ++i) {
        mixture.draw(val_CX);
        data << ";" << val_CX[X] << std::endl;
        }

        data.close();

        std::cout << "Simulation mixture:" << std::endl;
        output_mixture(mixture);
        std::cout << "==================================" << std::endl;
        }

        // Run an EM for a given number nc of mixture components (kernels)
        //========================================================
        void run_em(const std::string &file, unsigned int nc,
        unsigned int &nparams, plFloat &llk,
        plFloat &bic, plJointDistribution &model)
        {
        const plVariable C("C", plIntegerType(0, nc-1));
        const plVariable X("X", plRealType(-100.0, 100.0));

        // EM Initial distribution on the class (kernel) variable: P(C)
        const bool random_prob = true;
        const plProbTable pc_init(C, random_prob);

        // EM Initial Gaussians : P(X | C)
        plDistributionTable px_init(X, C);
        for(unsigned int i = 0; i < nc; ++i) {
        px_init.push( plNormal(X, -10 + plRandomFloat(20.), 1.0),
        int(i));
        }

        // P(C) is learnt as an histogram
        plLearnHistogram LC(C);
        // P(X | C) is learnt as a set of gaussians (a gaussian for each value of C)
        plCndLearnObject <plLearn1dNormal> LX(X, C);

        // Creating the EM learner instance
        plCSVFileDataDescriptor myCSVdata(file, C^X);
        std::vector <plLearnObject*> learn_objs(2); learn_objs[0] = &LC;
    learn_objs[1] = &LX;
        plEMLearner myEM(pc_init*px_init, learn_objs);

        // Run untill convergence
        myEM.run(myCSVdata, 0.0001);

        // Fill the output parameters
        nparams = myEM.get_n_parameters();
        llk = myEM.get_last_computed_loglikelihood();
        bic = llk - 0.5*nparams*std::log(myCSVdata.get_n_records());
        model = myEM.get_joint_distribution();
        }

        // Run an EM for each candidate number of components (kernels)
        //========================================================
        void run_em(const std::string &file,
        const std::vector<unsigned int> &n_mixture_candidates,
        std::vector<unsigned int> &nparams,
        std::vector<plFloat> &llk,
        std::vector<plFloat> &bic,
        std::vector<plJointDistribution> &model)
        {  
        nparams.resize( n_mixture_candidates.size() );
        llk.resize( n_mixture_candidates.size() );
        bic.resize( n_mixture_candidates.size() );
        model.resize( n_mixture_candidates.size() );

        for(unsigned int i = 0; i < n_mixture_candidates.size(); ++i) {
        const unsigned int nc = n_mixture_candidates[i];
        run_em(file, nc,
        nparams[i], llk[i], bic[i], model[i]);
        }
        }

        //========================================================
        int main()
        {
        /////////////////////////////////
        //  DATA SIMULATION/GENERATION
        /////////////////////////////////

        const std::string file = "gaussian_mixture_data.csv";
        const unsigned int ndata = 5000;
        generate_data(file, ndata);

        /////////////////////////////////
        //  EM-BIC BASED LEARNING
        /////////////////////////////////

        // Number of components (kernels) candidates
        std::vector<unsigned int> n_mixture_candidates;
        n_mixture_candidates.push_back(1);
        n_mixture_candidates.push_back(2);
        n_mixture_candidates.push_back(3);
        n_mixture_candidates.push_back(4);

        // Output parameters for each number of components (kernels) candidate
        std::vector<unsigned int> nparams; // The number of parameters
        std::vector<plFloat> llk; // The log-likelihood
        std::vector<plFloat> bic; // The bic score
        std::vector<plJointDistribution> model; // the learnt model

        // Run an EM for each number of components (kernels) candidate
        run_em(file, n_mixture_candidates,
        nparams, llk, bic, model);


        /////////////////////////////////
        //  OUTPUT THE LEARNING RESULTS
        /////////////////////////////////

        // Output the estimate results of each number of components (kernels)
    candidate
        for(unsigned int i = 0; i < n_mixture_candidates.size(); ++i) {
        std::cout << "NC:\t"                     << n_mixture_candidates[i] <<
    std::endl
        << "--BIC:\t"                  << bic[i]                  << std::endl
        << "--Log_likelihood:\t"       << llk[i]                  << std::endl
        << "--Number of parameters:\t" << nparams[i]              << std::endl;
        output_mixture(model[i]);
        std::cout << "==================================" << std::endl <<
    std::endl;
        }

        // Get the model with the best BIC score
        unsigned int best_candidate_index = std::max_element(bic.begin(), bic.end())
    - bic.begin();

        // Output the best BIC-based estimate
        std::cout << "\n\nBest NC:\t"            <<
    n_mixture_candidates[best_candidate_index] << std::endl
        << "--Best BIC:\t"             << bic[best_candidate_index]
    << std::endl
        << "--Log_llk:\t"              << llk[best_candidate_index]
    << std::endl
        << "--Number of parameters:\t" << nparams[best_candidate_index]
    << std::endl
        << std::endl;
        output_mixture(model[best_candidate_index]);

        return 0;
        }  

    for which the output will be:  

        Simultation mixture:
        P(C) =
        C   Probability
        0   0.3
        1   0.7

        P(X|C) = plDistributionTable {
        C = 0:
        plNormal(X, -10,  1)

        C = 1:
        plNormal(X, 10, 3)


        }
        ==================================
        NC: 1
        --BIC:  -18359.7
        --Log_likelihood: -18351.2
        --Number of parameters: 2
        P(C) =
        C   Probability
        0   1

        P(X|C) = plCndDistribution {
        C = 0:
        plNormal(X, 4.12168,  9.50011)


        }
        ==================================

        NC: 2
        --BIC:  -13973.8
        --Log_likelihood: -13952.5
        --Number of parameters: 5
        P(C) =
        C   Probability
        0   0.705
        1   0.295

        P(X|C) = plCndDistribution {
        C = 0:
        plNormal(X, 10.0453,  2.93926)

        C = 1:
        plNormal(X, -10.0347, 1.01676)


        }
        ==================================

        NC: 3
        --BIC:  -13987.1
        --Log_likelihood: -13953
        --Number of parameters: 8
        P(C) =
        C   Probability
        0   0.295
        1   0.70297
        2   0.00203016

        P(X|C) = plCndDistribution {
        C = 0:
        plNormal(X, -10.0347, 1.01676)

        C = 1:
        plNormal(X, 10.0678,  2.91296)

        C = 2:
        plNormal(X, 2.23893,  0.90511)


        }
        ==================================

        NC: 4
        --BIC:  -14000.3
        --Log_likelihood: -13953.5
        --Number of parameters: 11
        P(C) =
        C   Probability
        0   0.295
        1   0.154698
        2   0.486083
        3   0.0642189

        P(X|C) = plCndDistribution {
        C = 0:
        plNormal(X, -10.0347, 1.01676)

        C = 1:
        plNormal(X, 8.06023,  1.73133)

        C = 2:
        plNormal(X, 11.2608,  2.40052)

        C = 3:
        plNormal(X, 5.62642,  1.94988)


        }
        ==================================



        Best NC:  2
        --Best BIC: -13973.8
        --Log_llk:  -13952.5
        --Number of parameters: 5

        P(C) =
        C   Probability
        0   0.705
        1   0.295

        P(X|C) = plCndDistribution {
        C = 0:
        plNormal(X, 10.0453,  2.93926)

        C = 1:
        plNormal(X, -10.0347, 1.01676)


        }  

    See also: plDataDescriptor  

    See also: plLearner::learn_model_parameters()  

    Constructors
    ------------
    * `plEMLearner()`  

        Default constructor.  

        To be used especially with add_component() to insert components  

    * `plEMLearner(const plComputableObjectList &init_distribs, const std::vector<
        plLearnObject *> &learn_objects)`  

        Constructor.  

        Parameters:  
        * `init_distribs` :  
            initial distributions.  
        * `learn_objects` :  
            a vector of learning objects allowing to provide the structure
            (dependencies), the parametrical form of each distribution, and the
            corresponding prior. The constructor clones the passed *learn_objects*
            and stores them internally (i.e. with no side-effect on the passed
            *learn_objects*).  

        ATTENTION: when using this function in Python, pass the parameter
        'learn_objects' as a Python list  

    * `plEMLearner(const std::vector< plLearnObject *> &learn_objects)`  

        Constructor.  

        Initial distributions are determined from the initial state of the
        *learn_objects*.  

        Parameters:  
        * `learn_objects` :  
            a vector of learning objects allowing to provide the structure
            (dependencies), the parametrical form of each distribution, and the
            corresponding prior. The constructor clones the passed *learn_objects*
            and stores them internally (i.e. with no side-effect on the passed
            *learn_objects*).  

        ATTENTION: If the initial state of the *learn_objects* is uniform (it's the
        case for default constructed plLearnObject), the EM algorithm can fail to
        converge because it will stay at the initial non-informative state. So,
        consider using the constructor:  

            plEMLearner(const plComputableObjectList &init_distribs,
            const std::vector <plLearnObject*> &learn_objects);
         even with random initialized *init_distribs*.  

        ATTENTION: when using this function in Python, pass the parameter
        'learn_objects' as a Python list  

    * `plEMLearner(const plEMLearner &other)`  

        Copy constructor.  

    C++ includes: plEMLearner.h

    """

    __swig_setmethods__ = {}
    for _s in [plLearner]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plEMLearner, name, value)
    __swig_getmethods__ = {}
    for _s in [plLearner]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plEMLearner, name)
    __repr__ = _swig_repr

    def add_component(self, *args) -> "void":
        """
        add_component(self, learn_object)
        add_component(self, learn_object, init_distribution)


        `add_component(const plLearnObject &learn_object)`  
        `add_component(const plLearnObject &learn_object, const plComputableObject
            &init_distribution)`  

        Overloaded function
        -------------------
        * `add_component(const plLearnObject &learn_object)`  

            Add a new component by providing the corresponding learning object.  

        * `add_component(const plLearnObject &learn_object, const plComputableObject
            &init_distribution)`  

            Add a new component by providing the corresponding learning object and the
            initial distribution.  

        """
        return _probt_python3.plEMLearner_add_component(self, *args)


    def set_initial_distributions(self, init_distributions: 'plComputableObjectList') -> "void":
        """
        set_initial_distributions(self, init_distributions)


        `set_initial_distributions(const plComputableObjectList &init_distributions)`  

        Set the initial distributions.  

        """
        return _probt_python3.plEMLearner_set_initial_distributions(self, init_distributions)


    def __init__(self, *args):
        """
        __init__(self) -> plEMLearner
        __init__(self, init_distribs, learn_objects) -> plEMLearner
        __init__(self, learn_objects) -> plEMLearner
        __init__(self, other) -> plEMLearner


        `plEMLearner()`  
        `plEMLearner(const plComputableObjectList &init_distribs, const std::vector<
            plLearnObject *> &learn_objects)`  
        `plEMLearner(const std::vector< plLearnObject *> &learn_objects)`  
        `plEMLearner(const plEMLearner &other)`  

        Overloaded function
        -------------------
        * `plEMLearner()`  

            Default constructor.  

            To be used especially with add_component() to insert components  

        * `plEMLearner(const plComputableObjectList &init_distribs, const std::vector<
            plLearnObject *> &learn_objects)`  

            Constructor.  

            Parameters:  
            * `init_distribs` :  
                initial distributions.  
            * `learn_objects` :  
                a vector of learning objects allowing to provide the structure
                (dependencies), the parametrical form of each distribution, and the
                corresponding prior. The constructor clones the passed *learn_objects*
                and stores them internally (i.e. with no side-effect on the passed
                *learn_objects*).  

            ATTENTION: when using this function in Python, pass the parameter
            'learn_objects' as a Python list  

        * `plEMLearner(const std::vector< plLearnObject *> &learn_objects)`  

            Constructor.  

            Initial distributions are determined from the initial state of the
            *learn_objects*.  

            Parameters:  
            * `learn_objects` :  
                a vector of learning objects allowing to provide the structure
                (dependencies), the parametrical form of each distribution, and the
                corresponding prior. The constructor clones the passed *learn_objects*
                and stores them internally (i.e. with no side-effect on the passed
                *learn_objects*).  

            ATTENTION: If the initial state of the *learn_objects* is uniform (it's the
            case for default constructed plLearnObject), the EM algorithm can fail to
            converge because it will stay at the initial non-informative state. So,
            consider using the constructor:  

                plEMLearner(const plComputableObjectList &init_distribs,
                const std::vector <plLearnObject*> &learn_objects);
             even with random initialized *init_distribs*.  

            ATTENTION: when using this function in Python, pass the parameter
            'learn_objects' as a Python list  

        * `plEMLearner(const plEMLearner &other)`  

            Copy constructor.  

        """
        this = _probt_python3.new_plEMLearner(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def assign_from(self, other: 'plEMLearner') -> "plEMLearner &":
        """
        assign_from(self, other) -> plEMLearner


        `assign_from(const plEMLearner &other) -> plEMLearner &`  

        Same as operator=()  

        """
        return _probt_python3.plEMLearner_assign_from(self, other)

    __swig_destroy__ = _probt_python3.delete_plEMLearner
    __del__ = lambda self: None

    def reset(self) -> "void":
        """
        reset(self)


        `reset()`  

        Resets the learner to its initial state.  

        """
        return _probt_python3.plEMLearner_reset(self)


    def run(self, *args) -> "void":
        """
        run(self, data_descriptor, nit)
        run(self, data_descriptor, nit)
        run(self, data_descriptor, convergence_loglikelihood_threshold, max_it) -> unsigned int
        run(self, data_descriptor, nit, missing_most_probable_value, missing_probability_table)


        `run(plDataDescriptor &data_descriptor, unsigned int nit)`  
        `run(plDataDescriptor &data_descriptor, int nit)`  
        `run(plDataDescriptor &data_descriptor, plFloat
            convergence_loglikelihood_threshold, unsigned int max_it) -> unsigned int`  
        `run(plDataDescriptor &data_descriptor, unsigned int nit, std::vector< plValues
            > &missing_most_probable_value, std::vector< std::vector< plProbValue > >
            &missing_probability_table)`  

        Overloaded function
        -------------------
        * `run(plDataDescriptor &data_descriptor, unsigned int nit)`  

            Run the EM algorithm for a given number of iterations.  

            Parameters:  
            * `data_descriptor` :  
                the data set on which the EM algorithm will iterate. It can contain
                arbitrary missing data.  
            * `nit` :  
                the number of iterations for which the EM algorithm will be run.  

        * `run(plDataDescriptor &data_descriptor, int nit)`  

            Run the EM algorithm for a given number of iterations.  

            Parameters:  
            * `data_descriptor` :  
                the data set on which the EM algorithm will iterate. It can contain
                arbitrary missing data.  
            * `nit` :  
                the number of iterations for which the EM algorithm will be run.  

        * `run(plDataDescriptor &data_descriptor, plFloat
            convergence_loglikelihood_threshold, unsigned int max_it) -> unsigned int`  

            Run the EM algorithm until convergence:  
             | log-likelihood(t) - log-likelihood(t-1) | / | (log-likelihood(t) + log-
            likelihood(t-1)/2.0 | < convergence_loglikelihood_threshold.  

            Parameters:  
            * `data_descriptor` :  
                the data set on which the EM algorithm will iterate. It can contain
                arbitrary missing data.  
            * `convergence_loglikelihood_threshold` :  
                convergence threshold of relative log-likelihood change between two
                successive EM iterations (smaller value means more iterations). The
                default value is set to 0.0001  
            * `max_it` :  
                the maximal number of iterations.  

            Returns:
            the number of iterations needed to reach the convergence  

        * `run(plDataDescriptor &data_descriptor, unsigned int nit, std::vector<
            plValues > &missing_most_probable_value, std::vector< std::vector<
            plProbValue > > &missing_probability_table)`  

            Run the EM algorithm for a given number of iterations and return the last
            iteration info.  

            Parameters:  
            * `data_descriptor` :  
                the data set on which the EM algorithm will iterate. It can contain
                arbitrary missing data.  
            * `nit` :  
                the number of iterations for which the EM algorithm will be run.  
            * `missing_most_probable_value` :  
                the values with the highest probability for the missing variables.  
            * `missing_probability_table` :  
                the current probability table on the missing variables.  

        """
        return _probt_python3.plEMLearner_run(self, *args)


    def get_distribution(self, n: 'unsigned int') -> "plComputableObject const &":
        """
        get_distribution(self, n) -> plComputableObject


        `get_distribution(unsigned int n) const -> const plComputableObject &`  

        Return the current estimation of the *nth* distribution.  

        Parameters
        ----------
        * `n` :  
            the position of the distribution to be returned.  

        Returns
        -------
        the current estimation of the *nth* distribution.  

        """
        return _probt_python3.plEMLearner_get_distribution(self, n)


    def set_distribution(self, n: 'unsigned int', new_distrib: 'plComputableObject') -> "void":
        """
        set_distribution(self, n, new_distrib)


        `set_distribution(unsigned int n, const plComputableObject &new_distrib)`  

        Set the *nth* distribution.  

        Parameters
        ----------
        * `n` :  
            the position of the distribution to be changed.  
        * `new_distrib` :  
            the new distribution.  

        """
        return _probt_python3.plEMLearner_set_distribution(self, n, new_distrib)


    def get_joint_distribution(self) -> "plJointDistribution const &":
        """
        get_joint_distribution(self) -> plJointDistribution


        `get_joint_distribution() const -> const plJointDistribution &`  

        Return the joint distribution (model) with the current learnt parameters.  

        Returns
        -------
        the joint distribution with the current learnt parameters.  

        """
        return _probt_python3.plEMLearner_get_joint_distribution(self)


    def set_same_missing_variables(self, same: 'bool'=True) -> "void":
        """
        set_same_missing_variables(self, same=True)
        set_same_missing_variables(self)


        `set_same_missing_variables(bool same=true)`  

        If 'same' = true, the learning data is assumed containing missing values for the
        same variables in all data rows (i.e., unobserved/latent variables exclusively).  

        If 'same' = false, the data may contain additional missing values.  

        This method is used just to speed up the algorithm.  

        """
        return _probt_python3.plEMLearner_set_same_missing_variables(self, same)


    def output_distributions(self, *args) -> "void":
        """
        output_distributions(self)
        output_distributions(self)


        `output_distributions(std::ostream &out=std::cout) const`  

        Outputs the current learnt distributions on the output stream 'out'.  

        """
        return _probt_python3.plEMLearner_output_distributions(self, *args)


    def set_distributions_display(self, display: 'bool'=True) -> "void":
        """
        set_distributions_display(self, display=True)
        set_distributions_display(self)


        `set_distributions_display(bool display=true)`  

        Sets distributions displaying, after each iteration, to ON or OFF.  

        """
        return _probt_python3.plEMLearner_set_distributions_display(self, display)


    def set_distributions_display_stream(self) -> "void":
        """
        set_distributions_display_stream(self)


        `set_distributions_display_stream(std::ostream &out)`  

        Sets distributions displaying stream to 'out'.  

        """
        return _probt_python3.plEMLearner_set_distributions_display_stream(self)


    def distribution_set_frozen(self, n: 'unsigned int', freeze: 'bool'=True) -> "void":
        """
        distribution_set_frozen(self, n, freeze=True)
        distribution_set_frozen(self, n)


        `distribution_set_frozen(unsigned int n, bool freeze=true)`  

        Freezes the nth distribution to its current state.  

        """
        return _probt_python3.plEMLearner_distribution_set_frozen(self, n, freeze)


    def use_junction_tree(self, use_jt: 'bool'=True) -> "void":
        """
        use_junction_tree(self, use_jt=True)
        use_junction_tree(self)


        `use_junction_tree(bool use_jt=true)`  

        Sets or unsets the use of a junction tree for inference.  

        By default, inference is done using the ordinary successive restrictions
        algorithm as accessed by plJointDistribution.  

        """
        return _probt_python3.plEMLearner_use_junction_tree(self, use_jt)


    def set_mc_integration_npoints(self, npoints: 'unsigned int') -> "void":
        """
        set_mc_integration_npoints(self, npoints)


        `set_mc_integration_npoints(unsigned int npoints)`  

        This method allows to set the marginalization mode to 'monte carlo' using
        'npoints' sample points.  

        It sets the integration mode to 'exact' if 'npoints' is null.  

        This is only used for computing the likelihood of the data (given the model)
        P(Observed) because this computation requires the marginalization over the
        missing variables. Calling this function is mondatory if at least one of the
        missing variables is continuous.  

        """
        return _probt_python3.plEMLearner_set_mc_integration_npoints(self, npoints)


    def set_approximate_compilation_time(self, compilation_time_in_seconds: 'plFloat') -> "void":
        """
        set_approximate_compilation_time(self, compilation_time_in_seconds)


        `set_approximate_compilation_time(plFloat compilation_time_in_seconds)`  

        This method allows to set the compilation mode to 'approximate' using a maximal
        time of 'compilation_time_in_seconds' (in seconds) when constructing the
        distribution P(Missing | Observed) in the E step.  

        It sets the compilation mode to 'exact' if 'compilation_time_in_seconds' is
        null.  

        Calling this function (or set_approximate_compilation_nsamples()) is mondatory
        if at least one of the missing variables is continuous.  

        Calling this function changes the stop criterion for constructing the
        distribution P(Missing | Observed) to 'time'.  

        See also: set_approximate_compilation_nsamples  

        """
        return _probt_python3.plEMLearner_set_approximate_compilation_time(self, compilation_time_in_seconds)


    def set_approximate_compilation_nsamples(self, n: 'unsigned int') -> "void":
        """
        set_approximate_compilation_nsamples(self, n)


        `set_approximate_compilation_nsamples(unsigned int n)`  

        This method allows to set the compilation mode to 'approximate' using a number
        of samples of 'n' when constructing the distribution P(Missing | Observed) in
        the E step.  

        It sets the compilation mode to 'exact' if 'n' is null.  

        Calling this function (or set_approximate_compilation_time()) is mondatory if at
        least one of the missing variables is continuous.  

        Calling this function changes the stop criterion for constructing the
        distribution P(Missing | Observed) to 'number of samples'.  

        See also: set_approximate_compilation_time  

        """
        return _probt_python3.plEMLearner_set_approximate_compilation_nsamples(self, n)


    def set_use_sampling_for_compilation(self, use_it: 'bool'=True) -> "void":
        """
        set_use_sampling_for_compilation(self, use_it=True)
        set_use_sampling_for_compilation(self)


        `set_use_sampling_for_compilation(bool use_it=true)`  

        This method allows to set the methode to be used for constructing the
        distribution P(Missing | Observed) in the E step when using approximate mode
        (using set_approximate_compilation_time or
        set_approximate_compilation_nsamples).  

        If set to *true*, P(Missing | Observed) will be sampled and the corresponding
        points will be directly used in the M_step instead to constructing explicitly
        the corresponding probability table.  

        The default value of this parameter is *false*. Do not change this parameter
        unless you understand exactly its effect.  

        """
        return _probt_python3.plEMLearner_set_use_sampling_for_compilation(self, use_it)


    def compute_missing_values_infos(self, data_descriptor: 'plDataDescriptor', missing_most_probable_value: 'plValuesVector', missing_probability_table: 'DoubleVectorVector') -> "void":
        """
        compute_missing_values_infos(self, data_descriptor, missing_most_probable_value, missing_probability_table)


        `compute_missing_values_infos(plDataDescriptor &data_descriptor, std::vector<
            plValues > &missing_most_probable_value, std::vector< std::vector<
            plProbValue > > &missing_probability_table)`  

        Compute for each data row: (i) the values with the highest probability for the
        missing variables argmax P(Missing)  

        (ii) the current probability table on the missing variables P(Missing).  

        """
        return _probt_python3.plEMLearner_compute_missing_values_infos(self, data_descriptor, missing_most_probable_value, missing_probability_table)


    def compute_loglikelihood(self, *args) -> "plFloat":
        """
        compute_loglikelihood(self, data_descriptor, data_loglikelihood) -> plFloat
        compute_loglikelihood(self, data_descriptor) -> plFloat


        `compute_loglikelihood(plDataDescriptor &data_descriptor, std::vector< plFloat >
            &data_loglikelihood) -> plFloat`  
        `compute_loglikelihood(plDataDescriptor &data_descriptor) -> plFloat`  

        Overloaded function
        -------------------
        * `compute_loglikelihood(plDataDescriptor &data_descriptor, std::vector< plFloat
            > &data_loglikelihood) -> plFloat`  

            Compute and return, for each data row, the log-likelihood of the data given
            the current parameters estimation.  

        * `compute_loglikelihood(plDataDescriptor &data_descriptor) -> plFloat`  

            Computes the log-likelihood of the data given the current parameters
            estimation.  

        """
        return _probt_python3.plEMLearner_compute_loglikelihood(self, *args)


    def get_computable_object_list(self) -> "plComputableObjectList":
        """
        get_computable_object_list(self) -> plComputableObjectList


        `get_computable_object_list() const -> plComputableObjectList`  

        Returns the list of distributions (computable object) corresponding to the
        current estimation.  

        """
        return _probt_python3.plEMLearner_get_computable_object_list(self)


    def set_trace_loglikelihood(self, trace_it: 'bool'=True) -> "void":
        """
        set_trace_loglikelihood(self, trace_it=True)
        set_trace_loglikelihood(self)


        `set_trace_loglikelihood(bool trace_it=true)`  

        Set/unset log-likelihood evolution output.  

        """
        return _probt_python3.plEMLearner_set_trace_loglikelihood(self, trace_it)


    def get_learn_object(self, n: 'unsigned int') -> "plLearnObject *":
        """
        get_learn_object(self, n) -> plLearnObject


        `get_learn_object(unsigned int n) const -> plLearnObject *`  

        Return a pointer to the *nth* internal learn object in the same order as passed
        to the constuctor.  

        Parameters
        ----------
        * `n` :  
            the position of the distribution to be returned.  

        Returns
        -------
        a pointer to the *nth* internal learn object in the same order as passed to the
        constuctor.  

        """
        return _probt_python3.plEMLearner_get_learn_object(self, n)


    def get_learn_objects(self) -> "std::vector< plLearnObject *,std::allocator< plLearnObject * > > const &":
        """
        get_learn_objects(self) -> plLearnObjectVector


        `get_learn_objects() const -> const std::vector< plLearnObject * > &`  

        Return the vector of the stored learn objects.  

        """
        return _probt_python3.plEMLearner_get_learn_objects(self)


    def iteration(self, *args) -> "void":
        """
        iteration(self, data_descriptor)
        iteration(self, data_descriptor, missing_most_probable_value, missing_probability_table)


        `iteration(plDataDescriptor &data_descriptor)`  
        `iteration(plDataDescriptor &data_descriptor, std::vector< plValues >
            &missing_most_probable_value, std::vector< std::vector< plProbValue > >
            &missing_probability_table)`  

        Overloaded function
        -------------------
        * `iteration(plDataDescriptor &data_descriptor)`  

            Run the EM algorithm for one iteration.  

            Parameters:  
            * `data_descriptor` :  
                the data set on which the EM algorithm will iterate. It can contain
                arbitrary missing data.  

        * `iteration(plDataDescriptor &data_descriptor, std::vector< plValues >
            &missing_most_probable_value, std::vector< std::vector< plProbValue > >
            &missing_probability_table)`  

            Run the EM algorithm for oneiterations and return this last iteration info.  

            Parameters:  
            * `data_descriptor` :  
                the data set on which the EM algorithm will iterate. It can contain
                arbitrary missing data.  
            * `missing_most_probable_value` :  
                the values with the highest probability for the missing variables argmax
                P(Missing).  
            * `missing_probability_table` :  
                the current probability table on the missing variables P(Missing).  

        """
        return _probt_python3.plEMLearner_iteration(self, *args)


    def get_last_computed_loglikelihood(self) -> "plFloat":
        """
        get_last_computed_loglikelihood(self) -> plFloat


        `get_last_computed_loglikelihood() const -> plFloat`  

        Returns the last cached loglikelihood value.  

        Throws an exception if this value is not available or made obsolete.  

        """
        return _probt_python3.plEMLearner_get_last_computed_loglikelihood(self)


    def set_trace_observation_and_inference_info(self, set_it: 'bool'=True) -> "void":
        """
        set_trace_observation_and_inference_info(self, set_it=True)
        set_trace_observation_and_inference_info(self)


        `set_trace_observation_and_inference_info(bool set_it=true)`  

        Set/unset observation and inference information for each data record.  

        """
        return _probt_python3.plEMLearner_set_trace_observation_and_inference_info(self, set_it)


    def get_n_parameters(self) -> "unsigned int":
        """
        get_n_parameters(self) -> unsigned int


        `get_n_parameters() const -> unsigned int`  

        Returns the number of parameters to be learnt.  

        """
        return _probt_python3.plEMLearner_get_n_parameters(self)


    def get_variables(self) -> "plVariablesConjunction const &":
        """
        get_variables(self) -> plVariablesConjunction


        `get_variables() const -> const plVariablesConjunction &`  

        Return EM varibles.  

        """
        return _probt_python3.plEMLearner_get_variables(self)

plEMLearner_swigregister = _probt_python3.plEMLearner_swigregister
plEMLearner_swigregister(plEMLearner)


fixup_dataframe_input(plEMLearner, 'run', [0])

PL_JT = _probt_python3.PL_JT
PL_SR = _probt_python3.PL_SR
PL_MCMC = _probt_python3.PL_MCMC
PL_GIBBS = _probt_python3.PL_GIBBS
PL_MI = _probt_python3.PL_MI
PL_MI_DIST = _probt_python3.PL_MI_DIST
PL_ENTROPY = _probt_python3.PL_ENTROPY
PL_BIC = _probt_python3.PL_BIC
PL_AIC = _probt_python3.PL_AIC
PL_MDL = _probt_python3.PL_MDL
PL_FORMAT_GENIE = _probt_python3.PL_FORMAT_GENIE
PL_FORMAT_NETICA = _probt_python3.PL_FORMAT_NETICA
PL_FORMAT_HUGIN = _probt_python3.PL_FORMAT_HUGIN
class plBayesianNetwork(plObject):
    """

    `plBayesianNetwork(const std::string &name="untitled_BN")`  
    `plBayesianNetwork(const plVariablesConjunction &variables, const std::string
        &name="untitled_BN")`  
    `plBayesianNetwork(const plJointDistribution &joint, const std::string
        &name="untitled_BN")`  
    `plBayesianNetwork(const plComputableObjectList &decomposition, const
        plVariablesConjunction &variables=plVariablesConjunction(), const
        std::string &name="untitled_BN")`  
    `plBayesianNetwork(const plBayesianNetwork &other)`  

    Class for building and/or learning (parameters and structure) a Bayesian network
    and using it for exact and approximate inference.  

    It provides also a support for one-time slice dynamic Bayesian networks.  

    This class provides a simple and high-level API for building/querying Bayesian
    networks. More advanced functionalities are provided by the low-level ProBT API.  

    Transitioning from this class to the low-level ProBT API is easy. Consider the
    following example using plBayesianNetwork:  

        double a_vals[] = {1, 3.6, 5};
        plVariable a("A", plDiscreteIntervalType(3, a_vals));
        plVariable b("B", plIntegerType(0, 10));
        plBayesianNetwork net;
        net.add_node(a);
        net.add_node(b);
        net.set_distribution(plUniform(a));
        net.set_distribution(plCndNormal(b, 5, a));
        plValues evidence(b);
        evidence[b] = 2;
        net.set_evidence(evidence);
        // P(A = 5 | B = 2)
        std::cout << net.get_belief(a).compute(5) << std::endl;  

    This example can be replicated with the low-level and more powerful ProBT API:  

        double a_vals[] = {1, 3.6, 5};
        plVariable a("A", plDiscreteIntervalType(3, a_vals));
        plVariable b("B", plIntegerType(0, 10));
        plJointDistribution j(a ^ b,
        plUniform(a) * plCndNormal(b, 5, a));
        plValues evidence(b);
        evidence[b] = 2;
        // P(A = 5 | B = 2)
        std::cout << j.ask(a, b).instantiate(evidence).compute(5) << std::endl;  


    Constructors
    ------------
    * `plBayesianNetwork(const std::string &name="untitled_BN")`  

        Builds an empty Bayesian network.  

        Add nodes to it using add_node(). Simultaneously add links and set the
        corresponding probability distribution using set_distribution(). Insert
        evidence using set_evidence(). Get a belief corresponding to this last
        evidence using get_belief() (inference/propagation in the network is made
        automatically for you when needed).  

    * `plBayesianNetwork(const plVariablesConjunction &variables, const std::string
        &name="untitled_BN")`  

        Creation with variables.  

    * `plBayesianNetwork(const plJointDistribution &joint, const std::string
        &name="untitled_BN")`  

        Builds a Bayesian network from a plJointDistribution object.  

    * `plBayesianNetwork(const plComputableObjectList &decomposition, const
        plVariablesConjunction &variables=plVariablesConjunction(), const
        std::string &name="untitled_BN")`  

        Builds a Bayesian network from a plComputableObjectList object.  

        'variables' must be the concatenation of all the variables used in the
        passed computable object list. If empty, it will be constructed from the
        passed computable object list  

    * `plBayesianNetwork(const plBayesianNetwork &other)`  

        Copy constructor.  

    C++ includes: plBayesianNetwork.h

    """

    __swig_setmethods__ = {}
    for _s in [plObject]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plBayesianNetwork, name, value)
    __swig_getmethods__ = {}
    for _s in [plObject]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plBayesianNetwork, name)
    __repr__ = _swig_repr

    def __init__(self, *args):
        """
        __init__(self, name) -> plBayesianNetwork
        __init__(self) -> plBayesianNetwork
        __init__(self, variables, name) -> plBayesianNetwork
        __init__(self, variables) -> plBayesianNetwork
        __init__(self, joint, name) -> plBayesianNetwork
        __init__(self, joint) -> plBayesianNetwork
        __init__(self, decomposition, variables, name) -> plBayesianNetwork
        __init__(self, decomposition, variables) -> plBayesianNetwork
        __init__(self, decomposition) -> plBayesianNetwork
        __init__(self, other) -> plBayesianNetwork


        `plBayesianNetwork(const std::string &name="untitled_BN")`  
        `plBayesianNetwork(const plVariablesConjunction &variables, const std::string
            &name="untitled_BN")`  
        `plBayesianNetwork(const plJointDistribution &joint, const std::string
            &name="untitled_BN")`  
        `plBayesianNetwork(const plComputableObjectList &decomposition, const
            plVariablesConjunction &variables=plVariablesConjunction(), const
            std::string &name="untitled_BN")`  
        `plBayesianNetwork(const plBayesianNetwork &other)`  

        Overloaded function
        -------------------
        * `plBayesianNetwork(const std::string &name="untitled_BN")`  

            Builds an empty Bayesian network.  

            Add nodes to it using add_node(). Simultaneously add links and set the
            corresponding probability distribution using set_distribution(). Insert
            evidence using set_evidence(). Get a belief corresponding to this last
            evidence using get_belief() (inference/propagation in the network is made
            automatically for you when needed).  

        * `plBayesianNetwork(const plVariablesConjunction &variables, const std::string
            &name="untitled_BN")`  

            Creation with variables.  

        * `plBayesianNetwork(const plJointDistribution &joint, const std::string
            &name="untitled_BN")`  

            Builds a Bayesian network from a plJointDistribution object.  

        * `plBayesianNetwork(const plComputableObjectList &decomposition, const
            plVariablesConjunction &variables=plVariablesConjunction(), const
            std::string &name="untitled_BN")`  

            Builds a Bayesian network from a plComputableObjectList object.  

            'variables' must be the concatenation of all the variables used in the
            passed computable object list. If empty, it will be constructed from the
            passed computable object list  

        * `plBayesianNetwork(const plBayesianNetwork &other)`  

            Copy constructor.  

        """
        this = _probt_python3.new_plBayesianNetwork(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this
    __swig_destroy__ = _probt_python3.delete_plBayesianNetwork
    __del__ = lambda self: None

    def assign_from(self, other: 'plBayesianNetwork') -> "plBayesianNetwork &":
        """
        assign_from(self, other) -> plBayesianNetwork


        `assign_from(const plBayesianNetwork &other) -> plBayesianNetwork &`  

        Same as operator=()  

        """
        return _probt_python3.plBayesianNetwork_assign_from(self, other)


    def enable_sanity_checking(self, enable_it: 'bool') -> "void":
        """
        enable_sanity_checking(self, enable_it)


        `enable_sanity_checking(bool enable_it)`  

        Enable/disable sanity checking.  

        Disabling sanity checking allows speeding up the computation (for huge networks
        for example). Sanity checking is enabled by default. It is always enabled in
        debug mode (DEBUG defined)  

        See also: sanity_checking_enabled()  

        """
        return _probt_python3.plBayesianNetwork_enable_sanity_checking(self, enable_it)


    def sanity_checking_enabled(self) -> "bool":
        """
        sanity_checking_enabled(self) -> bool


        `sanity_checking_enabled() const -> bool`  

        Get sanity checking status.  

        Return true iif:  

        *   enable_sanity_checking() has been set to true OR  
        *   DEBUG is defined  

        See also: enable_sanity_checking()  

        """
        return _probt_python3.plBayesianNetwork_sanity_checking_enabled(self)


    def set_nodes(self, *args) -> "void":
        """
        set_nodes(self, nodes)
        set_nodes(self, nodes)


        `set_nodes(const plVariablesConjunction &nodes)`  
        `set_nodes(const std::vector< plVariable > &nodes)`  

        Overloaded function
        -------------------
        * `set_nodes(const plVariablesConjunction &nodes)`  

            Clear the network and set its nodes.  

        * `set_nodes(const std::vector< plVariable > &nodes)`  

            Clear the network and set its nodes.  

        """
        return _probt_python3.plBayesianNetwork_set_nodes(self, *args)


    def add_node(self, *args) -> "void":
        """
        add_node(self, name, type)
        add_node(self, node)


        `add_node(const std::string &name, const plType &type)`  
        `add_node(const plVariable &node)`  

        Overloaded function
        -------------------
        * `add_node(const std::string &name, const plType &type)`  

            Add a node with name *name* and of type *type*.  

        * `add_node(const plVariable &node)`  

            Declares a node in the network.  

            The node is described by a plVariable object, which represents a variable.  

        """
        return _probt_python3.plBayesianNetwork_add_node(self, *args)


    def remove_node(self, *args) -> "void":
        """
        remove_node(self, node)
        remove_node(self, name)


        `remove_node(const plVariable &node)`  
        `remove_node(const std::string &name)`  

        Overloaded function
        -------------------
        * `remove_node(const plVariable &node)`  

            Removes the node *node* if exists.  

        * `remove_node(const std::string &name)`  

            Removes the node with the name *name* if exists.  

        """
        return _probt_python3.plBayesianNetwork_remove_node(self, *args)


    def set_distribution(self, *args) -> "void":
        """
        set_distribution(self, distribution)
        set_distribution(self, learnable_distribution)


        `set_distribution(const plComputableObject &distribution)`  
        `set_distribution(const plLearnObject &learnable_distribution)`  

        Overloaded function
        -------------------
        * `set_distribution(const plComputableObject &distribution)`  

            Sets the distribution associated to a given node.  

            The distribution itself specifies the network link:  

            *   its left variable is the node to which the distribution is attached  
            *   its right variables are the parent nodes.  

            If the distribution is non-conditional (in ProBT terminology, a
            plDistribution), this also establishes the fact that the node has no
            parents.  

            For instance,  

                net.set_distribution(plUniform(a));
             specifies that node *a* has no parents, and that the prior distribution on
            *a* is a uniform one.  

            If the distribution is conditional (a plCndDistribution), its right
            variables become the parents of the node.  

            For instance,  

                net.set_distribution(plCndNormal(b, a, 1));
             specifies that node *b* has *a* for only parent, and that its associated
            conditional probability distribution is a Normal (Gaussian) centered on the
            value of *a*, and of constant standard deviation equal to one.  

        * `set_distribution(const plLearnObject &learnable_distribution)`  

            Sets the distribution associated to a given node to be a learnable
            distribution.  

            You may learn all learnable distributions of a network using
            learn_parameters(). Within the same network, you may freely mix learnable
            and non-learnable distributions.  

            For instance:  

                plVariable a("A", plIntegerType(0, 42));
                plVariable b("B", plIntegerType(-2, 2));
                plVariable c("C", plIntegerType(-1, 1));
                plBayesianNetwork net;
                net.add_node(a);
                net.add_node(b);
                net.add_node(c);
                plLearnLaplace learn_a(a);
                net.set_distribution(learn_a);
                plCndLearnObject<plLearnNormal> learn_b_k_a(b, a);
                net.set_distribution(learn_b_k_a);
                plCndLearnObject<plLearnNormal> learn_c_k_b(c, b);
                net.set_distribution(learn_c_k_b);
                net.learn_parameters("data.csv");
                std::cout << net << std::endl;


        """
        return _probt_python3.plBayesianNetwork_set_distribution(self, *args)


    def add_edge(self, *args) -> "void":
        """
        add_edge(self, source, destination)
        add_edge(self, source_name, destination_name)


        `add_edge(const plVariable &source, const plVariable &destination)`  
        `add_edge(const std::string &source_name, const std::string &destination_name)`  

        Overloaded function
        -------------------
        * `add_edge(const plVariable &source, const plVariable &destination)`  

            Add an edge to the network.  

            You must call set_nodes() or add_node() to create the nodes before creating
            an edge between nodes. An exception will be raised if you do not do this.  

            Do not call add_edge() / remove_edge() if you want to customize the
            distributions later using set_distribution()  

            See also: set_distribution()  

            Changing the parents of a given node changes its default distribution as
            follows:  

            *   if the node is discrete and all its parents are discrete:
                plCndLearnObject<plLearnLaplace>(node, parents)  
            *   if the node is discrete and all its parents are continuous:
                plLearnSoftmax(node, parents)  
            *   if the node is discrete and its parents are mixed:
                plLearnSoftmaxFamily(node, continuous_parents, discrete_parents)  
            *   if the node is continuous and all its parents are discrete:
                plCndLearnObject<plLearn1dNormal>(node, parents)  
            *   if the node is continuous and all its parents are continuous:
                plLearnLinearRegression(node, parents)  
            *   if the node is continuous and its parents are mixed:
                plLearnLinearRegressionFamily(node, continuous_parents,
                discrete_parents)  

            If the node is a root (with no parents):  

            *   if the node is discrete: plLearnLaplace(node)  
            *   if the node is continuous: plLearn1dNormal(node)  

            See also: plLearnObject::create_learner()  

        * `add_edge(const std::string &source_name, const std::string
            &destination_name)`  

            Add an edge to the network.  

            You must call set_nodes() or add_node() to create the nodes before creating
            an edge between nodes. An exception will be raised if you do not do this.  

            Do not call add_edge() / remove_edge() if you want to customize the
            distributions later using set_distribution()  

            See also: set_distribution()  

            Changing the parents of a given node changes its default distribution as
            follows:  

            *   if the node is discrete and all its parents are discrete:
                plCndLearnObject<plLearnLaplace>(node, parents)  
            *   if the node is discrete and all its parents are continuous:
                plLearnSoftmax(node, parents)  
            *   if the node is discrete and its parents are mixed:
                plLearnSoftmaxFamily(node, continuous_parents, discrete_parents)  
            *   if the node is continuous and all its parents are discrete:
                plCndLearnObject<plLearn1dNormal>(node, parents)  
            *   if the node is continuous and all its parents are continuous:
                plLearnLinearRegression(node, parents)  
            *   if the node is continuous and its parents are mixed:
                plLearnLinearRegressionFamily(node, continuous_parents,
                discrete_parents)  

            If the node is a root (with no parents):  

            *   if the node is discrete: plLearnLaplace(node)  
            *   if the node is continuous: plLearn1dNormal(node)  

            See also: plLearnObject::create_learner()  

        """
        return _probt_python3.plBayesianNetwork_add_edge(self, *args)


    def remove_edge(self, *args) -> "void":
        """
        remove_edge(self, source, destination)
        remove_edge(self, source_name, destination_name)


        `remove_edge(const plVariable &source, const plVariable &destination)`  
        `remove_edge(const std::string &source_name, const std::string
            &destination_name)`  

        Overloaded function
        -------------------
        * `remove_edge(const plVariable &source, const plVariable &destination)`  

            Remove an edge from the network.  

            Do not call add_edge() / remove_edge() if you want to customize the
            distributions later using set_distribution()  

            See also: set_distribution()  

            Changing the parents of a given node changes its default distribution as
            follows:  

            *   if the node is discrete and all its parents are discrete:
                plCndLearnObject<plLearnLaplace>(node, parents)  
            *   if the node is discrete and all its parents are continuous:
                plLearnSoftmax(node, parents)  
            *   if the node is discrete and its parents are mixed:
                plLearnSoftmaxFamily(node, continuous_parents, discrete_parents)  
            *   if the node is continuous and all its parents are discrete:
                plCndLearnObject<plLearn1dNormal>(node, parents)  
            *   if the node is continuous and all its parents are continuous:
                plLearnLinearRegression(node, parents)  
            *   if the node is continuous and its parents are mixed:
                plLearnLinearRegressionFamily(node, continuous_parents,
                discrete_parents)  

            If the node is a root (with no parents):  

            *   if the node is discrete: plLearnLaplace(node)  
            *   if the node is continuous: plLearn1dNormal(node)  

            See also: plLearnObject::create_learner()  

        * `remove_edge(const std::string &source_name, const std::string
            &destination_name)`  

            Remove an edge from the network.  

            Do not call add_edge() / remove_edge() if you want to customize the
            distributions later using set_distribution()  

            See also: set_distribution()  

            Changing the parents of a given node changes its default distribution as
            follows:  

            *   if the node is discrete and all its parents are discrete:
                plCndLearnObject<plLearnLaplace>(node, parents)  
            *   if the node is discrete and all its parents are continuous:
                plLearnSoftmax(node, parents)  
            *   if the node is discrete and its parents are mixed:
                plLearnSoftmaxFamily(node, continuous_parents, discrete_parents)  
            *   if the node is continuous and all its parents are discrete:
                plCndLearnObject<plLearn1dNormal>(node, parents)  
            *   if the node is continuous and all its parents are continuous:
                plLearnLinearRegression(node, parents)  
            *   if the node is continuous and its parents are mixed:
                plLearnLinearRegressionFamily(node, continuous_parents,
                discrete_parents)  

            If the node is a root (with no parents):  

            *   if the node is discrete: plLearnLaplace(node)  
            *   if the node is continuous: plLearn1dNormal(node)  

            See also: plLearnObject::create_learner()  

        """
        return _probt_python3.plBayesianNetwork_remove_edge(self, *args)


    def nodes(self) -> "plVariablesConjunction const &":
        """
        nodes(self) -> plVariablesConjunction


        `nodes() const -> const plVariablesConjunction &`  

        Get the BN nodes.  

        """
        return _probt_python3.plBayesianNetwork_nodes(self)


    def get_variables(self) -> "plVariablesConjunction const &":
        """
        get_variables(self) -> plVariablesConjunction


        `get_variables() const -> const plVariablesConjunction &`  

        Same as nodes()  

        """
        return _probt_python3.plBayesianNetwork_get_variables(self)


    def edges(self) -> "plBayesianNetwork::bn_edge_list_t":
        """
        edges(self) -> plBnEdgeList


        `edges() const -> bn_edge_list_t`  

        Get the BN edges as a set of pairs (source, destination)  

        """
        return _probt_python3.plBayesianNetwork_edges(self)


    def get_n_nodes(self) -> "size_t":
        """
        get_n_nodes(self) -> size_t


        `get_n_nodes() const -> size_t`  

        Get the number of nodes.  

        """
        return _probt_python3.plBayesianNetwork_get_n_nodes(self)


    def get_nth_node_name(self, n: 'unsigned int') -> "std::string":
        """
        get_nth_node_name(self, n) -> std::string


        `get_nth_node_name(unsigned int n) const -> std::string`  

        Get the nth node name.  

        """
        return _probt_python3.plBayesianNetwork_get_nth_node_name(self, n)


    def get_node(self, *args) -> "plVariablesConjunction":
        """
        get_node(self, n) -> plVariable
        get_node(self, node_name) -> plVariable
        get_node(self, node_names) -> plVariablesConjunction


        `get_node(unsigned int n) const -> plVariable`  
        `get_node(const std::string &node_name) const -> plVariable`  
        `get_node(const std::vector< std::string > &node_names) const ->
            plVariablesConjunction`  

        Overloaded function
        -------------------
        * `get_node(unsigned int n) const -> plVariable`  

            Get the nth node.  

        * `get_node(const std::string &node_name) const -> plVariable`  

            Get the node having *node_name* as name.  

        * `get_node(const std::vector< std::string > &node_names) const ->
            plVariablesConjunction`  

            Get the node conjunction from *node_names* names.  

        """
        return _probt_python3.plBayesianNetwork_get_node(self, *args)


    def clear(self) -> "void":
        """
        clear(self)


        `clear()`  

        Clear all BN's nodes and the associated distributions/learnable_distributions.  

        """
        return _probt_python3.plBayesianNetwork_clear(self)


    def set_evidence(self, evidence: 'plValues', check_validity: 'bool'=True) -> "void":
        """
        set_evidence(self, evidence, check_validity=True)
        set_evidence(self, evidence)


        `set_evidence(const plValues &evidence, bool check_validity=true)`  

        Sets the evidence in the network.  

        This replaces previously existing evidence. Evidence is contained in a plValues
        object. For instance, to insert evidence over nodes *a* and *c*, that a = 2 and
        c = 42:  

            plValues evidence(a ^ c);
            evidence[a] = 2;
            evidence[c] = 42;
            net.set_evidence(evidence);


        """
        return _probt_python3.plBayesianNetwork_set_evidence(self, evidence, check_validity)


    def add_evidence(self, *args) -> "void":
        """
        add_evidence(self, added_evidence, check_validity=True)
        add_evidence(self, added_evidence)
        add_evidence(self, evidence_variable, val, check_validity=True)
        add_evidence(self, evidence_variable, val)
        add_evidence(self, evidence_variable, val, check_validity=True)
        add_evidence(self, evidence_variable, val)
        add_evidence(self, evidence_variable, val, check_validity=True)
        add_evidence(self, evidence_variable, val)
        add_evidence(self, evidence_variable, val, check_validity=True)
        add_evidence(self, evidence_variable, val)
        add_evidence(self, evidence_variable_name, val, check_validity=True)
        add_evidence(self, evidence_variable_name, val)
        add_evidence(self, evidence_variable_name, val, check_validity=True)
        add_evidence(self, evidence_variable_name, val)
        add_evidence(self, evidence_variable_name, val, check_validity=True)
        add_evidence(self, evidence_variable_name, val)
        add_evidence(self, evidence_variable_name, val, check_validity=True)
        add_evidence(self, evidence_variable_name, val)


        `add_evidence(const plValues &added_evidence, bool check_validity=true)`  
        `add_evidence(const plVariable &evidence_variable, int val, bool
            check_validity=true)`  
        `add_evidence(const plVariable &evidence_variable, double val, bool
            check_validity=true)`  
        `add_evidence(const plVariable &evidence_variable, float val, bool
            check_validity=true)`  
        `add_evidence(const plVariable &evidence_variable, long double val, bool
            check_validity=true)`  
        `add_evidence(const plVariable &evidence_variable, const std::string &val, bool
            check_validity=true)`  
        `add_evidence(const std::string &evidence_variable_name, int val, bool
            check_validity=true)`  
        `add_evidence(const std::string &evidence_variable_name, double val, bool
            check_validity=true)`  
        `add_evidence(const std::string &evidence_variable_name, float val, bool
            check_validity=true)`  
        `add_evidence(const std::string &evidence_variable_name, long double val, bool
            check_validity=true)`  
        `add_evidence(const std::string &evidence_variable_name, const std::string &val,
            bool check_validity=true)`  

        Overloaded function
        -------------------
        * `add_evidence(const plValues &added_evidence, bool check_validity=true)`  

            Adds evidence into the network.  

            This adds the new evidence to the previously existing evidence. Evidence is
            contained in a plValues object. For instance, to add an evidence over nodes
            *a* and *c*, that a=2 and c = 42:  

                plValues evidence(a ^ c);
                evidence[a] = 2;
                evidence[c] = 42;
                net.add_evidence(evidence);


        * `add_evidence(const plVariable &evidence_variable, int val, bool
            check_validity=true)`  

            Same as add_evidence(const plValues&, bool) above but using a variable and
            its corresponding value.  

        * `add_evidence(const plVariable &evidence_variable, double val, bool
            check_validity=true)`  

            Same as add_evidence(const plValues&, bool) above but using a variable and
            its corresponding value.  

        * `add_evidence(const plVariable &evidence_variable, float val, bool
            check_validity=true)`  

            Same as add_evidence(const plValues&, bool) above but using a variable and
            its corresponding value.  

        * `add_evidence(const plVariable &evidence_variable, long double val, bool
            check_validity=true)`  

            Same as add_evidence(const plValues&, bool) above but using a variable and
            its corresponding value.  

        * `add_evidence(const plVariable &evidence_variable, const std::string &val,
            bool check_validity=true)`  

            Same as add_evidence(const plValues&, bool) above but using a variable and
            its corresponding value.  

        * `add_evidence(const std::string &evidence_variable_name, int val, bool
            check_validity=true)`  

            Same as add_evidence(const plValues&, bool) above but using a variable name
            and its corresponding value.  

        * `add_evidence(const std::string &evidence_variable_name, double val, bool
            check_validity=true)`  

            Same as add_evidence(const plValues&, bool) above but using a variable name
            and its corresponding value.  

        * `add_evidence(const std::string &evidence_variable_name, float val, bool
            check_validity=true)`  

            Same as add_evidence(const plValues&, bool) above but using a variable name
            and its corresponding value.  

        * `add_evidence(const std::string &evidence_variable_name, long double val, bool
            check_validity=true)`  

            Same as add_evidence(const plValues&, bool) above but using a variable name
            and its corresponding value.  

        * `add_evidence(const std::string &evidence_variable_name, const std::string
            &val, bool check_validity=true)`  

            Same as add_evidence(const plValues&, bool) above but using a variable name
            and its corresponding value.  

        """
        return _probt_python3.plBayesianNetwork_add_evidence(self, *args)


    def get_hard_evidence(self) -> "plValues const &":
        """
        get_hard_evidence(self) -> plValues


        `get_hard_evidence() const -> const plValues &`  

        Get the current hard evidence.  

        """
        return _probt_python3.plBayesianNetwork_get_hard_evidence(self)


    def get_soft_evidence(self) -> "plComputableObjectList const &":
        """
        get_soft_evidence(self) -> plComputableObjectList


        `get_soft_evidence() const -> const plComputableObjectList &`  

        Get the current hard evidence.  

        """
        return _probt_python3.plBayesianNetwork_get_soft_evidence(self)


    def clear_hard_evidence(self) -> "void":
        """
        clear_hard_evidence(self)


        `clear_hard_evidence()`  

        Clears the hard evidence previously inserted in the network.  

        """
        return _probt_python3.plBayesianNetwork_clear_hard_evidence(self)


    def clear_evidence(self) -> "void":
        """
        clear_evidence(self)


        `clear_evidence()`  

        Clears both hard and soft evidence previously inserted in the network.  

        """
        return _probt_python3.plBayesianNetwork_clear_evidence(self)


    def learn_parameters(self, *args) -> "void":
        """
        learn_parameters(self, data_set, em_iterations=-1, no_em=False)
        learn_parameters(self, data_set, em_iterations=-1)
        learn_parameters(self, data_set)
        learn_parameters(self, data_set, em_iterations=-1, no_em=False)
        learn_parameters(self, data_set, em_iterations=-1)
        learn_parameters(self, data_set)


        `learn_parameters(plDataDescriptor &data_set, int em_iterations=-1, bool
            no_em=false)`  
        `learn_parameters(const std::vector< plValues > &data_set, int em_iterations=-1,
            bool no_em=false)`  

        Overloaded function
        -------------------
        * `learn_parameters(plDataDescriptor &data_set, int em_iterations=-1, bool
            no_em=false)`  

            Learn the parameters of the learnable distributions in of the network.  

            There can be arbitrary missing data in the learning observations. If *no_em*
            is set to true (the default is *false*), only available values are used.
            Otherwise, EM (Expectation-Maximization) algorithm is used. This EM
            algorithm is run for *em_iterations* iterations if a positive value is
            provided. If *em_iterations* is not positive (the default value), the
            algorithm will be run until convergence.  

            The learning data is made of observations on the network variables, in a
            data descriptor object (plDataDescriptor) *data_set*.  

            See also: plDataDescriptor  

            See also: learn_parameters_em()  

            See also: learn_parameters_no_em()  

        * `learn_parameters(const std::vector< plValues > &data_set, int
            em_iterations=-1, bool no_em=false)`  

            Same as above but using a vector af plValues.  

        """
        return _probt_python3.plBayesianNetwork_learn_parameters(self, *args)


    def learn_parameters_em(self, *args) -> "plFloat":
        """
        learn_parameters_em(self, data_set, em_iterations=-1, same_missing_variables=False, use_most_probable_value=False) -> plFloat
        learn_parameters_em(self, data_set, em_iterations=-1, same_missing_variables=False) -> plFloat
        learn_parameters_em(self, data_set, em_iterations=-1) -> plFloat
        learn_parameters_em(self, data_set) -> plFloat
        learn_parameters_em(self, data_set, em_iterations=-1, same_missing_variables=False, use_most_probable_value=False) -> plFloat
        learn_parameters_em(self, data_set, em_iterations=-1, same_missing_variables=False) -> plFloat
        learn_parameters_em(self, data_set, em_iterations=-1) -> plFloat
        learn_parameters_em(self, data_set) -> plFloat
        learn_parameters_em(self, init_model, data_set, em_iterations=-1, same_missing_variables=False, use_most_probable_value=False) -> plFloat
        learn_parameters_em(self, init_model, data_set, em_iterations=-1, same_missing_variables=False) -> plFloat
        learn_parameters_em(self, init_model, data_set, em_iterations=-1) -> plFloat
        learn_parameters_em(self, init_model, data_set) -> plFloat
        learn_parameters_em(self, init_model, data_set, em_iterations=-1, same_missing_variables=False, use_most_probable_value=False) -> plFloat
        learn_parameters_em(self, init_model, data_set, em_iterations=-1, same_missing_variables=False) -> plFloat
        learn_parameters_em(self, init_model, data_set, em_iterations=-1) -> plFloat
        learn_parameters_em(self, init_model, data_set) -> plFloat


        `learn_parameters_em(plDataDescriptor &data_set, int em_iterations=-1, bool
            same_missing_variables=false, bool use_most_probable_value=false) ->
            plFloat`  
        `learn_parameters_em(const std::vector< plValues > &data_set, int
            em_iterations=-1, bool same_missing_variables=false, bool
            use_most_probable_value=false) -> plFloat`  
        `learn_parameters_em(const plComputableObjectList &init_model, plDataDescriptor
            &data_set, int em_iterations=-1, bool same_missing_variables=false, bool
            use_most_probable_value=false) -> plFloat`  
        `learn_parameters_em(const plComputableObjectList &init_model, const
            std::vector< plValues > &data_set, int em_iterations=-1, bool
            same_missing_variables=false, bool use_most_probable_value=false) ->
            plFloat`  

        Overloaded function
        -------------------
        * `learn_parameters_em(plDataDescriptor &data_set, int em_iterations=-1, bool
            same_missing_variables=false, bool use_most_probable_value=false) ->
            plFloat`  

            Learn the parameters of learnable distributions in the network using the EM
            algorithm.  

            There can be arbitrary missing data, including the case of latent variables,
            in the learning observations and EM (Expectation-Maximization) algorithm is
            used.  

            Parameters:  
            * `data_set` :  
                The data set to be used.  
            * `em_iterations` :  
                The number of iterations to be performed. If the value is not positive
                (the default value), the algorithm will be run until convergence (see
                set_em_convergence_threshold()).  
            * `same_missing_variables` :  
                Set to True if you are sure that the missing values concern the same
                variables (columns) for all data records. This information can speedup
                the processing using EM algorithm  
            * `use_most_probable_value` :  
                If set to true (default is false), the most probable value of the
                missing variables is used instead of all the all possible values weights
                with their corresponding probabilities  

            Returns:
            The log-likelihood of the learnt model if the algorithm is run until
            convergence, zero otherwise (i.e. when a positive value is provided for the
            parameter 'em_iterations').  

            See also: plDataDescriptor  

            See also: set_em_convergence_threshold()  

            See also: learn_parameters()  

            See also: learn_parameters_no_em()  

        * `learn_parameters_em(const std::vector< plValues > &data_set, int
            em_iterations=-1, bool same_missing_variables=false, bool
            use_most_probable_value=false) -> plFloat`  

            Same as above but using a vector af plValues.  

        * `learn_parameters_em(const plComputableObjectList &init_model,
            plDataDescriptor &data_set, int em_iterations=-1, bool
            same_missing_variables=false, bool use_most_probable_value=false) ->
            plFloat`  

            Same as above but with initializing the model to the decomposition provided
            by 'init_model'.  

        * `learn_parameters_em(const plComputableObjectList &init_model, const
            std::vector< plValues > &data_set, int em_iterations=-1, bool
            same_missing_variables=false, bool use_most_probable_value=false) ->
            plFloat`  

            Same as above but using a vector af plValues.  

        """
        return _probt_python3.plBayesianNetwork_learn_parameters_em(self, *args)


    def learn_parameters_no_em(self, *args) -> "void":
        """
        learn_parameters_no_em(self, data_set)
        learn_parameters_no_em(self, data_set)


        `learn_parameters_no_em(plDataDescriptor &data_set)`  
        `learn_parameters_no_em(const std::vector< plValues > &data_set)`  

        Overloaded function
        -------------------
        * `learn_parameters_no_em(plDataDescriptor &data_set)`  

            Learn the parameters of learnable distributions in the network.  

            There can be arbitrary missing data in the learning observations. However,
            only available values are used.  

            The learning data is made of observations on the network variables, in a
            data descriptor object (plDataDescriptor) *data_set*.  

            See also: plDataDescriptor  

            See also: learn_parameters()  

            See also: learn_parameters_em()  

        * `learn_parameters_no_em(const std::vector< plValues > &data_set)`  

            Same as above but using a vector af plValues.  

        """
        return _probt_python3.plBayesianNetwork_learn_parameters_no_em(self, *args)


    def learn_parameters_add_point(self, *args) -> "bool":
        """
        learn_parameters_add_point(self, data_row, weight=1.0) -> bool
        learn_parameters_add_point(self, data_row) -> bool
        learn_parameters_add_point(self, data_row, definitions, weight=1.0) -> bool
        learn_parameters_add_point(self, data_row, definitions) -> bool


        `learn_parameters_add_point(const plValues &data_row, plFloat weight=PL_ONE) ->
            bool`  
        `learn_parameters_add_point(const plValues &data_row, const std::vector< bool >
            &definitions, plFloat weight=PL_ONE) -> bool`  

        Overloaded function
        -------------------
        * `learn_parameters_add_point(const plValues &data_row, plFloat weight=PL_ONE)
            -> bool`  

            Insert a learning point and adjust the parameters of the BN.  

        * `learn_parameters_add_point(const plValues &data_row, const std::vector< bool
            > &definitions, plFloat weight=PL_ONE) -> bool`  

            Insert a learning point and adjust the parameters of the BN.  

        """
        return _probt_python3.plBayesianNetwork_learn_parameters_add_point(self, *args)


    def learn_parameters_get_total_weight(self) -> "plFloat":
        """
        learn_parameters_get_total_weight(self) -> plFloat


        `learn_parameters_get_total_weight() const -> plFloat`  

        Return the total weight of the data points inserted using
        learn_parameters_add_point()  

        """
        return _probt_python3.plBayesianNetwork_learn_parameters_get_total_weight(self)


    def learn_parameters_rescale_total_weight(self, s: 'plFloat') -> "void":
        """
        learn_parameters_rescale_total_weight(self, s)


        `learn_parameters_rescale_total_weight(plFloat s)`  

        Rescale the total weight of the data points inserted using
        learn_parameters_add_point()  

        This allows, for example, to decrease the importance of the old data points
        compared to the new ones  

        """
        return _probt_python3.plBayesianNetwork_learn_parameters_rescale_total_weight(self, s)


    def reset_learned_parameters(self) -> "void":
        """
        reset_learned_parameters(self)


        `reset_learned_parameters()`  

        Reset the learned distributions to their initial values.  

        """
        return _probt_python3.plBayesianNetwork_reset_learned_parameters(self)


    def get_n_parameters(self) -> "unsigned int":
        """
        get_n_parameters(self) -> unsigned int


        `get_n_parameters() const -> unsigned int`  

        Get the total number of parameters to be learnt.  

        """
        return _probt_python3.plBayesianNetwork_get_n_parameters(self)


    def learned_parameters_number(self) -> "unsigned int":
        """
        learned_parameters_number(self) -> unsigned int


        `learned_parameters_number() const -> unsigned int`  

        Same as get_n_parameters()  

        """
        return _probt_python3.plBayesianNetwork_learned_parameters_number(self)


    def learn_structure(self, *args) -> "plFloat":
        """
        learn_structure(self, data, use_current_structure_as_starting_point=True, keep_current_edges=False, edge_score=PL_MI, node_score=PL_AIC, root_node, maxp=10, maxpc=1000, edges_to_exclude) -> plFloat
        learn_structure(self, data, use_current_structure_as_starting_point=True, keep_current_edges=False, edge_score=PL_MI, node_score=PL_AIC, root_node, maxp=10, maxpc=1000) -> plFloat
        learn_structure(self, data, use_current_structure_as_starting_point=True, keep_current_edges=False, edge_score=PL_MI, node_score=PL_AIC, root_node, maxp=10) -> plFloat
        learn_structure(self, data, use_current_structure_as_starting_point=True, keep_current_edges=False, edge_score=PL_MI, node_score=PL_AIC, root_node) -> plFloat
        learn_structure(self, data, use_current_structure_as_starting_point=True, keep_current_edges=False, edge_score=PL_MI, node_score=PL_AIC) -> plFloat
        learn_structure(self, data, use_current_structure_as_starting_point=True, keep_current_edges=False, edge_score=PL_MI) -> plFloat
        learn_structure(self, data, use_current_structure_as_starting_point=True, keep_current_edges=False) -> plFloat
        learn_structure(self, data, use_current_structure_as_starting_point=True) -> plFloat
        learn_structure(self, data) -> plFloat
        learn_structure(self, data, use_current_structure_as_starting_point=True, keep_current_edges=False, edge_score=PL_MI, node_score=PL_AIC, root_node, maxp=10, maxpc=1000, edges_to_exclude) -> plFloat
        learn_structure(self, data, use_current_structure_as_starting_point=True, keep_current_edges=False, edge_score=PL_MI, node_score=PL_AIC, root_node, maxp=10, maxpc=1000) -> plFloat
        learn_structure(self, data, use_current_structure_as_starting_point=True, keep_current_edges=False, edge_score=PL_MI, node_score=PL_AIC, root_node, maxp=10) -> plFloat
        learn_structure(self, data, use_current_structure_as_starting_point=True, keep_current_edges=False, edge_score=PL_MI, node_score=PL_AIC, root_node) -> plFloat
        learn_structure(self, data, use_current_structure_as_starting_point=True, keep_current_edges=False, edge_score=PL_MI, node_score=PL_AIC) -> plFloat
        learn_structure(self, data, use_current_structure_as_starting_point=True, keep_current_edges=False, edge_score=PL_MI) -> plFloat
        learn_structure(self, data, use_current_structure_as_starting_point=True, keep_current_edges=False) -> plFloat
        learn_structure(self, data, use_current_structure_as_starting_point=True) -> plFloat
        learn_structure(self, data) -> plFloat


        `learn_structure(plDataDescriptor &data, bool
            use_current_structure_as_starting_point=true, bool keep_current_edges=false,
            plStructureLearningScore edge_score=PL_MI, plStructureLearningScore
            node_score=PL_AIC, const plVariable &root_node=plVariable(), unsigned int
            maxp=10, unsigned int maxpc=1000, const bn_edge_list_t
            &edges_to_exclude=bn_edge_list_t()) -> plFloat`  
        `learn_structure(const std::vector< plValues > &data, bool
            use_current_structure_as_starting_point=true, bool keep_current_edges=false,
            plStructureLearningScore edge_score=PL_MI, plStructureLearningScore
            node_score=PL_AIC, const plVariable &root_node=plVariable(), unsigned int
            maxp=10, unsigned int maxpc=1000, const bn_edge_list_t
            &edges_to_exclude=bn_edge_list_t()) -> plFloat`  

        Overloaded function
        -------------------
        * `learn_structure(plDataDescriptor &data, bool
            use_current_structure_as_starting_point=true, bool keep_current_edges=false,
            plStructureLearningScore edge_score=PL_MI, plStructureLearningScore
            node_score=PL_AIC, const plVariable &root_node=plVariable(), unsigned int
            maxp=10, unsigned int maxpc=1000, const bn_edge_list_t
            &edges_to_exclude=bn_edge_list_t()) -> plFloat`  

            Learn the structure of the network.  

            It assumes that the nodes (variables) of the net have been already inserted.  

            The learning data is made of observations on the network variables, in a
            data descriptor object (plDataDescriptor) *data_set*.  

            For instance, we can build a network with variables A, B, and C :  

                plVariable a("A", plIntegerType(0, 42));
                plVariable b("B", plIntegerType(-2, 2));
                plVariable c("C", plIntegerType(-1, 1));
                plBayesianNetwork net;
                net.add_node(a);
                net.add_node(b);
                net.add_node(c);

                plCSVDataDescriptor cvs_data("data.csv", a^b^c);
                net.learn_structure(cvs_data);
                std::cout << net << std::endl;  

            Parameters:  
            * `data` :  
                The data source to be used for learning the structure and then the
                parameters  
            * `use_current_structure_as_starting_point` :  
                If 'true', the current structure is used as a starting point  
            * `keep_current_edges` :  
                If 'true', all the current edges will be kept in the final output
                structure  
            * `edge_score` :  
                The edge score to be used for the preliminary Directed Minimum Spanning
                Tree phase. This parameter (and the DMST algorithm) is used only when
                'use_current_structure_as_starting_point=false'  
            * `node_score` :  
                The node score to be used for the final Greedy Search phase.  
            * `root_node` :  
                The root node if any  
            * `maxp` :  
                The maximal number of parents allowed for a given node  
            * `maxpc` :  
                The cardinality (numbers of discrete states) of parents allowed for a
                given node  
            * `edges_to_exclude` :  
                The edges to mandatory exclude in the final output structure  

            Returns:
            the score (node_score) of the output structure on the provided data  

            See also: plDataDescriptor  

        * `learn_structure(const std::vector< plValues > &data, bool
            use_current_structure_as_starting_point=true, bool keep_current_edges=false,
            plStructureLearningScore edge_score=PL_MI, plStructureLearningScore
            node_score=PL_AIC, const plVariable &root_node=plVariable(), unsigned int
            maxp=10, unsigned int maxpc=1000, const bn_edge_list_t
            &edges_to_exclude=bn_edge_list_t()) -> plFloat`  

            Same as above but using a vector af plValues.  

        """
        return _probt_python3.plBayesianNetwork_learn_structure(self, *args)


    def learn_structure_tree_augmented_naive_bayes(self, *args) -> "void":
        """
        learn_structure_tree_augmented_naive_bayes(self, data, class_node, edge_score=PL_AIC, score_threshold=0.0, keep_current_edges=False, edges_to_exclude)
        learn_structure_tree_augmented_naive_bayes(self, data, class_node, edge_score=PL_AIC, score_threshold=0.0, keep_current_edges=False)
        learn_structure_tree_augmented_naive_bayes(self, data, class_node, edge_score=PL_AIC, score_threshold=0.0)
        learn_structure_tree_augmented_naive_bayes(self, data, class_node, edge_score=PL_AIC)
        learn_structure_tree_augmented_naive_bayes(self, data, class_node)
        learn_structure_tree_augmented_naive_bayes(self, data, class_node, edge_score=PL_AIC, score_threshold=0.0, keep_current_edges=False, edges_to_exclude)
        learn_structure_tree_augmented_naive_bayes(self, data, class_node, edge_score=PL_AIC, score_threshold=0.0, keep_current_edges=False)
        learn_structure_tree_augmented_naive_bayes(self, data, class_node, edge_score=PL_AIC, score_threshold=0.0)
        learn_structure_tree_augmented_naive_bayes(self, data, class_node, edge_score=PL_AIC)
        learn_structure_tree_augmented_naive_bayes(self, data, class_node)


        `learn_structure_tree_augmented_naive_bayes(plDataDescriptor &data, const
            plVariable &class_node, plStructureLearningScore edge_score=PL_AIC, plFloat
            score_threshold=PL_ZERO, bool keep_current_edges=false, const bn_edge_list_t
            &edges_to_exclude=bn_edge_list_t())`  
        `learn_structure_tree_augmented_naive_bayes(const std::vector< plValues > &data,
            const plVariable &class_node, plStructureLearningScore edge_score=PL_AIC,
            plFloat score_threshold=PL_ZERO, bool keep_current_edges=false, const
            bn_edge_list_t &edges_to_exclude=bn_edge_list_t())`  

        Overloaded function
        -------------------
        * `learn_structure_tree_augmented_naive_bayes(plDataDescriptor &data, const
            plVariable &class_node, plStructureLearningScore edge_score=PL_AIC, plFloat
            score_threshold=PL_ZERO, bool keep_current_edges=false, const bn_edge_list_t
            &edges_to_exclude=bn_edge_list_t())`  

            Learn the structure of the network as a tree augmented naive bayes (TANB)  

            Parameters:  
            * `data` :  
                The data source to be used for learning the structure and then the
                parameters  
            * `class_node` :  
                The class node  
            * `edge_score` :  
                The edge score to be used for evaluating edges. It will used as
                conditional regarding the class node for evaluating 'non class -> non
                class' edges, and non conditional when evaluating 'class -> non class'
                edges  
            * `score_threshold` :  
                The threshold to be used to decide if a given edge is to be added  
            * `keep_current_edges` :  
                If 'true', all the current edges will be kept in the final output
                structure. It's the responsibility of the caller to check that the
                current edges are compatible with a TANB structure  
            * `edges_to_exclude` :  
                The edges to mandatory exclude in the final output structure  

        * `learn_structure_tree_augmented_naive_bayes(const std::vector< plValues >
            &data, const plVariable &class_node, plStructureLearningScore
            edge_score=PL_AIC, plFloat score_threshold=PL_ZERO, bool
            keep_current_edges=false, const bn_edge_list_t
            &edges_to_exclude=bn_edge_list_t())`  

            Same as above but using a vector af plValues.  

        """
        return _probt_python3.plBayesianNetwork_learn_structure_tree_augmented_naive_bayes(self, *args)


    def learn_structure_TANB(self, *args) -> "void":
        """
        learn_structure_TANB(self, data, class_node, edge_score=PL_AIC, score_threshold=0.0, keep_current_edges=False, edges_to_exclude)
        learn_structure_TANB(self, data, class_node, edge_score=PL_AIC, score_threshold=0.0, keep_current_edges=False)
        learn_structure_TANB(self, data, class_node, edge_score=PL_AIC, score_threshold=0.0)
        learn_structure_TANB(self, data, class_node, edge_score=PL_AIC)
        learn_structure_TANB(self, data, class_node)
        learn_structure_TANB(self, data, class_node, edge_score=PL_AIC, score_threshold=0.0, keep_current_edges=False, edges_to_exclude)
        learn_structure_TANB(self, data, class_node, edge_score=PL_AIC, score_threshold=0.0, keep_current_edges=False)
        learn_structure_TANB(self, data, class_node, edge_score=PL_AIC, score_threshold=0.0)
        learn_structure_TANB(self, data, class_node, edge_score=PL_AIC)
        learn_structure_TANB(self, data, class_node)


        `learn_structure_TANB(plDataDescriptor &data, const plVariable &class_node,
            plStructureLearningScore edge_score=PL_AIC, plFloat score_threshold=PL_ZERO,
            bool keep_current_edges=false, const bn_edge_list_t
            &edges_to_exclude=bn_edge_list_t())`  
        `learn_structure_TANB(const std::vector< plValues > &data, const plVariable
            &class_node, plStructureLearningScore edge_score=PL_AIC, plFloat
            score_threshold=PL_ZERO, bool keep_current_edges=false, const bn_edge_list_t
            &edges_to_exclude=bn_edge_list_t())`  

        Overloaded function
        -------------------
        * `learn_structure_TANB(plDataDescriptor &data, const plVariable &class_node,
            plStructureLearningScore edge_score=PL_AIC, plFloat score_threshold=PL_ZERO,
            bool keep_current_edges=false, const bn_edge_list_t
            &edges_to_exclude=bn_edge_list_t())`  

            Same as learn_structure_tree_augmented_naive_bayes()  

        * `learn_structure_TANB(const std::vector< plValues > &data, const plVariable
            &class_node, plStructureLearningScore edge_score=PL_AIC, plFloat
            score_threshold=PL_ZERO, bool keep_current_edges=false, const bn_edge_list_t
            &edges_to_exclude=bn_edge_list_t())`  

            Same as learn_structure_tree_augmented_naive_bayes()  

        """
        return _probt_python3.plBayesianNetwork_learn_structure_TANB(self, *args)


    def learn_naive_bayes(self, *args) -> "void":
        """
        learn_naive_bayes(self, data, class_node, edge_score=PL_MI, score_threshold)
        learn_naive_bayes(self, data, class_node, edge_score=PL_MI)
        learn_naive_bayes(self, data, class_node)
        learn_naive_bayes(self, data, class_node, edge_score=PL_MI, score_threshold)
        learn_naive_bayes(self, data, class_node, edge_score=PL_MI)
        learn_naive_bayes(self, data, class_node)


        `learn_naive_bayes(plDataDescriptor &data, const plVariable &class_node,
            plStructureLearningScore edge_score=PL_MI, plFloat
            score_threshold=-std::numeric_limits< plFloat >::infinity())`  
        `learn_naive_bayes(const std::vector< plValues > &data, const plVariable
            &class_node, plStructureLearningScore edge_score=PL_MI, plFloat
            score_threshold=-std::numeric_limits< plFloat >::infinity())`  

        Overloaded function
        -------------------
        * `learn_naive_bayes(plDataDescriptor &data, const plVariable &class_node,
            plStructureLearningScore edge_score=PL_MI, plFloat
            score_threshold=-std::numeric_limits< plFloat >::infinity())`  

            Set the structure to naive bayes and learn the parameters using a data set
            while removing the edges having a value for score less than a given
            threshold.  

            Parameters:  
            * `data` :  
                The data source to be used for learning the structure and then the
                parameters  
            * `class_node` :  
                The class node  
            * `edge_score` :  
                The edge score to be used for evaluating the 'class -> non class' edges.
                This parameter is used iff 'score_threshold' below is not -infinity  
            * `score_threshold` :  
                The threshold to be used for removing some 'class -> non class' edges.
                The default value -infinity means that no 'class -> non class' edge will
                be removed  

        * `learn_naive_bayes(const std::vector< plValues > &data, const plVariable
            &class_node, plStructureLearningScore edge_score=PL_MI, plFloat
            score_threshold=-std::numeric_limits< plFloat >::infinity())`  

            Same as above but using a vector af plValues.  

        """
        return _probt_python3.plBayesianNetwork_learn_naive_bayes(self, *args)


    def learn_NB(self, *args) -> "void":
        """
        learn_NB(self, data, class_node, edge_score=PL_MI, score_threshold)
        learn_NB(self, data, class_node, edge_score=PL_MI)
        learn_NB(self, data, class_node)
        learn_NB(self, data, class_node, edge_score=PL_MI, score_threshold)
        learn_NB(self, data, class_node, edge_score=PL_MI)
        learn_NB(self, data, class_node)


        `learn_NB(plDataDescriptor &data, const plVariable &class_node,
            plStructureLearningScore edge_score=PL_MI, plFloat
            score_threshold=-std::numeric_limits< plFloat >::infinity())`  
        `learn_NB(const std::vector< plValues > &data, const plVariable &class_node,
            plStructureLearningScore edge_score=PL_MI, plFloat
            score_threshold=-std::numeric_limits< plFloat >::infinity())`  

        Overloaded function
        -------------------
        * `learn_NB(plDataDescriptor &data, const plVariable &class_node,
            plStructureLearningScore edge_score=PL_MI, plFloat
            score_threshold=-std::numeric_limits< plFloat >::infinity())`  

            Same as learn_naive_bayes()  

        * `learn_NB(const std::vector< plValues > &data, const plVariable &class_node,
            plStructureLearningScore edge_score=PL_MI, plFloat
            score_threshold=-std::numeric_limits< plFloat >::infinity())`  

            Same as learn_naive_bayes()  

        """
        return _probt_python3.plBayesianNetwork_learn_NB(self, *args)


    def get_belief(self, *args) -> "plDistribution const &":
        """
        get_belief(self, node_name) -> plDistribution
        get_belief(self, node_names) -> plDistribution
        get_belief(self, node_name, evidence) -> plDistribution
        get_belief(self, node_names, evidence) -> plDistribution
        get_belief(self, node_conjunction) -> plDistribution
        get_belief(self, node_conjunction, evidence) -> plDistribution


        `get_belief(const std::string &node_name) const -> const plDistribution &`  
        `get_belief(const std::vector< std::string > &node_names) const -> const
            plDistribution &`  
        `get_belief(const std::string &node_name, const plValues &evidence) const ->
            const plDistribution &`  
        `get_belief(const std::vector< std::string > &node_names, const plValues
            &evidence) const -> const plDistribution &`  
        `get_belief(const plVariablesConjunction &node_conjunction) const -> const
            plDistribution &`  
        `get_belief(const plVariablesConjunction &node_conjunction, const plValues
            &evidence) const -> const plDistribution &`  

        Overloaded function
        -------------------
        * `get_belief(const std::string &node_name) const -> const plDistribution &`  

            Return the belief associated to a given node with name *node_name*, knowing
            the currently inserted evidence.  

            Belief is returned as a plDistribution object, that is a non-conditional
            probability distribution whose values can be inspected using
            plDistribution::compute() and plDistribution::tabulate().  

            This belief can also be used as a building block for another
            plJointDistribution or plBayesianNetwork object (using
            plBayesianNetwork::set_distribution()).  

        * `get_belief(const std::vector< std::string > &node_names) const -> const
            plDistribution &`  

            Return the belief associated to a given conjunction of nodes, knowing the
            currently inserted evidence.  

            Belief is returned as a plDistribution object, that is a non-conditional
            probability distribution whose values can be inspected using
            plDistribution::compute() and plDistribution::tabulate().  

            This belief can also be used as a building block for another
            plJointDistribution or plBayesianNetwork object (using
            plBayesianNetwork::set_distribution()).  

        * `get_belief(const std::string &node_name, const plValues &evidence) const ->
            const plDistribution &`  

            Same as above while setting the evidence temporally to *evidence*.  

        * `get_belief(const std::vector< std::string > &node_names, const plValues
            &evidence) const -> const plDistribution &`  

            Same as above while setting the evidence temporally to *evidence*.  

        * `get_belief(const plVariablesConjunction &node_conjunction) const -> const
            plDistribution &`  

            Return the belief associated to a given conjunction of nodes, knowing the
            currently inserted evidence.  

            Belief is returned as a plDistribution object, that is a non-conditional
            probability distribution whose values can be inspected using
            plDistribution::compute() and plDistribution::tabulate().  

            This belief can also be used as a building block for another
            plJointDistribution or plBayesianNetwork object (using
            plBayesianNetwork::set_distribution()).  

        * `get_belief(const plVariablesConjunction &node_conjunction, const plValues
            &evidence) const -> const plDistribution &`  

            Same as above while setting the evidence temporally to *evidence*.  

        """
        return _probt_python3.plBayesianNetwork_get_belief(self, *args)


    def get_belief_expression(self, *args) -> "plDistribution const &":
        """
        get_belief_expression(self, node_name) -> plDistribution
        get_belief_expression(self, node_names) -> plDistribution
        get_belief_expression(self, node_name, evidence) -> plDistribution
        get_belief_expression(self, node_names, evidence) -> plDistribution
        get_belief_expression(self, node_conjunction) -> plDistribution
        get_belief_expression(self, node_conjunction, evidence) -> plDistribution


        `get_belief_expression(const std::string &node_name) const -> const
            plDistribution &`  
        `get_belief_expression(const std::vector< std::string > &node_names) const ->
            const plDistribution &`  
        `get_belief_expression(const std::string &node_name, const plValues &evidence)
            const -> const plDistribution &`  
        `get_belief_expression(const std::vector< std::string > &node_names, const
            plValues &evidence) const -> const plDistribution &`  
        `get_belief_expression(const plVariablesConjunction &node_conjunction) const ->
            const plDistribution &`  
        `get_belief_expression(const plVariablesConjunction &node_conjunction, const
            plValues &evidence) const -> const plDistribution &`  

        Overloaded function
        -------------------
        * `get_belief_expression(const std::string &node_name) const -> const
            plDistribution &`  

            Get the expression corresponding to the belief.  

        * `get_belief_expression(const std::vector< std::string > &node_names) const ->
            const plDistribution &`  

            Get the expression corresponding to the belief.  

        * `get_belief_expression(const std::string &node_name, const plValues &evidence)
            const -> const plDistribution &`  

            Get the expression corresponding to the belief.  

        * `get_belief_expression(const std::vector< std::string > &node_names, const
            plValues &evidence) const -> const plDistribution &`  

            Get the expression corresponding to the belief.  

        * `get_belief_expression(const plVariablesConjunction &node_conjunction) const
            -> const plDistribution &`  

            Get the expression corresponding to the belief.  

        * `get_belief_expression(const plVariablesConjunction &node_conjunction, const
            plValues &evidence) const -> const plDistribution &`  

            Get the expression corresponding to the belief.  

        """
        return _probt_python3.plBayesianNetwork_get_belief_expression(self, *args)


    def get_belief_table(self, *args) -> "std::vector< plProbValue,std::allocator< plProbValue > > const &":
        """
        get_belief_table(self, node_name) -> DoubleVector
        get_belief_table(self, node_name, evidence) -> DoubleVector
        get_belief_table(self, node_conjunction) -> DoubleVector
        get_belief_table(self, node_conjunction, evidence) -> DoubleVector
        get_belief_table(self, node_names) -> DoubleVector
        get_belief_table(self, node_names, evidence) -> DoubleVector


        `get_belief_table(const std::string &node_name) const -> const std::vector<
            plProbValue > &`  
        `get_belief_table(const std::string &node_name, const plValues &evidence) const
            -> const std::vector< plProbValue > &`  
        `get_belief_table(const plVariablesConjunction &node_conjunction) const -> const
            std::vector< plProbValue > &`  
        `get_belief_table(const plVariablesConjunction &node_conjunction, const plValues
            &evidence) const -> const std::vector< plProbValue > &`  
        `get_belief_table(const std::vector< std::string > &node_names) const -> const
            std::vector< plProbValue > &`  
        `get_belief_table(const std::vector< std::string > &node_names, const plValues
            &evidence) const -> const std::vector< plProbValue > &`  

        Overloaded function
        -------------------
        * `get_belief_table(const std::string &node_name) const -> const std::vector<
            plProbValue > &`  

            Returns the belief table associated to a given node with name *node_name*,
            knowing the currently inserted evidence.  

        * `get_belief_table(const std::string &node_name, const plValues &evidence)
            const -> const std::vector< plProbValue > &`  

            Same as above while setting the evidence temporally to *evidence*.  

        * `get_belief_table(const plVariablesConjunction &node_conjunction) const ->
            const std::vector< plProbValue > &`  

            Returns the belief table associated to a given conjunction of nodes, knowing
            the currently inserted evidence.  

        * `get_belief_table(const plVariablesConjunction &node_conjunction, const
            plValues &evidence) const -> const std::vector< plProbValue > &`  

            Same as above while setting the evidence temporally to *evidence*.  

        * `get_belief_table(const std::vector< std::string > &node_names) const -> const
            std::vector< plProbValue > &`  

            Returns the belief table associated to a given node with name *node_name*,
            knowing the currently inserted evidence.  

        * `get_belief_table(const std::vector< std::string > &node_names, const plValues
            &evidence) const -> const std::vector< plProbValue > &`  

            Same as above while setting the evidence temporally to *evidence*.  

        """
        return _probt_python3.plBayesianNetwork_get_belief_table(self, *args)


    def get_joint_distribution(self, *args) -> "plJointDistribution &":
        """
        get_joint_distribution(self) -> plJointDistribution
        get_joint_distribution(self) -> plJointDistribution


        `get_joint_distribution() const -> const plJointDistribution &`  
        `get_joint_distribution() -> plJointDistribution &`  

        Overloaded function
        -------------------
        * `get_joint_distribution() const -> const plJointDistribution &`  

            Returns a const reference plJointDistribution object built from this
            Bayesian network.  

        * `get_joint_distribution() -> plJointDistribution &`  

            Returns a reference plJointDistribution object built from this Bayesian
            network.  

        """
        return _probt_python3.plBayesianNetwork_get_joint_distribution(self, *args)


    def get_junction_tree(self, *args) -> "plJunctionTree &":
        """
        get_junction_tree(self) -> plJunctionTree
        get_junction_tree(self) -> plJunctionTree


        `get_junction_tree() const -> const plJunctionTree &`  
        `get_junction_tree() -> plJunctionTree &`  

        Overloaded function
        -------------------
        * `get_junction_tree() const -> const plJunctionTree &`  

            Returns a const reference plJunctionTree object built from this Bayesian
            network.  

        * `get_junction_tree() -> plJunctionTree &`  

            Returns a reference plJunctionTree object built from this Bayesian network.  

        """
        return _probt_python3.plBayesianNetwork_get_junction_tree(self, *args)


    def save(self, file_name: 'std::string const &') -> "void":
        """
        save(self, file_name)


        `save(const std::string &file_name) const`  

        Saves the BN in a file.  

        """
        return _probt_python3.plBayesianNetwork_save(self, file_name)


    def load(self, file_name: 'std::string const &') -> "void":
        """
        load(self, file_name)


        `load(const std::string &file_name)`  

        Loads the BN from a file.  

        """
        return _probt_python3.plBayesianNetwork_load(self, file_name)


    def name(self) -> "std::string const &":
        """
        name(self) -> std::string const &


        `name() const -> const std::string &`  

        Return BN's name.  

        """
        return _probt_python3.plBayesianNetwork_name(self)


    def set_name(self, name: 'std::string const &') -> "void":
        """
        set_name(self, name)


        `set_name(const std::string &name)`  

        Sets BN's name.  

        """
        return _probt_python3.plBayesianNetwork_set_name(self, name)


    def set_inference_algorithm(self, algo: 'plInferenceAlgorithm') -> "void":
        """
        set_inference_algorithm(self, algo)


        `set_inference_algorithm(plInferenceAlgorithm algo)`  

        Sets the inference algorithm to be used.  

        Possible values are:  

        *   PL_JT for the "Junction Tree" exact inference algorithm,  
        *   PL_SR for the "Successive Restrictions" exact inference algorithm (a
            sophisticated variant of variable elimination) and  
        *   PL_MCMC for Markov Chain Monte Carlo based approximate inference.  
        *   PL_GIBBS for Gibbs sampling based approximate inference.  

        The default initial value is PL_SR.  

        When using PL_SR, the inference parameters could be customized using
        set_inference_optimization_criterion().  

        When using PL_MCMC, the inference parameters could be customized using
        set_mcmc_nsamples()  

        When using PL_GIBBS, the inference parameters could be customized using
        set_gibbs_inference_n_samples(),
        set_gibbs_inference_continuous_belief_fit_gmm_n(), and set_gibbs_burnin_n()  

        """
        return _probt_python3.plBayesianNetwork_set_inference_algorithm(self, algo)


    def get_inference_algorithm(self) -> "plInferenceAlgorithm":
        """
        get_inference_algorithm(self) -> plInferenceAlgorithm


        `get_inference_algorithm() const -> plInferenceAlgorithm`  

        Get the inference algorithm.  

        """
        return _probt_python3.plBayesianNetwork_get_inference_algorithm(self)


    def set_inference_optimization_criterion(self, criterion: 'plOptimizationCriterion') -> "void":
        """
        set_inference_optimization_criterion(self, criterion)


        `set_inference_optimization_criterion(plOptimizationCriterion criterion)`  

        Set/change the optimality criterion when computing inference expressions using
        the Successive Restrictions algorithm (PL_SR).  

        This function has only an effect when using the Successive Restrictions
        algorithm (i.e., when using PL_SR in set_inference_algorithm())  

        The parameter *criterion* should take a value among:  

        1) PL_NO_OPTIMIZATION will not attempt to optimize the expression for any
        particular purpose.  
         2) PL_OPTIMIZE_COMPILATION_TIME will optimize, for a given query P(A | B), the
        expression so that the computation time for the first inference P(A | B = b) is
        minimal.  
         3) PL_OPTIMIZE_UPDATE_TIME will optimize, for a given query P(A | B), the
        expression for repeated inferences P(A | B = b1), P(A | B = b2), , P(A | B =
        bn) (i.e, minimize the computation time needed for updating the query).  
         4) PL_OPTIMIZE_MEMORY_USE will optimize the expression for minimal memory use.  

        """
        return _probt_python3.plBayesianNetwork_set_inference_optimization_criterion(self, criterion)


    def set_mcmc_nsamples(self, mc_nsamples: 'int') -> "void":
        """
        set_mcmc_nsamples(self, mc_nsamples)


        `set_mcmc_nsamples(int mc_nsamples)`  

        Set/change the number of Monte Carlo sample points to be used for approximating
        marginalization (i.e., computation of the sums/integrals) or for compiling a
        distribution.  

        When mc_nsamples is negative, the actual number will be:  

        *   For marginalization: n = -mc_nsamples x free_vars_dim in which free_vars_dim
            is the number of variables on which we will marginalize.  
        *   For compilation: n = -mc_nsamples x distribution_dim in which
            distribution_dim is the dimension of the distribution to be compiled.  

        The default value is -1000  

        """
        return _probt_python3.plBayesianNetwork_set_mcmc_nsamples(self, mc_nsamples)


    def draw_graph(self, *args) -> "void":
        """
        draw_graph(self, file_name, drawing_language)
        draw_graph(self, file_name)


        `draw_graph(const std::string &file_name, plDrawingLanguage
            drawing_language=PL_XFIG_GRAPH) const`  

        Writes the drawing instructions to represent the graph of the net in
        *file_name*.  

        The current implementation allows using xfig and graphviz dot.  

        See also: draw_graph_dot  

        """
        return _probt_python3.plBayesianNetwork_draw_graph(self, *args)


    def draw_graph_dot(self, *args) -> "void":
        """
        draw_graph_dot(self, file_name, dot_node_shape, dot_node_color, dot_node_fill_color, dot_background_color, dot_edge_color, dot_rankdir)
        draw_graph_dot(self, file_name, dot_node_shape, dot_node_color, dot_node_fill_color, dot_background_color, dot_edge_color)
        draw_graph_dot(self, file_name, dot_node_shape, dot_node_color, dot_node_fill_color, dot_background_color)
        draw_graph_dot(self, file_name, dot_node_shape, dot_node_color, dot_node_fill_color)
        draw_graph_dot(self, file_name, dot_node_shape, dot_node_color)
        draw_graph_dot(self, file_name, dot_node_shape)
        draw_graph_dot(self, file_name)


        `draw_graph_dot(const std::string &file_name, const std::string
            &dot_node_shape="ellipse", const std::string &dot_node_color="black",
            const std::string &dot_node_fill_color="lightblue", const std::string
            &dot_background_color="white", const std::string
            &dot_edge_color="black", const std::string &dot_rankdir="TD") const`  
        `draw_graph_dot(std::ostream &out, const std::string &dot_node_shape="", const
            std::string &dot_node_color="", const std::string
            &dot_node_fill_color="", const std::string &dot_background_color="",
            const std::string &dot_edge_color="", const std::string &dot_rankdir="")
            const`  

        Overloaded function
        -------------------
        * `draw_graph_dot(const std::string &file_name, const std::string
            &dot_node_shape="ellipse", const std::string &dot_node_color="black",
            const std::string &dot_node_fill_color="lightblue", const std::string
            &dot_background_color="white", const std::string
            &dot_edge_color="black", const std::string &dot_rankdir="TD") const`  

            Writes the graphviz dot drawing instructions to represent the graph of the
            net in *file_name*.  

            The parameters dot_node_shape, dot_node_color, dot_node_fill_color,
            dot_background_color, and dot_rankdir correspond to graphviz dot ones (see
            http://www.graphviz.org/pdf/dotguide.pdf). There values will be inserted in
            the generated dot file without checking their validity.  

            To generate an image file from the generated graphvis dot *file_name*, you
            can use "dot -T'img_format' 'file_name' -o file_name.'img_format' " in
            which 'img_format' could be "pdf", "png",... The supported image formats
            could be found in http://www.graphviz.org/pdf/dotguide.pdf  

        * `draw_graph_dot(std::ostream &out, const std::string &dot_node_shape="",
            const std::string &dot_node_color="", const std::string
            &dot_node_fill_color="", const std::string &dot_background_color="",
            const std::string &dot_edge_color="", const std::string &dot_rankdir="")
            const`  

            Same as draw_graph_dot(const std::string &file_name, ...) above but uses a
            stream instead of a file.  

        """
        return _probt_python3.plBayesianNetwork_draw_graph_dot(self, *args)


    def as_graph_dot(self, *args) -> "std::string":
        """
        as_graph_dot(self, dot_node_shape, dot_node_color, dot_node_fill_color, dot_background_color, dot_edge_color, dot_rankdir) -> std::string
        as_graph_dot(self, dot_node_shape, dot_node_color, dot_node_fill_color, dot_background_color, dot_edge_color) -> std::string
        as_graph_dot(self, dot_node_shape, dot_node_color, dot_node_fill_color, dot_background_color) -> std::string
        as_graph_dot(self, dot_node_shape, dot_node_color, dot_node_fill_color) -> std::string
        as_graph_dot(self, dot_node_shape, dot_node_color) -> std::string
        as_graph_dot(self, dot_node_shape) -> std::string
        as_graph_dot(self) -> std::string


        `as_graph_dot(const std::string &dot_node_shape="ellipse", const std::string
            &dot_node_color="black", const std::string
            &dot_node_fill_color="lightblue", const std::string
            &dot_background_color="white", const std::string
            &dot_edge_color="black", const std::string &dot_rankdir="TD") const ->
            std::string`  

        Same as above but the dot code is returned as a string.  

        """
        return _probt_python3.plBayesianNetwork_as_graph_dot(self, *args)


    def python_draw_graph(self) -> "void":
        """
        python_draw_graph(self)


        `python_draw_graph()`  

        Only for Python: Same as draw_graph_dot() above.  

        """
        return _probt_python3.plBayesianNetwork_python_draw_graph(self)


    def sample(self, *args) -> "std::vector< plValues,std::allocator< plValues > >":
        """
        sample(self, file, nsamples, missing_probabilities)
        sample(self, file, nsamples)
        sample(self, nsamples, missing_probabilities) -> plValuesVector
        sample(self, nsamples) -> plValuesVector


        `sample(const std::string &file, unsigned int nsamples, const std::vector<
            plProbValue > &missing_probabilities=std::vector< plProbValue >()) const`  
        `sample(std::ostream &os, unsigned int nsamples, const std::vector< plProbValue
            > &missing_probabilities=std::vector< plProbValue >()) const`  
        `sample(unsigned int nsamples, const std::vector< plProbValue >
            &missing_probabilities=std::vector< plProbValue >()) const -> std::vector<
            plValues >`  

        Overloaded function
        -------------------
        * `sample(const std::string &file, unsigned int nsamples, const std::vector<
            plProbValue > &missing_probabilities=std::vector< plProbValue >()) const`  

            Generate *nsamples* data samples in a CSV output file *file* according to
            the model defined by the net.  

            This uses forward sampling and does not take into account evidence that may
            have been inserted. Use gibbs_samples() if you want to take into account the
            inserted evidence.  

            Simulating missing values is possible by providing the missing probability
            for each variable in the vector *missing_probabilities*.  

            The generated CSV file will be structured as follows:  

            *   its first line (the header) gives the names of the variables (nodes)  
            *   each of the following lines gives the values of the variables for a
                given data instance  
            *   a value can be left empty to signify that it is missing.  

            See also: gibbs_samples()  

        * `sample(std::ostream &os, unsigned int nsamples, const std::vector<
            plProbValue > &missing_probabilities=std::vector< plProbValue >()) const`  

            Same as above but uses an ostream instead of a file name.  

        * `sample(unsigned int nsamples, const std::vector< plProbValue >
            &missing_probabilities=std::vector< plProbValue >()) const -> std::vector<
            plValues >`  

            Return *nsamples* data samples according to the model defined by the net.  

            This uses forward sampling and does not take into account evidence that may
            have been inserted. Use gibbs_samples() if you want to take into account the
            inserted evidence.  

            See also: gibbs_samples()  

        """
        return _probt_python3.plBayesianNetwork_sample(self, *args)


    def gibbs_sample(self, *args) -> "plValues":
        """
        gibbs_sample(self, period=1, evidence) -> plValues
        gibbs_sample(self, period=1) -> plValues
        gibbs_sample(self) -> plValues


        `gibbs_sample(unsigned int period=1, const plValues &evidence=plValues()) const
            -> plValues`  

        Run Gibbs sampling for *period* steps and return the last state.  

        The difference with sample() above is that the current evidence is taken into
        account  

        See also: sample()  

        See also: gibbs_samples()  

        """
        return _probt_python3.plBayesianNetwork_gibbs_sample(self, *args)


    def gibbs_samples(self, *args) -> "std::vector< plValues,std::allocator< plValues > >":
        """
        gibbs_samples(self, nsamples, evidence, init_gibbs_state, period=0) -> plValuesVector
        gibbs_samples(self, nsamples, evidence, init_gibbs_state) -> plValuesVector
        gibbs_samples(self, nsamples, evidence) -> plValuesVector
        gibbs_samples(self, nsamples) -> plValuesVector


        `gibbs_samples(unsigned int nsamples, const plValues &evidence=plValues(), const
            plValues &init_gibbs_state=plValues(), unsigned int period=0) const ->
            std::vector< plValues >`  

        Run Gibbs sampling to get *nsamples* samples starting from the initial state
        *init_gibbs_state* (when provided).  

        For each sample, the sampler is run for a *period* steps (if 0,
        get_gibbs_period_n() is used) and return the last state  

        See also: sample()  

        """
        return _probt_python3.plBayesianNetwork_gibbs_samples(self, *args)


    def exists_node(self, *args) -> "bool":
        """
        exists_node(self, node) -> bool
        exists_node(self, name) -> bool


        `exists_node(const plVariable &node) const -> bool`  
        `exists_node(const std::string &name) const -> bool`  

        Overloaded function
        -------------------
        * `exists_node(const plVariable &node) const -> bool`  

            Return *true* iff the node exists.  

        * `exists_node(const std::string &name) const -> bool`  

            Return *true* iff a node with name *name* exists.  

        """
        return _probt_python3.plBayesianNetwork_exists_node(self, *args)


    def node_parents(self, *args) -> "plVariablesConjunction":
        """
        node_parents(self, node) -> plVariablesConjunction
        node_parents(self, name) -> plVariablesConjunction


        `node_parents(const plVariable &node) const -> plVariablesConjunction`  
        `node_parents(const std::string &name) const -> plVariablesConjunction`  

        Overloaded function
        -------------------
        * `node_parents(const plVariable &node) const -> plVariablesConjunction`  

            Return node's parents.  

        * `node_parents(const std::string &name) const -> plVariablesConjunction`  

            Return the parents of the node having the name *name*.  

        """
        return _probt_python3.plBayesianNetwork_node_parents(self, *args)


    def node_children(self, *args) -> "plVariablesConjunction":
        """
        node_children(self, node) -> plVariablesConjunction
        node_children(self, name) -> plVariablesConjunction


        `node_children(const plVariable &node) const -> plVariablesConjunction`  
        `node_children(const std::string &name) const -> plVariablesConjunction`  

        Overloaded function
        -------------------
        * `node_children(const plVariable &node) const -> plVariablesConjunction`  

            Return node's children.  

        * `node_children(const std::string &name) const -> plVariablesConjunction`  

            Return the children of the node having the name *name*.  

        """
        return _probt_python3.plBayesianNetwork_node_children(self, *args)


    def apply_prediction(self, *args) -> "std::vector< plValues,std::allocator< plValues > >":
        """
        apply_prediction(self, target_variables, data, output_file, classif_prob_thresholds, nrows)
        apply_prediction(self, target_variables, data, output_file, classif_prob_thresholds)
        apply_prediction(self, target_variables, data, output_file)
        apply_prediction(self, target_variables, data, output_file, classif_prob_thresholds)
        apply_prediction(self, target_variables, data, output_file)
        apply_prediction(self, target_variables, data, classif_prob_thresholds, nrows) -> plValuesVector
        apply_prediction(self, target_variables, data, classif_prob_thresholds) -> plValuesVector
        apply_prediction(self, target_variables, data) -> plValuesVector
        apply_prediction(self, target_variables, data, classif_prob_thresholds) -> plValuesVector
        apply_prediction(self, target_variables, data) -> plValuesVector


        `apply_prediction(const plVariablesConjunction &target_variables,
            plDataDescriptor &data, const std::string &output_file, const std::vector<
            plProbValue > &classif_prob_thresholds=std::vector< plProbValue >(),
            unsigned int nrows=std::numeric_limits< unsigned int >::max()) const`  
        `apply_prediction(const plVariablesConjunction &target_variables, const
            std::vector< plValues > &data, const std::string &output_file, const
            std::vector< plProbValue > &classif_prob_thresholds=std::vector< plProbValue
            >()) const`  
        `apply_prediction(const plVariablesConjunction &target_variables,
            plDataDescriptor &data, const std::vector< plProbValue >
            &classif_prob_thresholds=std::vector< plProbValue >(), unsigned int
            nrows=std::numeric_limits< unsigned int >::max()) const -> std::vector<
            plValues >`  
        `apply_prediction(const plVariablesConjunction &target_variables, const
            std::vector< plValues > &data, const std::vector< plProbValue >
            &classif_prob_thresholds=std::vector< plProbValue >()) const -> std::vector<
            plValues >`  

        Overloaded function
        -------------------
        * `apply_prediction(const plVariablesConjunction &target_variables,
            plDataDescriptor &data, const std::string &output_file, const std::vector<
            plProbValue > &classif_prob_thresholds=std::vector< plProbValue >(),
            unsigned int nrows=std::numeric_limits< unsigned int >::max()) const`  

            Ask a query to the BN and apply it to a data set.  

            Parameters:  
            * `target_variables` :  
                The target variables to predict  
            * `data` :  
                The input data set to be used for prediction  
            * `output_file` :  
                The output file. It will include the columns (variables) of the input
                data set with additional columns corresponding the predicted target
                variables and the corresponding distribution table  
            * `classif_prob_thresholds` :  
                The probability thresholds to be applied for classification  
            * `nrows` :  
                The number of data rows to be used for this prediction (starting from
                the current position in the input data source)  

            See also: prediction()  

        * `apply_prediction(const plVariablesConjunction &target_variables, const
            std::vector< plValues > &data, const std::string &output_file, const
            std::vector< plProbValue > &classif_prob_thresholds=std::vector< plProbValue
            >()) const`  

            Same as above but using a vector of plValues.  

        * `apply_prediction(const plVariablesConjunction &target_variables,
            plDataDescriptor &data, const std::vector< plProbValue >
            &classif_prob_thresholds=std::vector< plProbValue >(), unsigned int
            nrows=std::numeric_limits< unsigned int >::max()) const -> std::vector<
            plValues >`  

            Ask a query to the BN and apply it to a data set.  

            Parameters:  
            * `target_variables` :  
                The target variables to predict  
            * `data` :  
                The input data set to be used for prediction  
            * `classif_prob_thresholds` :  
                The probability thresholds to be applied for classification  
            * `nrows` :  
                The number of data rows to be used for this prediction (starting from
                the current position in the input data source)  

            Returns:
            for each data record, the value of *target_variables* that maximises the
            probability given the evidence provided by the data row P(target_variables |
            row_evidence). This value could be void (empty plValues) if no prediction is
            provided (when using classif_prob_threshold).  

            See also: prediction()  

            See also: plCndDistribution::apply_prediction()  

        * `apply_prediction(const plVariablesConjunction &target_variables, const
            std::vector< plValues > &data, const std::vector< plProbValue >
            &classif_prob_thresholds=std::vector< plProbValue >()) const -> std::vector<
            plValues >`  

            Same as above but using a vector of plValues.  

        """
        return _probt_python3.plBayesianNetwork_apply_prediction(self, *args)


    def apply_classification_proba(self, *args) -> "std::vector< std::vector< plProbValue,std::allocator< plProbValue > >,std::allocator< std::vector< plProbValue,std::allocator< plProbValue > > > >":
        """
        apply_classification_proba(self, target_variables, data, nrows) -> DoubleVectorVector
        apply_classification_proba(self, target_variables, data) -> DoubleVectorVector
        apply_classification_proba(self, target_variables, data) -> DoubleVectorVector


        `apply_classification_proba(const plVariablesConjunction &target_variables,
            plDataDescriptor &data, unsigned int nrows=std::numeric_limits< unsigned int
            >::max()) const -> std::vector< std::vector< plProbValue > >`  
        `apply_classification_proba(const plVariablesConjunction &target_variables,
            const std::vector< plValues > &data) const -> std::vector< std::vector<
            plProbValue > >`  

        Overloaded function
        -------------------
        * `apply_classification_proba(const plVariablesConjunction &target_variables,
            plDataDescriptor &data, unsigned int nrows=std::numeric_limits< unsigned int
            >::max()) const -> std::vector< std::vector< plProbValue > >`  

            Same as apply_prediction() returning std::vector<plValues> but returning the
            classification probabilities for each data row.  

            See also: prediction()  

            See also: apply_prediction()  

            See also: plCndDistribution::apply_prediction()  

        * `apply_classification_proba(const plVariablesConjunction &target_variables,
            const std::vector< plValues > &data) const -> std::vector< std::vector<
            plProbValue > >`  

            Same as above but using a vector of plValues.  

        """
        return _probt_python3.plBayesianNetwork_apply_classification_proba(self, *args)


    def prediction(self, *args) -> "plValues":
        """
        prediction(self, target_variables, evidence, prob_thresholds) -> plValues
        prediction(self, target_variables, evidence) -> plValues


        `prediction(const plVariablesConjunction &target_variables, const plValues
            &evidence, const std::vector< plProbValue > &prob_thresholds=std::vector<
            plProbValue >()) const -> plValues`  

        Return the value of *target_variables* that maximises the probability given the
        evidence *evidence* P(target_variables | evidence).  

        Equivalent to:  

            plBayesianNetwork net(...);
            .
            .
            .
            net.set_evidence(evidence.remove(target_variables));
            plValues result = net.get_belief(target_variables).best();


        """
        return _probt_python3.plBayesianNetwork_prediction(self, *args)


    def validate_prediction(self, *args) -> "plPredictionPerformanceReport":
        """
        validate_prediction(self, target_variables, data, classif_prob_thresholds, output_file, nrows) -> plPredictionPerformanceReport
        validate_prediction(self, target_variables, data, classif_prob_thresholds, output_file) -> plPredictionPerformanceReport
        validate_prediction(self, target_variables, data, classif_prob_thresholds) -> plPredictionPerformanceReport
        validate_prediction(self, target_variables, data) -> plPredictionPerformanceReport
        validate_prediction(self, target_variables, data, classif_prob_thresholds, output_file) -> plPredictionPerformanceReport
        validate_prediction(self, target_variables, data, classif_prob_thresholds) -> plPredictionPerformanceReport
        validate_prediction(self, target_variables, data) -> plPredictionPerformanceReport


        `validate_prediction(const plVariablesConjunction &target_variables,
            plDataDescriptor &data, const std::vector< plProbValue >
            &classif_prob_thresholds=std::vector< plProbValue >(), const std::string
            &output_file="", unsigned int nrows=std::numeric_limits< unsigned int
            >::max()) const -> plPredictionPerformanceReport`  
        `validate_prediction(const plVariablesConjunction &target_variables, const
            std::vector< plValues > &data, const std::vector< plProbValue >
            &classif_prob_thresholds=std::vector< plProbValue >(), const std::string
            &output_file="") const -> plPredictionPerformanceReport`  

        Overloaded function
        -------------------
        * `validate_prediction(const plVariablesConjunction &target_variables,
            plDataDescriptor &data, const std::vector< plProbValue >
            &classif_prob_thresholds=std::vector< plProbValue >(), const std::string
            &output_file="", unsigned int nrows=std::numeric_limits< unsigned int
            >::max()) const -> plPredictionPerformanceReport`  

            Ask a query to the model, apply it to a data set, and provide validation
            statistics.  

            Parameters:  
            * `target_variables` :  
                The target variables to predict  
            * `data` :  
                The input data set to be used for validation  
            * `classif_prob_thresholds` :  
                The probability thresholds to be applied for classification  
            * `output_file` :  
                The output file. It will include the columns (variables) of the input
                data set with additional columns corresponding the predicted target
                variables and the corresponding distribution table  
            * `nrows` :  
                The number of data rows to be used for this validation (starting from
                the current position in the input data source)  

            Returns:
            The validation results  

            See also: plCndDistribution::validate_prediction()  

        * `validate_prediction(const plVariablesConjunction &target_variables, const
            std::vector< plValues > &data, const std::vector< plProbValue >
            &classif_prob_thresholds=std::vector< plProbValue >(), const std::string
            &output_file="") const -> plPredictionPerformanceReport`  

            Same as above but using a vector of plValues.  

        """
        return _probt_python3.plBayesianNetwork_validate_prediction(self, *args)


    def get_markov_blanket(self, *args) -> "plVariablesConjunction":
        """
        get_markov_blanket(self, node) -> plVariablesConjunction
        get_markov_blanket(self, node_name) -> plVariablesConjunction


        `get_markov_blanket(const plVariable &node) const -> plVariablesConjunction`  
        `get_markov_blanket(const std::string &node_name) const ->
            plVariablesConjunction`  

        Overloaded function
        -------------------
        * `get_markov_blanket(const plVariable &node) const -> plVariablesConjunction`  

            Return Markov blanket for a given node.  

        * `get_markov_blanket(const std::string &node_name) const ->
            plVariablesConjunction`  

            Return Markov blanket for a given node.  

        """
        return _probt_python3.plBayesianNetwork_get_markov_blanket(self, *args)


    def set_verbose_structure_learning(self, verbose: 'bool'=True) -> "void":
        """
        set_verbose_structure_learning(self, verbose=True)
        set_verbose_structure_learning(self)


        `set_verbose_structure_learning(bool verbose=true)`  

        Set/unset verbose mode for structure learning.  

        If true, the structure learning algorithms will display intermediate results  

        """
        return _probt_python3.plBayesianNetwork_set_verbose_structure_learning(self, verbose)


    def set_verbose_em_learning(self, verbose: 'bool'=True) -> "void":
        """
        set_verbose_em_learning(self, verbose=True)
        set_verbose_em_learning(self)


        `set_verbose_em_learning(bool verbose=true)`  

        Set/unset verbose mode for parameter learning using EM.  

        If true, the parameter learning algorithm will display intermediate results  

        """
        return _probt_python3.plBayesianNetwork_set_verbose_em_learning(self, verbose)


    def set_compiled_belief_distribution(self, compile_it: 'bool') -> "void":
        """
        set_compiled_belief_distribution(self, compile_it)


        `set_compiled_belief_distribution(bool compile_it)`  

        If set to 'true' (the default value), the distributions returned by get_belief()
        are compiled.  

        Set it to 'false' if you do not need compiled distributions  

        """
        return _probt_python3.plBayesianNetwork_set_compiled_belief_distribution(self, compile_it)


    def compute_data_record_log_likelihood(self, data_record: 'plValues') -> "plFloat":
        """
        compute_data_record_log_likelihood(self, data_record) -> plFloat


        `compute_data_record_log_likelihood(const plValues &data_record) const ->
            plFloat`  

        Compute the log-likelihood of a given record.  

        """
        return _probt_python3.plBayesianNetwork_compute_data_record_log_likelihood(self, data_record)


    def compute_data_set_log_likelihood(self, *args) -> "plFloat":
        """
        compute_data_set_log_likelihood(self, data_set, nrows) -> plFloat
        compute_data_set_log_likelihood(self, data_set) -> plFloat
        compute_data_set_log_likelihood(self, data_records) -> plFloat


        `compute_data_set_log_likelihood(plDataDescriptor &data_set, unsigned int
            nrows=std::numeric_limits< unsigned int >::max()) const -> plFloat`  
        `compute_data_set_log_likelihood(const std::vector< plValues > &data_records)
            const -> plFloat`  

        Overloaded function
        -------------------
        * `compute_data_set_log_likelihood(plDataDescriptor &data_set, unsigned int
            nrows=std::numeric_limits< unsigned int >::max()) const -> plFloat`  

            Compute the log-likelihood of a given data set.  

            Parameters:  
            * `data_set` :  
                the data set for which the log-likelihood will be computed  
            * `nrows` :  
                The number of data rows to be used (starting from the current position
                in the input data source)  

            Returns:
            log-likelihood of the data set  

        * `compute_data_set_log_likelihood(const std::vector< plValues > &data_records)
            const -> plFloat`  

            Compute the log-likelihood of a given vector of data records.  

            Parameters:  
            * `data_records` :  
                the vector of data records for which the log-likelihood will be computed  

            Returns:
            log-likelihood of the data set  

        """
        return _probt_python3.plBayesianNetwork_compute_data_set_log_likelihood(self, *args)


    def get_node_distribution(self, *args) -> "plComputableObject":
        """
        get_node_distribution(self, node) -> plComputableObject
        get_node_distribution(self, node_name) -> plComputableObject


        `get_node_distribution(const plVariable &node) const -> plComputableObject`  
        `get_node_distribution(const std::string &node_name) const ->
            plComputableObject`  

        Overloaded function
        -------------------
        * `get_node_distribution(const plVariable &node) const -> plComputableObject`  

            Get the input distribution over the node *node*.  

        * `get_node_distribution(const std::string &node_name) const ->
            plComputableObject`  

            Get the input distribution over the node *node*.  

        """
        return _probt_python3.plBayesianNetwork_get_node_distribution(self, *args)


    def get_node_learnable_distribution(self, *args) -> "plLearnObject const &":
        """
        get_node_learnable_distribution(self, node) -> plLearnObject
        get_node_learnable_distribution(self, node_name) -> plLearnObject


        `get_node_learnable_distribution(const plVariable &node) const -> const
            plLearnObject &`  
        `get_node_learnable_distribution(const std::string &node_name) const -> const
            plLearnObject &`  

        Overloaded function
        -------------------
        * `get_node_learnable_distribution(const plVariable &node) const -> const
            plLearnObject &`  

            Get the input learnable distribution over the node *node*.  

        * `get_node_learnable_distribution(const std::string &node_name) const -> const
            plLearnObject &`  

            Get the input learnable distribution over the node *node*.  

        """
        return _probt_python3.plBayesianNetwork_get_node_learnable_distribution(self, *args)


    def add_time_transition_edge(self, *args) -> "void":
        """
        add_time_transition_edge(self, node_prec_timeslice, node_current_timeslice)
        add_time_transition_edge(self, node_prec_timeslice_name, node_current_timeslice_name)


        `add_time_transition_edge(const plVariable &node_prec_timeslice, const
            plVariable &node_current_timeslice)`  
        `add_time_transition_edge(const std::string &node_prec_timeslice_name, const
            std::string &node_current_timeslice_name)`  

        Overloaded function
        -------------------
        * `add_time_transition_edge(const plVariable &node_prec_timeslice, const
            plVariable &node_current_timeslice)`  

            Add a time-transition edge.  

            For example, to add a time transition edge \[ P(X_{t} | X_{t-1} ) \], one
            can write:  

                plBayesianNetwork bn;
                const plVariable x("X", PL_BINARY_TYPE);
                const plVariable x_("X_", PL_BINARY_TYPE);

                bn.add_node(x);
                bn.add_node(x_);

                bn.add_time_transition_edge( x_, x );


        * `add_time_transition_edge(const std::string &node_prec_timeslice_name, const
            std::string &node_current_timeslice_name)`  

            Same as above but the nodes are referenced by their names.  

        """
        return _probt_python3.plBayesianNetwork_add_time_transition_edge(self, *args)


    def set_time_transition_distribution(self, transition: 'plCndDistribution') -> "void":
        """
        set_time_transition_distribution(self, transition)


        `set_time_transition_distribution(const plCndDistribution &transition)`  

        Set a time-transition edge.  

        For example, to set a time-transition distribution \[ P(X_{t} | X_{t-1} ) \],
        one can write:  

            plBayesianNetwork bn;
            const plVariable x("X", PL_BINARY_TYPE);
            const plVariable x_("X_", PL_BINARY_TYPE);

            bn.add_node(x);
            bn.add_node(x_);

            const plCndDistribution transition( x, x_);

            bn.set_time_transition_distribution( transition );  

        See also: next_time_slice()  

        """
        return _probt_python3.plBayesianNetwork_set_time_transition_distribution(self, transition)


    def set_time_transition_learnable_distribution(self, learnable_transition: 'plLearnObject') -> "void":
        """
        set_time_transition_learnable_distribution(self, learnable_transition)


        `set_time_transition_learnable_distribution(const plLearnObject
            &learnable_transition)`  

        Set a time-transition learnable distribution.  

        For example, to set a learnable time transition distribution \[ P(X_{t} |
        X_{t-1} ) \], one can write:  

            plBayesianNetwork bn;
            const plVariable x("X", PL_BINARY_TYPE);
            const plVariable x_("X_", PL_BINARY_TYPE);

            bn.add_node(x);
            bn.add_node(x_);

            plCndLearnObject<plLearnHistogram> learnable_transition( x, x_);

            bn.set_time_transition_learnable_distribution( learnable_transition );  

        See also: next_time_slice()  

        """
        return _probt_python3.plBayesianNetwork_set_time_transition_learnable_distribution(self, learnable_transition)


    def next_time_slice(self, *args) -> "void":
        """
        next_time_slice(self)
        next_time_slice(self, evidence)


        `next_time_slice()`  
        `next_time_slice(const plValues &evidence)`  

        Overloaded function
        -------------------
        * `next_time_slice()`  

            Update all the time-slice distributions if the BN is dynamic.  

            A typical use is as follows:  

                plBayesianNetwork bn;
                const plVariable x("X", PL_BINARY_TYPE);
                const plVariable x_("X_", PL_BINARY_TYPE);
                const plVariable o("O", plRealType(-100000., 100000.));

                bn.add_node(x);
                bn.add_node(x_);
                bn.add_node(o);

                const plCndDistribution transition( x, x_);

                bn.set_time_transition_distribution( transition );

                // Dynamic BN joint distribution: P( X X_ O) = P(X_) P(X | X_) P(O | X)

                plValues observation(o);

                for(unsigned int i = 0; i < 5; ++i) {
                  observation[o] = -10. + plRandom::uniform_float(10.);
                  bn.set_evidence(observation);
                  std::cout << bn << std::endl;
                  bn.next_time_slice();
                }


        * `next_time_slice(const plValues &evidence)`  

            Same as above while setting the evidence temporally to *evidence*.  

        """
        return _probt_python3.plBayesianNetwork_next_time_slice(self, *args)


    def get_time_slice_edges(self) -> "plBayesianNetwork::bn_edge_list_t":
        """
        get_time_slice_edges(self) -> plBnEdgeList


        `get_time_slice_edges() const -> bn_edge_list_t`  

        Get the time-slice edges as pairs of (var_{t-1}, (var_{t}).  

        """
        return _probt_python3.plBayesianNetwork_get_time_slice_edges(self)


    def set_query_cache_max_size(self, new_size: 'unsigned int') -> "void":
        """
        set_query_cache_max_size(self, new_size)


        `set_query_cache_max_size(unsigned int new_size)`  

        Set the maximum number of the cached target distributions.  

        The default value is 10.  

        """
        return _probt_python3.plBayesianNetwork_set_query_cache_max_size(self, new_size)


    def set_soft_evidence(self, soft_evidence: 'plDistribution') -> "void":
        """
        set_soft_evidence(self, soft_evidence)


        `set_soft_evidence(const plDistribution &soft_evidence)`  

        Set a soft evidence.  

        """
        return _probt_python3.plBayesianNetwork_set_soft_evidence(self, soft_evidence)


    def clear_soft_evidences(self) -> "void":
        """
        clear_soft_evidences(self)


        `clear_soft_evidences()`  

        Clear all soft evidences.  

        """
        return _probt_python3.plBayesianNetwork_clear_soft_evidences(self)


    def set_em_convergence_threshold(self, em_convergence_threshold: 'plFloat') -> "void":
        """
        set_em_convergence_threshold(self, em_convergence_threshold)


        `set_em_convergence_threshold(plFloat em_convergence_threshold)`  

        Set the convergence threshold for the EM algorithm (parameter learning).  

        The provided threshold represents the relative log-likelihood change between two
        successive EM iterations (smaller value means more iterations). The default
        value is set to 0.0001  

        """
        return _probt_python3.plBayesianNetwork_set_em_convergence_threshold(self, em_convergence_threshold)


    def is_hard_evidence_variable(self, vars: 'plVariablesConjunction') -> "bool":
        """
        is_hard_evidence_variable(self, vars) -> bool


        `is_hard_evidence_variable(const plVariablesConjunction &vars) const -> bool`  

        Test if a variable is a hard evidence one.  

        """
        return _probt_python3.plBayesianNetwork_is_hard_evidence_variable(self, vars)


    def is_soft_evidence_variable(self, vars: 'plVariablesConjunction') -> "bool":
        """
        is_soft_evidence_variable(self, vars) -> bool


        `is_soft_evidence_variable(const plVariablesConjunction &vars) const -> bool`  

        Test if a variable is a soft evidence one.  

        """
        return _probt_python3.plBayesianNetwork_is_soft_evidence_variable(self, vars)


    def get_gibbs_inference_n_samples(self) -> "unsigned int":
        """
        get_gibbs_inference_n_samples(self) -> unsigned int


        `get_gibbs_inference_n_samples() const -> unsigned int`  

        Get the number of Gibbs samples when using PL_GIBBS inference.  

        """
        return _probt_python3.plBayesianNetwork_get_gibbs_inference_n_samples(self)


    def set_gibbs_inference_n_samples(self, nsamples: 'unsigned int') -> "void":
        """
        set_gibbs_inference_n_samples(self, nsamples)


        `set_gibbs_inference_n_samples(unsigned int nsamples)`  

        Set/change the number of Gibbs samples when using PL_GIBBS inference.  

        """
        return _probt_python3.plBayesianNetwork_set_gibbs_inference_n_samples(self, nsamples)


    def get_gibbs_inference_continuous_belief_fit_gmm_n(self) -> "std::vector< unsigned int,std::allocator< unsigned int > >":
        """
        get_gibbs_inference_continuous_belief_fit_gmm_n(self) -> UnsignedIntVector


        `get_gibbs_inference_continuous_belief_fit_gmm_n() const -> std::vector<
            unsigned int >`  

        Get the number of Gaussians to be used for fitting continuous belief when using
        PL_GIBBS inference.  

        """
        return _probt_python3.plBayesianNetwork_get_gibbs_inference_continuous_belief_fit_gmm_n(self)


    def set_gibbs_inference_continuous_belief_fit_gmm_n(self, nmixtures: 'UnsignedIntVector') -> "void":
        """
        set_gibbs_inference_continuous_belief_fit_gmm_n(self, nmixtures)


        `set_gibbs_inference_continuous_belief_fit_gmm_n(const std::vector< unsigned int
            > &nmixtures)`  

        Set/change the number of Gaussians to be used for fitting continuous belief when
        using PL_GIBBS inference.  

        The actual number of Gaussians will be selected according to the BIC score  

        """
        return _probt_python3.plBayesianNetwork_set_gibbs_inference_continuous_belief_fit_gmm_n(self, nmixtures)


    def set_gibbs_inference_init_state(self, init_state: 'plValues') -> "void":
        """
        set_gibbs_inference_init_state(self, init_state)


        `set_gibbs_inference_init_state(const plValues &init_state)`  

        Set/change the initial state to be used when using PL_GIBBS inference.  

        """
        return _probt_python3.plBayesianNetwork_set_gibbs_inference_init_state(self, init_state)


    def set_gibbs_burnin_n(self, n: 'unsigned int') -> "void":
        """
        set_gibbs_burnin_n(self, n)


        `set_gibbs_burnin_n(unsigned int n)`  

        Set/change the number of burnin steps to be used for GIBBS sampling.  

        """
        return _probt_python3.plBayesianNetwork_set_gibbs_burnin_n(self, n)


    def get_gibbs_burnin_n(self) -> "unsigned int":
        """
        get_gibbs_burnin_n(self) -> unsigned int


        `get_gibbs_burnin_n() const -> unsigned int`  

        Get the number of burnin steps to be used for GIBBS sampling.  

        """
        return _probt_python3.plBayesianNetwork_get_gibbs_burnin_n(self)


    def set_gibbs_period_n(self, n: 'unsigned int') -> "void":
        """
        set_gibbs_period_n(self, n)


        `set_gibbs_period_n(unsigned int n)`  

        Set/change the number of samples to ignore before returnig a state for GIBBS
        sampling.  

        """
        return _probt_python3.plBayesianNetwork_set_gibbs_period_n(self, n)


    def get_gibbs_period_n(self) -> "unsigned int":
        """
        get_gibbs_period_n(self) -> unsigned int


        `get_gibbs_period_n() const -> unsigned int`  

        Get the number of ignored before returnig a state for GIBBS sampling.  

        """
        return _probt_python3.plBayesianNetwork_get_gibbs_period_n(self)


    def get_continuous_node_n_mixtures(self) -> "std::vector< unsigned int,std::allocator< unsigned int > > const &":
        """
        get_continuous_node_n_mixtures(self) -> UnsignedIntVector


        `get_continuous_node_n_mixtures() const -> const std::vector< unsigned > &`  

        Get the candidate number of mixtures to be used for continuous nodes.  

        """
        return _probt_python3.plBayesianNetwork_get_continuous_node_n_mixtures(self)


    def set_continuous_node_n_mixtures(self, continuous_node_n_mixtures: 'UnsignedIntVector') -> "void":
        """
        set_continuous_node_n_mixtures(self, continuous_node_n_mixtures)


        `set_continuous_node_n_mixtures(const std::vector< unsigned >
            &continuous_node_n_mixtures)`  

        Set/change the candidate number of mixtures to be used for continuous nodes.  

        """
        return _probt_python3.plBayesianNetwork_set_continuous_node_n_mixtures(self, continuous_node_n_mixtures)


    def clear_inference_caches(self) -> "void":
        """
        clear_inference_caches(self)


        `clear_inference_caches()`  

        Clear inference caches.  

        """
        return _probt_python3.plBayesianNetwork_clear_inference_caches(self)


    def export_as(self, format: 'plImportExportFormat', file_name: 'std::string const &') -> "void":
        """
        export_as(self, format, file_name)


        `export_as(plImportExportFormat format, const std::string &file_name) const`  

        Export to the format *format*.  

        The allowed values are:  

        *   PL_FORMAT_GENIE: Genie xdsl  
        *   PL_FORMAT_NETICA: Netica dne  
        *   PL_FORMAT_HUGIN: Hugin net  

        """
        return _probt_python3.plBayesianNetwork_export_as(self, format, file_name)


    def import_from(self, format: 'plImportExportFormat', file_name: 'std::string const &') -> "void":
        """
        import_from(self, format, file_name)


        `import_from(plImportExportFormat format, const std::string &file_name)`  

        Import from the format *format*.  

        The allowed values are:  

        *   PL_FORMAT_GENIE: Genie xdsl  
        *   PL_FORMAT_NETICA: Netica dne  
        *   PL_FORMAT_HUGIN: Hugin net  

        """
        return _probt_python3.plBayesianNetwork_import_from(self, format, file_name)


    def save_as_genie(self, file_name: 'std::string const &') -> "void":
        """
        save_as_genie(self, file_name)


        `save_as_genie(const std::string &file_name) const`  

        Save as Genie xdsl file.  

        """
        return _probt_python3.plBayesianNetwork_save_as_genie(self, file_name)


    def load_from_genie(self, file_name: 'std::string const &') -> "void":
        """
        load_from_genie(self, file_name)


        `load_from_genie(const std::string &file_name)`  

        Load from a Genie xdsl file.  

        """
        return _probt_python3.plBayesianNetwork_load_from_genie(self, file_name)


    def save_as_netica(self, file_name: 'std::string const &') -> "void":
        """
        save_as_netica(self, file_name)


        `save_as_netica(const std::string &file_name) const`  

        Save as Netica dne file.  

        """
        return _probt_python3.plBayesianNetwork_save_as_netica(self, file_name)


    def load_from_netica(self, file_name: 'std::string const &') -> "void":
        """
        load_from_netica(self, file_name)


        `load_from_netica(const std::string &file_name)`  

        Load from a Netica dne file.  

        """
        return _probt_python3.plBayesianNetwork_load_from_netica(self, file_name)


    def save_as_hugin(self, file_name: 'std::string const &') -> "void":
        """
        save_as_hugin(self, file_name)


        `save_as_hugin(const std::string &file_name) const`  

        Save as Hugin net file.  

        """
        return _probt_python3.plBayesianNetwork_save_as_hugin(self, file_name)


    def load_from_hugin(self, file_name: 'std::string const &') -> "void":
        """
        load_from_hugin(self, file_name)


        `load_from_hugin(const std::string &file_name)`  

        Load from a Hugin net file.  

        """
        return _probt_python3.plBayesianNetwork_load_from_hugin(self, file_name)


    def __getstate__(self) -> "std::string":
        """__getstate__(self) -> std::string"""
        return _probt_python3.plBayesianNetwork___getstate__(self)


    def __setstate_internal(self, sState: 'std::string const &') -> "void":
        """__setstate_internal(self, sState)"""
        return _probt_python3.plBayesianNetwork___setstate_internal(self, sState)


    def __setstate__(self, sState):
        self.__init__()
        self.__setstate_internal(sState)

plBayesianNetwork_swigregister = _probt_python3.plBayesianNetwork_swigregister
plBayesianNetwork_swigregister(plBayesianNetwork)


# pypl.i: %pythoncode for plBayesianNetwork methods

@patch
def plBayesianNetwork_set_evidence(orig, self, values, check=True):
  import six
  if isinstance(values, dict):
    var_values = {}
    for k, v in six.iteritems(values):
      if not isinstance(k, plVariable):
        var = self.get_node(k)
      else:
        var = k  
      var_values[var] = v
  else:
    var_values = values        
  return orig(self, var_values, check)

@patch
def plBayesianNetwork_get_belief_table(orig, self, node, *args, **kwargs):
  tup = orig(self, node, *args, **kwargs)
  if not isinstance(node, plVariablesConjunction):
    node = self.get_node(node)
  vals = [plValues(v) for v in plValues(node).all()]
  ret = dataframe_of_values(vals)
  index_columns = list(ret.columns)
  ret["probability"] = tup
  ret.set_index(index_columns, inplace=True)
  return ret

@patch
def plBayesianNetwork_sample(orig, self, *args, **kwargs):
  output = orig(self, *args, **kwargs)
  if output is not None: return dataframe_of_values(output)

@patch
def plBayesianNetwork_gibbs_samples(orig, self, *args, **kwargs):
  return dataframe_of_values(orig(self, *args, **kwargs))

@patch
def plBayesianNetwork_apply_prediction(orig, self, *args, **kwargs):
  output = orig(self, *args, **kwargs)
  if output is not None: return dataframe_of_values(output)

@patch
def plDistribution_sample(orig, self, *args, **kwargs):
  output = orig(self, *args, **kwargs)
  return dataframe_of_values(output)

@patch
def plBayesianNetwork_apply_classification_proba(orig, self, variables, *args, **kwargs):
    import numpy as np
    import pandas as pd
    output = orig(self, variables, *args, **kwargs)
    col_names = ['P(' + str(v)[2:-3] + ')' for v in plValues(variables).all()]
    np_array = np.empty( (len(output), len(col_names)), dtype=np.float_)
    for i, r in enumerate(output):
        for j in range(len(col_names)):
            np_array[i][j] = r[j]
    df = pd.DataFrame()
    for j in range(len(col_names)):
        df[col_names[j]] = np_array[:,j]
    return df

fixup_dataframe_input(plBayesianNetwork, 'learn_parameters', [0])
fixup_dataframe_input(plBayesianNetwork, 'learn_parameters_em',  [0, 1])
fixup_dataframe_input(plBayesianNetwork, 'learn_parameters_no_em',  [0])
fixup_dataframe_input(plBayesianNetwork, 'learn_structure', [0])
fixup_dataframe_input(plBayesianNetwork, 'learn_structure_tree_augmented_naive_bayes', [0])
fixup_dataframe_input(plBayesianNetwork, 'learn_structure_TANB', [0]) 
fixup_dataframe_input(plBayesianNetwork, 'learn_naive_bayes', [0])
fixup_dataframe_input(plBayesianNetwork, 'learn_NB', [0])
fixup_dataframe_input(plBayesianNetwork, 'apply_prediction', [1])
fixup_dataframe_input(plBayesianNetwork, 'apply_classification_proba', [1])			   
fixup_dataframe_input(plBayesianNetwork, 'validate_prediction', [1])			   
fixup_dataframe_input(plBayesianNetwork, 'compute_data_set_log_likelihood', [0])			   



def plPhi(x: 'plFloat') -> "plFloat":
    """
    plPhi(x) -> plFloat


    `plPhi(plFloat x) -> plFloat`  

    This function implements the Phi function.  

    Phi is the cumulative (repartition) function of the standard normal (Gaussian)
    distribution: Phi(x) = 0.5 + 0.5 * erf( x/sqrt(2) )  

    """
    return _probt_python3.plPhi(x)

def plInvPhi(u: 'plFloat') -> "plFloat":
    """
    plInvPhi(u) -> plFloat


    `plInvPhi(plFloat u) -> PL_DLL_API plFloat`  

    This function implements the inverse of the Phi function above.  

    """
    return _probt_python3.plInvPhi(u)
class plStatFunctions(_object):
    """


    Statistics utility functions.  

    C++ includes: plStatFunctions.h

    """

    __swig_setmethods__ = {}
    __setattr__ = lambda self, name, value: _swig_setattr(self, plStatFunctions, name, value)
    __swig_getmethods__ = {}
    __getattr__ = lambda self, name: _swig_getattr(self, plStatFunctions, name)
    __repr__ = _swig_repr

    def erf(x: 'plFloat') -> "plFloat":
        """
        erf(x) -> plFloat


        `erf(plFloat x) -> plFloat`  

        Erf function.  

        """
        return _probt_python3.plStatFunctions_erf(x)

    erf = staticmethod(erf)

    def normal_pdf(x: 'plFloat', mu: 'plFloat'=0.0, sigma: 'plFloat'=1.0) -> "plFloat":
        """
        normal_pdf(x, mu=0.0, sigma=1.0) -> plFloat
        normal_pdf(x, mu=0.0) -> plFloat
        normal_pdf(x) -> plFloat


        `normal_pdf(plFloat x, plFloat mu=0.0, plFloat sigma=1.0) -> plFloat`  

        Normal Probability Density Function (pdf).  

        """
        return _probt_python3.plStatFunctions_normal_pdf(x, mu, sigma)

    normal_pdf = staticmethod(normal_pdf)

    def phi(x: 'plFloat') -> "plFloat":
        """
        phi(x) -> plFloat


        `phi(plFloat x) -> plFloat`  

        Phi is the Cumulative (repartition) Distribution Function (cdf) of the stantard
        normal (Gaussian) distribution: Phi(x) = 0.5 + 0.5 * erf(x/sqrt(2) ).  

        """
        return _probt_python3.plStatFunctions_phi(x)

    phi = staticmethod(phi)

    def inv_phi(u: 'plFloat') -> "plFloat":
        """
        inv_phi(u) -> plFloat


        `inv_phi(plFloat u) -> plFloat`  

        The inverse of the Phi function above.  

        """
        return _probt_python3.plStatFunctions_inv_phi(u)

    inv_phi = staticmethod(inv_phi)

    def log_multinomial_beta(x: 'DoubleVector') -> "plFloat":
        """
        log_multinomial_beta(x) -> plFloat


        `log_multinomial_beta(const std::vector< plFloat > &x) -> plFloat`  

        Log Multinomial Beta function.  

        """
        return _probt_python3.plStatFunctions_log_multinomial_beta(x)

    log_multinomial_beta = staticmethod(log_multinomial_beta)

    def multinomial_beta(x: 'DoubleVector') -> "plFloat":
        """
        multinomial_beta(x) -> plFloat


        `multinomial_beta(const std::vector< plFloat > &x) -> plFloat`  

        Multinomial Beta function.  

        """
        return _probt_python3.plStatFunctions_multinomial_beta(x)

    multinomial_beta = staticmethod(multinomial_beta)

    def log_beta(x: 'plFloat', y: 'plFloat') -> "plFloat":
        """
        log_beta(x, y) -> plFloat


        `log_beta(plFloat x, plFloat y) -> plFloat`  

        Log Beta function.  

        """
        return _probt_python3.plStatFunctions_log_beta(x, y)

    log_beta = staticmethod(log_beta)

    def beta(x: 'plFloat', y: 'plFloat') -> "plFloat":
        """
        beta(x, y) -> plFloat


        `beta(plFloat x, plFloat y) -> plFloat`  

        Beta function.  

        """
        return _probt_python3.plStatFunctions_beta(x, y)

    beta = staticmethod(beta)

    def log_gamma(x: 'plFloat') -> "plFloat":
        """
        log_gamma(x) -> plFloat


        `log_gamma(plFloat x) -> plFloat`  

        Log-Gamma function.  

        """
        return _probt_python3.plStatFunctions_log_gamma(x)

    log_gamma = staticmethod(log_gamma)

    def gamma(x: 'plFloat') -> "plFloat":
        """
        gamma(x) -> plFloat


        `gamma(plFloat x) -> plFloat`  

        Gamma function.  

        """
        return _probt_python3.plStatFunctions_gamma(x)

    gamma = staticmethod(gamma)

    def incomplete_gamma(a: 'plFloat', x: 'plFloat') -> "plFloat":
        """
        incomplete_gamma(a, x) -> plFloat


        `incomplete_gamma(plFloat a, plFloat x) -> plFloat`  

        Incomplete Gamma integral.  

        The function is defined by: \[ igamma(a, x) = \frac {1} {\Gamma(a)} \int_0^x
        e^{-t} t^{a-1} dt. \]  

        See also: incomplete_gamma_c  

        """
        return _probt_python3.plStatFunctions_incomplete_gamma(a, x)

    incomplete_gamma = staticmethod(incomplete_gamma)

    def incomplete_gamma_c(a: 'plFloat', x: 'plFloat') -> "plFloat":
        """
        incomplete_gamma_c(a, x) -> plFloat


        `incomplete_gamma_c(plFloat a, plFloat x) -> plFloat`  

        Complemented incomplete Gamma integral.  

        The function is defined by: \[ igammac(a, x) = 1 - igamma(a, x) = \frac {1}
        {\Gamma(a)} \int_x^{\infty} e^{-t} t^{a-1} dt. \]  

        See also: incomplete_gamma  

        """
        return _probt_python3.plStatFunctions_incomplete_gamma_c(a, x)

    incomplete_gamma_c = staticmethod(incomplete_gamma_c)

    def log_factorial(n: 'unsigned int') -> "plFloat":
        """
        log_factorial(n) -> plFloat


        `log_factorial(unsigned int n) -> plFloat`  

        Return the log of n!.  

        """
        return _probt_python3.plStatFunctions_log_factorial(n)

    log_factorial = staticmethod(log_factorial)

    def factorial(n: 'unsigned int') -> "plFloat":
        """
        factorial(n) -> plFloat


        `factorial(unsigned int n) -> plFloat`  

        Return n!.  

        """
        return _probt_python3.plStatFunctions_factorial(n)

    factorial = staticmethod(factorial)

    def __init__(self):
        """
        __init__(self) -> plStatFunctions



        Statistics utility functions.  

        C++ includes: plStatFunctions.h

        """
        this = _probt_python3.new_plStatFunctions()
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this
    __swig_destroy__ = _probt_python3.delete_plStatFunctions
    __del__ = lambda self: None
plStatFunctions_swigregister = _probt_python3.plStatFunctions_swigregister
plStatFunctions_swigregister(plStatFunctions)

def plStatFunctions_erf(x: 'plFloat') -> "plFloat":
    """
    plStatFunctions_erf(x) -> plFloat


    `erf(plFloat x) -> plFloat`  

    Erf function.  

    """
    return _probt_python3.plStatFunctions_erf(x)

def plStatFunctions_normal_pdf(x: 'plFloat', mu: 'plFloat'=0.0, sigma: 'plFloat'=1.0) -> "plFloat":
    """
    normal_pdf(x, mu=0.0, sigma=1.0) -> plFloat
    normal_pdf(x, mu=0.0) -> plFloat
    plStatFunctions_normal_pdf(x) -> plFloat


    `normal_pdf(plFloat x, plFloat mu=0.0, plFloat sigma=1.0) -> plFloat`  

    Normal Probability Density Function (pdf).  

    """
    return _probt_python3.plStatFunctions_normal_pdf(x, mu, sigma)

def plStatFunctions_phi(x: 'plFloat') -> "plFloat":
    """
    plStatFunctions_phi(x) -> plFloat


    `phi(plFloat x) -> plFloat`  

    Phi is the Cumulative (repartition) Distribution Function (cdf) of the stantard
    normal (Gaussian) distribution: Phi(x) = 0.5 + 0.5 * erf(x/sqrt(2) ).  

    """
    return _probt_python3.plStatFunctions_phi(x)

def plStatFunctions_inv_phi(u: 'plFloat') -> "plFloat":
    """
    plStatFunctions_inv_phi(u) -> plFloat


    `inv_phi(plFloat u) -> plFloat`  

    The inverse of the Phi function above.  

    """
    return _probt_python3.plStatFunctions_inv_phi(u)

def plStatFunctions_log_multinomial_beta(x: 'DoubleVector') -> "plFloat":
    """
    plStatFunctions_log_multinomial_beta(x) -> plFloat


    `log_multinomial_beta(const std::vector< plFloat > &x) -> plFloat`  

    Log Multinomial Beta function.  

    """
    return _probt_python3.plStatFunctions_log_multinomial_beta(x)

def plStatFunctions_multinomial_beta(x: 'DoubleVector') -> "plFloat":
    """
    plStatFunctions_multinomial_beta(x) -> plFloat


    `multinomial_beta(const std::vector< plFloat > &x) -> plFloat`  

    Multinomial Beta function.  

    """
    return _probt_python3.plStatFunctions_multinomial_beta(x)

def plStatFunctions_log_beta(x: 'plFloat', y: 'plFloat') -> "plFloat":
    """
    plStatFunctions_log_beta(x, y) -> plFloat


    `log_beta(plFloat x, plFloat y) -> plFloat`  

    Log Beta function.  

    """
    return _probt_python3.plStatFunctions_log_beta(x, y)

def plStatFunctions_beta(x: 'plFloat', y: 'plFloat') -> "plFloat":
    """
    plStatFunctions_beta(x, y) -> plFloat


    `beta(plFloat x, plFloat y) -> plFloat`  

    Beta function.  

    """
    return _probt_python3.plStatFunctions_beta(x, y)

def plStatFunctions_log_gamma(x: 'plFloat') -> "plFloat":
    """
    plStatFunctions_log_gamma(x) -> plFloat


    `log_gamma(plFloat x) -> plFloat`  

    Log-Gamma function.  

    """
    return _probt_python3.plStatFunctions_log_gamma(x)

def plStatFunctions_gamma(x: 'plFloat') -> "plFloat":
    """
    plStatFunctions_gamma(x) -> plFloat


    `gamma(plFloat x) -> plFloat`  

    Gamma function.  

    """
    return _probt_python3.plStatFunctions_gamma(x)

def plStatFunctions_incomplete_gamma(a: 'plFloat', x: 'plFloat') -> "plFloat":
    """
    plStatFunctions_incomplete_gamma(a, x) -> plFloat


    `incomplete_gamma(plFloat a, plFloat x) -> plFloat`  

    Incomplete Gamma integral.  

    The function is defined by: \[ igamma(a, x) = \frac {1} {\Gamma(a)} \int_0^x
    e^{-t} t^{a-1} dt. \]  

    See also: incomplete_gamma_c  

    """
    return _probt_python3.plStatFunctions_incomplete_gamma(a, x)

def plStatFunctions_incomplete_gamma_c(a: 'plFloat', x: 'plFloat') -> "plFloat":
    """
    plStatFunctions_incomplete_gamma_c(a, x) -> plFloat


    `incomplete_gamma_c(plFloat a, plFloat x) -> plFloat`  

    Complemented incomplete Gamma integral.  

    The function is defined by: \[ igammac(a, x) = 1 - igamma(a, x) = \frac {1}
    {\Gamma(a)} \int_x^{\infty} e^{-t} t^{a-1} dt. \]  

    See also: incomplete_gamma  

    """
    return _probt_python3.plStatFunctions_incomplete_gamma_c(a, x)

def plStatFunctions_log_factorial(n: 'unsigned int') -> "plFloat":
    """
    plStatFunctions_log_factorial(n) -> plFloat


    `log_factorial(unsigned int n) -> plFloat`  

    Return the log of n!.  

    """
    return _probt_python3.plStatFunctions_log_factorial(n)

def plStatFunctions_factorial(n: 'unsigned int') -> "plFloat":
    """
    plStatFunctions_factorial(n) -> plFloat


    `factorial(unsigned int n) -> plFloat`  

    Return n!.  

    """
    return _probt_python3.plStatFunctions_factorial(n)


def plErf(x: 'plFloat') -> "plFloat":
    """
    plErf(x) -> plFloat


    `plErf(plFloat x) -> plFloat`  

    Erf function.  

    """
    return _probt_python3.plErf(x)

def plLogFactorial(n: 'unsigned int') -> "plFloat":
    """
    plLogFactorial(n) -> plFloat


    `plLogFactorial(unsigned int n) -> plFloat`  

    Return the log of n!  

    """
    return _probt_python3.plLogFactorial(n)

def plFactorial(n: 'unsigned int') -> "plFloat":
    """
    plFactorial(n) -> plFloat


    `plFactorial(unsigned int n) -> plFloat`  

    Return n!  

    """
    return _probt_python3.plFactorial(n)
class plPCA(plObject):
    """

    `plPCA()`  
    `plPCA(const plVariablesConjunction &variables)`  

    Principal component analysis (PCA)  

    Linear dimensionality reduction using eigenvalue decomposition of the covariance
    matrix and keeping only the most significant eigen vectors to project the data
    to a lower dimensional space  

    Constructors
    ------------
    * `plPCA()`  

        Default constructor.  

    * `plPCA(const plVariablesConjunction &variables)`  

        Constructor using a set of variables.  

    C++ includes: plPCA.h

    """

    __swig_setmethods__ = {}
    for _s in [plObject]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plPCA, name, value)
    __swig_getmethods__ = {}
    for _s in [plObject]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plPCA, name)
    __repr__ = _swig_repr

    def __init__(self, *args):
        """
        __init__(self) -> plPCA
        __init__(self, variables) -> plPCA


        `plPCA()`  
        `plPCA(const plVariablesConjunction &variables)`  

        Overloaded function
        -------------------
        * `plPCA()`  

            Default constructor.  

        * `plPCA(const plVariablesConjunction &variables)`  

            Constructor using a set of variables.  

        """
        this = _probt_python3.new_plPCA(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def get_variables(self) -> "plVariablesConjunction const &":
        """
        get_variables(self) -> plVariablesConjunction


        `get_variables() const -> const plVariablesConjunction &`  

        Get PCA variables.  

        """
        return _probt_python3.plPCA_get_variables(self)


    def fit(self, *args) -> "void":
        """
        fit(self, data)
        fit(self, data)
        fit(self, data)
        fit(self, data)
        fit(self, data)
        fit(self, data)


        `fit(plDataDescriptor &data)`  
        `fit(const std::vector< std::vector< double > > &data)`  
        `fit(const std::vector< std::vector< float > > &data)`  
        `fit(const std::vector< std::vector< long double > > &data)`  
        `fit(const std::vector< plFloatVector > &data)`  
        `fit(const std::vector< plValues > &data)`  

        Overloaded function
        -------------------
        * `fit(plDataDescriptor &data)`  

            Fit the model with data.  

        * `fit(const std::vector< std::vector< double > > &data)`  

            Fit the model with data.  

        * `fit(const std::vector< std::vector< float > > &data)`  

            Fit the model with data.  

        * `fit(const std::vector< std::vector< long double > > &data)`  

            Fit the model with data.  

        * `fit(const std::vector< plFloatVector > &data)`  

            Fit the model with data.  

        * `fit(const std::vector< plValues > &data)`  

            Fit the model with data.  

        """
        return _probt_python3.plPCA_fit(self, *args)


    def components(self, nc: 'size_t'=0) -> "plFloatMatrix":
        """
        components(self, nc=0) -> plFloatMatrix
        components(self) -> plFloatMatrix


        `components(size_t nc=0) const -> plFloatMatrix`  

        Components with maximum variance.  

        If nc (number of components) is 0 then all components are returned  

        """
        return _probt_python3.plPCA_components(self, nc)


    def explained_variance_ratio(self, nc: 'size_t'=0) -> "plFloatVector":
        """
        explained_variance_ratio(self, nc=0) -> plFloatVector
        explained_variance_ratio(self) -> plFloatVector


        `explained_variance_ratio(size_t nc=0) const -> plFloatVector`  

        Percentage of variance explained by each of the selected components.  

        If nc (number of components) is 0 then all components are returned and the sum
        of explained variances is equal to 1.0.  

        """
        return _probt_python3.plPCA_explained_variance_ratio(self, nc)


    def explained_variance(self, nc: 'size_t'=0) -> "plFloatVector":
        """
        explained_variance(self, nc=0) -> plFloatVector
        explained_variance(self) -> plFloatVector


        `explained_variance(size_t nc=0) const -> plFloatVector`  

        Explainded variance (eigenvalues) for the selected components If nc (number of
        components) is 0 then all eigenvalues are returned.  

        """
        return _probt_python3.plPCA_explained_variance(self, nc)


    def get_n_components_for_explained_variance(self, ratio: 'plFloat') -> "size_t":
        """
        get_n_components_for_explained_variance(self, ratio) -> size_t


        `get_n_components_for_explained_variance(plFloat ratio) -> size_t`  

        Return the number of components allowing to explain a given ratio (in [0, 1]) of
        the variance.  

        """
        return _probt_python3.plPCA_get_n_components_for_explained_variance(self, ratio)


    def get_n_components_mle(self) -> "size_t":
        """
        get_n_components_mle(self) -> size_t


        `get_n_components_mle() const -> size_t`  

        Return the number of components using Minka's MLE to guess the dimension.  

        Based on 'Thomas P. Minka: Automatic Choice of Dimensionality for PCA. NIPS
        2000: 598-604'  

        """
        return _probt_python3.plPCA_get_n_components_mle(self)


    def data_mean(self) -> "plFloatVector":
        """
        data_mean(self) -> plFloatVector


        `data_mean() const -> plFloatVector`  

        Per-feature empirical mean, estimated from the training set.  

        """
        return _probt_python3.plPCA_data_mean(self)


    def data_variance(self) -> "plFloatMatrix":
        """
        data_variance(self) -> plFloatMatrix


        `data_variance() const -> plFloatMatrix`  

        Empirical variance, estimated from the training set.  

        """
        return _probt_python3.plPCA_data_variance(self)


    def variance(self, nc: 'size_t') -> "plFloatMatrix":
        """
        variance(self, nc) -> plFloatMatrix


        `variance(size_t nc) const -> plFloatMatrix`  

        Compute data covariance with the generative model unsing 'nc' components.  

        variance = components(nc).T * S**2 * components(cn) + noise_variance(nc) *
        eye(n_features) where S**2 contains the explained variances
        explained_variance(nc) as diagonal  

        """
        return _probt_python3.plPCA_variance(self, nc)


    def noise_variance(self, nc: 'size_t') -> "plFloat":
        """
        noise_variance(self, nc) -> plFloat


        `noise_variance(size_t nc) const -> plFloat`  

        Noise variance given 'nc' the number of components.  

        """
        return _probt_python3.plPCA_noise_variance(self, nc)


    def transform_point(self, *args) -> "plFloatVector":
        """
        transform_point(self, point, nc=0) -> DoubleVector
        transform_point(self, point) -> DoubleVector
        transform_point(self, point, nc=0) -> FloatVector
        transform_point(self, point) -> FloatVector
        transform_point(self, point, nc=0) -> LongDoubleVector
        transform_point(self, point) -> LongDoubleVector
        transform_point(self, point, nc=0) -> plFloatVector
        transform_point(self, point) -> plFloatVector


        `transform_point(const std::vector< double > &point, size_t nc=0) const ->
            std::vector< double >`  
        `transform_point(const std::vector< float > &point, size_t nc=0) const ->
            std::vector< float >`  
        `transform_point(const std::vector< long double > &point, size_t nc=0) const ->
            std::vector< long double >`  
        `transform_point(const plFloatVector &point, size_t nc=0) const ->
            plFloatVector`  

        Overloaded function
        -------------------
        * `transform_point(const std::vector< double > &point, size_t nc=0) const ->
            std::vector< double >`  

            Apply the dimensionality reduction on 'point' by keeping only the 'nc'
            principal components.  

        * `transform_point(const std::vector< float > &point, size_t nc=0) const ->
            std::vector< float >`  

            Apply the dimensionality reduction on 'point' by keeping only the 'nc'
            principal components.  

        * `transform_point(const std::vector< long double > &point, size_t nc=0) const
            -> std::vector< long double >`  

            Apply the dimensionality reduction on 'point' by keeping only the 'nc'
            principal components.  

        * `transform_point(const plFloatVector &point, size_t nc=0) const ->
            plFloatVector`  

            Apply the dimensionality reduction on 'point' by keeping only the 'nc'
            principal components.  

        """
        return _probt_python3.plPCA_transform_point(self, *args)


    def transform_points(self, *args) -> "std::vector< plFloatVector,std::allocator< plFloatVector > >":
        """
        transform_points(self, points, nc=0) -> DoubleVectorVector
        transform_points(self, points) -> DoubleVectorVector
        transform_points(self, points, nc=0) -> FloatVectorVector
        transform_points(self, points) -> FloatVectorVector
        transform_points(self, points, nc=0) -> LongDoubleVectorVector
        transform_points(self, points) -> LongDoubleVectorVector
        transform_points(self, points, nc=0) -> plFlVectorVector
        transform_points(self, points) -> plFlVectorVector


        `transform_points(const std::vector< std::vector< double > > &points, size_t
            nc=0) const -> std::vector< std::vector< double > >`  
        `transform_points(const std::vector< std::vector< float > > &points, size_t
            nc=0) const -> std::vector< std::vector< float > >`  
        `transform_points(const std::vector< std::vector< long double > > &points,
            size_t nc=0) const -> std::vector< std::vector< long double > >`  
        `transform_points(const std::vector< plFloatVector > &points, size_t nc=0) const
            -> std::vector< plFloatVector >`  

        Overloaded function
        -------------------
        * `transform_points(const std::vector< std::vector< double > > &points, size_t
            nc=0) const -> std::vector< std::vector< double > >`  

            Apply the dimensionality reduction on the set 'points' of points by keeping
            only the 'nc' principal components.  

        * `transform_points(const std::vector< std::vector< float > > &points, size_t
            nc=0) const -> std::vector< std::vector< float > >`  

            Apply the dimensionality reduction on the set 'points' of points by keeping
            only the 'nc' principal components.  

        * `transform_points(const std::vector< std::vector< long double > > &points,
            size_t nc=0) const -> std::vector< std::vector< long double > >`  

            Apply the dimensionality reduction on the set 'points' of points by keeping
            only the 'nc' principal components.  

        * `transform_points(const std::vector< plFloatVector > &points, size_t nc=0)
            const -> std::vector< plFloatVector >`  

            Apply the dimensionality reduction on the set 'points' of points by keeping
            only the 'nc' principal components.  

        """
        return _probt_python3.plPCA_transform_points(self, *args)


    def inverse_transform_point(self, *args) -> "plFloatVector":
        """
        inverse_transform_point(self, transformed_point) -> DoubleVector
        inverse_transform_point(self, transformed_point) -> FloatVector
        inverse_transform_point(self, transformed_point) -> LongDoubleVector
        inverse_transform_point(self, transformed_point) -> plFloatVector


        `inverse_transform_point(const std::vector< double > &transformed_point) const
            -> std::vector< double >`  
        `inverse_transform_point(const std::vector< float > &transformed_point) const ->
            std::vector< float >`  
        `inverse_transform_point(const std::vector< long double > &transformed_point)
            const -> std::vector< long double >`  
        `inverse_transform_point(const plFloatVector &transformed_point) const ->
            plFloatVector`  

        Overloaded function
        -------------------
        * `inverse_transform_point(const std::vector< double > &transformed_point) const
            -> std::vector< double >`  

            Transform data back to its original space, i.e., return an input
            'point_original' whose transform would be 'transformed_point'.  

        * `inverse_transform_point(const std::vector< float > &transformed_point) const
            -> std::vector< float >`  

            Transform data back to its original space, i.e., return an input
            'point_original' whose transform would be 'transformed_point'.  

        * `inverse_transform_point(const std::vector< long double > &transformed_point)
            const -> std::vector< long double >`  

            Transform data back to its original space, i.e., return an input
            'point_original' whose transform would be 'transformed_point'.  

        * `inverse_transform_point(const plFloatVector &transformed_point) const ->
            plFloatVector`  

            Transform data back to its original space, i.e., return an input
            'point_original' whose transform would be 'transformed_point'.  

        """
        return _probt_python3.plPCA_inverse_transform_point(self, *args)


    def inverse_transform_points(self, *args) -> "std::vector< plFloatVector,std::allocator< plFloatVector > >":
        """
        inverse_transform_points(self, transformed_points) -> DoubleVectorVector
        inverse_transform_points(self, transformed_points) -> FloatVectorVector
        inverse_transform_points(self, transformed_points) -> LongDoubleVectorVector
        inverse_transform_points(self, transformed_points) -> plFlVectorVector


        `inverse_transform_points(const std::vector< std::vector< double > >
            &transformed_points) const -> std::vector< std::vector< double > >`  
        `inverse_transform_points(const std::vector< std::vector< float > >
            &transformed_points) const -> std::vector< std::vector< float > >`  
        `inverse_transform_points(const std::vector< std::vector< long double > >
            &transformed_points) const -> std::vector< std::vector< long double > >`  
        `inverse_transform_points(const std::vector< plFloatVector >
            &transformed_points) const -> std::vector< plFloatVector >`  

        Overloaded function
        -------------------
        * `inverse_transform_points(const std::vector< std::vector< double > >
            &transformed_points) const -> std::vector< std::vector< double > >`  

            Transform data back to its original space, i.e., return an input
            'point_originals' whose transform would be 'transformed_points'.  

        * `inverse_transform_points(const std::vector< std::vector< float > >
            &transformed_points) const -> std::vector< std::vector< float > >`  

            Transform data back to its original space, i.e., return an input
            'point_originals' whose transform would be 'transformed_points'.  

        * `inverse_transform_points(const std::vector< std::vector< long double > >
            &transformed_points) const -> std::vector< std::vector< long double > >`  

            Transform data back to its original space, i.e., return an input
            'point_originals' whose transform would be 'transformed_points'.  

        * `inverse_transform_points(const std::vector< plFloatVector >
            &transformed_points) const -> std::vector< plFloatVector >`  

            Transform data back to its original space, i.e., return an input
            'point_originals' whose transform would be 'transformed_points'.  

        """
        return _probt_python3.plPCA_inverse_transform_points(self, *args)

    __swig_destroy__ = _probt_python3.delete_plPCA
    __del__ = lambda self: None
plPCA_swigregister = _probt_python3.plPCA_swigregister
plPCA_swigregister(plPCA)


fixup_dataframe_input(plPCA, 'fit', [0])

PL_KMEANS_INIT_FORGY = _probt_python3.PL_KMEANS_INIT_FORGY
PL_KMEANS_INIT_RANDOM_PARTITION = _probt_python3.PL_KMEANS_INIT_RANDOM_PARTITION
PL_KMEANS_INIT_BOTH = _probt_python3.PL_KMEANS_INIT_BOTH
class plOneDCartesian(_object):
    """


    Structure implementing the k-means utility functions for the 1D case using
    cartesian distance.  

    See also: plKMeans  

    See also: plNdCartesian  

    C++ includes: plKMeans.h

    """

    __swig_setmethods__ = {}
    __setattr__ = lambda self, name, value: _swig_setattr(self, plOneDCartesian, name, value)
    __swig_getmethods__ = {}
    __getattr__ = lambda self, name: _swig_getattr(self, plOneDCartesian, name)
    __repr__ = _swig_repr

    def dist2(p1: 'plFloat', p2: 'plFloat') -> "plFloat":
        """
        dist2(p1, p2) -> plFloat


        `dist2(plFloat p1, plFloat p2) -> plFloat`  

        Cartesian distance.  

        """
        return _probt_python3.plOneDCartesian_dist2(p1, p2)

    dist2 = staticmethod(dist2)

    def inplace_add(output: 'plFloat &', inc: 'plFloat') -> "void":
        """
        inplace_add(output, inc)


        `inplace_add(plFloat &output, plFloat inc)`  

        Add a point to another.  

        """
        return _probt_python3.plOneDCartesian_inplace_add(output, inc)

    inplace_add = staticmethod(inplace_add)

    def inplace_div(output: 'plFloat &', n: 'size_t') -> "void":
        """
        inplace_div(output, n)


        `inplace_div(plFloat &output, size_t n)`  

        Divide a point by n.  

        """
        return _probt_python3.plOneDCartesian_inplace_div(output, n)

    inplace_div = staticmethod(inplace_div)

    def set_to_zero(output: 'plFloat &') -> "void":
        """
        set_to_zero(output)


        `set_to_zero(plFloat &output)`  

        Set the point to zero.  

        """
        return _probt_python3.plOneDCartesian_set_to_zero(output)

    set_to_zero = staticmethod(set_to_zero)

    def __init__(self):
        """
        __init__(self) -> plOneDCartesian



        Structure implementing the k-means utility functions for the 1D case using
        cartesian distance.  

        See also: plKMeans  

        See also: plNdCartesian  

        C++ includes: plKMeans.h

        """
        this = _probt_python3.new_plOneDCartesian()
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this
    __swig_destroy__ = _probt_python3.delete_plOneDCartesian
    __del__ = lambda self: None
plOneDCartesian_swigregister = _probt_python3.plOneDCartesian_swigregister
plOneDCartesian_swigregister(plOneDCartesian)

def plOneDCartesian_dist2(p1: 'plFloat', p2: 'plFloat') -> "plFloat":
    """
    plOneDCartesian_dist2(p1, p2) -> plFloat


    `dist2(plFloat p1, plFloat p2) -> plFloat`  

    Cartesian distance.  

    """
    return _probt_python3.plOneDCartesian_dist2(p1, p2)

def plOneDCartesian_inplace_add(output: 'plFloat &', inc: 'plFloat') -> "void":
    """
    plOneDCartesian_inplace_add(output, inc)


    `inplace_add(plFloat &output, plFloat inc)`  

    Add a point to another.  

    """
    return _probt_python3.plOneDCartesian_inplace_add(output, inc)

def plOneDCartesian_inplace_div(output: 'plFloat &', n: 'size_t') -> "void":
    """
    plOneDCartesian_inplace_div(output, n)


    `inplace_div(plFloat &output, size_t n)`  

    Divide a point by n.  

    """
    return _probt_python3.plOneDCartesian_inplace_div(output, n)

def plOneDCartesian_set_to_zero(output: 'plFloat &') -> "void":
    """
    plOneDCartesian_set_to_zero(output)


    `set_to_zero(plFloat &output)`  

    Set the point to zero.  

    """
    return _probt_python3.plOneDCartesian_set_to_zero(output)

class plKMeansNdCartesian(_object):
    """


    Template class implementing k-means clustering.  

    Parameters
    ----------
    * `PointT` :  
        The type for data vector (e.g., std::vector<double> for nD dimensional case
        or 'double' for one-dimensional case)  
    * `PointTFuncs` :  
        a structure implementing functions:  

        *   plFloat dist2(const PointT &p1, const PointT &p2): the square of the
            distance to be used (e.g., cartesian)  
        *   void inplace_add(PointT &output, const PointT &inc)  
        *   void inplace_div(PointT &output, size_t n)  
        *   void set_to_zero(PointT &output)  

    See also: plNdCartesian  

    See also: plOneDCartesian  

    See also: plKMeansNdCartesian  

    See also: plKMeans1dCartesian  

    plKMeansNdCartesian and plKMeans1dCartesian are typedefs using this template.  

    C++ includes: plKMeans.h

    """

    __swig_setmethods__ = {}
    __setattr__ = lambda self, name, value: _swig_setattr(self, plKMeansNdCartesian, name, value)
    __swig_getmethods__ = {}
    __getattr__ = lambda self, name: _swig_getattr(self, plKMeansNdCartesian, name)
    __repr__ = _swig_repr

    def __init__(self, k: 'size_t'):
        """
        __init__(self, k) -> plKMeansNdCartesian


        `plKMeans(size_t k)`  

        Constructor.  

        Parameters
        ----------
        * `k` :  
            the number of clusters  

        """
        this = _probt_python3.new_plKMeansNdCartesian(k)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def fit(self, data_points: 'DoubleVectorVector', n_random_trials: 'size_t'=5, max_iter: 'size_t'=100000, init_method: 'plKMeansInitializationMethod'=PL_KMEANS_INIT_BOTH) -> "plFloat":
        """
        fit(self, data_points, n_random_trials=5, max_iter=100000, init_method=PL_KMEANS_INIT_BOTH) -> plFloat
        fit(self, data_points, n_random_trials=5, max_iter=100000) -> plFloat
        fit(self, data_points, n_random_trials=5) -> plFloat
        fit(self, data_points) -> plFloat


        `fit(const std::vector< PointT > &data_points, size_t n_random_trials=5, size_t
            max_iter=100000, plKMeansInitializationMethod
            init_method=PL_KMEANS_INIT_BOTH) -> plFloat`  

        Run the algorithm using n_random_trials initializations and keep the solution
        maximizing Dunn index.  

        Parameters
        ----------
        * `data_points` :  
            The data set to be used for the k-means clustering  
        * `n_random_trials` :  
            The number of random initializations to be used for maximizing Dunn index  
        * `max_iter` :  
            The max number of iterations for each random initialization  
        * `init_method` :  
            initialization method among PL_KMEANS_INIT_FORGY,
            PL_KMEANS_INIT_RANDOM_PARTITION, and PL_KMEANS_INIT_BOTH  

        The clustering results can be retrieved using:  

        *   get_means(), get_counts(), and get_assignments() or  
        *   get_mean(), get_count(), and get_assignment()  
        *   get_inter_cluster_distances(), get_intra_cluster_distances()  

        Returns
        -------
        Dunn index value  

        """
        return _probt_python3.plKMeansNdCartesian_fit(self, data_points, n_random_trials, max_iter, init_method)


    def predict(self, data_points: 'DoubleVectorVector') -> "std::vector< unsigned int,std::allocator< unsigned int > >":
        """
        predict(self, data_points) -> UnsignedIntVector


        `predict(const std::vector< PointT > &data_points) -> std::vector< unsigned int
            >`  

        Return, for each data point, the closest cluster.  

        """
        return _probt_python3.plKMeansNdCartesian_predict(self, data_points)


    def get_means(self) -> "std::vector< std::vector< double,std::allocator< double > >,std::allocator< std::vector< double,std::allocator< double > > > > const &":
        """
        get_means(self) -> DoubleVectorVector


        `get_means() const -> const std::vector< PointT > &`  

        Get the resulting k means (cluster centers)  

        """
        return _probt_python3.plKMeansNdCartesian_get_means(self)


    def get_counts(self) -> "std::vector< unsigned int,std::allocator< unsigned int > > const &":
        """
        get_counts(self) -> UnsignedIntVector


        `get_counts() const -> const std::vector< unsigned int > &`  

        Get the count corresponding to each cluster.  

        """
        return _probt_python3.plKMeansNdCartesian_get_counts(self)


    def get_assignments(self) -> "std::vector< unsigned int,std::allocator< unsigned int > > const &":
        """
        get_assignments(self) -> UnsignedIntVector


        `get_assignments() const -> const std::vector< unsigned int > &`  

        Get, for each data point, the id (in {0, .., k-1}) of the cluster to which it
        has been assigned.  

        """
        return _probt_python3.plKMeansNdCartesian_get_assignments(self)


    def get_k(self) -> "size_t":
        """
        get_k(self) -> size_t


        `get_k() const -> size_t`  

        Return the number of clusters k.  

        """
        return _probt_python3.plKMeansNdCartesian_get_k(self)


    def get_mean(self, i: 'size_t') -> "std::vector< double,std::allocator< double > > const &":
        """
        get_mean(self, i) -> DoubleVector


        `get_mean(size_t i) const -> const PointT &`  

        Get the ith (i in {0, .., k-1}) cluster (mean)  

        """
        return _probt_python3.plKMeansNdCartesian_get_mean(self, i)


    def get_count(self, i: 'size_t') -> "unsigned int":
        """
        get_count(self, i) -> unsigned int


        `get_count(size_t i) const -> unsigned int`  

        Get the count (number of data points) assigned to the ith (i in {0, .., k-1})
        cluster.  

        """
        return _probt_python3.plKMeansNdCartesian_get_count(self, i)


    def get_assignment(self, n: 'size_t') -> "unsigned int":
        """
        get_assignment(self, n) -> unsigned int


        `get_assignment(size_t n) const -> unsigned int`  

        Get the index (in {0, .., k-1}) of the cluster to which the nth data point has
        been assigned.  

        """
        return _probt_python3.plKMeansNdCartesian_get_assignment(self, n)


    def get_inter_cluster_distances(self) -> "std::vector< plFloat,std::allocator< plFloat > > const &":
        """
        get_inter_cluster_distances(self) -> DoubleVector


        `get_inter_cluster_distances() const -> const std::vector< plFloat > &`  

        Get the k*(k-1)/2 inter cluster distances.  

        """
        return _probt_python3.plKMeansNdCartesian_get_inter_cluster_distances(self)


    def get_intra_cluster_distances(self) -> "std::vector< plFloat,std::allocator< plFloat > > const &":
        """
        get_intra_cluster_distances(self) -> DoubleVector


        `get_intra_cluster_distances() const -> const std::vector< plFloat > &`  

        Get the k intra cluster distances.  

        """
        return _probt_python3.plKMeansNdCartesian_get_intra_cluster_distances(self)


    def python_plot_results(self, arg2: 'DoubleVectorVector') -> "void":
        """
        python_plot_results(self, arg2)


        `python_plot_results(const std::vector< PointT > &)`  

        Only for Python: Plot the clustering results.  

        """
        return _probt_python3.plKMeansNdCartesian_python_plot_results(self, arg2)

    __swig_destroy__ = _probt_python3.delete_plKMeansNdCartesian
    __del__ = lambda self: None
plKMeansNdCartesian_swigregister = _probt_python3.plKMeansNdCartesian_swigregister
plKMeansNdCartesian_swigregister(plKMeansNdCartesian)

class plKMeans1dCartesian(_object):
    """


    Template class implementing k-means clustering.  

    Parameters
    ----------
    * `PointT` :  
        The type for data vector (e.g., std::vector<double> for nD dimensional case
        or 'double' for one-dimensional case)  
    * `PointTFuncs` :  
        a structure implementing functions:  

        *   plFloat dist2(const PointT &p1, const PointT &p2): the square of the
            distance to be used (e.g., cartesian)  
        *   void inplace_add(PointT &output, const PointT &inc)  
        *   void inplace_div(PointT &output, size_t n)  
        *   void set_to_zero(PointT &output)  

    See also: plNdCartesian  

    See also: plOneDCartesian  

    See also: plKMeansNdCartesian  

    See also: plKMeans1dCartesian  

    plKMeansNdCartesian and plKMeans1dCartesian are typedefs using this template.  

    C++ includes: plKMeans.h

    """

    __swig_setmethods__ = {}
    __setattr__ = lambda self, name, value: _swig_setattr(self, plKMeans1dCartesian, name, value)
    __swig_getmethods__ = {}
    __getattr__ = lambda self, name: _swig_getattr(self, plKMeans1dCartesian, name)
    __repr__ = _swig_repr

    def __init__(self, k: 'size_t'):
        """
        __init__(self, k) -> plKMeans1dCartesian


        `plKMeans(size_t k)`  

        Constructor.  

        Parameters
        ----------
        * `k` :  
            the number of clusters  

        """
        this = _probt_python3.new_plKMeans1dCartesian(k)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def fit(self, data_points: 'DoubleVector', n_random_trials: 'size_t'=5, max_iter: 'size_t'=100000, init_method: 'plKMeansInitializationMethod'=PL_KMEANS_INIT_BOTH) -> "plFloat":
        """
        fit(self, data_points, n_random_trials=5, max_iter=100000, init_method=PL_KMEANS_INIT_BOTH) -> plFloat
        fit(self, data_points, n_random_trials=5, max_iter=100000) -> plFloat
        fit(self, data_points, n_random_trials=5) -> plFloat
        fit(self, data_points) -> plFloat


        `fit(const std::vector< PointT > &data_points, size_t n_random_trials=5, size_t
            max_iter=100000, plKMeansInitializationMethod
            init_method=PL_KMEANS_INIT_BOTH) -> plFloat`  

        Run the algorithm using n_random_trials initializations and keep the solution
        maximizing Dunn index.  

        Parameters
        ----------
        * `data_points` :  
            The data set to be used for the k-means clustering  
        * `n_random_trials` :  
            The number of random initializations to be used for maximizing Dunn index  
        * `max_iter` :  
            The max number of iterations for each random initialization  
        * `init_method` :  
            initialization method among PL_KMEANS_INIT_FORGY,
            PL_KMEANS_INIT_RANDOM_PARTITION, and PL_KMEANS_INIT_BOTH  

        The clustering results can be retrieved using:  

        *   get_means(), get_counts(), and get_assignments() or  
        *   get_mean(), get_count(), and get_assignment()  
        *   get_inter_cluster_distances(), get_intra_cluster_distances()  

        Returns
        -------
        Dunn index value  

        """
        return _probt_python3.plKMeans1dCartesian_fit(self, data_points, n_random_trials, max_iter, init_method)


    def predict(self, data_points: 'DoubleVector') -> "std::vector< unsigned int,std::allocator< unsigned int > >":
        """
        predict(self, data_points) -> UnsignedIntVector


        `predict(const std::vector< PointT > &data_points) -> std::vector< unsigned int
            >`  

        Return, for each data point, the closest cluster.  

        """
        return _probt_python3.plKMeans1dCartesian_predict(self, data_points)


    def get_means(self) -> "std::vector< double,std::allocator< double > > const &":
        """
        get_means(self) -> DoubleVector


        `get_means() const -> const std::vector< PointT > &`  

        Get the resulting k means (cluster centers)  

        """
        return _probt_python3.plKMeans1dCartesian_get_means(self)


    def get_counts(self) -> "std::vector< unsigned int,std::allocator< unsigned int > > const &":
        """
        get_counts(self) -> UnsignedIntVector


        `get_counts() const -> const std::vector< unsigned int > &`  

        Get the count corresponding to each cluster.  

        """
        return _probt_python3.plKMeans1dCartesian_get_counts(self)


    def get_assignments(self) -> "std::vector< unsigned int,std::allocator< unsigned int > > const &":
        """
        get_assignments(self) -> UnsignedIntVector


        `get_assignments() const -> const std::vector< unsigned int > &`  

        Get, for each data point, the id (in {0, .., k-1}) of the cluster to which it
        has been assigned.  

        """
        return _probt_python3.plKMeans1dCartesian_get_assignments(self)


    def get_k(self) -> "size_t":
        """
        get_k(self) -> size_t


        `get_k() const -> size_t`  

        Return the number of clusters k.  

        """
        return _probt_python3.plKMeans1dCartesian_get_k(self)


    def get_mean(self, i: 'size_t') -> "double const &":
        """
        get_mean(self, i) -> double const &


        `get_mean(size_t i) const -> const PointT &`  

        Get the ith (i in {0, .., k-1}) cluster (mean)  

        """
        return _probt_python3.plKMeans1dCartesian_get_mean(self, i)


    def get_count(self, i: 'size_t') -> "unsigned int":
        """
        get_count(self, i) -> unsigned int


        `get_count(size_t i) const -> unsigned int`  

        Get the count (number of data points) assigned to the ith (i in {0, .., k-1})
        cluster.  

        """
        return _probt_python3.plKMeans1dCartesian_get_count(self, i)


    def get_assignment(self, n: 'size_t') -> "unsigned int":
        """
        get_assignment(self, n) -> unsigned int


        `get_assignment(size_t n) const -> unsigned int`  

        Get the index (in {0, .., k-1}) of the cluster to which the nth data point has
        been assigned.  

        """
        return _probt_python3.plKMeans1dCartesian_get_assignment(self, n)


    def get_inter_cluster_distances(self) -> "std::vector< plFloat,std::allocator< plFloat > > const &":
        """
        get_inter_cluster_distances(self) -> DoubleVector


        `get_inter_cluster_distances() const -> const std::vector< plFloat > &`  

        Get the k*(k-1)/2 inter cluster distances.  

        """
        return _probt_python3.plKMeans1dCartesian_get_inter_cluster_distances(self)


    def get_intra_cluster_distances(self) -> "std::vector< plFloat,std::allocator< plFloat > > const &":
        """
        get_intra_cluster_distances(self) -> DoubleVector


        `get_intra_cluster_distances() const -> const std::vector< plFloat > &`  

        Get the k intra cluster distances.  

        """
        return _probt_python3.plKMeans1dCartesian_get_intra_cluster_distances(self)


    def python_plot_results(self, arg2: 'DoubleVector') -> "void":
        """
        python_plot_results(self, arg2)


        `python_plot_results(const std::vector< PointT > &)`  

        Only for Python: Plot the clustering results.  

        """
        return _probt_python3.plKMeans1dCartesian_python_plot_results(self, arg2)

    __swig_destroy__ = _probt_python3.delete_plKMeans1dCartesian
    __del__ = lambda self: None
plKMeans1dCartesian_swigregister = _probt_python3.plKMeans1dCartesian_swigregister
plKMeans1dCartesian_swigregister(plKMeans1dCartesian)

class plStructureLearner(plLearner):
    """

    `plStructureLearner(const plJointDistribution &joint)`  
    `plStructureLearner(const plVariablesConjunction &variables, const
        variable_edge_list_t &init_edges=variable_edge_list_t())`  
    `plStructureLearner(const plStructureLearner &)`  

    This is the main interface of ProBT Structure Learning functionality.  

    Given a set of variables and a dataset, this class allows to discover the
    dependancy structure of the variables.  

    Constructors
    ------------
    * `plStructureLearner(const plJointDistribution &joint)`  

        Construct a structure learner that will operate on the given joint
        distribution as an initial structure.  

        Note that the parameters of the initial joint distribution will not be used,
        only the structure.  

    * `plStructureLearner(const plVariablesConjunction &variables, const
        variable_edge_list_t &init_edges=variable_edge_list_t())`  

        Construct a structure learner that will operate on the given variables and
        the given initial structure.  

    * `plStructureLearner(const plStructureLearner &)`  

        Copy constructor.  

    C++ includes: plStructureLearner.h

    """

    __swig_setmethods__ = {}
    for _s in [plLearner]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plStructureLearner, name, value)
    __swig_getmethods__ = {}
    for _s in [plLearner]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plStructureLearner, name)
    __repr__ = _swig_repr

    def __init__(self, *args):
        """
        __init__(self, joint) -> plStructureLearner
        __init__(self, variables, init_edges) -> plStructureLearner
        __init__(self, variables) -> plStructureLearner
        __init__(self, arg2) -> plStructureLearner


        `plStructureLearner(const plJointDistribution &joint)`  
        `plStructureLearner(const plVariablesConjunction &variables, const
            variable_edge_list_t &init_edges=variable_edge_list_t())`  
        `plStructureLearner(const plStructureLearner &)`  

        Overloaded function
        -------------------
        * `plStructureLearner(const plJointDistribution &joint)`  

            Construct a structure learner that will operate on the given joint
            distribution as an initial structure.  

            Note that the parameters of the initial joint distribution will not be used,
            only the structure.  

        * `plStructureLearner(const plVariablesConjunction &variables, const
            variable_edge_list_t &init_edges=variable_edge_list_t())`  

            Construct a structure learner that will operate on the given variables and
            the given initial structure.  

        * `plStructureLearner(const plStructureLearner &)`  

            Copy constructor.  

        """
        this = _probt_python3.new_plStructureLearner(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this
    __swig_destroy__ = _probt_python3.delete_plStructureLearner
    __del__ = lambda self: None

    def DMST(self, *args) -> "bool":
        """
        DMST(self, score, vertex_order, root_node, included_edges, excluded_edges) -> bool
        DMST(self, score, vertex_order, root_node, included_edges) -> bool
        DMST(self, score, vertex_order, root_node) -> bool
        DMST(self, score, root_node, included_edges, excluded_edges) -> bool
        DMST(self, score, root_node, included_edges) -> bool
        DMST(self, score, root_node) -> bool


        `DMST(const plEdgeScore &score, std::vector< plVariable > &vertex_order, const
            plVariable &root_node, const variable_edge_list_t
            &included_edges=variable_edge_list_t(), const variable_edge_list_t
            &excluded_edges=variable_edge_list_t()) -> bool`  
        `DMST(const plEdgeScore &score, const plVariable &root_node, const
            variable_edge_list_t &included_edges=variable_edge_list_t(), const
            variable_edge_list_t &excluded_edges=variable_edge_list_t()) -> bool`  

        Overloaded function
        -------------------
        * `DMST(const plEdgeScore &score, std::vector< plVariable > &vertex_order, const
            plVariable &root_node, const variable_edge_list_t
            &included_edges=variable_edge_list_t(), const variable_edge_list_t
            &excluded_edges=variable_edge_list_t()) -> bool`  

            Learn the dependancy structure from the dataset using the Directed Minimum
            Spanning Tree algorithm.  

            If a structure was previously learned with this plStructureLearner, it is
            lost. To access the result of this algorithm, use the
            get_joint_distribution() method.  

            Parameters:  
            * `score` :  
                the chosen score function ;  
            * `vertex_order` :  
                the order of the vertices in the resulting tree (which is usefull as
                input to the K2 algorithm).  
            * `root_node` :  
                the root used for directing the edges ;  
            * `included_edges` :  
                mandatory edges (undirected) ;  
            * `excluded_edges` :  
                forbiden edges (undirected) ; Note that the included_edges and
                excluded_edges constraints can be incompatible with the choice of the
                tree root.  

            Returns:
            true if the included_edges and excluded_edges constraints could be respected
            given the chosen root_index.  

            See also: plEdgeScore and its derived classes.  

        * `DMST(const plEdgeScore &score, const plVariable &root_node, const
            variable_edge_list_t &included_edges=variable_edge_list_t(), const
            variable_edge_list_t &excluded_edges=variable_edge_list_t()) -> bool`  

            Learn the dependancy structure from the dataset using the Directed Minimum
            Spanning Tree algorithm.  

            If a structure was previously learned with this plStructureLearner, it is
            lost. To access the result of this algorithm, use the
            get_joint_distribution() method.  

            Parameters:  
            * `score` :  
                the chosen score function  
            * `root_node` :  
                the root used for directing the edges ;  
            * `included_edges` :  
                mandatory edges (undirected) ;  
            * `excluded_edges` :  
                forbiden edges (undirected) ; Note that the included_edges and
                excluded_edges constraints can be incompatible with the choice of the
                tree root.  

            Returns:
            true if the included_edges and excluded_edges constraints could be respected
            given the chosen root_index.  

            See also: plEdgeScore and its derived classes.  

        """
        return _probt_python3.plStructureLearner_DMST(self, *args)


    def K2(self, *args) -> "void":
        """
        K2(self, score, vertex_order, included_edges, excluded_edges, max_parents=100, max_parent_card=100000)
        K2(self, score, vertex_order, included_edges, excluded_edges, max_parents=100)
        K2(self, score, vertex_order, included_edges, excluded_edges)
        K2(self, score, vertex_order, included_edges)
        K2(self, score, vertex_order)


        `K2(const plNodeScore &score, const std::vector< plVariable > &vertex_order,
            const variable_edge_list_t &included_edges=variable_edge_list_t(), const
            variable_edge_list_t &excluded_edges=variable_edge_list_t(), unsigned int
            max_parents=100, unsigned int max_parent_card=100000)`  

        Learn the structure with the K2 algorithm.  

        If a structure was previously learned with this plStructureLearner, it is used
        as a starting point. To access the result of this algorithm, use the
        get_joint_distribution() method.  

        Parameters
        ----------
        * `score` :  
            the chosen score function ;  
        * `included_edges` :  
            mandatory edges (directed) ;  
        * `excluded_edges` :  
            forbiden edges (directed) ;  
        * `vertex_order` :  
            the order constraint on the graph vertices ;  
        * `max_parents` :  
            the maximum number of parents per node  
        * `max_parent_card` :  
            maximum parents cardinality  

        See also: plNodeScore and its derived classes.  

        """
        return _probt_python3.plStructureLearner_K2(self, *args)


    def GS(self, *args) -> "void":
        """
        GS(self, score, included_edges, excluded_edges, max_parents=100, max_parent_card=100000)
        GS(self, score, included_edges, excluded_edges, max_parents=100)
        GS(self, score, included_edges, excluded_edges)
        GS(self, score, included_edges)
        GS(self, score)


        `GS(const plNodeScore &score, const variable_edge_list_t
            &included_edges=variable_edge_list_t(), const variable_edge_list_t
            &excluded_edges=variable_edge_list_t(), unsigned int max_parents=100,
            unsigned int max_parent_card=100000)`  

        Learn the structure with the Greedy Search algorithm.  

        If a structure was previously learned with this plStructureLearner, it is used
        as a starting point. To access the result of this algorithm, use the
        get_joint_distribution() method.  

        Parameters
        ----------
        * `score` :  
            the chosen score function  
        * `max_parents` :  
            maximum number of parents  
        * `max_parent_card` :  
            maximum parents cardinality  
        * `included_edges` :  
            mandatory edges (directed);  
        * `excluded_edges` :  
            forbiden edges (directed);  

        See also: plNodeScore and its derived classes.  

        """
        return _probt_python3.plStructureLearner_GS(self, *args)


    def get_joint_distribution(self, data_desc: 'plDataDescriptor') -> "plJointDistribution":
        """
        get_joint_distribution(self, data_desc) -> plJointDistribution


        `get_joint_distribution(plDataDescriptor &data_desc) const ->
            plJointDistribution`  

        Perform the parameter learning, and returns the joint distribution.  

        Parameters
        ----------
        * `data_desc` :  
            the data descriptor (for learning the parameters).  

        Returns
        -------
        a joint distribution corresponding to the dependancy structure obtained with
        DMST(), K2() or GS() and the probability tables learned from the data with the
        Laplace succession rule.  

        """
        return _probt_python3.plStructureLearner_get_joint_distribution(self, data_desc)


    def get_variables(self) -> "plVariablesConjunction const &":
        """
        get_variables(self) -> plVariablesConjunction


        `get_variables() const -> plVariablesConjunction const  &`  

        Returns the variables passed when the object was constructed.  

        """
        return _probt_python3.plStructureLearner_get_variables(self)


    def get_edges(self) -> "std::vector< std::pair< plVariable,plVariable >,std::allocator< std::pair< plVariable,plVariable > > >":
        """
        get_edges(self) -> plBnEdgeList


        `get_edges() const -> std::vector< std::pair< plVariable, plVariable > >`  

        Get the current structure edges.  

        """
        return _probt_python3.plStructureLearner_get_edges(self)


    def set_verbose(self, verbose: 'bool') -> "void":
        """
        set_verbose(self, verbose)


        `set_verbose(bool verbose)`  

        Set/unset verbose mode.  

        """
        return _probt_python3.plStructureLearner_set_verbose(self, verbose)

plStructureLearner_swigregister = _probt_python3.plStructureLearner_swigregister
plStructureLearner_swigregister(plStructureLearner)

class plScore(_object):
    """

    `plScore()`  

    Base-class for scores.  

    See also: class plStructureLearner.  

    Constructors
    ------------
    * `plScore()`  

    C++ includes: plScores.h

    """

    __swig_setmethods__ = {}
    __setattr__ = lambda self, name, value: _swig_setattr(self, plScore, name, value)
    __swig_getmethods__ = {}
    __getattr__ = lambda self, name: _swig_getattr(self, plScore, name)
    __repr__ = _swig_repr

    def __init__(self):
        """
        __init__(self) -> plScore


        `plScore()`  

        """
        this = _probt_python3.new_plScore()
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this
    __swig_destroy__ = _probt_python3.delete_plScore
    __del__ = lambda self: None
plScore_swigregister = _probt_python3.plScore_swigregister
plScore_swigregister(plScore)

class plNodeScore(plScore):
    """

    `plNodeScore()`  

    Base-class for decomposable node scores.  

    See also: class plStructureLearner.  

    Constructors
    ------------
    * `plNodeScore()`  

    C++ includes: plScores.h

    """

    __swig_setmethods__ = {}
    for _s in [plScore]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plNodeScore, name, value)
    __swig_getmethods__ = {}
    for _s in [plScore]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plNodeScore, name)

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined - class is abstract")
    __repr__ = _swig_repr

    def __call__(self, *args) -> "plFloat":
        """
        __call__(self, node, parents) -> plFloat
        __call__(self, jd) -> plFloat
        """
        return _probt_python3.plNodeScore___call__(self, *args)

    __swig_destroy__ = _probt_python3.delete_plNodeScore
    __del__ = lambda self: None
plNodeScore_swigregister = _probt_python3.plNodeScore_swigregister
plNodeScore_swigregister(plNodeScore)

class plNodeScore_t(plNodeScore):
    """

    `plNodeScore_t(plDataDescriptor &data_desc)`  

    Base-class template for node scores operating on datasets.  

    This provides storage for the data descriptor.  

    Constructors
    ------------
    * `plNodeScore_t(plDataDescriptor &data_desc)`  

        Construct a node score object operating on a given dataset.  

        Parameters:  
        * `data_desc` :  
            the data descriptor ;  

        Note that the object keeps a reference to the dataset, so don't destroy it
        during the lifetime of the score object.  

    C++ includes: plScores.h

    """

    __swig_setmethods__ = {}
    for _s in [plNodeScore]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plNodeScore_t, name, value)
    __swig_getmethods__ = {}
    for _s in [plNodeScore]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plNodeScore_t, name)

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined - class is abstract")
    __repr__ = _swig_repr
    __swig_destroy__ = _probt_python3.delete_plNodeScore_t
    __del__ = lambda self: None
plNodeScore_t_swigregister = _probt_python3.plNodeScore_t_swigregister
plNodeScore_t_swigregister(plNodeScore_t)

class plNodeScoreAIC(plNodeScore_t):
    """

    `plNodeScoreAIC(plDataDescriptor &data_desc)`  

    Akaike's Information Criterion.  

    Constructors
    ------------
    * `plNodeScoreAIC(plDataDescriptor &data_desc)`  

        Construct a node score object using Akaike's Information Criterion, for
        evaluating a model's performance with respect to a dataset.  

        Parameters:  
        * `data_desc` :  
            the data descriptor  

        Note that the object keeps a reference to the dataset, so don't destroy it
        during the lifetime of the score object.  

    C++ includes: plScores.h

    """

    __swig_setmethods__ = {}
    for _s in [plNodeScore_t]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plNodeScoreAIC, name, value)
    __swig_getmethods__ = {}
    for _s in [plNodeScore_t]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plNodeScoreAIC, name)
    __repr__ = _swig_repr

    def __init__(self, data_desc: 'plDataDescriptor'):
        """
        __init__(self, data_desc) -> plNodeScoreAIC


        `plNodeScoreAIC(plDataDescriptor &data_desc)`  

        Construct a node score object using Akaike's Information Criterion, for
        evaluating a model's performance with respect to a dataset.  

        Parameters
        ----------
        * `data_desc` :  
            the data descriptor  

        Note that the object keeps a reference to the dataset, so don't destroy it
        during the lifetime of the score object.  

        """
        this = _probt_python3.new_plNodeScoreAIC(data_desc)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def __call__(self, *args) -> "plFloat":
        """
        __call__(self, node, parents) -> plFloat
        __call__(self, jd) -> plFloat
        """
        return _probt_python3.plNodeScoreAIC___call__(self, *args)

    __swig_destroy__ = _probt_python3.delete_plNodeScoreAIC
    __del__ = lambda self: None
plNodeScoreAIC_swigregister = _probt_python3.plNodeScoreAIC_swigregister
plNodeScoreAIC_swigregister(plNodeScoreAIC)

class plNodeScoreBIC(plNodeScore_t):
    """

    `plNodeScoreBIC(plDataDescriptor &data_desc)`  

    Bayesian Information Criterion.  

    Constructors
    ------------
    * `plNodeScoreBIC(plDataDescriptor &data_desc)`  

        Construct a node score object using the Bayesian Information Criterion, for
        evaluating a model's performance with respect to a dataset.  

        Parameters:  
        * `data_desc` :  
            the data descriptor  

        Note that the object keeps a reference to the dataset, so don't destroy it
        during the lifetime of the score object.  

    C++ includes: plScores.h

    """

    __swig_setmethods__ = {}
    for _s in [plNodeScore_t]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plNodeScoreBIC, name, value)
    __swig_getmethods__ = {}
    for _s in [plNodeScore_t]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plNodeScoreBIC, name)
    __repr__ = _swig_repr

    def __init__(self, data_desc: 'plDataDescriptor'):
        """
        __init__(self, data_desc) -> plNodeScoreBIC


        `plNodeScoreBIC(plDataDescriptor &data_desc)`  

        Construct a node score object using the Bayesian Information Criterion, for
        evaluating a model's performance with respect to a dataset.  

        Parameters
        ----------
        * `data_desc` :  
            the data descriptor  

        Note that the object keeps a reference to the dataset, so don't destroy it
        during the lifetime of the score object.  

        """
        this = _probt_python3.new_plNodeScoreBIC(data_desc)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def __call__(self, *args) -> "plFloat":
        """
        __call__(self, node, parents) -> plFloat
        __call__(self, jd) -> plFloat
        """
        return _probt_python3.plNodeScoreBIC___call__(self, *args)

    __swig_destroy__ = _probt_python3.delete_plNodeScoreBIC
    __del__ = lambda self: None
plNodeScoreBIC_swigregister = _probt_python3.plNodeScoreBIC_swigregister
plNodeScoreBIC_swigregister(plNodeScoreBIC)

class plNodeScoreBDeu(plNodeScore_t):
    """

    `plNodeScoreBDeu(plDataDescriptor &data_desc, plFloat Nprime)`  

    Bayesian Dirichlet Equivalent Uniform.  

    Constructors
    ------------
    * `plNodeScoreBDeu(plDataDescriptor &data_desc, plFloat Nprime)`  

        Construct a node score object using the Bayesian Dirichlet Equivalent
        Uniform criterion, for evaluating a model's performance with respect to a
        dataset.  

        Parameters:  
        * `data_desc` :  
            the data descriptor  
        * `Nprime` :  
            parameter used for defining the bayesian prior.  

        Note that the object keeps a reference to the dataset, so don't destroy it
        during the lifetime of the score object.  

    C++ includes: plScores.h

    """

    __swig_setmethods__ = {}
    for _s in [plNodeScore_t]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plNodeScoreBDeu, name, value)
    __swig_getmethods__ = {}
    for _s in [plNodeScore_t]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plNodeScoreBDeu, name)
    __repr__ = _swig_repr

    def __init__(self, data_desc: 'plDataDescriptor', Nprime: 'plFloat'):
        """
        __init__(self, data_desc, Nprime) -> plNodeScoreBDeu


        `plNodeScoreBDeu(plDataDescriptor &data_desc, plFloat Nprime)`  

        Construct a node score object using the Bayesian Dirichlet Equivalent Uniform
        criterion, for evaluating a model's performance with respect to a dataset.  

        Parameters
        ----------
        * `data_desc` :  
            the data descriptor  
        * `Nprime` :  
            parameter used for defining the bayesian prior.  

        Note that the object keeps a reference to the dataset, so don't destroy it
        during the lifetime of the score object.  

        """
        this = _probt_python3.new_plNodeScoreBDeu(data_desc, Nprime)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def __call__(self, *args) -> "plFloat":
        """
        __call__(self, node, parents) -> plFloat
        __call__(self, jd) -> plFloat
        """
        return _probt_python3.plNodeScoreBDeu___call__(self, *args)

    __swig_destroy__ = _probt_python3.delete_plNodeScoreBDeu
    __del__ = lambda self: None
plNodeScoreBDeu_swigregister = _probt_python3.plNodeScoreBDeu_swigregister
plNodeScoreBDeu_swigregister(plNodeScoreBDeu)

class plNodeScoreMDL(plNodeScore_t):
    """

    `plNodeScoreMDL(plDataDescriptor &data_desc)`  

    Minimum Description Length.  

    Constructors
    ------------
    * `plNodeScoreMDL(plDataDescriptor &data_desc)`  

        Construct a node score object using the Minimum Description Length, for
        evaluating a model's performance with respect to a dataset.  

        Parameters:  
        * `data_desc` :  
            the data descriptor  

        Note that the object keeps a reference to the dataset, so don't destroy it
        during the lifetime of the score object.  

    C++ includes: plScores.h

    """

    __swig_setmethods__ = {}
    for _s in [plNodeScore_t]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plNodeScoreMDL, name, value)
    __swig_getmethods__ = {}
    for _s in [plNodeScore_t]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plNodeScoreMDL, name)
    __repr__ = _swig_repr

    def __init__(self, data_desc: 'plDataDescriptor'):
        """
        __init__(self, data_desc) -> plNodeScoreMDL


        `plNodeScoreMDL(plDataDescriptor &data_desc)`  

        Construct a node score object using the Minimum Description Length, for
        evaluating a model's performance with respect to a dataset.  

        Parameters
        ----------
        * `data_desc` :  
            the data descriptor  

        Note that the object keeps a reference to the dataset, so don't destroy it
        during the lifetime of the score object.  

        """
        this = _probt_python3.new_plNodeScoreMDL(data_desc)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def __call__(self, *args) -> "plFloat":
        """
        __call__(self, node, parents) -> plFloat
        __call__(self, jd) -> plFloat
        """
        return _probt_python3.plNodeScoreMDL___call__(self, *args)

    __swig_destroy__ = _probt_python3.delete_plNodeScoreMDL
    __del__ = lambda self: None
plNodeScoreMDL_swigregister = _probt_python3.plNodeScoreMDL_swigregister
plNodeScoreMDL_swigregister(plNodeScoreMDL)

class plEdgeScore(plScore):
    """

    `plEdgeScore()`  
    `plEdgeScore(const plVariablesConjunction &conditioning_variables)`  

    Base-class for decomposable edge scores.  

    See also: class plStructureLearner.  

    Constructors
    ------------
    * `plEdgeScore()`  

        Default constructor.  

    * `plEdgeScore(const plVariablesConjunction &conditioning_variables)`  

        Constructor using conditioning variables.  

    C++ includes: plScores.h

    """

    __swig_setmethods__ = {}
    for _s in [plScore]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plEdgeScore, name, value)
    __swig_getmethods__ = {}
    for _s in [plScore]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plEdgeScore, name)

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined - class is abstract")
    __repr__ = _swig_repr

    def __call__(self, *args) -> "plFloat":
        """
        __call__(self, A, B) -> plFloat
        __call__(self, A, B, C) -> plFloat
        __call__(self, jd) -> plFloat
        """
        return _probt_python3.plEdgeScore___call__(self, *args)

    __swig_destroy__ = _probt_python3.delete_plEdgeScore
    __del__ = lambda self: None
plEdgeScore_swigregister = _probt_python3.plEdgeScore_swigregister
plEdgeScore_swigregister(plEdgeScore)

class plEdgeScoreMI(plEdgeScore):
    """

    `plEdgeScoreMI(plDataDescriptor &data_desc)`  
    `plEdgeScoreMI(plDataDescriptor &data_desc, const plVariablesConjunction
        &conditioning_variables)`  

    Mutual Information.  

    Constructors
    ------------
    * `plEdgeScoreMI(plDataDescriptor &data_desc)`  

        Construct a Mutual information edge score object operating on a given
        dataset.  

        Parameters:  
        * `data_desc` :  
            the data descriptor ;  

        Note that the object keeps a reference to the dataset, so don't destroy it
        during the lifetime of the score object.  

    * `plEdgeScoreMI(plDataDescriptor &data_desc, const plVariablesConjunction
        &conditioning_variables)`  

        Constructor using conditioning variables.  

    C++ includes: plScores.h

    """

    __swig_setmethods__ = {}
    for _s in [plEdgeScore]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plEdgeScoreMI, name, value)
    __swig_getmethods__ = {}
    for _s in [plEdgeScore]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plEdgeScoreMI, name)
    __repr__ = _swig_repr

    def __init__(self, *args):
        """
        __init__(self, data_desc) -> plEdgeScoreMI
        __init__(self, data_desc, conditioning_variables) -> plEdgeScoreMI


        `plEdgeScoreMI(plDataDescriptor &data_desc)`  
        `plEdgeScoreMI(plDataDescriptor &data_desc, const plVariablesConjunction
            &conditioning_variables)`  

        Overloaded function
        -------------------
        * `plEdgeScoreMI(plDataDescriptor &data_desc)`  

            Construct a Mutual information edge score object operating on a given
            dataset.  

            Parameters:  
            * `data_desc` :  
                the data descriptor ;  

            Note that the object keeps a reference to the dataset, so don't destroy it
            during the lifetime of the score object.  

        * `plEdgeScoreMI(plDataDescriptor &data_desc, const plVariablesConjunction
            &conditioning_variables)`  

            Constructor using conditioning variables.  

        """
        this = _probt_python3.new_plEdgeScoreMI(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def __call__(self, *args) -> "plFloat":
        """
        __call__(self, A, B) -> plFloat
        __call__(self, A, B, C) -> plFloat
        __call__(self, jd) -> plFloat
        """
        return _probt_python3.plEdgeScoreMI___call__(self, *args)

    __swig_destroy__ = _probt_python3.delete_plEdgeScoreMI
    __del__ = lambda self: None
plEdgeScoreMI_swigregister = _probt_python3.plEdgeScoreMI_swigregister
plEdgeScoreMI_swigregister(plEdgeScoreMI)

class plEdgeScoreMIDistance(plEdgeScore):
    """

    `plEdgeScoreMIDistance(plDataDescriptor &data_desc)`  
    `plEdgeScoreMIDistance(plDataDescriptor &data_desc, const plVariablesConjunction
        &conditioning_variables)`  

    Normalized metric variant of the Mutual Information.  

    D(X,Y) = I(X,Y) / H(X,Y)  

    Constructors
    ------------
    * `plEdgeScoreMIDistance(plDataDescriptor &data_desc)`  

        Construct a mutual information distance edge score object operating on a
        given dataset.  

        Parameters:  
        * `data_desc` :  
            the data descriptor ;  

        Note that the object keeps a reference to the dataset, so don't destroy it
        during the lifetime of the score object.  

    * `plEdgeScoreMIDistance(plDataDescriptor &data_desc, const
        plVariablesConjunction &conditioning_variables)`  

        Constructor using conditioning variables.  

    C++ includes: plScores.h

    """

    __swig_setmethods__ = {}
    for _s in [plEdgeScore]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plEdgeScoreMIDistance, name, value)
    __swig_getmethods__ = {}
    for _s in [plEdgeScore]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plEdgeScoreMIDistance, name)
    __repr__ = _swig_repr

    def __init__(self, *args):
        """
        __init__(self, data_desc) -> plEdgeScoreMIDistance
        __init__(self, data_desc, conditioning_variables) -> plEdgeScoreMIDistance


        `plEdgeScoreMIDistance(plDataDescriptor &data_desc)`  
        `plEdgeScoreMIDistance(plDataDescriptor &data_desc, const plVariablesConjunction
            &conditioning_variables)`  

        Overloaded function
        -------------------
        * `plEdgeScoreMIDistance(plDataDescriptor &data_desc)`  

            Construct a mutual information distance edge score object operating on a
            given dataset.  

            Parameters:  
            * `data_desc` :  
                the data descriptor ;  

            Note that the object keeps a reference to the dataset, so don't destroy it
            during the lifetime of the score object.  

        * `plEdgeScoreMIDistance(plDataDescriptor &data_desc, const
            plVariablesConjunction &conditioning_variables)`  

            Constructor using conditioning variables.  

        """
        this = _probt_python3.new_plEdgeScoreMIDistance(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def __call__(self, *args) -> "plFloat":
        """
        __call__(self, A, B) -> plFloat
        __call__(self, A, B, C) -> plFloat
        __call__(self, jd) -> plFloat
        """
        return _probt_python3.plEdgeScoreMIDistance___call__(self, *args)

    __swig_destroy__ = _probt_python3.delete_plEdgeScoreMIDistance
    __del__ = lambda self: None
plEdgeScoreMIDistance_swigregister = _probt_python3.plEdgeScoreMIDistance_swigregister
plEdgeScoreMIDistance_swigregister(plEdgeScoreMIDistance)

class plEdgeScoreEntropy(plEdgeScore):
    """

    `plEdgeScoreEntropy(plDataDescriptor &data_desc)`  
    `plEdgeScoreEntropy(plDataDescriptor &data_desc, const plVariablesConjunction
        &conditioning_variables)`  

    Entropy.  

    Constructors
    ------------
    * `plEdgeScoreEntropy(plDataDescriptor &data_desc)`  

        Construct an Entropy edge score object operating on a given dataset.  

        Parameters:  
        * `data_desc` :  
            the data descriptor ;  

        Note that the object keeps a reference to the dataset, so don't destroy it
        during the lifetime of the score object.  

    * `plEdgeScoreEntropy(plDataDescriptor &data_desc, const plVariablesConjunction
        &conditioning_variables)`  

        Constructor using conditioning variables.  

    C++ includes: plScores.h

    """

    __swig_setmethods__ = {}
    for _s in [plEdgeScore]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plEdgeScoreEntropy, name, value)
    __swig_getmethods__ = {}
    for _s in [plEdgeScore]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plEdgeScoreEntropy, name)
    __repr__ = _swig_repr

    def __init__(self, *args):
        """
        __init__(self, data_desc) -> plEdgeScoreEntropy
        __init__(self, data_desc, conditioning_variables) -> plEdgeScoreEntropy


        `plEdgeScoreEntropy(plDataDescriptor &data_desc)`  
        `plEdgeScoreEntropy(plDataDescriptor &data_desc, const plVariablesConjunction
            &conditioning_variables)`  

        Overloaded function
        -------------------
        * `plEdgeScoreEntropy(plDataDescriptor &data_desc)`  

            Construct an Entropy edge score object operating on a given dataset.  

            Parameters:  
            * `data_desc` :  
                the data descriptor ;  

            Note that the object keeps a reference to the dataset, so don't destroy it
            during the lifetime of the score object.  

        * `plEdgeScoreEntropy(plDataDescriptor &data_desc, const plVariablesConjunction
            &conditioning_variables)`  

            Constructor using conditioning variables.  

        """
        this = _probt_python3.new_plEdgeScoreEntropy(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def __call__(self, *args) -> "plFloat":
        """
        __call__(self, A, B) -> plFloat
        __call__(self, A, B, C) -> plFloat
        __call__(self, jd) -> plFloat
        """
        return _probt_python3.plEdgeScoreEntropy___call__(self, *args)

    __swig_destroy__ = _probt_python3.delete_plEdgeScoreEntropy
    __del__ = lambda self: None
plEdgeScoreEntropy_swigregister = _probt_python3.plEdgeScoreEntropy_swigregister
plEdgeScoreEntropy_swigregister(plEdgeScoreEntropy)

class plEdgeScoreAIC(_object):
    """

    `plEdgeScoreAIC(plDataDescriptor &data_desc)`  
    `plEdgeScoreAIC(plDataDescriptor &data_desc, const plVariablesConjunction
        &conditioning_variables)`  

    Akaike's Information Criterion used as an edge score.  

    See also: plNodeScoreAIC, plEdgeScoreFromNodeScore.  

    Constructors
    ------------
    * `plEdgeScoreAIC(plDataDescriptor &data_desc)`  

        Construct an AIC edge score object operating on a given dataset.  

        Parameters:  
        * `data_desc` :  
            the data descriptor ;  

        Note that the object keeps a reference to the dataset, so don't destroy it
        during the lifetime of the score object.  

    * `plEdgeScoreAIC(plDataDescriptor &data_desc, const plVariablesConjunction
        &conditioning_variables)`  

        Construct an AIC edge score object operating on a given dataset.  

        Parameters:  
        * `data_desc` :  
            the data descriptor ;  
        * `conditioning_variables` :  
            the variables condioning the score If this parameter is not empty, the
            score is assumed to be conditional Note that the object keeps a
            reference to the dataset, so don't destroy it during the lifetime of the
            score object.  

    C++ includes: plScores.h

    """

    __swig_setmethods__ = {}
    __setattr__ = lambda self, name, value: _swig_setattr(self, plEdgeScoreAIC, name, value)
    __swig_getmethods__ = {}
    __getattr__ = lambda self, name: _swig_getattr(self, plEdgeScoreAIC, name)
    __repr__ = _swig_repr

    def __init__(self, *args):
        """
        __init__(self, data_desc) -> plEdgeScoreAIC
        __init__(self, data_desc, conditioning_variables) -> plEdgeScoreAIC


        `plEdgeScoreAIC(plDataDescriptor &data_desc)`  
        `plEdgeScoreAIC(plDataDescriptor &data_desc, const plVariablesConjunction
            &conditioning_variables)`  

        Overloaded function
        -------------------
        * `plEdgeScoreAIC(plDataDescriptor &data_desc)`  

            Construct an AIC edge score object operating on a given dataset.  

            Parameters:  
            * `data_desc` :  
                the data descriptor ;  

            Note that the object keeps a reference to the dataset, so don't destroy it
            during the lifetime of the score object.  

        * `plEdgeScoreAIC(plDataDescriptor &data_desc, const plVariablesConjunction
            &conditioning_variables)`  

            Construct an AIC edge score object operating on a given dataset.  

            Parameters:  
            * `data_desc` :  
                the data descriptor ;  
            * `conditioning_variables` :  
                the variables condioning the score If this parameter is not empty, the
                score is assumed to be conditional Note that the object keeps a
                reference to the dataset, so don't destroy it during the lifetime of the
                score object.  

        """
        this = _probt_python3.new_plEdgeScoreAIC(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this
    __swig_destroy__ = _probt_python3.delete_plEdgeScoreAIC
    __del__ = lambda self: None
plEdgeScoreAIC_swigregister = _probt_python3.plEdgeScoreAIC_swigregister
plEdgeScoreAIC_swigregister(plEdgeScoreAIC)

class plEdgeScoreBIC(_object):
    """

    `plEdgeScoreBIC(plDataDescriptor &data_desc)`  
    `plEdgeScoreBIC(plDataDescriptor &data_desc, const plVariablesConjunction
        &conditioning_variables)`  

    Bayesian Information Criterian used as an edge score.  

    See also: plNodeScoreBIC, plEdgeScoreFromNodeScore.  

    Constructors
    ------------
    * `plEdgeScoreBIC(plDataDescriptor &data_desc)`  

        Construct a BIC edge score object operating on a given dataset.  

        Parameters:  
        * `data_desc` :  
            the data descriptor ;  

        Note that the object keeps a reference to the dataset, so don't destroy it
        during the lifetime of the score object.  

    * `plEdgeScoreBIC(plDataDescriptor &data_desc, const plVariablesConjunction
        &conditioning_variables)`  

        Construct a BIC edge score object operating on a given dataset.  

        Parameters:  
        * `data_desc` :  
            the data descriptor ;  
        * `conditioning_variables` :  
            the variables condioning the score If this parameter is not empty, the
            score is assumed to be conditional  

        Note that the object keeps a reference to the dataset, so don't destroy it
        during the lifetime of the score object.  

    C++ includes: plScores.h

    """

    __swig_setmethods__ = {}
    __setattr__ = lambda self, name, value: _swig_setattr(self, plEdgeScoreBIC, name, value)
    __swig_getmethods__ = {}
    __getattr__ = lambda self, name: _swig_getattr(self, plEdgeScoreBIC, name)
    __repr__ = _swig_repr

    def __init__(self, *args):
        """
        __init__(self, data_desc) -> plEdgeScoreBIC
        __init__(self, data_desc, conditioning_variables) -> plEdgeScoreBIC


        `plEdgeScoreBIC(plDataDescriptor &data_desc)`  
        `plEdgeScoreBIC(plDataDescriptor &data_desc, const plVariablesConjunction
            &conditioning_variables)`  

        Overloaded function
        -------------------
        * `plEdgeScoreBIC(plDataDescriptor &data_desc)`  

            Construct a BIC edge score object operating on a given dataset.  

            Parameters:  
            * `data_desc` :  
                the data descriptor ;  

            Note that the object keeps a reference to the dataset, so don't destroy it
            during the lifetime of the score object.  

        * `plEdgeScoreBIC(plDataDescriptor &data_desc, const plVariablesConjunction
            &conditioning_variables)`  

            Construct a BIC edge score object operating on a given dataset.  

            Parameters:  
            * `data_desc` :  
                the data descriptor ;  
            * `conditioning_variables` :  
                the variables condioning the score If this parameter is not empty, the
                score is assumed to be conditional  

            Note that the object keeps a reference to the dataset, so don't destroy it
            during the lifetime of the score object.  

        """
        this = _probt_python3.new_plEdgeScoreBIC(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this
    __swig_destroy__ = _probt_python3.delete_plEdgeScoreBIC
    __del__ = lambda self: None
plEdgeScoreBIC_swigregister = _probt_python3.plEdgeScoreBIC_swigregister
plEdgeScoreBIC_swigregister(plEdgeScoreBIC)

class plEdgeScoreBDeu(_object):
    """

    `plEdgeScoreBDeu(plDataDescriptor &data_desc, plFloat Nprime)`  
    `plEdgeScoreBDeu(plDataDescriptor &data_desc, plFloat Nprime, const
        plVariablesConjunction &conditioning_variables)`  

    Bayesian Dirichlet Equivalent Uniform used as an edge score.  

    See also: plNodeScoreBDeu, plEdgeScoreFromNodeScore.  

    Constructors
    ------------
    * `plEdgeScoreBDeu(plDataDescriptor &data_desc, plFloat Nprime)`  

        Construct a BDeu edge score object operating on a given dataset.  

        Parameters:  
        * `data_desc` :  
            the data descriptor ;  
        * `Nprime` :  
            parameter used for defining the bayesian prior.  

        Note that the object keeps a reference to the dataset, so don't destroy it
        during the lifetime of the score object.  

    * `plEdgeScoreBDeu(plDataDescriptor &data_desc, plFloat Nprime, const
        plVariablesConjunction &conditioning_variables)`  

        Construct a BDeu edge score object operating on a given dataset.  

        Parameters:  
        * `data_desc` :  
            the data descriptor ;  
        * `Nprime` :  
            parameter used for defining the bayesian prior.  
        * `conditioning_variables` :  
            the variables condioning the score If this parameter is not empty, the
            score is assumed to be conditional  

        Note that the object keeps a reference to the dataset, so don't destroy it
        during the lifetime of the score object.  

    C++ includes: plScores.h

    """

    __swig_setmethods__ = {}
    __setattr__ = lambda self, name, value: _swig_setattr(self, plEdgeScoreBDeu, name, value)
    __swig_getmethods__ = {}
    __getattr__ = lambda self, name: _swig_getattr(self, plEdgeScoreBDeu, name)
    __repr__ = _swig_repr

    def __init__(self, *args):
        """
        __init__(self, data_desc, Nprime) -> plEdgeScoreBDeu
        __init__(self, data_desc, Nprime, conditioning_variables) -> plEdgeScoreBDeu


        `plEdgeScoreBDeu(plDataDescriptor &data_desc, plFloat Nprime)`  
        `plEdgeScoreBDeu(plDataDescriptor &data_desc, plFloat Nprime, const
            plVariablesConjunction &conditioning_variables)`  

        Overloaded function
        -------------------
        * `plEdgeScoreBDeu(plDataDescriptor &data_desc, plFloat Nprime)`  

            Construct a BDeu edge score object operating on a given dataset.  

            Parameters:  
            * `data_desc` :  
                the data descriptor ;  
            * `Nprime` :  
                parameter used for defining the bayesian prior.  

            Note that the object keeps a reference to the dataset, so don't destroy it
            during the lifetime of the score object.  

        * `plEdgeScoreBDeu(plDataDescriptor &data_desc, plFloat Nprime, const
            plVariablesConjunction &conditioning_variables)`  

            Construct a BDeu edge score object operating on a given dataset.  

            Parameters:  
            * `data_desc` :  
                the data descriptor ;  
            * `Nprime` :  
                parameter used for defining the bayesian prior.  
            * `conditioning_variables` :  
                the variables condioning the score If this parameter is not empty, the
                score is assumed to be conditional  

            Note that the object keeps a reference to the dataset, so don't destroy it
            during the lifetime of the score object.  

        """
        this = _probt_python3.new_plEdgeScoreBDeu(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this
    __swig_destroy__ = _probt_python3.delete_plEdgeScoreBDeu
    __del__ = lambda self: None
plEdgeScoreBDeu_swigregister = _probt_python3.plEdgeScoreBDeu_swigregister
plEdgeScoreBDeu_swigregister(plEdgeScoreBDeu)

class plEdgeScoreMDL(_object):
    """

    `plEdgeScoreMDL(plDataDescriptor &data_desc)`  
    `plEdgeScoreMDL(plDataDescriptor &data_desc, const plVariablesConjunction
        &conditioning_variables)`  

    Minimum Description Length used as an edge score.  

    See also: plNodeScoreMDL, plEdgeScoreFromNodeScore.  

    Constructors
    ------------
    * `plEdgeScoreMDL(plDataDescriptor &data_desc)`  

        Construct an MDL edge score object operating on a given dataset.  

        Parameters:  
        * `data_desc` :  
            the data descriptor ;  

        Note that the object keeps a reference to the dataset, so don't destroy it
        during the lifetime of the score object.  

    * `plEdgeScoreMDL(plDataDescriptor &data_desc, const plVariablesConjunction
        &conditioning_variables)`  

        Construct an MDL edge score object operating on a given dataset.  

        Parameters:  
        * `data_desc` :  
            the data descriptor ;  
        * `conditioning_variables` :  
            the variables condioning the score If this parameter is not empty, the
            score is assumed to be conditional  

        Note that the object keeps a reference to the dataset, so don't destroy it
        during the lifetime of the score object.  

    C++ includes: plScores.h

    """

    __swig_setmethods__ = {}
    __setattr__ = lambda self, name, value: _swig_setattr(self, plEdgeScoreMDL, name, value)
    __swig_getmethods__ = {}
    __getattr__ = lambda self, name: _swig_getattr(self, plEdgeScoreMDL, name)
    __repr__ = _swig_repr

    def __init__(self, *args):
        """
        __init__(self, data_desc) -> plEdgeScoreMDL
        __init__(self, data_desc, conditioning_variables) -> plEdgeScoreMDL


        `plEdgeScoreMDL(plDataDescriptor &data_desc)`  
        `plEdgeScoreMDL(plDataDescriptor &data_desc, const plVariablesConjunction
            &conditioning_variables)`  

        Overloaded function
        -------------------
        * `plEdgeScoreMDL(plDataDescriptor &data_desc)`  

            Construct an MDL edge score object operating on a given dataset.  

            Parameters:  
            * `data_desc` :  
                the data descriptor ;  

            Note that the object keeps a reference to the dataset, so don't destroy it
            during the lifetime of the score object.  

        * `plEdgeScoreMDL(plDataDescriptor &data_desc, const plVariablesConjunction
            &conditioning_variables)`  

            Construct an MDL edge score object operating on a given dataset.  

            Parameters:  
            * `data_desc` :  
                the data descriptor ;  
            * `conditioning_variables` :  
                the variables condioning the score If this parameter is not empty, the
                score is assumed to be conditional  

            Note that the object keeps a reference to the dataset, so don't destroy it
            during the lifetime of the score object.  

        """
        this = _probt_python3.new_plEdgeScoreMDL(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this
    __swig_destroy__ = _probt_python3.delete_plEdgeScoreMDL
    __del__ = lambda self: None
plEdgeScoreMDL_swigregister = _probt_python3.plEdgeScoreMDL_swigregister
plEdgeScoreMDL_swigregister(plEdgeScoreMDL)

class plSerializer(_object):
    """

    `plPythonSerializer()`  
    `plPythonSerializer(PyObject *dict, PyObject *name)`  

    Specialisation of plSerializer to use with the Python bindings.  

    Constructors
    ------------
    * `plPythonSerializer()`  

    * `plPythonSerializer(PyObject *dict, PyObject *name)`  

        Construct from a Python dictionary.  

    C++ includes: plPythonSerializer.h

    """

    __swig_setmethods__ = {}
    __setattr__ = lambda self, name, value: _swig_setattr(self, plSerializer, name, value)
    __swig_getmethods__ = {}
    __getattr__ = lambda self, name: _swig_getattr(self, plSerializer, name)
    __repr__ = _swig_repr

    def PYSTRING_ASSTRING(o: 'PyObject *', s: 'std::string &') -> "bool":
        """
        PYSTRING_ASSTRING(o, s) -> bool


        `PYSTRING_ASSTRING(PyObject *o, std::string &s) -> bool`  

        """
        return _probt_python3.plSerializer_PYSTRING_ASSTRING(o, s)

    PYSTRING_ASSTRING = staticmethod(PYSTRING_ASSTRING)
    __swig_destroy__ = _probt_python3.delete_plSerializer
    __del__ = lambda self: None

    def __init__(self, *args):
        """
        __init__(self) -> plSerializer
        __init__(self, dict, name) -> plSerializer


        `plPythonSerializer()`  
        `plPythonSerializer(PyObject *dict, PyObject *name)`  

        Overloaded function
        -------------------
        * `plPythonSerializer()`  

        * `plPythonSerializer(PyObject *dict, PyObject *name)`  

            Construct from a Python dictionary.  

        """
        this = _probt_python3.new_plSerializer(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def clear(self) -> "void":
        """
        clear(self)


        `clear()`  

        Delete all previously stored objects.  

        """
        return _probt_python3.plSerializer_clear(self)


    def add_object(self, name: 'PyObject *', object: 'PyObject *') -> "PyObject *":
        """
        add_object(self, name, object) -> PyObject *


        `add_object(PyObject *name, PyObject *object) -> PyObject *`  

        Add an object in the map, without cloning it.  

        """
        return _probt_python3.plSerializer_add_object(self, name, object)


    def get_object(self, name: 'PyObject *') -> "PyObject *":
        """
        get_object(self, name) -> PyObject *


        `get_object(PyObject *name) -> PyObject *`  

        Get one object from the map, or None if it does not exist.  

        """
        return _probt_python3.plSerializer_get_object(self, name)


    def get_all_objects_map(self) -> "PyObject *":
        """
        get_all_objects_map(self) -> PyObject *


        `get_all_objects_map() -> PyObject *`  

        Get all contained objects as a Python map.  

        """
        return _probt_python3.plSerializer_get_all_objects_map(self)


    def save_to_string(self, *args) -> "PyObject *":
        """
        save_to_string(self, format) -> PyObject
        save_to_string(self) -> PyObject *


        `save_to_string(plSerializer::ArchiveType format=PL_DEFAULT_ARCHIVE) const ->
            PyObject *`  

        Serialize the contained objects, and return the archive as a Python string.  

        """
        return _probt_python3.plSerializer_save_to_string(self, *args)


    def load_from_string(self, *args) -> "void":
        """
        load_from_string(self, str, format)
        load_from_string(self, str)


        `load_from_string(PyObject *str, plSerializer::ArchiveType
            format=PL_DEFAULT_ARCHIVE)`  

        Load from the given serialization archive, given as a python string.  

        """
        return _probt_python3.plSerializer_load_from_string(self, *args)


    def save(self, *args) -> "void":
        """
        save(self, fileName, format)
        save(self, fileName)


        `save(const std::string &fileName, plSerializer::ArchiveType
            format=PL_DEFAULT_ARCHIVE) const`  

        Serialize the contained objects to the given file.  

        """
        return _probt_python3.plSerializer_save(self, *args)


    def load(self, *args) -> "void":
        """
        load(self, fileName, format)
        load(self, fileName)


        `load(const std::string &fileName, plSerializer::ArchiveType
            format=PL_DEFAULT_ARCHIVE)`  

        Load from the given serialization archive file.  

        """
        return _probt_python3.plSerializer_load(self, *args)

plSerializer_swigregister = _probt_python3.plSerializer_swigregister
plSerializer_swigregister(plSerializer)

def plSerializer_PYSTRING_ASSTRING(o: 'PyObject *', s: 'std::string &') -> "bool":
    """
    plSerializer_PYSTRING_ASSTRING(o, s) -> bool


    `PYSTRING_ASSTRING(PyObject *o, std::string &s) -> bool`  

    """
    return _probt_python3.plSerializer_PYSTRING_ASSTRING(o, s)


def serialize_to_string(the_dict, name='untitled'):
  '''
  Input: a dictionary of plObject instances.
  Output: the XML archive as a string.
  '''
  serializer = plSerializer(the_dict, name)
  return serializer.save_to_string()

def deserialize_from_string(the_string):
  '''
  Input: an XML archive as a string.
  Output: a dictionary of plObject instances.
  '''
  serializer = plSerializer()
  serializer.load_from_string(the_string)
  return serializer.get_all_objects_map()

PL_DEFAULT_N_RANDOM_INIT = _probt_python3.PL_DEFAULT_N_RANDOM_INIT
PL_DEFAULT_PRIOR_WEIGHT = _probt_python3.PL_DEFAULT_PRIOR_WEIGHT
PL_DEFAULT_CONV_THRESHOLD = _probt_python3.PL_DEFAULT_CONV_THRESHOLD
PL_DEFAULT_HMM_ITERATIONS = _probt_python3.PL_DEFAULT_HMM_ITERATIONS
class plConcurrentHmmSetLearner(plObject):
    """

    `plConcurrentHmmSetLearner()`  
    `plConcurrentHmmSetLearner(const std::string &model_name, const std::vector<
        std::string > &class_names, const plLearnObject
        *observation_decomposition=0, const std::vector< std::vector< plProbValue >
        > &transition_matrix_final_states=std::vector< std::vector< plProbValue >
        >(), const std::vector< std::vector< plProbValue > >
        &transition_matrix_non_final_states=std::vector< std::vector< plProbValue >
        >())`  
    `plConcurrentHmmSetLearner(const plConcurrentHmmSetLearner &)`  

    This class implements HMM set learning and evaluation.  

    See also: plHMM  

    See also: plConcurrentHmmSet  

    Constructors
    ------------
    * `plConcurrentHmmSetLearner()`  

        Default constructor.  

    * `plConcurrentHmmSetLearner(const std::string &model_name, const std::vector<
        std::string > &class_names, const plLearnObject
        *observation_decomposition=0, const std::vector< std::vector< plProbValue >
        > &transition_matrix_final_states=std::vector< std::vector< plProbValue >
        >(), const std::vector< std::vector< plProbValue > >
        &transition_matrix_non_final_states=std::vector< std::vector< plProbValue >
        >())`  

        Constructor.  

        Parameters:  
        * `model_name` :  
            The name of the model to be used for naming the learnt models and the
            corresponding ProBT xml files when saved  
        * `class_names` :  
            The name of the classes of the model  
        * `observation_decomposition` :  
            The observation (emission) distribution learner. The passed pointer is
            cloned and stored internally. The observation (emission) variables can
            be discrete and/or continuous. For example, when assuming a joint normal
            distribution on a set of continuous observation variables, one can use a
            plLearnNdNormal. One can use a plLearnHistogram in case of discrete
            variables. Moreover, the observation (emission) distribution can be
            decomposed. For example, a 2D observation distribution can be decomposed
            as:  

            *   $ P(O_x O_y) = P(O_x) P(O_y) $,  
            *   $ P(O_x O_y) = P(O_x) P(O_y | O_x) $.  
                Using ProBT, a such decomposed emission distribution can be
                expressed using the *plLearnDistributions* class to define the
                learner of the emission distribution. If observation_decomposition
                is not set, then a multidimensional Normal is assumed.  
        * `transition_matrix_final_states` :  
            Transition matrix for final states. transition_matrix_final_states[p][q]
            should hold P([Cnew=q] | [Cpred = q] and Cpred was in a final state) i.e
            the probability, during a time step, to pass from the class p to the
            class q when assuming that the current internal state for class p is a
            final one. transition_matrix_final_states[p] must be a vector of
            probabilities whose elements sum up to one.  
        * `transition_matrix_non_final_states` :  
            Transition matrix for non final states.
            transition_matrix_non_final_states[p][q] should hold P([Cnew=q] | [Cpred
            = q] and Cpred was in a NON final state) i.e the probability, during a
            time step, to pass from the class p to the class q when assuming that
            the current internal state for class p is a final one.
            transition_matrix_non_final_states[p] must be a vector of probabilities
            whose elements sum up to one.  

        If transition_matrix_non_final_states or transition_matrix_final_states are
        empty, then identity matrices are assumed  

    * `plConcurrentHmmSetLearner(const plConcurrentHmmSetLearner &)`  

        Copy constructor.  

    C++ includes: plConcurrentHmmSetLearner.h

    """

    __swig_setmethods__ = {}
    for _s in [plObject]:
        __swig_setmethods__.update(getattr(_s, '__swig_setmethods__', {}))
    __setattr__ = lambda self, name, value: _swig_setattr(self, plConcurrentHmmSetLearner, name, value)
    __swig_getmethods__ = {}
    for _s in [plObject]:
        __swig_getmethods__.update(getattr(_s, '__swig_getmethods__', {}))
    __getattr__ = lambda self, name: _swig_getattr(self, plConcurrentHmmSetLearner, name)
    __repr__ = _swig_repr

    def __init__(self, *args):
        """
        __init__(self) -> plConcurrentHmmSetLearner
        __init__(self, model_name, class_names, observation_decomposition=None, transition_matrix_final_states, transition_matrix_non_final_states) -> plConcurrentHmmSetLearner
        __init__(self, model_name, class_names, observation_decomposition=None, transition_matrix_final_states) -> plConcurrentHmmSetLearner
        __init__(self, model_name, class_names, observation_decomposition=None) -> plConcurrentHmmSetLearner
        __init__(self, model_name, class_names) -> plConcurrentHmmSetLearner
        __init__(self, arg2) -> plConcurrentHmmSetLearner


        `plConcurrentHmmSetLearner()`  
        `plConcurrentHmmSetLearner(const std::string &model_name, const std::vector<
            std::string > &class_names, const plLearnObject
            *observation_decomposition=0, const std::vector< std::vector< plProbValue >
            > &transition_matrix_final_states=std::vector< std::vector< plProbValue >
            >(), const std::vector< std::vector< plProbValue > >
            &transition_matrix_non_final_states=std::vector< std::vector< plProbValue >
            >())`  
        `plConcurrentHmmSetLearner(const plConcurrentHmmSetLearner &)`  

        Overloaded function
        -------------------
        * `plConcurrentHmmSetLearner()`  

            Default constructor.  

        * `plConcurrentHmmSetLearner(const std::string &model_name, const std::vector<
            std::string > &class_names, const plLearnObject
            *observation_decomposition=0, const std::vector< std::vector< plProbValue >
            > &transition_matrix_final_states=std::vector< std::vector< plProbValue >
            >(), const std::vector< std::vector< plProbValue > >
            &transition_matrix_non_final_states=std::vector< std::vector< plProbValue >
            >())`  

            Constructor.  

            Parameters:  
            * `model_name` :  
                The name of the model to be used for naming the learnt models and the
                corresponding ProBT xml files when saved  
            * `class_names` :  
                The name of the classes of the model  
            * `observation_decomposition` :  
                The observation (emission) distribution learner. The passed pointer is
                cloned and stored internally. The observation (emission) variables can
                be discrete and/or continuous. For example, when assuming a joint normal
                distribution on a set of continuous observation variables, one can use a
                plLearnNdNormal. One can use a plLearnHistogram in case of discrete
                variables. Moreover, the observation (emission) distribution can be
                decomposed. For example, a 2D observation distribution can be decomposed
                as:  

                *   $ P(O_x O_y) = P(O_x) P(O_y) $,  
                *   $ P(O_x O_y) = P(O_x) P(O_y | O_x) $.  
                    Using ProBT, a such decomposed emission distribution can be
                    expressed using the *plLearnDistributions* class to define the
                    learner of the emission distribution. If observation_decomposition
                    is not set, then a multidimensional Normal is assumed.  
            * `transition_matrix_final_states` :  
                Transition matrix for final states. transition_matrix_final_states[p][q]
                should hold P([Cnew=q] | [Cpred = q] and Cpred was in a final state) i.e
                the probability, during a time step, to pass from the class p to the
                class q when assuming that the current internal state for class p is a
                final one. transition_matrix_final_states[p] must be a vector of
                probabilities whose elements sum up to one.  
            * `transition_matrix_non_final_states` :  
                Transition matrix for non final states.
                transition_matrix_non_final_states[p][q] should hold P([Cnew=q] | [Cpred
                = q] and Cpred was in a NON final state) i.e the probability, during a
                time step, to pass from the class p to the class q when assuming that
                the current internal state for class p is a final one.
                transition_matrix_non_final_states[p] must be a vector of probabilities
                whose elements sum up to one.  

            If transition_matrix_non_final_states or transition_matrix_final_states are
            empty, then identity matrices are assumed  

        * `plConcurrentHmmSetLearner(const plConcurrentHmmSetLearner &)`  

            Copy constructor.  

        """
        this = _probt_python3.new_plConcurrentHmmSetLearner(*args)
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this
    __swig_destroy__ = _probt_python3.delete_plConcurrentHmmSetLearner
    __del__ = lambda self: None

    def set_verbose(self, verbose: 'bool') -> "void":
        """
        set_verbose(self, verbose)


        `set_verbose(bool verbose)`  

        Set/unset verbose mode.  

        """
        return _probt_python3.plConcurrentHmmSetLearner_set_verbose(self, verbose)


    def set_output_stream(self, *args) -> "void":
        """
        set_output_stream(self)
        set_output_stream(self, out)


        `set_output_stream(std::ostream &out)`  
        `set_output_stream(plStringStream &out)`  

        Overloaded function
        -------------------
        * `set_output_stream(std::ostream &out)`  

            Set the output stream to be used when verbose mode is enabled.  

            The default is std::cout  

        * `set_output_stream(plStringStream &out)`  

        """
        return _probt_python3.plConcurrentHmmSetLearner_set_output_stream(self, *args)


    def enable_multi_threading(self, enable_it: 'bool') -> "void":
        """
        enable_multi_threading(self, enable_it)


        `enable_multi_threading(bool enable_it)`  

        Enable/disable multithreading.  

        """
        return _probt_python3.plConcurrentHmmSetLearner_enable_multi_threading(self, enable_it)


    def set_observation_model(self, *args) -> "void":
        """
        set_observation_model(self, observation_decomposition)
        set_observation_model(self, observation_variable_names, observation_variable_is_continuous, observation_variable_min, observation_variable_max, observation_variable_groups, observation_variable_group_parents)
        set_observation_model(self, observation_variable_names, observation_variable_is_continuous, observation_variable_min, observation_variable_max, observation_variable_groups)
        set_observation_model(self, observation_variable_names, observation_variable_is_continuous, observation_variable_min, observation_variable_max)
        set_observation_model(self, observation_variable_names, observation_variable_is_continuous, observation_variable_min)
        set_observation_model(self, observation_variable_names, observation_variable_is_continuous)
        set_observation_model(self, observation_variable_names)
        set_observation_model(self, observation_variables, observation_variable_groups, observation_variable_group_parents)
        set_observation_model(self, observation_variables, observation_variable_groups)
        set_observation_model(self, observation_variables)


        `set_observation_model(const plLearnObject &observation_decomposition)`  
        `set_observation_model(const std::vector< std::string >
            &observation_variable_names, const std::vector< bool >
            &observation_variable_is_continuous=std::vector< bool >(), const
            std::vector< plFloat > &observation_variable_min=std::vector< plFloat >(),
            const std::vector< plFloat > &observation_variable_max=std::vector< plFloat
            >(), const std::vector< std::vector< unsigned int > >
            &observation_variable_groups=std::vector< std::vector< unsigned int > >(),
            const std::vector< std::vector< unsigned int > >
            &observation_variable_group_parents=std::vector< std::vector< unsigned int >
            >())`  
        `set_observation_model(const plVariablesConjunction &observation_variables,
            const std::vector< plVariablesConjunction >
            &observation_variable_groups=std::vector< plVariablesConjunction >(), const
            std::vector< plVariablesConjunction >
            &observation_variable_group_parents=std::vector< plVariablesConjunction
            >())`  

        Overloaded function
        -------------------
        * `set_observation_model(const plLearnObject &observation_decomposition)`  

            Set/change the observation model.  

            Parameters:  
            * `observation_decomposition` :  
                The observation (emission) distribution learner. The observation
                (emission) variables can be discrete and/or continuous. For example,
                when assuming a joint normal distribution on a set of continuous
                observation variables, one can use a plLearnNdNormal. One can use a
                plLearnHistogram in case of discrete variables. Moreover, the
                observation (emission) distribution can be decomposed. For example, a 2D
                observation distribution can be decomposed as:  

                *   $ P(O_x O_y) = P(O_x) P(O_y) $,  
                *   $ P(O_x O_y) = P(O_x) P(O_y | O_x) $.  
                    Using ProBT, a such decomposed emission distribution can be
                    expressed using the *plLearnDistributions* class to define the
                    learner of the emission distribution. If observation_decomposition
                    is not set, then a multidimensional Normal is assumed.  

        * `set_observation_model(const std::vector< std::string >
            &observation_variable_names, const std::vector< bool >
            &observation_variable_is_continuous=std::vector< bool >(), const
            std::vector< plFloat > &observation_variable_min=std::vector< plFloat >(),
            const std::vector< plFloat > &observation_variable_max=std::vector< plFloat
            >(), const std::vector< std::vector< unsigned int > >
            &observation_variable_groups=std::vector< std::vector< unsigned int > >(),
            const std::vector< std::vector< unsigned int > >
            &observation_variable_group_parents=std::vector< std::vector< unsigned int >
            >())`  

            Set/change the observation model.  

            Parameters:  
            * `observation_variable_names` :  
                The names of the observation variables  
            * `observation_variable_is_continuous` :  
                For each variable in the list above, True if the variable is continuous,
                False otherwise  
            * `observation_variable_min` :  
                For each variable in the list above, the min value for the range
                (inclusive)  
            * `observation_variable_max` :  
                For each variable in the list above, the max value for the range
                (inclusive for discrete variables and exclusive for continuous ones)  
            * `observation_variable_groups` :  
                A set of indices for variable groups. For example, for
                observation_variable_names = ["X", "A", "Z"], one can use
                observation_variable_groups = [ [0, 2], [1] ] to declare two groups of
                variables [X, Z] and [A]. This leads to the decomposition P(X A Z) = P(X
                Z) P(A)  
            * `observation_variable_group_parents` :  
                A set of indices for variable group parents. For example, for
                observation_variable_names = ["X", "A", "Z"], one can use
                observation_variable_groups = [ [0, 2], [1] ] to declare two groups of
                variables ([X, Z], [A]) and observation_variable_group_parents = [ [1],
                [] ] to declare [1] ([A]) as the parents for the first group [0, 2] ([X,
                Z]) and no parents for the second group [1] ([A]). This leads to the
                decomposition P(X A Z) = P(X Z | A) P(A)  

            For each distribution learner, its parametric form (type) depends of the
            type of the variable conjunctions and their parents as returned by
            plLearnObject::create_learner()  

            See also: plLearnObject::create_learnable_decomposition(),
                plLearnObject::create_learner()  

            See also: plVariablesConjunction::create_variables()  

        * `set_observation_model(const plVariablesConjunction &observation_variables,
            const std::vector< plVariablesConjunction >
            &observation_variable_groups=std::vector< plVariablesConjunction >(), const
            std::vector< plVariablesConjunction >
            &observation_variable_group_parents=std::vector< plVariablesConjunction
            >())`  

            Same as above.  

            However plVariablesConjunction are used instead of using indices  

        """
        return _probt_python3.plConcurrentHmmSetLearner_set_observation_model(self, *args)


    def set_transition_matrices(self, *args) -> "void":
        """
        set_transition_matrices(self, transition_matrix_final_states, transition_matrix_non_final_states)
        set_transition_matrices(self, mp, m, final, non_final)


        `set_transition_matrices(const std::vector< std::vector< plProbValue > >
            &transition_matrix_final_states, const std::vector< std::vector< plProbValue
            > > &transition_matrix_non_final_states)`  
        `set_transition_matrices(unsigned int mp, unsigned int m, plProbValue final,
            plProbValue non_final)`  

        Overloaded function
        -------------------
        * `set_transition_matrices(const std::vector< std::vector< plProbValue > >
            &transition_matrix_final_states, const std::vector< std::vector< plProbValue
            > > &transition_matrix_non_final_states)`  

            Set/change the transition matrices.  

            Parameters:  
            * `transition_matrix_final_states` :  
                Transition matrix for final states transition_matrix_final_states[p][q]
                should hold P([Cnew=q] | [Cpred = q] and Cpred was in a final state) i.e
                the probability, during a time step, to pass from the class p to the
                class q when assuming that the current internal state for class p is a
                final one. transition_matrix_final_states[p] must be a vector of
                probabilities whose elements sum up to one.  
            * `transition_matrix_non_final_states` :  
                Transition matrix for non final states
                transition_matrix_non_final_states[p][q] should hold P([Cnew=q] | [Cpred
                = q] and Cpred was in a NON final state) i.e the probability, during a
                time step, to pass from the class p to the class q when assuming that
                the current internal state for class p is a non final one.
                transition_matrix_non_final_states[p] must be a vector of probabilities
                whose elements sum up to one.  

            If these matrices are not set, then identity ones are assumed  

        * `set_transition_matrices(unsigned int mp, unsigned int m, plProbValue final,
            plProbValue non_final)`  

            Set/change an element of the transition matrices between models (HMMs).  

        """
        return _probt_python3.plConcurrentHmmSetLearner_set_transition_matrices(self, *args)


    def run_learning(self, *args) -> "void":
        """
        run_learning(self, learn_obs_sequences, candidate_nstates, n_initialisation_random_trials=3, learning_prior_weight=0.01, convergence_threshold=0.0, max_hmm_iterations=200)
        run_learning(self, learn_obs_sequences, candidate_nstates, n_initialisation_random_trials=3, learning_prior_weight=0.01, convergence_threshold=0.0)
        run_learning(self, learn_obs_sequences, candidate_nstates, n_initialisation_random_trials=3, learning_prior_weight=0.01)
        run_learning(self, learn_obs_sequences, candidate_nstates, n_initialisation_random_trials=3)
        run_learning(self, learn_obs_sequences, candidate_nstates)
        run_learning(self, csv_learning_files, candidate_nstates, csv_file_has_header=False, csv_file_nrows_to_ignore=0, csv_file_columns_to_ignore, n_initialisation_random_trials=3, learning_prior_weight=0.01, convergence_threshold=0.0, max_hmm_iterations=200)
        run_learning(self, csv_learning_files, candidate_nstates, csv_file_has_header=False, csv_file_nrows_to_ignore=0, csv_file_columns_to_ignore, n_initialisation_random_trials=3, learning_prior_weight=0.01, convergence_threshold=0.0)
        run_learning(self, csv_learning_files, candidate_nstates, csv_file_has_header=False, csv_file_nrows_to_ignore=0, csv_file_columns_to_ignore, n_initialisation_random_trials=3, learning_prior_weight=0.01)
        run_learning(self, csv_learning_files, candidate_nstates, csv_file_has_header=False, csv_file_nrows_to_ignore=0, csv_file_columns_to_ignore, n_initialisation_random_trials=3)
        run_learning(self, csv_learning_files, candidate_nstates, csv_file_has_header=False, csv_file_nrows_to_ignore=0, csv_file_columns_to_ignore)
        run_learning(self, csv_learning_files, candidate_nstates, csv_file_has_header=False, csv_file_nrows_to_ignore=0)
        run_learning(self, csv_learning_files, candidate_nstates, csv_file_has_header=False)
        run_learning(self, csv_learning_files, candidate_nstates)


        `run_learning(const std::vector< plHMM::ObservationSequenceArray_t >
            &learn_obs_sequences, const std::vector< unsigned int > &candidate_nstates,
            unsigned int n_initialisation_random_trials=PL_DEFAULT_N_RANDOM_INIT,
            plFloat learning_prior_weight=PL_DEFAULT_PRIOR_WEIGHT, plFloat
            convergence_threshold=PL_DEFAULT_CONV_THRESHOLD, unsigned int
            max_hmm_iterations=PL_DEFAULT_HMM_ITERATIONS)`  
        `run_learning(const std::vector< std::vector< std::string > >
            &csv_learning_files, const std::vector< unsigned int > &candidate_nstates,
            bool csv_file_has_header=false, unsigned int csv_file_nrows_to_ignore=0,
            const std::vector< unsigned int > &csv_file_columns_to_ignore=std::vector<
            unsigned int >(), unsigned int
            n_initialisation_random_trials=PL_DEFAULT_N_RANDOM_INIT, plFloat
            learning_prior_weight=PL_DEFAULT_PRIOR_WEIGHT, plFloat
            convergence_threshold=PL_DEFAULT_CONV_THRESHOLD, unsigned int
            max_hmm_iterations=PL_DEFAULT_HMM_ITERATIONS)`  

        Overloaded function
        -------------------
        * `run_learning(const std::vector< plHMM::ObservationSequenceArray_t >
            &learn_obs_sequences, const std::vector< unsigned int > &candidate_nstates,
            unsigned int n_initialisation_random_trials=PL_DEFAULT_N_RANDOM_INIT,
            plFloat learning_prior_weight=PL_DEFAULT_PRIOR_WEIGHT, plFloat
            convergence_threshold=PL_DEFAULT_CONV_THRESHOLD, unsigned int
            max_hmm_iterations=PL_DEFAULT_HMM_ITERATIONS)`  

            Run learning assuming a given list of numbers for the internal HMM states.  

            The learning will generate a map (key: name, value: model) with the learnt
            models (plConcurrentHmmSet) (see get_model_map()).  

            For example, for model_name="SequenceClassifier" and candidate_nstates =
            [5, 10, 50], run_learning() will generate the plConcurrentHmmSet instances
            with the following names:  

            *   "SequenceClassifier05": A plConcurrentHmmSet instance with HMMs having
                5 internal states each  
            *   "SequenceClassifier10": A plConcurrentHmmSet instance with HMMs having
                10 internal states each  
            *   "SequenceClassifier50": A plConcurrentHmmSet instance with HMMs having
                50 internal states each  
            *   "SequenceClassifierBestLK": A plConcurrentHmmSet instance with HMMs
                having each the number of internal states allowing to maximize the
                learning log-likelihood  
            *   "SequenceClassifierBestBIC": A plConcurrentHmmSet instance with HMMs
                having each the number of internal states allowing to maximize the
                learning BIC score  
            *   "SequenceClassifierBestAIC": A plConcurrentHmmSet instance with HMMs
                having each the number of internal states allowing to maximize the
                learning AIC score  

            The values of the log-likelihood, BIC, and AIC score can be retrieved using
            get_model_log_likelihood(), get_model_bic(), and get_model_aic()
            respectively.  

            Parameters:  
            * `learn_obs_sequences` :  
                A vector of observation sequence arrays (an observation sequence array
                for each class (HMM)). An observation sequence is a vector of float
                vectors (observations). In each observation, order of elements matter.
                This order must correspond to the observation_decomposition learner's
                variables as in `observation_decomposition->get_left_variables()` or the
                order defined by the parameter observation_variable_names. In case the
                orders do not match, you will get incorrect results, and possibly
                occurrence of plWarning 17 (value out of range).  
            * `candidate_nstates` :  
                The candidate numbers of HMM internal states.  
            * `n_initialisation_random_trials` :  
                The number of random initialisations. Providing a large number maximizes
                the chance of having a well-fitted model. In addition to the random
                initialisation trials, a deterministic initialisation is also performed
                when the deterministic initialisation is set to true (ie. this leads to
                n_initialisation_random_trials+1 initialisations)  
            * `learning_prior_weight` :  
                The weight to be used for initialising the emission distribution from
                the whole data set. A small value will lead to a more accurate
                classification while increasing the risk af having degenerate statistics
                (especially when using a large number of internal states).  
            * `convergence_threshold` :  
                convergence threshold of relative log-likelihood change between two
                successive iterations (smaller value means more iterations). The default
                value is set to 0.0 The convergence criterion is computed as:  
                | log-likelihood(t) - log-likelihood(t-1) | / | (log-likelihood(t) +
                log-likelihood(t-1)/2.0 | < convergence_threshold.  
            * `max_hmm_iterations` :  
                maximal number of iterations  

            See also: plHMM::ObservationSequenceArray_t  

            See also: plHMM::ObservationSequence_t  

            See also: plHMM::Observation_t  

        * `run_learning(const std::vector< std::vector< std::string > >
            &csv_learning_files, const std::vector< unsigned int > &candidate_nstates,
            bool csv_file_has_header=false, unsigned int csv_file_nrows_to_ignore=0,
            const std::vector< unsigned int > &csv_file_columns_to_ignore=std::vector<
            unsigned int >(), unsigned int
            n_initialisation_random_trials=PL_DEFAULT_N_RANDOM_INIT, plFloat
            learning_prior_weight=PL_DEFAULT_PRIOR_WEIGHT, plFloat
            convergence_threshold=PL_DEFAULT_CONV_THRESHOLD, unsigned int
            max_hmm_iterations=PL_DEFAULT_HMM_ITERATIONS)`  

            Run learning assuming a given list of numbers for the internal HMM states.  

            The learning data is provided as a list of csv files (sequences) and each
            file is loaded when needed (not preloaded in memory)  

            The learning will generate a map (key: name, value: model) with the learnt
            models (plConcurrentHmmSet) (see get_model_map()).  

            For example, for model_name="SequenceClassifier" and candidate_nstates =
            [5, 10, 50], run_learning() will generate the plConcurrentHmmSet instances
            with the following names:  

            *   "SequenceClassifier05": A plConcurrentHmmSet instance with HMMs having
                5 internal states each  
            *   "SequenceClassifier10": A plConcurrentHmmSet instance with HMMs having
                10 internal states each  
            *   "SequenceClassifier50": A plConcurrentHmmSet instance with HMMs having
                50 internal states each  
            *   "SequenceClassifierBestLK": A plConcurrentHmmSet instance with HMMs
                having each the number of internal states allowing to maximize the
                learning log-likelihood  
            *   "SequenceClassifierBestBIC": A plConcurrentHmmSet instance with HMMs
                having each the number of internal states allowing to maximize the
                learning BIC score  
            *   "SequenceClassifierBestAIC": A plConcurrentHmmSet instance with HMMs
                having each the number of internal states allowing to maximize the
                learning AIC score  

            The values of the log-likelihood, BIC, and AIC score can be retrieved using
            get_model_log_likelihood(), get_model_bic(), and get_model_aic()
            respectively.  

            Parameters:  
            * `csv_learning_files` :  
                A vector of string vectors (a string vector for each class (HMM)).  
            * `candidate_nstates` :  
                The candidate numbers of HMM internal states.  
            * `csv_file_has_header` :  
                True if the csv files do have a header with the names of observation
                variables (the names of observation_decomposition->get_left_variables()
                of those provided in observation_variable_names)  
            * `csv_file_nrows_to_ignore` :  
                The number of rows to be ignored in the csv files. Only used when
                csv_file_has_header=False  
            * `csv_file_columns_to_ignore` :  
                The indices (starting from 0) of the csv columns to be ignored. Only
                used when csv_file_has_header=False  
            * `n_initialisation_random_trials` :  
                The number of random initialisations. Providing a large number maximise
                to chance for having a well-fitted model. In addition to the random
                initialisation trials, a deterministic initialisation is also performed
                when the deterministic initialisation is set to true (ie. this leads to
                n_initialisation_random_trials+1 initialisations)  
            * `learning_prior_weight` :  
                The weight to be used for initialising the emission distribution from
                the whole data set. A small value will lead to a more accurate
                classification while increasing the risk af having degenerated
                statistics during the learning process especially when using a large
                number of internal states.  
            * `convergence_threshold` :  
                convergence threshold of relative log-likelihood change between two
                successive iterations (smaller value means more iterations). The default
                value is set to 0.0 The convergence criterion is computed as:  
                | log-likelihood(t) - log-likelihood(t-1) | / | (log-likelihood(t) +
                log-likelihood(t-1)/2.0 | < convergence_threshold.  
            * `max_hmm_iterations` :  
                maximal number of iterations  

        """
        return _probt_python3.plConcurrentHmmSetLearner_run_learning(self, *args)


    def get_model_map(self) -> "std::map< std::string,plConcurrentHmmSet,std::less< std::string >,std::allocator< std::pair< std::string const,plConcurrentHmmSet > > > const &":
        """
        get_model_map(self) -> std::map< std::string,plConcurrentHmmSet,std::less< std::string >,std::allocator< std::pair< std::string const,plConcurrentHmmSet > > > const &


        `get_model_map() const -> const std::map< std::string, plConcurrentHmmSet > &`  

        Get a map (key: name, value: model) with the learnt models (plConcurrentHmmSet).  

        This function must be called after calling run_learning()  

        """
        return _probt_python3.plConcurrentHmmSetLearner_get_model_map(self)


    def get_model_log_likelihood(self) -> "std::vector< std::vector< plFloat,std::allocator< plFloat > >,std::allocator< std::vector< plFloat,std::allocator< plFloat > > > >":
        """
        get_model_log_likelihood(self) -> DoubleVectorVector


        `get_model_log_likelihood() const -> std::vector< std::vector< plFloat > >`  

        Get the learning log-likelihood score per class and per number of states.  

        This function must be called after calling run_learning()  

        """
        return _probt_python3.plConcurrentHmmSetLearner_get_model_log_likelihood(self)


    def get_model_bic(self) -> "std::vector< std::vector< plFloat,std::allocator< plFloat > >,std::allocator< std::vector< plFloat,std::allocator< plFloat > > > >":
        """
        get_model_bic(self) -> DoubleVectorVector


        `get_model_bic() const -> std::vector< std::vector< plFloat > >`  

        Get the learning bic score per class and per number of states.  

        This function must be called after calling run_learning()  

        """
        return _probt_python3.plConcurrentHmmSetLearner_get_model_bic(self)


    def get_model_aic(self) -> "std::vector< std::vector< plFloat,std::allocator< plFloat > >,std::allocator< std::vector< plFloat,std::allocator< plFloat > > > >":
        """
        get_model_aic(self) -> DoubleVectorVector


        `get_model_aic() const -> std::vector< std::vector< plFloat > >`  

        Get the learning aic score per class and per number of states.  

        This function must be called after calling run_learning()  

        """
        return _probt_python3.plConcurrentHmmSetLearner_get_model_aic(self)


    def save_models(self, model_output_dir: 'std::string const &') -> "void":
        """
        save_models(self, model_output_dir)


        `save_models(const std::string &model_output_dir) const`  

        Save the learnt models (plConcurrentHmmSet) as ProBT xml files in a given output
        directory.  

        This function must be called after calling run_learning()  

        Parameters
        ----------
        * `model_output_dir` :  
            The output directory where the files will be saved. The directory must exist
            and have writing permissions  

        For example, for model_name="SequenceClassifier" and candidate_nstates = [5,
        10, 50], run_learning() and save_models() will generate the following files:  

        *   "model_output_dir/SequenceClassifier05.xml": A plConcurrentHmmSet instance
            with HMMs having 5 internal states each  
        *   "model_output_dir/SequenceClassifier10.xml": A plConcurrentHmmSet instance
            with HMMs having 10 internal states each  
        *   "model_output_dir/SequenceClassifier50.xml": A plConcurrentHmmSet instance
            with HMMs having 50 internal states each  
        *   "model_output_dir/SequenceClassifierBestLK.xml": A plConcurrentHmmSet
            instance with HMMs having each the number of internal states allowing to
            maximize the learning log-likelihood  
        *   "model_output_dir/SequenceClassifierBestBIC.xml": A plConcurrentHmmSet
            instance with HMMs having each the number of internal states allowing to
            maximize the learning BIC score  
        *   "model_output_dir/SequenceClassifierBestAIC.xml": A plConcurrentHmmSet
            instance with HMMs having each the number of internal states allowing to
            maximize the learning AIC score  

        """
        return _probt_python3.plConcurrentHmmSetLearner_save_models(self, model_output_dir)


    def load_csv_files(*args) -> "std::vector< plHMM::ObservationSequenceArray_t,std::allocator< plHMM::ObservationSequenceArray_t > >":
        """
        load_csv_files(csv_files, csv_file_nrows_to_ignore, csv_file_columns_to_ignore, ncols=0) -> DoubleVectorVectorVector
        load_csv_files(csv_files, csv_file_nrows_to_ignore, csv_file_columns_to_ignore) -> DoubleVectorVectorVector
        load_csv_files(csv_files, csv_file_nrows_to_ignore, csv_file_columns_to_ignore) -> DoubleVectorVectorVectorVector


        `load_csv_files(const std::vector< std::string > &csv_files, unsigned int
            csv_file_nrows_to_ignore, const std::vector< unsigned int >
            &csv_file_columns_to_ignore, unsigned int ncols=0) ->
            plHMM::ObservationSequenceArray_t`  
        `load_csv_files(const std::vector< std::vector< std::string > > &csv_files,
            unsigned int csv_file_nrows_to_ignore, const std::vector< unsigned int >
            &csv_file_columns_to_ignore) -> std::vector<
            plHMM::ObservationSequenceArray_t >`  

        Overloaded function
        -------------------
        * `load_csv_files(const std::vector< std::string > &csv_files, unsigned int
            csv_file_nrows_to_ignore, const std::vector< unsigned int >
            &csv_file_columns_to_ignore, unsigned int ncols=0) ->
            plHMM::ObservationSequenceArray_t`  

            Load the data matrix for model learning/testing.  

            Parameters:  
            * `csv_files` :  
                A vector of file names  
            * `csv_file_nrows_to_ignore` :  
                The number of rows to be ignored in the csv files  
            * `csv_file_columns_to_ignore` :  
                The indices (starting from 0) of the csv columns to be ignored  
            * `ncols` :  
                The number of fields to be loaded. If 0 (the default value), the number
                will be guessed from the csv files  

            Returns:
            obs_sequences The loaded observation matrix: A vector of observation
            sequence arrays (an observation sequence array for each class (HMM)). An
            observation sequence is a vector of float vectors (observations)  

            See also: plHMM::ObservationSequenceArray_t  

            See also: plHMM::ObservationSequence_t  

            See also: plHMM::Observation_t  

        * `load_csv_files(const std::vector< std::vector< std::string > > &csv_files,
            unsigned int csv_file_nrows_to_ignore, const std::vector< unsigned int >
            &csv_file_columns_to_ignore) -> std::vector<
            plHMM::ObservationSequenceArray_t >`  

            Load the data matrix for model learning/testing.  

            Parameters:  
            * `csv_files` :  
                A vector of string vectors (a string vector for each class (HMM))  
            * `csv_file_nrows_to_ignore` :  
                The number of rows to be ignored in the csv files  
            * `csv_file_columns_to_ignore` :  
                The indices (starting from 0) of the csv columns to be ignored  

            Returns:
            obs_sequences The loaded observation matrix: A vector of observation
            sequence arrays (an observation sequence array for each class (HMM)). An
            observation sequence is a vector of float vectors (observations)  

            See also: plHMM::ObservationSequenceArray_t  

            See also: plHMM::ObservationSequence_t  

            See also: plHMM::Observation_t  

        """
        return _probt_python3.plConcurrentHmmSetLearner_load_csv_files(*args)

    load_csv_files = staticmethod(load_csv_files)

    def load_csv_data(self, *args) -> "std::vector< plHMM::ObservationSequenceArray_t,std::allocator< plHMM::ObservationSequenceArray_t > >":
        """
        load_csv_data(self, csv_files, csv_file_has_header=False, csv_file_nrows_to_ignore=0, csv_file_columns_to_ignore) -> DoubleVectorVectorVectorVector
        load_csv_data(self, csv_files, csv_file_has_header=False, csv_file_nrows_to_ignore=0) -> DoubleVectorVectorVectorVector
        load_csv_data(self, csv_files, csv_file_has_header=False) -> DoubleVectorVectorVectorVector
        load_csv_data(self, csv_files) -> DoubleVectorVectorVectorVector


        `load_csv_data(const std::vector< std::vector< std::string > > &csv_files, bool
            csv_file_has_header=false, unsigned int csv_file_nrows_to_ignore=0, const
            std::vector< unsigned int > &csv_file_columns_to_ignore=std::vector<
            unsigned int >()) const -> std::vector< plHMM::ObservationSequenceArray_t >`  

        Load the data matrix for model learning/testing.  

        Parameters
        ----------
        * `csv_files` :  
            A vector of string vectors (a string vector for each class (HMM))  
        * `csv_file_has_header` :  
            True if the csv files do have header with the names of observation variables
            (the names of observation_decomposition->get_left_variables() of those
            provided in observation_variable_names)  
        * `csv_file_nrows_to_ignore` :  
            The number of rows to be ignored in the csv files. Only used when
            csv_file_has_header=False  
        * `csv_file_columns_to_ignore` :  
            The indices (starting from 0) of the csv columns to be ignored. Only used
            when csv_file_has_header=False  

        Returns
        -------
        obs_sequences The loaded observation matrix: A vector of observation sequence
        arrays (an observation sequence array for each class (HMM)). An observation
        sequence is a vector of float vectors (observations)  

        See also: plHMM::ObservationSequenceArray_t  

        See also: plHMM::ObservationSequence_t  

        See also: plHMM::Observation_t  

        """
        return _probt_python3.plConcurrentHmmSetLearner_load_csv_data(self, *args)


    def file_system_to_file_names(*args) -> "std::vector< std::vector< std::string,std::allocator< std::string > >,std::allocator< std::vector< std::string,std::allocator< std::string > > > >":
        """
        file_system_to_file_names(data_path, class_names, profile_names, file_prefix, file_suffix) -> StringVectorVector
        file_system_to_file_names(data_path, class_names, profile_names, file_prefix) -> StringVectorVector
        file_system_to_file_names(data_path, class_names, profile_names) -> StringVectorVector
        file_system_to_file_names(data_path, class_names, file_prefix, file_suffix) -> StringVectorVector
        file_system_to_file_names(data_path, class_names, file_prefix) -> StringVectorVector
        file_system_to_file_names(data_path, class_names) -> StringVectorVector


        `file_system_to_file_names(const std::string &data_path, const std::vector<
            std::string > &class_names, const std::vector< std::string > &profile_names,
            const std::string &file_prefix="", const std::string &file_suffix="") ->
            std::vector< std::vector< std::string > >`  
        `file_system_to_file_names(const std::string &data_path, const std::vector<
            std::string > &class_names, const std::string &file_prefix="", const
            std::string &file_suffix="") -> std::vector< std::vector< std::string > >`  

        Overloaded function
        -------------------
        * `file_system_to_file_names(const std::string &data_path, const std::vector<
            std::string > &class_names, const std::vector< std::string > &profile_names,
            const std::string &file_prefix="", const std::string &file_suffix="") ->
            std::vector< std::vector< std::string > >`  

            Get a list of files from a file system hierarchy.  

            For example, in a gesture recognition example with 3 classes (gesture1,
            gesture2, gesture3) with sets of sequence files recorded for 2 persons
            (person1, person2). If we have the following file system hierarchy:  

                | gesture_data
                | |- gesture1
                | | | - person1
                | | | | - example1.txt
                | | | | - example2.txt
                | | | - person2
                | | | | - example1.txt
                | | | | - example2.txt
                | | | | - example3.txt
                | | | - person3
                | | | | - example1.txt
                | | | | - example2.txt
                | | | | - example3.txt
                | |- gesture2
                | | | - person1
                | | | | - example1.txt
                | | | - person2
                | | | | - example1.txt
                | | | | - example2.txt
                | | | | - example3.txt
                | | | - person3
                | | | | - example1.txt
                | | | | - example2.txt
                | | | | - example3.txt
                | |- gesture3
                | | | - person1
                | | | | - example1.txt
                | | | | - example2.txt
                | | | | - example3.txt
                | | | - person2
                | | | | - example1.txt
                | | | | - example2.txt
                | | | | - example3.txt
                | | | | - example4.txt
                | | | - person3
                | | | | - example1.txt
                | | | | - example2.txt
                | | | | - example3.txt  

            Calling file_system_to_file_names() with data_path="gesture_data",
            class_names=["gesture1", "gesture2", "gesture3"] and
            profile_names=["person1", "person2"] will return:  

                [
                [
                "gesture_data/gesture1/person1/example1.txt",
                "gesture_data/gesture1/person1/example2.txt",
                "gesture_data/gesture1/person2/example1.txt",
                "gesture_data/gesture1/person2/example2.txt",
                "gesture_data/gesture1/person2/example3.txt"
                ]
                [
                "gesture_data/gesture2/person1/example1.txt",
                "gesture_data/gesture2/person2/example1.txt",
                "gesture_data/gesture2/person2/example2.txt",
                "gesture_data/gesture2/person2/example3.txt"
                ]
                [
                "gesture_data/gesture3/person1/example1.txt",
                "gesture_data/gesture3/person1/example2.txt",
                "gesture_data/gesture3/person1/example3.txt",  
                "gesture_data/gesture3/person2/example1.txt",
                "gesture_data/gesture3/person2/example2.txt",
                "gesture_data/gesture3/person2/example3.txt",
                "gesture_data/gesture3/person2/example4.txt"
                ]
                ]  

            Parameters:  
            * `data_path` :  
                The root file hierarchy to scan  
            * `class_names` :  
                The class names corresponding to the subdirectories of data_path to scan  
            * `profile_names` :  
                The profile names corresponding to the subdirectories of
                data_path/class_name to scan  
            * `file_prefix` :  
                Prefix of the files to be loaded from the directories
                data_path/class_name/profile_name  
            * `file_suffix` :  
                Suffix of the files to be loaded from the directories
                data_path/class_name/profile_name  

            Returns:
            A vector of string vectors (a string vector for each class (HMM)).  

        * `file_system_to_file_names(const std::string &data_path, const std::vector<
            std::string > &class_names, const std::string &file_prefix="", const
            std::string &file_suffix="") -> std::vector< std::vector< std::string > >`  

            Get a list of files from a file system hierarchy.  

            For example, in a gesture recognition example with 3 classes (gesture1,
            gesture2, gesture3). If we have the following file system hierarchy:  

                | gesture_data
                | |- gesture1
                | | | - example1.txt
                | | | - example2.txt
                | |- gesture2
                | | | - example1.txt
                | |- gesture3
                | | | - example1.txt
                | | | - example2.txt
                | | | - example3.txt  

            Calling file_system_to_file_names() with data_path="gesture_data",
            class_names=["gesture1", "gesture2", "gesture3"] and
            profile_names=["person1", "person2"] will return:  

                [
                ["gesture_data/gesture1/example1.txt",
            "gesture_data/gesture1/example2.txt"]
                ["gesture_data/gesture2/example1.txt"]
                ["gesture_data/gesture3/example1.txt",
            "gesture_data/gesture3/example2.txt",
            "gesture_data/gesture3/example3.txt"]
                ]  

            Parameters:  
            * `data_path` :  
                The root file hierarchy to scan  
            * `class_names` :  
                The class names corresponding to the subdirectories of data_path to scan  
            * `file_prefix` :  
                Prefix of the files to be loaded from the directories
                data_path/class_name  
            * `file_suffix` :  
                Suffix of the files to be loaded from the directories
                data_path/class_name  

            Returns:
            A vector of string vectors (a string vector for each class (HMM)).  

        """
        return _probt_python3.plConcurrentHmmSetLearner_file_system_to_file_names(*args)

    file_system_to_file_names = staticmethod(file_system_to_file_names)

    def get_sorted_directory_files(*args) -> "bool":
        """
        get_sorted_directory_files(dir_name, file_names, file_prefix, file_suffix) -> bool
        get_sorted_directory_files(dir_name, file_names, file_prefix) -> bool
        get_sorted_directory_files(dir_name, file_names) -> bool


        `get_sorted_directory_files(const std::string &dir_name, std::vector<
            std::string > &file_names, const std::string &file_prefix="", const
            std::string &file_suffix="") -> bool`  

        Get the list of files of a given directory.  

        """
        return _probt_python3.plConcurrentHmmSetLearner_get_sorted_directory_files(*args)

    get_sorted_directory_files = staticmethod(get_sorted_directory_files)

    def run_offline_evaluation(self, *args) -> "void":
        """
        run_offline_evaluation(self, test_obs_sequences)
        run_offline_evaluation(self, csv_testing_files, csv_file_has_header=False, csv_file_nrows_to_ignore=0, csv_file_columns_to_ignore)
        run_offline_evaluation(self, csv_testing_files, csv_file_has_header=False, csv_file_nrows_to_ignore=0)
        run_offline_evaluation(self, csv_testing_files, csv_file_has_header=False)
        run_offline_evaluation(self, csv_testing_files)


        `run_offline_evaluation(const std::vector< plHMM::ObservationSequenceArray_t >
            &test_obs_sequences)`  
        `run_offline_evaluation(const std::vector< std::vector< std::string > >
            &csv_testing_files, bool csv_file_has_header=false, unsigned int
            csv_file_nrows_to_ignore=0, const std::vector< unsigned int >
            &csv_file_columns_to_ignore=std::vector< unsigned int >())`  

        Overloaded function
        -------------------
        * `run_offline_evaluation(const std::vector< plHMM::ObservationSequenceArray_t >
            &test_obs_sequences)`  

            Run offline evaluation of all the learnt models and put the results in a map
            (see model_offline_performance_map())  

            Parameters:  
            * `test_obs_sequences` :  
                A vector of observation sequence arrays (an observation sequence array
                for each class (HMM)). An observation sequence is a vector of float
                vectors (observations). In each observation, order of elements matter.
                This order must correspond to the observation_decomposition learner's
                variables as in `observation_decomposition->get_left_variables()` or the
                order defined by the parameter observation_variable_names. In case the
                orders do not match, you will get incorrect results, and possibly
                occurrence of plWarning 17 (value out of range).  

            See also: plHMM::ObservationSequenceArray_t  

            See also: plHMM::ObservationSequence_t  

            See also: plHMM::Observation_t  

        * `run_offline_evaluation(const std::vector< std::vector< std::string > >
            &csv_testing_files, bool csv_file_has_header=false, unsigned int
            csv_file_nrows_to_ignore=0, const std::vector< unsigned int >
            &csv_file_columns_to_ignore=std::vector< unsigned int >())`  

            Same as above however each observation sequence is loaded when needed (not
            preloaded in memory)  

        """
        return _probt_python3.plConcurrentHmmSetLearner_run_offline_evaluation(self, *args)


    def model_offline_performance_map(self) -> "std::map< std::string,plPredictionPerformanceReport,std::less< std::string >,std::allocator< std::pair< std::string const,plPredictionPerformanceReport > > > const &":
        """
        model_offline_performance_map(self) -> std::map< std::string,plPredictionPerformanceReport,std::less< std::string >,std::allocator< std::pair< std::string const,plPredictionPerformanceReport > > > const &


        `model_offline_performance_map() const -> const std::map< std::string,
            plPredictionPerformanceReport > &`  

        Get a map (key: model name, value: model offline perfs as a
        plPredictionPerformanceReport) for each model.  

        """
        return _probt_python3.plConcurrentHmmSetLearner_model_offline_performance_map(self)


    def run_online_evaluation(self, *args) -> "void":
        """
        run_online_evaluation(self, test_obs_sequences, transition_matrix_final_states, transition_matrix_non_final_states, obs_llk_threshold)
        run_online_evaluation(self, test_obs_sequences, transition_matrix_final_states, transition_matrix_non_final_states)
        run_online_evaluation(self, test_obs_sequences, transition_matrix_final_states)
        run_online_evaluation(self, test_obs_sequences)
        run_online_evaluation(self, test_obs_sequences, class_values, transition_matrix_final_states, transition_matrix_non_final_states, obs_llk_threshold)
        run_online_evaluation(self, test_obs_sequences, class_values, transition_matrix_final_states, transition_matrix_non_final_states)
        run_online_evaluation(self, test_obs_sequences, class_values, transition_matrix_final_states)
        run_online_evaluation(self, test_obs_sequences, class_values)


        `run_online_evaluation(const std::vector< plHMM::ObservationSequenceArray_t >
            &test_obs_sequences, const std::vector< std::vector< plProbValue > >
            &transition_matrix_final_states=std::vector< std::vector< plProbValue > >(),
            const std::vector< std::vector< plProbValue > >
            &transition_matrix_non_final_states=std::vector< std::vector< plProbValue >
            >(), plFloat obs_llk_threshold=-std::numeric_limits< plFloat >::infinity())`  
        `run_online_evaluation(const plHMM::ObservationSequenceArray_t
            &test_obs_sequences, const std::vector< std::vector< unsigned int > >
            &class_values, const std::vector< std::vector< plProbValue > >
            &transition_matrix_final_states=std::vector< std::vector< plProbValue > >(),
            const std::vector< std::vector< plProbValue > >
            &transition_matrix_non_final_states=std::vector< std::vector< plProbValue >
            >(), plFloat obs_llk_threshold=-std::numeric_limits< plFloat >::infinity())`  

        Overloaded function
        -------------------
        * `run_online_evaluation(const std::vector< plHMM::ObservationSequenceArray_t >
            &test_obs_sequences, const std::vector< std::vector< plProbValue > >
            &transition_matrix_final_states=std::vector< std::vector< plProbValue > >(),
            const std::vector< std::vector< plProbValue > >
            &transition_matrix_non_final_states=std::vector< std::vector< plProbValue >
            >(), plFloat obs_llk_threshold=-std::numeric_limits< plFloat >::infinity())`  

            Run online evaluation of all the learnt models and put the results in a map
            (see model_online_performance_map())  

            Parameters:  
            * `test_obs_sequences` :  
                A vector of observation sequence arrays (an observation sequence array
                for each class (HMM)). An observation sequence is a vector of float
                vectors (observations). In each observation, order of elements matter.
                This order must correspond to the observation_decomposition learner's
                variables as in `observation_decomposition->get_left_variables()` or the
                order defined by the parameter observation_variable_names. In case the
                orders do not match, you will get incorrect results, and possibly
                occurrence of plWarning 17 (value out of range).  
            * `transition_matrix_final_states` :  
                Transition matrix for final states (see definition in
                set_transition_matrices())  
            * `transition_matrix_non_final_states` :  
                Transition matrix for non final states (see definition in
                set_transition_matrices())  
            * `obs_llk_threshold` :  
                The minimal log-likelihood of the observations to be accepted. If the
                log-likelihood of the observation is less than this threshold, then the
                classification will return UNKNOWN (last column in the confusion matrix)  

            See also: plHMM::ObservationSequenceArray_t  

            See also: plHMM::ObservationSequence_t  

            See also: plHMM::Observation_t  

        * `run_online_evaluation(const plHMM::ObservationSequenceArray_t
            &test_obs_sequences, const std::vector< std::vector< unsigned int > >
            &class_values, const std::vector< std::vector< plProbValue > >
            &transition_matrix_final_states=std::vector< std::vector< plProbValue > >(),
            const std::vector< std::vector< plProbValue > >
            &transition_matrix_non_final_states=std::vector< std::vector< plProbValue >
            >(), plFloat obs_llk_threshold=-std::numeric_limits< plFloat >::infinity())`  

            Run online evaluation of all the learnt models and put the results in a map
            (see model_online_performance_map())  

            Parameters:  
            * `test_obs_sequences` :  
                An observation sequence array. An observation sequence is a vector of
                float vectors (observations). In each observation, order of elements
                matter. This order must correspond to the observation_decomposition
                learner's variables as in
                `observation_decomposition->get_left_variables()` or the order defined
                by the parameter observation_variable_names. In case the orders do not
                match, you will get incorrect results, and possibly occurrence of
                plWarning 17 (value out of range).  
            * `class_values` :  
                The class values (starting from 0) corresponding to each each time-step
                (observation) in the test_obs_sequences sequences  
            * `transition_matrix_final_states` :  
                Transition matrix for final states (see definition in
                set_transition_matrices())  
            * `transition_matrix_non_final_states` :  
                Transition matrix for non final states (see definition in
                set_transition_matrices())  
            * `obs_llk_threshold` :  
                The minimal log-likelihood of the observations to be accepted. If the
                log-likelihood of the observation is less than this threshold, then the
                classification will return UNKNOWN (last column in the confusion matrix)  

            See also: plHMM::ObservationSequenceArray_t  

            See also: plHMM::ObservationSequence_t  

            See also: plHMM::Observation_t  

        """
        return _probt_python3.plConcurrentHmmSetLearner_run_online_evaluation(self, *args)


    def model_online_performance_map(self) -> "std::map< std::string,plPredictionPerformanceReport,std::less< std::string >,std::allocator< std::pair< std::string const,plPredictionPerformanceReport > > > const &":
        """
        model_online_performance_map(self) -> std::map< std::string,plPredictionPerformanceReport,std::less< std::string >,std::allocator< std::pair< std::string const,plPredictionPerformanceReport > > > const &


        `model_online_performance_map() const -> const std::map< std::string,
            plPredictionPerformanceReport > &`  

        Get a map (key: model name, value: model offline perfs as a
        plPredictionPerformanceReport) for each learnt model.  

        """
        return _probt_python3.plConcurrentHmmSetLearner_model_online_performance_map(self)


    def compute_dissimilarity_matrices(self, *args) -> "void":
        """
        compute_dissimilarity_matrices(self, obs_sequences, symmetric=False)
        compute_dissimilarity_matrices(self, obs_sequences)
        compute_dissimilarity_matrices(self, csv_learning_files, csv_file_has_header=False, csv_file_nrows_to_ignore=0, csv_file_columns_to_ignore, symmetric=False)
        compute_dissimilarity_matrices(self, csv_learning_files, csv_file_has_header=False, csv_file_nrows_to_ignore=0, csv_file_columns_to_ignore)
        compute_dissimilarity_matrices(self, csv_learning_files, csv_file_has_header=False, csv_file_nrows_to_ignore=0)
        compute_dissimilarity_matrices(self, csv_learning_files, csv_file_has_header=False)
        compute_dissimilarity_matrices(self, csv_learning_files)


        `compute_dissimilarity_matrices(const std::vector<
            plHMM::ObservationSequenceArray_t > &obs_sequences, bool symmetric=false)`  
        `compute_dissimilarity_matrices(const std::vector< std::vector< std::string > >
            &csv_learning_files, bool csv_file_has_header=false, unsigned int
            csv_file_nrows_to_ignore=0, const std::vector< unsigned int >
            &csv_file_columns_to_ignore=std::vector< unsigned int >(), bool
            symmetric=false)`  

        Overloaded function
        -------------------
        * `compute_dissimilarity_matrices(const std::vector<
            plHMM::ObservationSequenceArray_t > &obs_sequences, bool symmetric=false)`  

            Compute the dissimilarity matrices of the learnt models and put the results
            in a map.  

            High dissimilarity values correspond to good offline classification
            performances  

            Parameters:  
            * `obs_sequences` :  
                An observation sequence array. An observation sequence is a vector of
                float vectors (observations). In each observation, order of elements
                matter. This order must correspond to the observation_decomposition
                learner's variables as in
                `observation_decomposition->get_left_variables()` or the order defined
                by the parameter observation_variable_names. In case the orders do not
                match, you will get incorrect results, and possibly occurrence of
                plWarning 17 (value out of range).  
            * `symmetric` :  
                If True, symmetric dissimilarity matrices are computed.  

            See also: plConcurrentHmmSet::compute_dissimilarity_matrix()  

            See also: plHMM::ObservationSequenceArray_t  

            See also: plHMM::ObservationSequence_t  

            See also: plHMM::Observation_t  

        * `compute_dissimilarity_matrices(const std::vector< std::vector< std::string >
            > &csv_learning_files, bool csv_file_has_header=false, unsigned int
            csv_file_nrows_to_ignore=0, const std::vector< unsigned int >
            &csv_file_columns_to_ignore=std::vector< unsigned int >(), bool
            symmetric=false)`  

            Same as above however each observation sequence is loaded when needed (not
            preloaded in memory)  

        """
        return _probt_python3.plConcurrentHmmSetLearner_compute_dissimilarity_matrices(self, *args)


    def model_dissimilarity_matrix_map(self) -> "std::map< std::string,plFloatMatrix,std::less< std::string >,std::allocator< std::pair< std::string const,plFloatMatrix > > > const &":
        """
        model_dissimilarity_matrix_map(self) -> std::map< std::string,plFloatMatrix,std::less< std::string >,std::allocator< std::pair< std::string const,plFloatMatrix > > > const &


        `model_dissimilarity_matrix_map() const -> const std::map< std::string,
            plFloatMatrix > &`  

        Get a map (key: model name, value: dissimilarity matrix) for each learnt model.  

        """
        return _probt_python3.plConcurrentHmmSetLearner_model_dissimilarity_matrix_map(self)


    def get_class_names(self) -> "std::vector< std::string,std::allocator< std::string > > const &":
        """
        get_class_names(self) -> StringVector


        `get_class_names() const -> const std::vector< std::string > &`  

        Get class names.  

        """
        return _probt_python3.plConcurrentHmmSetLearner_get_class_names(self)


    def python_plot_learning_scores(self) -> "void":
        """
        python_plot_learning_scores(self)


        `python_plot_learning_scores()`  

        Only for Python: Plot the log-likelihood, BIC, and AIC scores.  

        """
        return _probt_python3.plConcurrentHmmSetLearner_python_plot_learning_scores(self)


    def observation_variables(self) -> "plVariablesConjunction":
        """
        observation_variables(self) -> plVariablesConjunction


        `observation_variables() const -> plVariablesConjunction`  

        Get the observation variables.  

        """
        return _probt_python3.plConcurrentHmmSetLearner_observation_variables(self)


    def get_error_files(csv_files: 'StringVectorVector', errors: 'PairUiVector') -> "std::vector< std::pair< std::string,unsigned int >,std::allocator< std::pair< std::string,unsigned int > > >":
        """
        get_error_files(csv_files, errors) -> PairStringUiVector


        `get_error_files(const std::vector< std::vector< std::string > > &csv_files,
            const std::vector< std::pair< unsigned int, unsigned int > > &errors) ->
            std::vector< std::pair< std::string, unsigned int > >`  

        Get the file examples corresponding to classification errors.  

        It returns for, each error, a pair <file, errornous predicted class index>.  

        Parameters
        ----------
        * `csv_files` :  
            The files corresponding to the sequences passed to run_offline_evaluation()  
        * `errors` :  
            Classification error information as returned by
            plPredictionPerformanceReport::get_classification_error_row_numbers()  

        To be used in conjunction with
        plPredictionPerformanceReport::get_classification_error_row_numbers() as
        follows:  

            plConcurrentHmmSetLearner my_learner(...);
            .
            .
            .
            my_learner.run_learning(...)
            .
            .
            .
            my_learner.run_offline_evaluation(csv_test_files, ...)
            plPredictionPerformanceReport my_perf_report =
        my_learner.model_offline_performance_map()["GestureAcceleroGyroBestBIC"];

            std::vector<std::pair<std::string, unsigned int> >
            error_files = plConcurrentHmmSetLearner::get_error_files(csv_test_files,
        my_perf_report.get_classification_error_row_numbers());


        """
        return _probt_python3.plConcurrentHmmSetLearner_get_error_files(csv_files, errors)

    get_error_files = staticmethod(get_error_files)

    def get_observation_model(self) -> "plLearnObject const *":
        """
        get_observation_model(self) -> plLearnObject


        `get_observation_model() const -> const plLearnObject *`  

        Get the observation model.  

        Return 0 if not set  

        """
        return _probt_python3.plConcurrentHmmSetLearner_get_observation_model(self)


    def observation_model_draw_graph_dot(self, *args) -> "void":
        """
        observation_model_draw_graph_dot(self, file_name, dot_node_shape, dot_node_color, dot_node_fill_color, dot_background_color, dot_edge_color, dot_rankdir)
        observation_model_draw_graph_dot(self, file_name, dot_node_shape, dot_node_color, dot_node_fill_color, dot_background_color, dot_edge_color)
        observation_model_draw_graph_dot(self, file_name, dot_node_shape, dot_node_color, dot_node_fill_color, dot_background_color)
        observation_model_draw_graph_dot(self, file_name, dot_node_shape, dot_node_color, dot_node_fill_color)
        observation_model_draw_graph_dot(self, file_name, dot_node_shape, dot_node_color)
        observation_model_draw_graph_dot(self, file_name, dot_node_shape)
        observation_model_draw_graph_dot(self, file_name)
        observation_model_draw_graph_dot(self, dot_node_shape, dot_node_color, dot_node_fill_color, dot_background_color, dot_edge_color, dot_rankdir)
        observation_model_draw_graph_dot(self, dot_node_shape, dot_node_color, dot_node_fill_color, dot_background_color, dot_edge_color)
        observation_model_draw_graph_dot(self, dot_node_shape, dot_node_color, dot_node_fill_color, dot_background_color)
        observation_model_draw_graph_dot(self, dot_node_shape, dot_node_color, dot_node_fill_color)
        observation_model_draw_graph_dot(self, dot_node_shape, dot_node_color)
        observation_model_draw_graph_dot(self, dot_node_shape)
        observation_model_draw_graph_dot(self)


        `observation_model_draw_graph_dot(const std::string &file_name, const
            std::string &dot_node_shape="ellipse", const std::string
            &dot_node_color="black", const std::string
            &dot_node_fill_color="lightblue", const std::string
            &dot_background_color="white", const std::string
            &dot_edge_color="black", const std::string &dot_rankdir="TD") const`  
        `observation_model_draw_graph_dot(std::ostream &out, const std::string
            &dot_node_shape="ellipse", const std::string &dot_node_color="black",
            const std::string &dot_node_fill_color="lightblue", const std::string
            &dot_background_color="white", const std::string
            &dot_edge_color="black", const std::string &dot_rankdir="TD") const`  

        Overloaded function
        -------------------
        * `observation_model_draw_graph_dot(const std::string &file_name, const
            std::string &dot_node_shape="ellipse", const std::string
            &dot_node_color="black", const std::string
            &dot_node_fill_color="lightblue", const std::string
            &dot_background_color="white", const std::string
            &dot_edge_color="black", const std::string &dot_rankdir="TD") const`  

            Writes the graphviz dot drawing instructions to represent the graph
            corresponding to the observation model in *file_name*.  

            The parameters dot_node_shape, dot_node_color, dot_node_fill_color,
            dot_background_color, and dot_rankdir correspond to graphviz dot ones (see
            http://www.graphviz.org/pdf/dotguide.pdf). There values will be inserted in
            the generated dot file without checking their validity.  

            To generate an image file from the generated graphvis dot *file_name*, you
            can use "dot -T'img_format' 'file_name' -o file_name.'img_format' " in
            which 'img_format' could be "pdf", "png",... The supported image formats
            could be found in http://www.graphviz.org/pdf/dotguide.pdf  

        * `observation_model_draw_graph_dot(std::ostream &out, const std::string
            &dot_node_shape="ellipse", const std::string &dot_node_color="black",
            const std::string &dot_node_fill_color="lightblue", const std::string
            &dot_background_color="white", const std::string
            &dot_edge_color="black", const std::string &dot_rankdir="TD") const`  

        """
        return _probt_python3.plConcurrentHmmSetLearner_observation_model_draw_graph_dot(self, *args)


    def observation_model_as_graph_dot(self, *args) -> "std::string":
        """
        observation_model_as_graph_dot(self, dot_node_shape, dot_node_color, dot_node_fill_color, dot_background_color, dot_edge_color, dot_rankdir) -> std::string
        observation_model_as_graph_dot(self, dot_node_shape, dot_node_color, dot_node_fill_color, dot_background_color, dot_edge_color) -> std::string
        observation_model_as_graph_dot(self, dot_node_shape, dot_node_color, dot_node_fill_color, dot_background_color) -> std::string
        observation_model_as_graph_dot(self, dot_node_shape, dot_node_color, dot_node_fill_color) -> std::string
        observation_model_as_graph_dot(self, dot_node_shape, dot_node_color) -> std::string
        observation_model_as_graph_dot(self, dot_node_shape) -> std::string
        observation_model_as_graph_dot(self) -> std::string


        `observation_model_as_graph_dot(const std::string &dot_node_shape="ellipse",
            const std::string &dot_node_color="black", const std::string
            &dot_node_fill_color="lightblue", const std::string
            &dot_background_color="white", const std::string
            &dot_edge_color="black", const std::string &dot_rankdir="TD") const ->
            std::string`  

        """
        return _probt_python3.plConcurrentHmmSetLearner_observation_model_as_graph_dot(self, *args)


    def python_observation_model_draw_graph_dot(self) -> "void":
        """
        python_observation_model_draw_graph_dot(self)


        `python_observation_model_draw_graph_dot()`  

        Only for Python: Same as observation_model_draw_graph_dot() above.  

        """
        return _probt_python3.plConcurrentHmmSetLearner_python_observation_model_draw_graph_dot(self)


    def set_deterministic_initialization(self, do_it: 'bool') -> "void":
        """
        set_deterministic_initialization(self, do_it)


        `set_deterministic_initialization(bool do_it)`  

        Set/unset the deterministic initialization in addition to the random ones.  

        """
        return _probt_python3.plConcurrentHmmSetLearner_set_deterministic_initialization(self, do_it)


    def get_continuous_node_n_mixtures(self) -> "std::vector< unsigned int,std::allocator< unsigned int > > const &":
        """
        get_continuous_node_n_mixtures(self) -> UnsignedIntVector


        `get_continuous_node_n_mixtures() const -> const std::vector< unsigned > &`  

        Get the candidate number of mixtures to be used for continuous variables.  

        """
        return _probt_python3.plConcurrentHmmSetLearner_get_continuous_node_n_mixtures(self)


    def set_continuous_node_n_mixtures(self, continuous_node_n_mixtures: 'UnsignedIntVector') -> "void":
        """
        set_continuous_node_n_mixtures(self, continuous_node_n_mixtures)


        `set_continuous_node_n_mixtures(const std::vector< unsigned >
            &continuous_node_n_mixtures)`  

        Set/change the candidate number of mixtures to be used for continuous variables.  

        """
        return _probt_python3.plConcurrentHmmSetLearner_set_continuous_node_n_mixtures(self, continuous_node_n_mixtures)


    def __getstate__(self) -> "std::string":
        """__getstate__(self) -> std::string"""
        return _probt_python3.plConcurrentHmmSetLearner___getstate__(self)


    def __setstate_internal(self, sState: 'std::string const &') -> "void":
        """__setstate_internal(self, sState)"""
        return _probt_python3.plConcurrentHmmSetLearner___setstate_internal(self, sState)


    def __setstate__(self, sState):
        self.__init__()
        self.__setstate_internal(sState)

plConcurrentHmmSetLearner_swigregister = _probt_python3.plConcurrentHmmSetLearner_swigregister
plConcurrentHmmSetLearner_swigregister(plConcurrentHmmSetLearner)

def plConcurrentHmmSetLearner_load_csv_files(*args) -> "std::vector< plHMM::ObservationSequenceArray_t,std::allocator< plHMM::ObservationSequenceArray_t > >":
    """
    load_csv_files(csv_files, csv_file_nrows_to_ignore, csv_file_columns_to_ignore, ncols=0) -> DoubleVectorVectorVector
    load_csv_files(csv_files, csv_file_nrows_to_ignore, csv_file_columns_to_ignore) -> DoubleVectorVectorVector
    plConcurrentHmmSetLearner_load_csv_files(csv_files, csv_file_nrows_to_ignore, csv_file_columns_to_ignore) -> DoubleVectorVectorVectorVector


    `load_csv_files(const std::vector< std::string > &csv_files, unsigned int
        csv_file_nrows_to_ignore, const std::vector< unsigned int >
        &csv_file_columns_to_ignore, unsigned int ncols=0) ->
        plHMM::ObservationSequenceArray_t`  
    `load_csv_files(const std::vector< std::vector< std::string > > &csv_files,
        unsigned int csv_file_nrows_to_ignore, const std::vector< unsigned int >
        &csv_file_columns_to_ignore) -> std::vector<
        plHMM::ObservationSequenceArray_t >`  

    Overloaded function
    -------------------
    * `load_csv_files(const std::vector< std::string > &csv_files, unsigned int
        csv_file_nrows_to_ignore, const std::vector< unsigned int >
        &csv_file_columns_to_ignore, unsigned int ncols=0) ->
        plHMM::ObservationSequenceArray_t`  

        Load the data matrix for model learning/testing.  

        Parameters:  
        * `csv_files` :  
            A vector of file names  
        * `csv_file_nrows_to_ignore` :  
            The number of rows to be ignored in the csv files  
        * `csv_file_columns_to_ignore` :  
            The indices (starting from 0) of the csv columns to be ignored  
        * `ncols` :  
            The number of fields to be loaded. If 0 (the default value), the number
            will be guessed from the csv files  

        Returns:
        obs_sequences The loaded observation matrix: A vector of observation
        sequence arrays (an observation sequence array for each class (HMM)). An
        observation sequence is a vector of float vectors (observations)  

        See also: plHMM::ObservationSequenceArray_t  

        See also: plHMM::ObservationSequence_t  

        See also: plHMM::Observation_t  

    * `load_csv_files(const std::vector< std::vector< std::string > > &csv_files,
        unsigned int csv_file_nrows_to_ignore, const std::vector< unsigned int >
        &csv_file_columns_to_ignore) -> std::vector<
        plHMM::ObservationSequenceArray_t >`  

        Load the data matrix for model learning/testing.  

        Parameters:  
        * `csv_files` :  
            A vector of string vectors (a string vector for each class (HMM))  
        * `csv_file_nrows_to_ignore` :  
            The number of rows to be ignored in the csv files  
        * `csv_file_columns_to_ignore` :  
            The indices (starting from 0) of the csv columns to be ignored  

        Returns:
        obs_sequences The loaded observation matrix: A vector of observation
        sequence arrays (an observation sequence array for each class (HMM)). An
        observation sequence is a vector of float vectors (observations)  

        See also: plHMM::ObservationSequenceArray_t  

        See also: plHMM::ObservationSequence_t  

        See also: plHMM::Observation_t  

    """
    return _probt_python3.plConcurrentHmmSetLearner_load_csv_files(*args)

def plConcurrentHmmSetLearner_file_system_to_file_names(*args) -> "std::vector< std::vector< std::string,std::allocator< std::string > >,std::allocator< std::vector< std::string,std::allocator< std::string > > > >":
    """
    file_system_to_file_names(data_path, class_names, profile_names, file_prefix, file_suffix) -> StringVectorVector
    file_system_to_file_names(data_path, class_names, profile_names, file_prefix) -> StringVectorVector
    file_system_to_file_names(data_path, class_names, profile_names) -> StringVectorVector
    file_system_to_file_names(data_path, class_names, file_prefix, file_suffix) -> StringVectorVector
    file_system_to_file_names(data_path, class_names, file_prefix) -> StringVectorVector
    plConcurrentHmmSetLearner_file_system_to_file_names(data_path, class_names) -> StringVectorVector


    `file_system_to_file_names(const std::string &data_path, const std::vector<
        std::string > &class_names, const std::vector< std::string > &profile_names,
        const std::string &file_prefix="", const std::string &file_suffix="") ->
        std::vector< std::vector< std::string > >`  
    `file_system_to_file_names(const std::string &data_path, const std::vector<
        std::string > &class_names, const std::string &file_prefix="", const
        std::string &file_suffix="") -> std::vector< std::vector< std::string > >`  

    Overloaded function
    -------------------
    * `file_system_to_file_names(const std::string &data_path, const std::vector<
        std::string > &class_names, const std::vector< std::string > &profile_names,
        const std::string &file_prefix="", const std::string &file_suffix="") ->
        std::vector< std::vector< std::string > >`  

        Get a list of files from a file system hierarchy.  

        For example, in a gesture recognition example with 3 classes (gesture1,
        gesture2, gesture3) with sets of sequence files recorded for 2 persons
        (person1, person2). If we have the following file system hierarchy:  

            | gesture_data
            | |- gesture1
            | | | - person1
            | | | | - example1.txt
            | | | | - example2.txt
            | | | - person2
            | | | | - example1.txt
            | | | | - example2.txt
            | | | | - example3.txt
            | | | - person3
            | | | | - example1.txt
            | | | | - example2.txt
            | | | | - example3.txt
            | |- gesture2
            | | | - person1
            | | | | - example1.txt
            | | | - person2
            | | | | - example1.txt
            | | | | - example2.txt
            | | | | - example3.txt
            | | | - person3
            | | | | - example1.txt
            | | | | - example2.txt
            | | | | - example3.txt
            | |- gesture3
            | | | - person1
            | | | | - example1.txt
            | | | | - example2.txt
            | | | | - example3.txt
            | | | - person2
            | | | | - example1.txt
            | | | | - example2.txt
            | | | | - example3.txt
            | | | | - example4.txt
            | | | - person3
            | | | | - example1.txt
            | | | | - example2.txt
            | | | | - example3.txt  

        Calling file_system_to_file_names() with data_path="gesture_data",
        class_names=["gesture1", "gesture2", "gesture3"] and
        profile_names=["person1", "person2"] will return:  

            [
            [
            "gesture_data/gesture1/person1/example1.txt",
            "gesture_data/gesture1/person1/example2.txt",
            "gesture_data/gesture1/person2/example1.txt",
            "gesture_data/gesture1/person2/example2.txt",
            "gesture_data/gesture1/person2/example3.txt"
            ]
            [
            "gesture_data/gesture2/person1/example1.txt",
            "gesture_data/gesture2/person2/example1.txt",
            "gesture_data/gesture2/person2/example2.txt",
            "gesture_data/gesture2/person2/example3.txt"
            ]
            [
            "gesture_data/gesture3/person1/example1.txt",
            "gesture_data/gesture3/person1/example2.txt",
            "gesture_data/gesture3/person1/example3.txt",  
            "gesture_data/gesture3/person2/example1.txt",
            "gesture_data/gesture3/person2/example2.txt",
            "gesture_data/gesture3/person2/example3.txt",
            "gesture_data/gesture3/person2/example4.txt"
            ]
            ]  

        Parameters:  
        * `data_path` :  
            The root file hierarchy to scan  
        * `class_names` :  
            The class names corresponding to the subdirectories of data_path to scan  
        * `profile_names` :  
            The profile names corresponding to the subdirectories of
            data_path/class_name to scan  
        * `file_prefix` :  
            Prefix of the files to be loaded from the directories
            data_path/class_name/profile_name  
        * `file_suffix` :  
            Suffix of the files to be loaded from the directories
            data_path/class_name/profile_name  

        Returns:
        A vector of string vectors (a string vector for each class (HMM)).  

    * `file_system_to_file_names(const std::string &data_path, const std::vector<
        std::string > &class_names, const std::string &file_prefix="", const
        std::string &file_suffix="") -> std::vector< std::vector< std::string > >`  

        Get a list of files from a file system hierarchy.  

        For example, in a gesture recognition example with 3 classes (gesture1,
        gesture2, gesture3). If we have the following file system hierarchy:  

            | gesture_data
            | |- gesture1
            | | | - example1.txt
            | | | - example2.txt
            | |- gesture2
            | | | - example1.txt
            | |- gesture3
            | | | - example1.txt
            | | | - example2.txt
            | | | - example3.txt  

        Calling file_system_to_file_names() with data_path="gesture_data",
        class_names=["gesture1", "gesture2", "gesture3"] and
        profile_names=["person1", "person2"] will return:  

            [
            ["gesture_data/gesture1/example1.txt",
        "gesture_data/gesture1/example2.txt"]
            ["gesture_data/gesture2/example1.txt"]
            ["gesture_data/gesture3/example1.txt",
        "gesture_data/gesture3/example2.txt",
        "gesture_data/gesture3/example3.txt"]
            ]  

        Parameters:  
        * `data_path` :  
            The root file hierarchy to scan  
        * `class_names` :  
            The class names corresponding to the subdirectories of data_path to scan  
        * `file_prefix` :  
            Prefix of the files to be loaded from the directories
            data_path/class_name  
        * `file_suffix` :  
            Suffix of the files to be loaded from the directories
            data_path/class_name  

        Returns:
        A vector of string vectors (a string vector for each class (HMM)).  

    """
    return _probt_python3.plConcurrentHmmSetLearner_file_system_to_file_names(*args)

def plConcurrentHmmSetLearner_get_sorted_directory_files(*args) -> "bool":
    """
    get_sorted_directory_files(dir_name, file_names, file_prefix, file_suffix) -> bool
    get_sorted_directory_files(dir_name, file_names, file_prefix) -> bool
    plConcurrentHmmSetLearner_get_sorted_directory_files(dir_name, file_names) -> bool


    `get_sorted_directory_files(const std::string &dir_name, std::vector<
        std::string > &file_names, const std::string &file_prefix="", const
        std::string &file_suffix="") -> bool`  

    Get the list of files of a given directory.  

    """
    return _probt_python3.plConcurrentHmmSetLearner_get_sorted_directory_files(*args)

def plConcurrentHmmSetLearner_get_error_files(csv_files: 'StringVectorVector', errors: 'PairUiVector') -> "std::vector< std::pair< std::string,unsigned int >,std::allocator< std::pair< std::string,unsigned int > > >":
    """
    plConcurrentHmmSetLearner_get_error_files(csv_files, errors) -> PairStringUiVector


    `get_error_files(const std::vector< std::vector< std::string > > &csv_files,
        const std::vector< std::pair< unsigned int, unsigned int > > &errors) ->
        std::vector< std::pair< std::string, unsigned int > >`  

    Get the file examples corresponding to classification errors.  

    It returns for, each error, a pair <file, errornous predicted class index>.  

    Parameters
    ----------
    * `csv_files` :  
        The files corresponding to the sequences passed to run_offline_evaluation()  
    * `errors` :  
        Classification error information as returned by
        plPredictionPerformanceReport::get_classification_error_row_numbers()  

    To be used in conjunction with
    plPredictionPerformanceReport::get_classification_error_row_numbers() as
    follows:  

        plConcurrentHmmSetLearner my_learner(...);
        .
        .
        .
        my_learner.run_learning(...)
        .
        .
        .
        my_learner.run_offline_evaluation(csv_test_files, ...)
        plPredictionPerformanceReport my_perf_report =
    my_learner.model_offline_performance_map()["GestureAcceleroGyroBestBIC"];

        std::vector<std::pair<std::string, unsigned int> >
        error_files = plConcurrentHmmSetLearner::get_error_files(csv_test_files,
    my_perf_report.get_classification_error_row_numbers());


    """
    return _probt_python3.plConcurrentHmmSetLearner_get_error_files(csv_files, errors)

###############################################################################
##                            Graphviz Graph drawing                         ##
###############################################################################

def _random_file_name(length):
    import random, string
    return ''.join(random.choice(string.ascii_lowercase) for _ in range(length))

def _save_fig_proba(distribution, filename, plot_scale, plot_color, plot_direction, plot_compact_histogram):
    import matplotlib.pyplot as plt
    w = plot_scale * 2.0
    h = plot_scale * 2.0
    fig = distribution.python_plot(plot_size=(w,h),
                                   scale=plot_scale,
                                   color=plot_color,
                                   direction=plot_direction,
                                   compact_histogram=plot_compact_histogram)
    fig.savefig(filename, bbox_inches='tight', transparent=True,
                pad_inches=0.05, dpi=fig.dpi, format='png')
    plt.close(fig)

def _get_evidence_clr(bn, 
                      node,
                      hard_evidence,
                      clr,
                      hard_clr,
                      soft_clr):
    if bn.is_hard_evidence_variable(node) or set(node.as_variable_vector()).issubset(set(hard_evidence.keys())):
        return hard_clr
    if bn.is_soft_evidence_variable(node):
        return soft_clr
    return clr

def _render_dot(dot, explicit_render):
    from graphviz import Source
    src = Source(dot)
    if explicit_render:
        tmp_name = _random_file_name(10) 
        tmp_gv_file = tmp_name+'.gv'
        return src.render(tmp_gv_file, view=True)
    return src

def _get_rindex(searched_right, all_vars):
    parents = []
    sub_parents = []
    for this_left in all_vars:
        inter = searched_right.get_intersection(this_left)
        if not inter.is_empty():
            parents.append(this_left)
            if this_left.size() != inter.size():
                sub_parents.append(inter)
            else:
                sub_parents.append(None)
    return parents, sub_parents

def _get_plot_image_dotstr(bn, var, hard_evidence, tmp_dir,
                           plot_scale, plot_color, plot_direction, plot_compact_histogram,
                           dot_node_fill_color):
    import os
    dotstr = ''
    var_name = var.to_string()[1:-1]
    filename = os.path.join(tmp_dir, _random_file_name(20)+var_name+'_plot.png')
    prob = bn.get_belief(var) if hard_evidence is None else bn.get_belief(var, hard_evidence)
    _save_fig_proba(prob, filename, plot_scale, plot_color, plot_direction, plot_compact_histogram)
    dotstr += ("shape=\"rectangle\", ")
    dotstr += ("image=\"" + filename + "\", ")
    dotstr += ("style=filled, fillcolor=\"" + dot_node_fill_color + "\", ")
    dotstr += ("label=\"\"")
    return dotstr

def _get_image_dotstr(var_name, image_file, scale, dot_node_fill_color):
    dotstr = ''
    dotstr += ("fixedsize=\"true\", ")
    dotstr += ("width=" + str(0.5*scale) +", ")
    dotstr += ("height=" + str(0.5*scale) +", ")
    dotstr += ("shape=\"rectangle\", ")
    dotstr += ("image=\"" + image_file + "\", ")
    dotstr += ("style=filled, fillcolor=\"" + dot_node_fill_color + "\", ")
    dotstr += ("label=\"\"")
    return dotstr

def _get_shape_dotstr(var, dot_node_shape,
                      dot_node_fill_color,
                      dot_node_color, scale):
    dotstr = ''
    var_name = var.to_string()[1:-1]
    dotstr += ("shape=\"" + dot_node_shape + "\", ")
    dotstr += ("style=filled, fillcolor=\"" + dot_node_fill_color + "\", ")
    dotstr += ("color=\"" + dot_node_color + "\", ")
    dotstr += ("label=\"" + var_name + "\"")
    dotstr += ("fontsize=\"" + str(12*scale) + "\"")
    return dotstr


def _probt_python_bn_graph_plot_prob(bn,
                                     dot_background_color='white',
                                     dot_node_shape='ellipse',
                                     dot_node_color='black',
                                     dot_node_fill_color='lightblue',
                                     dot_hard_evidence_node_fill_color='#AAAA00',
                                     dot_soft_evidence_node_fill_color='orange',
                                     dot_edge_color='black',
                                     dot_rankdir='TD',
                                     plot_scale=1,
                                     plot_color='#00BBAA',
                                     plot_direction=None,
                                     plot_compact_histogram=None,
                                     belief_for_nodes=None,
                                     tmp_dir='',
                                     explicit_render=False,
                                     hard_evidence={},
                                     node_images={}):
    """
    Generate a graphviz dot graph for Python, while computing and plotting the belief of a subset of the BN nodes.
    It allows also replacing the standard dot nodes by user-provided images.

    The parameters dot_node_shape, dot_node_color, dot_node_fill_color,
    dot_background_color, and dot_rankdir correspond to graphviz dot ones (see
    http://www.graphviz.org/pdf/dotguide.pdf). There values will be inserted
    in the generated dot file without checking their validity.

# Arguments
        dot_background_color: dot graph background color
        dot_node_shape: dot node shape (to be used only for nodes for which no image is used)
        dot_node_color: dot node contour color (to be used for nodes for which no image is used)
        dot_node_fill_color: dot node fill color (to be used for nodes for which no image is used)
        dot_hard_evidence_node_fill_color: dot node fill color for hard evidence nodes 
        dot_soft_evidence_node_fill_color: dot node fill color for soft evidence nodes 
        dot_edge_color: dot edge color 
        dot_rankdir: dot digraph direction
        plot_scale: plotting scale
        plot_color: distribution plot color
        plot_direction: distribution plot direction among 'H' (horizontal), 'V' (vertical), or None (automatic choice)
        plot_compact_histogram: set to True for plotting the discrete distributions only for non null values
        belief_for_nodes: the list of nodes fo which the belief is computed and plotted (None=all nodes)
        tmp_dir: the temporary directory in which the generated images are stored
        explicit_render: set to False for explicit rendering of the dot generate code (use False, the default, for jupyter notebooks)
        hard_evidence: the hard evidence to be used for inferring the belief (see the belief_for_nodes parameter above)
        node_images: a dictionary node_name -> image_file_name allowing to replace the standard dot nodes by user images

    """    
    dotstr = "digraph \"" + bn.name() + "\" {\n"
    dotstr += ("rankdir=\"" + dot_rankdir + "\";\n")
    dotstr += ("label=\"" + bn.name() + "\";\n")
    dotstr += ("bgcolor=\"" + dot_background_color + "\";\n")
    var2index = {}
    dists = bn.get_joint_distribution().get_computable_object_list()
    all_vars = []
    for d in dists:
        var = d.get_left_variables()
        var_name = var.to_string()[1:-1]
        dotstr += ("\"" + var_name + "\" [")
        node_fill_color = _get_evidence_clr(bn, var, hard_evidence,
                                            dot_node_fill_color,
                                            dot_hard_evidence_node_fill_color,
                                            dot_soft_evidence_node_fill_color)
        if var.size() <= 2 and (belief_for_nodes is None or not set(var.get_names()).isdisjoint(belief_for_nodes)):
            dotstr += _get_plot_image_dotstr(bn, var, hard_evidence, tmp_dir,
                                             plot_scale, plot_color, plot_direction, plot_compact_histogram,
                                             node_fill_color)
        elif var_name in list(node_images.keys()):
            dotstr += _get_image_dotstr(var_name, node_images[var_name], plot_scale, node_fill_color)
        else:
            dotstr += _get_shape_dotstr(var, dot_node_shape, node_fill_color,
                                        dot_node_color, plot_scale)
        dotstr += "];\n"
        all_vars.append(var)

    for d in dists:
        left_var = d.get_left_variables()
        left_var_name = left_var.to_string()[1:-1]
        right_var = d.get_right_variables()
        parents, sub_parents = _get_rindex(right_var, all_vars)
        for pa, sub_p in zip(parents, sub_parents):
            dotstr += ( "\"" + pa.to_string()[1:-1] + "\"->\"" + left_var_name + "\" [")
            dotstr += ("color=\"" + dot_edge_color + "\"")
            if sub_p is not None:
                dotstr += (", label=\"" + sub_p.to_string()[1:-1] + "\"")
            dotstr += "];\n"

    dotstr += "}\n"

    return _render_dot(dotstr, explicit_render)
plBayesianNetwork.python_belief_graph = _probt_python_bn_graph_plot_prob

def _probt_python_bn_graph_plot(bn,
                                dot_node_shape='ellipse',
                                dot_node_color='black', 
                                dot_node_fill_color='lightblue', 
                                dot_background_color='white', 
                                dot_edge_color='black',
                                dot_rankdir='TD',
                                explicit_render=False):
    """
    ProBT's model graph plotting for Python, corresponding  
    to plBayesianNetwork::draw_graph_dot()
    """
    dot = bn.as_graph_dot(dot_node_shape, dot_node_color,
                          dot_node_fill_color, dot_background_color,
                          dot_edge_color, dot_rankdir)
    return _render_dot(dot, explicit_render)
plBayesianNetwork.python_draw_graph = _probt_python_bn_graph_plot

def _probt_python_joint_graph_plot(joint,
                                   dot_graph_label='',
                                   dot_node_shape='ellipse',
                                   dot_node_color='black',
                                   dot_node_fill_color='lightblue',
                                   dot_background_color='white',
                                   dot_edge_color='black',
                                   dot_rankdir='TD',
                                   explicit_render=False):
    """
    ProBT's joint distribution graph plotting for Python, corresponding
    to plJointDistribution::draw_graph_dot()
    """
    dot = joint.as_graph_dot(dot_graph_label,
                             dot_node_shape, dot_node_color,
                             dot_node_fill_color, dot_background_color,
                             dot_edge_color, dot_rankdir)
    return _render_dot(dot, explicit_render)
plJointDistribution.python_draw_graph = _probt_python_joint_graph_plot

def _probt_python_jt_graph_plot(jt,
                                dot_graph_label='',
                                dot_node_shape='ellipse',
                                dot_node_color='black',
                                dot_node_fill_color='lightblue',
                                dot_background_color='white',
                                dot_edge_color='black',
                                dot_rankdir='TD',
                                explicit_render=False):
    """
    ProBT's Junction Tree graph plotting for Python, corresponding to 
    plJunctionTree::output_clique_tree_dot()
    """
    dot = jt.as_graph_dot(dot_graph_label,
                          dot_node_shape, dot_node_color,
                          dot_node_fill_color, dot_background_color,
                          dot_edge_color, dot_rankdir)
    return _render_dot(dot, explicit_render)
plJunctionTree.python_draw_clique_tree = _probt_python_jt_graph_plot

def _probt_python_observation_model_plot(hmm_learner,
                                         dot_node_shape='ellipse',
                                         dot_node_color='black', 
                                         dot_node_fill_color='lightblue', 
                                         dot_background_color='white', 
                                         dot_edge_color='black',
                                         dot_rankdir='TD',
                                         explicit_render=False):
    """
    ProBT's observation model graph plotting for Python, corresponding  
    to plConcurrentHmmSetLearner::observation_model_draw_graph_dot()
    """
    dot = hmm_learner.observation_model_as_graph_dot(dot_node_shape,
                                                     dot_node_color,
                                                     dot_node_fill_color,
                                                     dot_background_color,
                                                     dot_edge_color,
                                                     dot_rankdir)
    return _render_dot(dot, explicit_render)
plConcurrentHmmSetLearner.python_observation_model_draw_graph_dot = _probt_python_observation_model_plot

###############################################################################
##                            Data Descriptor plotting                       ##
###############################################################################

def _name_limit_length(name, l):
    if len(name) <= l:
        return name
    ldots = 3
    lbig = (l-ldots)/2
    lend = l - lbig - ldots
    return name[:lbig] + '...' + name[len(name)-lend:]

def _probt_python_data_plot(data, title='',
                            show_column=None,
                            scale_column=None,
                            offset_column=None,
                            time_stamp_column_name=None,
                            time_stamp_format='%m/%d/%Y:%H:%M:%S',
                            plot_size=(20,5)):
    """
    ProBT's data descriptor plotting for Python, 
    corresponding to plDataDescriptor::generate_gnuplot().

    Keyword arguments:
    show_column -- dictionay with column names as keys and True or False as values
    scale_column -- dictionay with column names as keys and scaling values (float) as values (will plot offset + scale*c)
    offset_column -- dictionay with column names as keys and offset values (float) as values
    time_stamp_column_name -- name of the timestap column if any
    time_stamp_format -- format of the timestap column if any
    """
    import matplotlib.pyplot as plt

    plt.figure(figsize=plot_size)
    vars = data.observed_variables()
    x = range(data.get_n_records())
    xlab = ''
    if time_stamp_column_name is not None:
        from datetime import datetime
        time_stamp_var = vars.get_variable_with_name(time_stamp_column_name)
        time_vals = StringVector()
        data.get_variable_values(time_stamp_var, time_vals)
        x = [datetime.strptime(d, time_stamp_format)
            for d in time_vals]
        xlab = time_stamp_column_name

    for v in vars:
        if v.name() != time_stamp_column_name:
            if show_column is None or show_column.get(v.name()) == True:
                vy = DoubleVector()
                data.get_variable_values(v, vy)
                scal = 1.0
                offset = 0.0
                if scale_column is not None:
                    scal = scale_column.get(v.name(), 1.0)
                if offset_column is not None:
                    offset = offset_column.get(v.name(), 0.)
                vy = [offset + d*scal for d in vy]
                plt.plot(x, vy, label=_name_limit_length(v.name(),10))
    plt.legend()
    plt.xlabel(xlab)
    plt.title(title)
plDataDescriptor.python_plot = _probt_python_data_plot


###############################################################################
## Conditional and non-conditional distribution plotting                     ##
###############################################################################
def _probt_python_plot_distribution_continuous_1D(distribution, nsamples, color, right_val):
    import matplotlib.pyplot as plt

    left = distribution.get_left_variables()
    left_type = left.get_type()
    min_value = left_type.get_min()
    max_value = left_type.get_max()
    sample_pts = [float(x+0.5)/float(nsamples)*(max_value-min_value)+min_value for x in range(nsamples)]
    if not distribution.isObject(PLDeterministic):
        output_pts = [distribution.compute(x) for x in sample_pts]
    else:
        dirac_point = list(plDeterministic(distribution).get_dirac_point().values())[0]
        output_pts = [1. if abs(x-dirac_point) <= (max_value-min_value)/nsamples else 0. for x in sample_pts]
    plt.plot( sample_pts, output_pts, color=color )
    ylab = 'P('+left.name()+' | ' + right_val +')' if right_val != '' else 'P('+left.name()+')'
    plt.ylabel(ylab)
    plt.xlabel(left.name())

def _probt_python_plot_img(array2d, x, y, xmin_value=None, xmax_value=None,
                           ymin_value=None, ymax_value=None, right_val=''):
    import matplotlib.pyplot as plt

    if xmin_value is not None:
        plt.imshow(array2d, interpolation='none', origin='lower', aspect='auto',
                   extent=[xmin_value, xmax_value, ymin_value, ymax_value])
    else:
        xtype = x.get_type()
        ytype = y.get_type()
        x_vals = xtype.get_values_as_strings()
        y_vals = ytype.get_values_as_strings()
        if len(x_vals) < 10 and len(y_vals) < 10 :
            ax = plt.gca()
            plt.imshow(array2d, interpolation='none', origin='lower', aspect='auto')
            ax.set_xticks(np.arange(len(x_vals)))
            ax.set_yticks(np.arange(len(y_vals)))
            ax.set_xticklabels(x_vals)
            ax.set_yticklabels(y_vals)
        else:
            plt.imshow(array2d, interpolation='none', origin='lower', aspect='auto',
                       extent=[xtype.get_min(), xtype.get_max(), ytype.get_min(), ytype.get_max()])

    title = 'P('+x.name() +' '+y.name()+' | ' + right_val +')' if right_val != '' else 'P('+x.name() +' '+y.name() +')'

    plt.colorbar()
    plt.title(title)
    plt.xlabel(x.name())
    plt.ylabel(y.name())


def _probt_python_plot_distribution_continuous_2D(distribution, nsamples, right_val):
    import numpy as np
    vars = distribution.get_variables()
    xvar = vars[0]
    yvar = vars[1]

    xtype = xvar.get_type()
    xmin_value = xtype.get_min()
    xmax_value = xtype.get_max()

    ytype = yvar.get_type()
    ymin_value = ytype.get_min()
    ymax_value = ytype.get_max()

    s = (nsamples, nsamples)
    probs = np.zeros(s)
    xstep = (xmax_value-xmin_value)/float(nsamples)
    ystep = (ymax_value-ymin_value)/float(nsamples)
    if not distribution.isObject(PLDeterministic):
        done = False
        nit = 0
        while not done and nit < 3:
#print('it:', nit)
            for ix in range(nsamples):
                for iy in range(nsamples):
                    probs[iy,ix] = distribution.compute([(ix+0.5)*xstep+xmin_value, (iy+0.5)*ystep+ymin_value])
                    if probs[iy,ix] > 0: done = True
            if not done:
                nsamples = 2*nsamples
                probs = np.zeros((nsamples, nsamples))
                xstep = (xmax_value-xmin_value)/float(nsamples)
                ystep = (ymax_value-ymin_value)/float(nsamples)
            nit +=1
    else:
        dirac_point = list(plDeterministic(distribution).get_dirac_point().values())
        dirac_point_x = dirac_point[0]
        dirac_point_y = dirac_point[1]
        ix = int((dirac_point_x - xmin_value)/xstep - 0.5)
        iy = int((dirac_point_y - ymin_value)/ystep - 0.5)
        probs[iy,ix] = 1.0

    _probt_python_plot_img(probs, xvar, yvar, xmin_value,
                           xmax_value, ymin_value, ymax_value, right_val)

def _set_bar_h(fig, ra, probs, labels, txt_format, ax, color, text_size, scale, vname, right_val):
    n = len(probs)
    fig.set_figheight(scale * n / 4.0)
    fig.set_figwidth(scale * 2.0)
    labels = ["{0}".format(l) for l in labels]
    labels.reverse()
    probs = [p for p in probs]
    probs.reverse()
    bars = ax.barh(ra, probs, align='center', color=color)
    ma = max(probs)
    for bar in bars:
        if bar.get_width() != 0:
            txt = txt_format.format(bar.get_width())
            ax.text(ma, bar.get_y(), txt, ha='right', va='bottom', fontsize=text_size)
    ax.set_xlim(0, ma)
    ax.set_yticks(ra)
    ax.set_yticklabels(labels)
    ax.set_xticklabels([])

    title = vname + ' for ' + right_val if right_val != '' else vname
    ax.set_title(title, fontsize=text_size)
    ax.get_xaxis().grid(False)

def _set_bar_v(fig, ra, probs, labels, txt_format, ax, color, text_size, scale, vname, right_val):
    fig.set_figwidth(scale * len(probs) / 4.0)
    fig.set_figheight(scale * 2.0)
    bars = ax.bar(ra, probs, align='center', color=color)
    ma = max(probs)
    ax.set_ylim(bottom=0, top=ma)
    ax.set_xticks(ra)
    ax.set_xticklabels(labels, rotation='vertical')
    ylab = 'P('+vname+' | ' + right_val +')' if right_val != '' else 'P('+vname+')'
    ax.set_ylabel(ylab, fontsize=text_size)
    ax.set_xlabel(vname, fontsize=text_size)
    ax.get_yaxis().grid(False)

def _support(labels, probs):
    mi = 0
    while probs[mi] == 0.:
        mi += 1

    l = len(probs)-1
    ma = l
    while probs[ma] == 0.:
        ma -= 1

    new_ra = range(mi, ma+1)
    new_prob = [probs[i] for i in new_ra]
    new_labels = labels[mi:ma+1]
    if mi != 0:
        new_labels[0] = "..."
    if ma != l:
        new_labels[-1] = "..." 

    return new_ra, new_prob, new_labels

def _probt_python_plot_distribution_histogram_1D(fig, distribution, scale, color, direction, right_val, compact_histogram):
    import matplotlib.pyplot as plt
    left = distribution.get_left_variables()
    _, probs = distribution.tabulate()
    labels = list(left.get_type().get_values_as_strings())
    ra = range(len(probs))

    if compact_histogram is None:
        compact_histogram = (len(labels) > 69)
    if compact_histogram:
        ra, probs, labels = _support(labels, probs)

    ax = fig.gca()
    text_size = 8*scale
    ndigits = 0
    txt_format = "{:."+str(ndigits)+"%}"
    if direction == 'H':
        _set_bar_h(fig, ra, probs, labels, txt_format, ax, color, text_size, scale, left.name(), right_val)    
    else:
        _set_bar_v(fig, ra, probs, labels, txt_format, ax, color, text_size, scale, left.name(), right_val)

    ax.tick_params(axis='both', which='major', labelsize=text_size)
    ax.margins(0)

def _probt_python_plot_distribution_histogram_2D(distribution, right_val):
    import numpy as np
    _, probs = distribution.compile().tabulate()
    vars = distribution.get_variables()
    x = vars[0]
    y = vars[1]
    nx = int(x.get_cardinality())
    ny = int(y.get_cardinality())

    s = (ny, nx)
    prob_matrix = np.zeros(s)

    for ix in range(nx):
        for iy in range(ny):
            prob_matrix[iy,ix] = probs[ix*ny+iy]
    _probt_python_plot_img(prob_matrix, x, y, right_val=right_val)

def _probt_python_plot_distribution_mixed(distribution, nsamples, color, right_val):
    import matplotlib.pyplot as plt
    vars = distribution.get_variables()
    dvars = vars.get_discrete_variables()
    cvar = plVariable(vars - dvars)
    ctype =  cvar.get_type()
    cmin_value = ctype.get_min()
    cmax_value = ctype.get_max()
    sample_pts = [float(x+0.5)/float(nsamples)*(cmax_value-cmin_value)+cmin_value for x in range(nsamples)]
    dval = plValues(dvars)
    vals = plValues(vars) 
    nd = int(dvars.get_cardinality())
    title = 'P('+dvars.name() +' '+cvar.name()+' | ' + right_val +')' if right_val != '' else 'P('+dvars.name() +' '+cvar.name() +')'
    for r, dv in enumerate(dval.all()):
       sp = plt.subplot(nd, 1, r+1)
       vals.set_partially(dv)
       output_pts = []
       for x in sample_pts:
           vals[cvar] = x
           output_pts.append(distribution.compute(vals))
       sp.plot( sample_pts, output_pts, color=color )
       sp.set_ylabel(dv.to_string()[1:-2])
       if r == 0: sp.set_title(title)
       if r < nd-1: sp.set_xticklabels([])
    plt.xlabel(cvar.name())

def _probt_python_plot_distribution(distribution,
                                    nsamples=101,
                                    right_val='',
                                    plot_size=(6,4),
                                    scale = 1,
                                    color = '#00BBAA',
                                    direction = None,
                                    compact_histogram = None):
    """
    ProBT's distribution plotting for Python, 
    corresponding to plDistribution::plot()
    """
    import matplotlib.pyplot as plt

    left = distribution.get_left_variables()
    if left.dim () > 2:
        raise TypeError('plDistribution.python_plot():' +
                        ' Only 1D and 2D distributions are supported')

    fig = plt.figure(figsize=plot_size)

    if left.dim() == 1:
        if left.is_discrete():
            if direction is None:
                direction = 'V' if left.get_cardinality() > 10 else 'H'
            if direction != 'V' and direction != 'H':
                raise ValueError("direction must be 'H' or 'V'") 
            _probt_python_plot_distribution_histogram_1D(fig, distribution, scale, color,
                                                         direction, right_val, compact_histogram)
        else:
            _probt_python_plot_distribution_continuous_1D(distribution, nsamples, color, right_val)
    else:
        if left.is_discretized():
            _probt_python_plot_distribution_histogram_2D(distribution, right_val)
        elif left.is_continuous():
            _probt_python_plot_distribution_continuous_2D(distribution, nsamples, right_val)
        else:
            _probt_python_plot_distribution_mixed(distribution, nsamples, color, right_val)
    return fig


def _probt_python_plot_cnd_distribution(cnd_distribution,
                                        nsamples=101,
                                        plot_size=(6,4),
                                        scale = 1,
                                        color = '#00BBAA',
                                        direction = None,
                                        compact_histogram = None):
    """
    ProBT's conditional distribution plotting for Python
    """
    import matplotlib.pyplot as plt

    right = cnd_distribution.get_right_variables()
    left = cnd_distribution.get_left_variables()
    if left.dim() > 2:
        raise TypeError('plCndDistribution.python_plot(): ' +
                        ' Only 1D and 2D distributions are supported')
    if not right.is_discrete():
        raise TypeError('plCndDistribution.python_plot(): Only distributions ' +
                        'with discrete right variables are supported')

    rvals = plValues(right)

    for rv in rvals.all():
        dist = cnd_distribution.instantiate(rv)
        rval = rv.to_string()[2:-2]
        _probt_python_plot_distribution(dist, nsamples=nsamples, right_val=rval, plot_size=plot_size,
                                        scale=scale,
                                        color=color,
                                        direction=direction,
                                        compact_histogram=compact_histogram)

def _probt_python_plot_computable_object(computable_object, nsamples=101, plot_size=(6,4),
                                         scale = 1,
                                         color = '#00BBAA',
                                         direction = None,
                                         compact_histogram = None):
    """
    ProBT's conditional and non-conditional distributions plotting for Python

# Arguments
        nsamples: the number of samples to be used for continuous distributions
        plot_size: matplot figsize,
        scale: plotting scale
        direction: distribution plot direction among 'H' (horizontal), 'V' (vertical), or None (automatic choice)
        compact_histogram: set to True for plotting the discrete distributions only for non null values
    """
    if computable_object.is_empty():
        raise TypeError('plComputableObject.python_plot(): The computable object is empty')

    if computable_object.isObject(PLDistribution):
        return _probt_python_plot_distribution(plDistribution(computable_object),
                                               nsamples=nsamples,
                                               plot_size=plot_size,
                                               scale=scale,
                                               color=color,
                                               direction=direction,
                                               compact_histogram=compact_histogram)
    else:
        if computable_object.isObject(PLCndDistribution):
            _probt_python_plot_cnd_distribution(plCndDistribution(computable_object),
                                                nsamples=nsamples,
                                                plot_size=plot_size,
                                                scale=scale,
                                                color=color,
                                                direction=direction,
                                                compact_histogram=compact_histogram)
        else:
            raise TypeError('plComputableObject.python_plot(): The computable object ' +
                            'is not a plDistribution nor plCndDistribution')
plComputableObject.python_plot = _probt_python_plot_computable_object

def _probt_python_plot_computable_object_as_img(computable_object,
                                               filename=None, scale=1, color='#00BBAA', direction=None, compact_histogram=None):
    import matplotlib.pyplot as plt
    import os
    if filename is None:
        filename = _random_file_name(5)+'.png'
    _save_fig_proba(computable_object, filename, scale, color, direction, compact_histogram)
    img = plt.imread(filename)
    os.remove(filename)
    return img
plComputableObject.python_plot_as_img = _probt_python_plot_computable_object_as_img

###############################################################################
##                     K-means and Mixture results plotting                  ##
###############################################################################
def _plKMeans1dCartesian_plot_results(kmeans, pts, ylabel='x', plot_size=(15, 15), plot_dimension=-1):
    """
    Plot the clustering results
    """
    import matplotlib
    import matplotlib.pyplot as plt
    plt.figure(figsize=plot_size)
    colors = list(matplotlib.colors.cnames.keys())

    plt.ylabel(ylabel)

    npts = len(pts)
    nclusters = kmeans.get_k()
    assignment = kmeans.get_assignments()

    if plot_dimension != -1:
        y = [p[plot_dimension] for p in pts]
    else:
        y = pts
    plt.scatter(range(npts), y, color=[colors[p] for p in assignment])

    means = kmeans.get_means()
    for c in range(nclusters):
        if plot_dimension == -1:
            m = [means[c] for p in range(npts)]
        else:
            m = [means[c][plot_dimension] for p in range(npts)]  
        plt.plot(range(npts), m, linewidth=4.0, color=colors[c])
plKMeans1dCartesian.python_plot_results = _plKMeans1dCartesian_plot_results

def _plKMeans2dCartesian_plot_results(kmeans, pts, plot_dimensions=[0, 1],
                                      xlabel='x', ylabel='y', plot_means=False,
                                      plot_size=(15, 15)):
    """
    Plot the clustering results
    """
    import matplotlib
    import matplotlib.pyplot as plt

    if len(plot_dimensions) > 2:
        raise TypeError('plKMeansNdCartesian.python_plot_results(): ' +
                        'The number of dimensions to be plotted should be 1 or 2')

    if len(pts) == 0:
        return

    dim = len(pts[0])
    for d in plot_dimensions:
        if d >= dim or d < 0:
            raise TypeError('plKMeansNdCartesian.python_plot_results(): ' +
                            'The dimensions to be plotted should be positive betwen 0 and clustering space dimension')

    if len(plot_dimensions) == 1:
        _plKMeans1dCartesian_plot_results(kmeans, ylabel=xlabel, plot_size=plot_size, plot_dimension=plot_dimensions[0])
        return

    plt.figure(figsize=plot_size)
    colors = list(matplotlib.colors.cnames.keys())

    plt.xlabel(xlabel)
    plt.ylabel(ylabel)

    npts = len(pts)
    nclusters = kmeans.get_k()
    means = kmeans.get_means()
    assignment = kmeans.get_assignments()
    x = [p[plot_dimensions[0]] for p in pts]
    y = [p[plot_dimensions[1]] for p in pts]
    plt.scatter(x, y, color=[colors[p] for p in assignment])

    if plot_means:
        for c in range(nclusters):
            plt.scatter(means[c][plot_dimensions[0]], means[c][plot_dimensions[1]], color=colors[c], s=1000)
plKMeansNdCartesian.python_plot_results = _plKMeans2dCartesian_plot_results


def _plLearnMixtureModel_plot_results(mixture, plot_size=(10,7), nsamples=101):
    """
    Plot the Mixture learning results
    """
    import matplotlib.pyplot as plt

    nparams = []
    lg_lk = []
    bic = []
    aic = []
    model = []
    candidates = mixture.get_n_mixture_candidates()
    for n in range(len(candidates)):
        nparams.append(mixture.get_model_n_learn_parameters(n))
        lg_lk.append(mixture.get_model_log_likelihood(n))
        bic.append(mixture.get_model_optimality_score(plLearnMixtureModel.BIC, n))
        aic.append(mixture.get_model_optimality_score(plLearnMixtureModel.AIC, n))
        model.append(mixture.get_model_joint(n))


    plt.figure(figsize=plot_size)
    plt.plot(candidates, nparams)
    plt.xlabel('Number of mixtures')
    plt.ylabel('Number of parameters')

    plt.figure(figsize=plot_size)
    plt.plot(candidates, lg_lk, label='log-likelihood')
    plt.plot(candidates, bic, label='BIC')
    plt.plot(candidates, aic, label='AIC')
    plt.legend(loc='lower left')
    plt.xlabel('Number of mixtures')

    for m in model:
        col = m.get_computable_object_list()
        pc = col[0]
        px = col[1]
        ol = px.get_factors()
        pc.python_plot(plot_size=plot_size, nsamples=nsamples)
        for p in ol:
            p.python_plot(plot_size=plot_size, nsamples=nsamples)
        m.ask(px.get_left_variables()).python_plot(plot_size=plot_size,nsamples=nsamples)
plLearnMixtureModel.python_plot_results = _plLearnMixtureModel_plot_results

###############################################################################
##                        HMM learning scores plotting                       ##
###############################################################################
def _plConcurrentHmmSetLearner_plot_learning_scores(hmm_set_learner, nstates, plot_size=(20,5)):
    """
    Plot HMM learning scores
    """
    import matplotlib.pyplot as plt

    model_log_likelihood = hmm_set_learner.get_model_log_likelihood()
    model_bic = hmm_set_learner.get_model_bic()
    model_aic = hmm_set_learner.get_model_aic()
    class_names = hmm_set_learner.get_class_names()
    for c in range(len(class_names)):
        plt.figure(figsize=plot_size)
        plt.plot(nstates, model_log_likelihood[c], label="log-likelihood")
        plt.plot(nstates, model_bic[c], label="BIC")
        plt.plot(nstates, model_aic[c], label="AIC")
        plt.legend()
        plt.xlabel('Number of states')
        plt.title('Learning scores for class '+class_names[c])
plConcurrentHmmSetLearner.python_plot_learning_scores = _plConcurrentHmmSetLearner_plot_learning_scores


def recursive_sublasses(cl, all_derived):
    all_derived.append(cl)
    for c in cl.__subclasses__():
        recursive_sublasses(c, all_derived)

def get_all_derived_classes(cl):
    lst = []
    recursive_sublasses(cl, lst)
    return lst

plObject_subclasses = get_all_derived_classes(plObject)
for c in plObject_subclasses:
    c.__str__ = c.to_string
    c.__repr__ = c.__str__

# Custom __str__ for plComputableObjectList
plComputableObjectList.__str__ = plComputableObjectList_str
plComputableObjectList.__repr__ = plComputableObjectList.__str__	


plFloatMatrix._repr_html_ = plFloatMatrix.as_html

import warnings
import copy
import inspect
import types
import numpy as np
import pandas as pd

try:
# using getfullargspec is needed in our cases for Python3
  from inspect import getfullargspec as getargspec
except ImportError:
# Python2 only has getargspec
  from inspect import getargspec


class SkLearnBnPredictor(object):
    '''Base class for the ProBT scikit-learn wrappers.

    Warning: This class should not be used directly.
    Use descendant classes SkLearnBnClassifier and SkLearnBnRegressor instead.

    The data arrays to be used for fit(), predict*(), and score() functions are allowed to contain missing values 
    (no need to perform missing values imputation).

    '''

    def __init__(self, target_variables=None, input_variables=None, 
                 build_bn=None, build_bn_variables=None, bn=None,
                 **sk_params):
        '''Create a scikit-learn estimator using a ProBT's plBayesianNetwork.

# Arguments
            target_variables: a ProBT variable conjunction (probt.plVariablesConjunction) corresponding to the target
            input_variables: a ProBT variable conjunction (probt.plVariablesConjunction) corresponding
                to the predictors
            build_bn: None or a callable function that should construct and return a ProBT 
                plBayesianNetwork, which will then be used to fit/predict.
                If None, the `bn` parameter must not be None
            build_bn_variables: a ProBT variable conjunction (probt.plVariablesConjunction) to be passed
                to `build_bn`
            bn: None or an already constructed instance of probt.plBayesianNetwork 
                if bn is None then build_bn will be called to fill the self.bn attribute.
                If bn is not None, build_bn will not be called and calling `fit` is not necessary
            sk_params: model parameters & fitting parameters

        `sk_params` takes both model parameters and fitting parameters. Legal model
        parameters are the arguments of `build_bn`. Note that like all other
        estimators in scikit-learn, `build_bn` should provide default values for
        its arguments, so that you could create the estimator without passing any
        values to `sk_params`.

        `sk_params` could also accept parameters for calling `fit`, `predict`,
        `predict_proba`, and `score` methods.
        Fitting (predicting) parameters are selected in the following order:

        1. Values passed to the dictionary arguments of
        `fit`, `predict`, `predict_proba`, and `score` methods
        2. Values passed to `sk_params`

        When using scikit-learn's `grid_search` API, legal tunable parameters are
        those you could pass to `sk_params`, including fitting parameters.
        In other words, you could use `grid_search` to search for the best
        `learning_mode` as well as the model parameters.

    '''
        self.bn = bn
        self.target_variables = target_variables
        self.input_variables = input_variables
        self.build_bn = build_bn
        self.build_bn_variables = build_bn_variables
        self.sk_params = sk_params
        self.check_params(sk_params)

    def check_params(self, params):
        '''Check for user typos in "params" keys to avoid
        unwanted usage of default values

# Arguments
            params: dictionary
                The parameters to be checked
        '''
        legal_params_fns = [self.probt_learn, self.probt_predict]
        if self.build_bn is not None:
            legal_params_fns.append(self.build_bn)

        legal_params = []
        for fn in legal_params_fns:
            legal_params += getargspec(fn)[0]
        legal_params = set(legal_params)

        for params_name in params:
            if params_name not in legal_params:
                raise ValueError('{} is not a legal parameter'.format(params_name))

    def get_params(self, deep=True):
        '''Get parameters for this estimator.

# Arguments
            deep: boolean, optional
                If True, will return the parameters for this estimator and
                contained sub-objects that are estimators.

# Returns
            params: dict
                Dictionary of parameter names mapped to their values.
        '''
        res = copy.deepcopy(self.sk_params)
        res.update({'build_bn': self.build_bn})
        res.update({'build_bn_variables': self.build_bn_variables})
        res.update({'target_variables': self.target_variables})
        res.update({'input_variables': self.input_variables})
        return res

    def set_params(self, **params):
        '''Set the parameters of this estimator.

# Arguments
        params: dict
            Dictionary of parameter names mapped to their values.

# Returns
            self
        '''
        self.check_params(params)
        self.sk_params.update(params)
        return self

    def filter_sk_params(self, fn, override={}):
        '''Filter sk_params and return those in fn's arguments

# Arguments
            fn: arbitrary function
            override: dictionary, values to override sk_params

# Returns
            res: dictionary dictionary containing variables
                in both sk_params and fn's arguments.
        '''
        res = {}
        fn_args = getargspec(fn)[0]
        for name, value in self.sk_params.items():
            if name in fn_args:
                res.update({name: value})
        res.update(override)
        return res

    def update_variables_from_bn(self):
        '''Updates target_variables and input_variables attributes in order to workaround
        a problem accuring after pickling target_variables, input_variables, and bn attributes.
        '''
        bn_vars = self.bn.nodes()
        self.target_variables = bn_vars.get_variables_with_names(self.target_variables.get_names())
        self.input_variables  = bn_vars.get_variables_with_names(self.input_variables.get_names())
        if self.build_bn_variables is not None:
            self.build_bn_variables = bn_vars.get_variables_with_names(self.build_bn_variables.get_names())

    def YX_probt_data_descriptor(self, X, Y):
        '''Construct a ProBT plDataDescriptor instance from a given X, Y numpy/pandas arrays

# Arguments
            X: array-like, shape `(n_samples, n_features)` or `(n_samples,)` when `n_features` = 1
                Samples where n_samples is the number of samples
                and n_features is the number of features.
            Y: array-like, shape `(n_samples,)` or `(n_samples, target_variables.dim())`
                True labels for X.

# Returns
            A ProBT plDataDescriptor having target_variables^input_variables as columns 
        '''
        if len(X) != len(Y):
            raise ValueError('X and Y must have the same size')

        YX_vars = self.target_variables^self.input_variables
        if isinstance(X, pd.DataFrame) and isinstance(Y, pd.DataFrame):
            return  plDataDescriptorFromPandasDF(pd.concat([Y, X], axis=1), YX_vars)

        if len(X.shape) == 1:
            X = X.reshape(-1, 1)
        if len(Y.shape) == 1:
            Y = Y.reshape(-1, 1)
        if X.shape[1] != self.input_variables.size():
            raise ValueError('X.shape[1] must be equal to input_variables dimension')
        return plDataDescriptor.create_from_python_data(np.hstack([Y,X]), YX_vars)

    def X_probt_data_descriptor(self, X):
        '''Construct a ProBT plDataDescriptor instance from a given X numpy/pandas array

# Arguments
            X: array-like, shape `(n_samples, n_features)` or `(n_samples,)` when `n_features` = 1
                Samples where n_samples is the number of samples
                and n_features is the number of features.

# Returns
            A ProBT plDataDescriptor having input_variables as columns 
        '''
        if isinstance(X, pd.DataFrame):
            return  plDataDescriptorFromPandasDF(X, self.input_variables)

        if len(X.shape) == 1:
            X = X.reshape(-1, 1)
        if X.shape[1] != self.input_variables.size():
            raise ValueError('X.shape[1] must be equal to input_variables dimension')
        return plDataDescriptor.create_from_python_data(X, self.input_variables)

    def probt_learn(self, YX_probt_data, learning_mode=None):
        '''Learn the self.bn  according to the given training data and learning mode

# Arguments
            YX_probt_data: a ProBT plDataDescriptor instance with the 
                training samples 
                and n_features is the number of features.
            learning_mode: None or sting among:
               - 'learn_parameters_no_em': learn parametrers with no EM
               - 'learn_parameters_em': learn parametrers with EM
               - 'learn_structure_NB': learn Naive Bayes structure
               - 'learn_structure_TANB': learn Tree Augmented Naive Bayes structure
               - 'learn_structure': learn structure with no contraints

# Returns
            None
        '''
        if learning_mode != 'learn_parameters_em' and (self.target_variables.size() + self.input_variables.size()) < self.bn.nodes().size():
            if learning_mode is not None:
                warnings.warn("SkLearnBnPredictor.probt_learn(): Only learning_mode='learn_parameters_em' "
                              + "is allowed when using latent variables. Setting learning_mode to 'learn_parameters_em'")
            learning_mode = 'learn_parameters_em'
        elif learning_mode is None: learning_mode = 'learn_parameters_no_em'

        if learning_mode == 'learn_parameters_no_em':
            self.bn.learn_parameters_no_em(YX_probt_data)
        elif learning_mode == 'learn_parameters_em':
            self.bn.learn_parameters_em(YX_probt_data)
        elif learning_mode == 'learn_structure_NB':
            self.bn.learn_NB(YX_probt_data, plVariable(self.target_variables))
        elif learning_mode == 'learn_structure_TANB':
            self.bn.learn_structure_TANB(YX_probt_data, plVariable(self.target_variables))
        elif learning_mode == 'learn_structure':
            self.bn.learn_structure(YX_probt_data, True, True, PL_MDL, 
                                    PL_BIC, plVariable(self.target_variables))
        else: raise ValueError('{} is not a legal parameter'.format(learning_mode))

    def fit(self, X, Y, **kwargs):
        '''Construct a new model (self.bn) with build_bn and fit the model according
        to the given training data.

# Arguments
            X: array-like, shape `(n_samples, n_features)` or `(n_samples,)` when `n_features` = 1
                Training samples where n_samples is the number of samples
                and n_features is the number of features. 
                X is allowed to contain missing values (no need to perform missing values imputation).
            Y: array-like, shape `(n_samples,)` or `(n_samples, target_variables.dim())`
                True labels for X. 
                Y is allowed to contain missing values (no need to perform missing values imputation).
            kwargs: dictionary arguments
                Legal arguments are the arguments of `probt_learn`

# Returns
            self: object
                Returns self.
        '''
        if self.build_bn is None:
            self.bn = plBayesianNetwork()
        else:
            self.bn = self.build_bn(self.build_bn_variables,
                                    **self.filter_sk_params(self.build_bn))
            self.update_variables_from_bn()

        fit_args = copy.deepcopy(self.filter_sk_params(self.probt_learn))
        fit_args.update(kwargs)
        YX_train_probt_data = self.YX_probt_data_descriptor(X, Y)
        self.probt_learn(YX_train_probt_data, **fit_args)

        return self

    def probt_predict(self, probt_data, classif_prob_thresholds=None):
        '''Predict using self.bn according to the given data and using the probability thresholds

# Arguments
            probt_data: a ProBT plDataDescriptor instance with the test samples 

            classif_prob_threshold: The probability thresholds to be applied for classification:
                If classe c has the highest probability value, c is returned as the predicted value iif 
                P(c) > classif_prob_thresholds[c]. An empty plValues (unknown) is returned otherwise.

# Returns
           preds: array-like, shape `(n_samples,)` or `(n_samples, target_variables.dim())`
                Class predictions.
        '''
        if classif_prob_thresholds is not None:
            p_y_vals = self.bn.apply_prediction(self.target_variables, probt_data, classif_prob_thresholds)
        else:
            p_y_vals = self.bn.apply_prediction(self.target_variables, probt_data)
        if len(p_y_vals.shape) == 2 and p_y_vals.shape[1] == 1 : return p_y_vals.iloc[:,0]
        else: return p_y_vals

    def predict(self, X, **kwargs):
        '''Returns the class predictions for the given test data.

# Arguments
            X: array-like, shape `(n_samples, n_features)`
                Test samples where n_samples is the number of samples
                and n_features is the number of features. 
                X is allowed to contain missing values (no need to perform missing values imputation).
            kwargs: dictionary arguments
                Legal arguments are the arguments of `plBayesianNetwork.apply_prediction`.

# Returns
            preds: array-like, shape `(n_samples,)` or `(n_samples, target_variables.dim())`
                Class predictions.
        '''
        self.update_variables_from_bn()
        kwargs = self.filter_sk_params(self.probt_predict, kwargs)
        X_probt_data = self.X_probt_data_descriptor(X)
        predict_args = copy.deepcopy(self.filter_sk_params(self.probt_predict))
        predict_args.update(kwargs)
        return self.probt_predict(X_probt_data, **predict_args)


class SkLearnBnClassifier(SkLearnBnPredictor):
    '''Implementation of the scikit-learn classifier API for ProBT.
    '''

    def predict_proba(self, X, **kwargs):
        '''Returns class probability estimates for the given test data.

# Arguments
            X: array-like, shape `(n_samples, n_features)`
                Test samples where n_samples is the number of samples
                and n_features is the number of features.
                X is allowed to contain missing values (no need to perform missing values imputation).
            kwargs: dictionary arguments
                Legal arguments are the arguments of `plBayesianNetwork.apply_classification_proba`.

# Returns
            proba: array-like, shape `(n_samples, n_classes)`
                Class probability estimates.
        '''
        self.update_variables_from_bn()
        kwargs = self.filter_sk_params(plBayesianNetwork.apply_classification_proba, kwargs)
        X_probt_data = self.X_probt_data_descriptor(X)
        probs = self.bn.apply_classification_proba(self.target_variables, X_probt_data, **kwargs)
        return probs

    def score(self, X, Y, **kwargs):
        '''Returns the classification accuracy on the given test data and labels.

# Arguments
            X: array-like, shape `(n_samples, n_features)` or `(n_samples,)` when `n_features` = 1
                Test samples where n_samples is the number of samples
                and n_features is the number of features. 
                X is allowed to contain missing values (no need to perform missing values imputation).
            Y: array-like, shape `(n_samples,)` or `(n_samples, target_variables.dim())`
                True labels for X.
                Y is allowed to contain missing values (no need to perform missing values imputation).
            kwargs: dictionary arguments
                Legal arguments are the arguments of `plBayesianNetwork.apply_prediction`.

# Returns
            score: float
                Accuracy of predictions on X wrt. y.
        '''
        kwargs = self.filter_sk_params(self.predict, kwargs)
        p_Y = self.predict(X, **kwargs)
        from sklearn.metrics import accuracy_score
        accuracy = accuracy_score(Y, p_Y)
        return accuracy 

class SkLearnBnRegressor(SkLearnBnPredictor):
    '''Implementation of the scikit-learn regressor API for ProBT.
    '''
    def score(self, X, Y, **kwargs):
        '''Returns the regressor negative RMSE on the given test data and labels.

# Arguments
            X: array-like, shape `(n_samples, n_features)` or `(n_samples,)` when `n_features` = 1
                Test samples where n_samples is the number of samples
                and n_features is the number of features.
                X is allowed to contain missing values (no need to perform missing values imputation).
            Y: array-like, shape `(n_samples,)` or `(n_samples, target_variables.dim())`
                True labels for X.
                Y is allowed to contain missing values (no need to perform missing values imputation).
            kwargs: dictionary arguments
                Legal arguments are the arguments of `predict`.

# Returns
            score: float
                The negative RMSE of predictions on X wrt. Y.
        '''
        kwargs = self.filter_sk_params(self.predict, kwargs)
        predicetd_Y = self.predict(X, **kwargs)
        from sklearn.metrics import mean_squared_error
        rmse = mean_squared_error(Y, predicetd_Y)**0.5
        return -rmse

import warnings
import copy
import inspect
import types
import math

try:
# using getfullargspec is needed in our cases for Python3
  from inspect import getfullargspec as getargspec
except ImportError:
# Python2 only has getargspec
  from inspect import getargspec


def _as_hmm_observation_sequence(df):
    hmm_obs_seq = HmmObservationSequence(df.shape[0])
    for r in range(df.shape[0]):
        obs = HmmObservation(df.shape[1])
        for c in range(df.shape[1]):
            obs[c] = df.iloc[r,c]
        hmm_obs_seq[r] = obs
    return hmm_obs_seq

def _XY_to_hmm_data(X, Y, nclasses):
    hmm_obs_seq_array_vector = []
    for c in range(nclasses):
        hmm_obs_seq_array_vector.append([])
    for x, y in zip(X, Y):
        hmm_obs_seq_array_vector[y].append(_as_hmm_observation_sequence(x))
    return hmm_obs_seq_array_vector


class SkLearnHMMSetClassifier(object):
    '''Implementation of the scikit-learn classifier API using ProBT's concurrent HMM set.

    '''

    def __init__(self,
                 model_name,
                 class_names,
                 candidate_nstates=None, 
                 n_initialisation_random_trials=3,
                 learning_prior_weight=10e-3,
                 convergence_threshold=0.,
                 metric='accuracy',
                 enable_multi_threading=False,
                 observation_variable_names=None,
                 observation_variable_is_continuous=None,
                 observation_variable_min=None,
                 observation_variable_max=None,
                 observation_model=None,
                 hmm_set=None,
                 **sk_params):
        '''Create a scikit-learn time-series classifier using ProBT's a concurrent HMM set.

# Arguments

        model_name: model's name (string)

        class_names: model class names (list of string)

        candidate_nstates: the candidate numbers of HMM internal states
        (list of int)

        n_initialisation_random_trials: the number (int) of random
        initialisations. Providing a large number maximizes the
        chance of having a well-fitted model. In addition to the
        random initialisation trials, a deterministic initialisation
        is also performed when the deterministic initialisation is
        set to true (ie. this leads to
        n_initialisation_random_trials+1 initialisations)

        learning_prior_weight: the weight (float) to be used for
        initialising the emission distribution from the whole data
        set. A small value will lead to a more accurate classification
        while increasing the risk af having degenerate statistics
        (especially when using a large number of internal states).

        convergence_threshold: convergence threshold (float) of the
        relative log-likelihood change between two successive iterations
        (smaller value means more iterations). The default value is set
        to 0.0 The convergence criterion is computed as:\n |
        log-likelihood(t) - log-likelihood(t-1) | / | (log-likelihood(t)
        + log-likelihood(t-1)/2.0 | < convergence_threshold.

        metric: metric function to be used as score. A string avlue
        among 'accuracy', 'dissimilarity-sum', and 'dissimilarity-min'

        enable_multi_threading: enabling/disabling multithreading
        (True/False)

        observation_variable_names: the names of the observation
        variables (list of string)

        observation_variable_is_continuous: For each variable in the
        list above, True if the variable is continuous, False otherwise
        (list of boolean)

        observation_variable_min: for each variable in the list above,
        the min value for the range (list of numbers)

        observation_variable_max: For each variable in the list above,
        the max value for the range (list of numbers)

        observation_model: 2-tuple in which observation_model[0] are the
        observation_variable_groups and observation_model[1] are the
        observation_variable_group_parents. For example, for
        observation_variable_names = ["X", "A", "Z"], one can use
        observation_variable_groups = [ [0, 2], [1] ] to declare two
        groups of variables ([X, Z], [A]) and
        observation_variable_group_parents = [ [1], [] ] to declare [1]
        ([A]) as the parents for the first group [0, 2] ([X, Z]) and no
        parents for the second group [1] ([A]). This leads to the
        decomposition P(X A Z) = P(X Z | A) P(A)

        hmm_set: None or an already constructed instance of probt.plConcurrentHmmSet

        sk_params: model parameters & fitting parameters

        `sk_params` takes both model parameters and fitting parameters.
        `sk_params` could also accept parameters for calling `fit`, `predict`,
        `predict_proba`, and `score` methods.
        Fitting (predicting) parameters are selected in the following order:

        1. Values passed to the dictionary arguments of
        `fit`, `predict`, `predict_proba`, and `score` methods
        2. Values passed to `sk_params`

        When using scikit-learn's `grid_search` API, legal tunable
        parameters are those you could pass to `sk_params`, including
        fitting parameters.
        '''
        self.class_names = class_names
        self.model_name = model_name
        self.candidate_nstates = candidate_nstates
        self.n_initialisation_random_trials = n_initialisation_random_trials
        self.learning_prior_weight = learning_prior_weight
        self.convergence_threshold = convergence_threshold
        self.metric = metric
        self.enable_multi_threading = enable_multi_threading
        self.observation_variable_names = observation_variable_names
        self.observation_variable_is_continuous = observation_variable_is_continuous
        self.observation_variable_min = observation_variable_min
        self.observation_variable_max = observation_variable_max
        self.observation_model = observation_model
        self.hmm_set = hmm_set
        self.hmm_set_learner = None
        self.sk_params = sk_params
        self.check_params(sk_params)


    def check_params(self, params):
        '''Check for user typos in "params" keys to avoid
        unwanted usage of default values

# Arguments
            params: dictionary
                The parameters to be checked
        '''
        legal_params_fns = [self.probt_learn, self.__init__]
        legal_params = []
        for fn in legal_params_fns:
            legal_params += getargspec(fn)[0]
        legal_params = set(legal_params)

        for params_name in params:
            if params_name not in legal_params:
                raise ValueError('{} is not a legal parameter'.format(params_name))

    def get_params(self, deep=True):
        '''Get parameters for this estimator.

# Arguments
            deep: boolean, optional
                If True, will return the parameters for this estimator and
                contained sub-objects that are estimators.

# Returns
            params: dict
                Dictionary of parameter names mapped to their values.
        '''
        res = copy.deepcopy(self.sk_params)
        res.update({'model_name': self.model_name})
        res.update({'class_names': self.class_names})
        res.update({'candidate_nstates': self.candidate_nstates})
        res.update({'n_initialisation_random_trials': self.n_initialisation_random_trials})
        res.update({'learning_prior_weight': self.learning_prior_weight})
        res.update({'convergence_threshold': self.convergence_threshold})
        res.update({'metric': self.metric})
        res.update({'enable_multi_threading': self.enable_multi_threading})
        res.update({'observation_variable_names': self.observation_variable_names})
        res.update({'observation_variable_is_continuous': self.observation_variable_is_continuous})
        res.update({'observation_variable_min': self.observation_variable_min})
        res.update({'observation_variable_max': self.observation_variable_max})
        res.update({'observation_model': self.observation_model})
        res.update({'hmm_set': self.hmm_set})

        return res

    def set_params(self, **params):
        '''Set the parameters of this estimator.

# Arguments
        params: dict
            Dictionary of parameter names mapped to their values.

# Returns
            self
        '''
        self.check_params(params)
        self.sk_params.update(params)
        if 'model_name' in params: self.model_name = params['model_name']
        if 'class_names' in params: self.class_names = param['class_names']
        if 'candidate_nstates' in params: self.candidate_nstates = params['candidate_nstates']
        if 'n_initialisation_random_trials' in params: self.n_initialisation_random_trials = params['n_initialisation_random_trials']
        if 'learning_prior_weight' in params: self.learning_prior_weight = params['learning_prior_weight']
        if 'convergence_threshold' in params: self.convergence_threshold = params['convergence_threshold']
        if 'enable_multi_threading' in params: self.enable_multi_threading = params['enable_multi_threading']
        if 'observation_variable_names' in params: self.observation_variable_names = params['observation_variable_names']
        if 'observation_variable_is_continuous' in params: self.observation_variable_is_continuous = params['observation_variable_is_continuous']
        if 'observation_variable_min' in params: self.observation_variable_min = params['observation_variable_min']
        if 'observation_variable_max' in params: self.observation_variable_max = params['observation_variable_max']
        if 'observation_model' in params: self.observation_model = params['observation_model']			      
        if 'hmm_set' in params: self.hmm_set = params['hmm_set']
        return self

    def filter_sk_params(self, fn, override={}):
        '''Filter sk_params and return those in fn's arguments

# Arguments
            fn: arbitrary function
            override: dictionary, values to override sk_params

# Returns
            res: dictionary dictionary containing variables
                in both sk_params and fn's arguments.
        '''
        res = {}
        fn_args = getargspec(fn)[0]
        for name, value in self.sk_params.items():
            if name in fn_args:
                res.update({name: value})
        res.update(override)
        return res

    def probt_learn(self,
                    hmm_data,
                    candidate_nstates=None, 
                    n_initialisation_random_trials=None, 
                    learning_prior_weight=None, 
                    convergence_threshold=None,
                    random_state=None,
                    verbose=True,
                    enable_multi_threading=None,
                    observation_model=None):
        '''Perform training of the concurrent HMM set

# Arguments
        hmm_data: Training data set. Each data element is a time series of observations

        candidate_nstates: the candidate numbers of HMM internal states (list of int)

        n_initialisation_random_trials: the number (int) of random
        initialisations. Providing a large number maximizes the
        chance of having a well-fitted model. In addition to the
        random initialisation trials, a deterministic initialisation
        is also performed when the deterministic initialisation is
        set to true (ie. this leads to
        n_initialisation_random_trials+1 initialisations)

        learning_prior_weight: the weight (float) to be used for
        initialising the emission distribution from the whole data
        set. A small value will lead to a more accurate classification
        while increasing the risk af having degenerate statistics
        (especially when using a large number of internal states).

        convergence_threshold: convergence threshold (float) of the
        relative log-likelihood change between two successive iterations
        (smaller value means more iterations). The default value is set
        to 0.0 The convergence criterion is computed as:\n |
        log-likelihood(t) - log-likelihood(t-1) | / | (log-likelihood(t)
        + log-likelihood(t-1)/2.0 | < convergence_threshold.

        random_state: random seed state

        verbose: True or False to set/unset verbose mode

        enable_multi_threading: enabling/disabling multithreading (True/False)

        observation_model: two elements list in which
        observation_model[0] are the observation_variable_groups and
        observation_model[1] are the
        observation_variable_group_parents. For example, for
        observation_variable_names = ["X", "A", "Z"], one can use
        observation_variable_groups = [ [0, 2], [1] ] to declare two
        groups of variables ([X, Z], [A]) and
        observation_variable_group_parents = [ [1], [] ] to declare [1]
        ([A]) as the parents for the first group [0, 2] ([X, Z]) and no
        parents for the second group [1] ([A]). This leads to the
        decomposition P(X A Z) = P(X Z | A) P(A)
        '''

        self.hmm_set_learner = plConcurrentHmmSetLearner(self.model_name, self.class_names)

        if candidate_nstates is None: candidate_nstates = self.candidate_nstates
        if n_initialisation_random_trials is None: n_initialisation_random_trials = self.n_initialisation_random_trials
        if learning_prior_weight is None: learning_prior_weight = self.learning_prior_weight
        if convergence_threshold is None: convergence_threshold = self.convergence_threshold
        if enable_multi_threading is None: enable_multi_threading = self.enable_multi_threading
        if observation_model is None: observation_model = self.observation_model

        if verbose:
            print('probt_learn...')
            print('  candidate_nstates =', candidate_nstates)
            print('  n_initialisation_random_trials =', n_initialisation_random_trials)
            print('  learning_prior_weight =', learning_prior_weight)
            print('  convergence_threshold =', convergence_threshold)
            print('  enable_multi_threading =', enable_multi_threading)
            print('  observation_variable_names =', self.observation_variable_names)
            print('  observation_variable_is_continuous =', self.observation_variable_is_continuous)
            print('  observation_variable_min =', self.observation_variable_min)
            print('  observation_variable_max =', self.observation_variable_max)
            print('  observation_variable_groups =', observation_variable_groups)
            print('  observation_variable_group_parents =', observation_variable_group_parents)
            print('\n')

        if candidate_nstates is None:
            raise ValueError('fit: candidate_nstates is None')

        self.hmm_set_learner.enable_multi_threading(enable_multi_threading)
        if random_state is not None: 
            plRandom.seed(random_state)
            self.hmm_set_learner.enable_multi_threading(False)

        self.hmm_set_learner.set_verbose(verbose)

        if self.observation_variable_names is not None:
            if self.observation_variable_is_continuous is None:
                self.observation_variable_is_continuous = BoolVector()
            if self.observation_variable_min is None:
                self.observation_variable_min = DoubleVector()
            if self.observation_variable_max is None:
                self.observation_variable_max = DoubleVector()
            if observation_model is None:
                observation_variable_groups = UnsignedIntVectorVector()
                observation_variable_group_parents = UnsignedIntVectorVector()
            else:
                observation_variable_groups = observation_model[0]
                observation_variable_group_parents = observation_model[1]
                assert len(observation_variable_groups) == len(observation_variable_group_parents)            
            self.hmm_set_learner.set_observation_model(self.observation_variable_names,
                                                       self.observation_variable_is_continuous,
                                                       self.observation_variable_min,
                                                       self.observation_variable_max,
                                                       observation_variable_groups,
                                                       observation_variable_group_parents)

        self.hmm_set_learner.run_learning(hmm_data,
                                          candidate_nstates,
                                          n_initialisation_random_trials,
                                          learning_prior_weight,
                                          convergence_threshold)
        mname = self.model_name + 'BestBIC'
        self.hmm_set = self.hmm_set_learner.get_model_map()[mname]
        return self

    def fit(self, X, Y, **kwargs):
        '''Construct a new model (self.hmm_set) and fit it according
        to the given training data.
# Arguments
            X: array-like, shape `(n_samples, n_features)` or `(n_samples,)` when `n_features` = 1
                Training samples where n_samples in the number of samples
                and n_features is the number of features.
            Y: array-like, shape `(n_samples,)`
                True labels for X.
            kwargs: dictionary arguments
                Legal arguments are the arguments of `probt_learn`

# Returns
            self: object
                Returns self.
        '''
        fit_args = copy.deepcopy(self.filter_sk_params(self.probt_learn))
        fit_args.update(kwargs)
        hmm_data = _XY_to_hmm_data(X, Y, len(self.class_names))
        return self.probt_learn(hmm_data, **fit_args)

    def predict(self, X, **kwargs):
        '''Returns the class predictions for the given test data.

# Arguments
            X: array-like, shape `(n_samples, n_features)`
                Test samples where n_samples in the number of samples
                and n_features is the number of features.
            kwargs: dictionary arguments
                Legal arguments are the arguments of `plConcurrentHmmSet.get_best_model`.

# Returns
            preds: array-like, shape `(n_samples,)` or `(n_samples, target_variables.dim())`
                Class predictions.
        '''
        if self.hmm_set is None:
            raise RuntimeError('predict: Undefined self.hmm_set. Did you forget to call fit()?')

#kwargs = self.filter_sk_params(plConcurrentHmmSet.get_best_model, kwargs)
        Y = [ self.hmm_set.get_best_model(_as_hmm_observation_sequence(oseq)) for oseq in X]
        return Y

    def predict_proba(self, X, **kwargs):
        '''Returns class probability estimates for the given test data.

# Arguments
            X: array-like, shape `(n_samples, n_features)`
                Test samples where n_samples in the number of samples
                and n_features is the number of features.
            kwargs: dictionary arguments
                Legal arguments are the arguments of `plConcurrentHmmSet.get_all_models_log_probabilities`.

# Returns
            proba: array-like, shape `(n_samples, n_classes)`
                Class probability estimates.
        '''
        if self.hmm_set is None:
            raise RuntimeError('predict_proba: Undefined self.hmm_set. Did you forget to call fit()?')

#kwargs = self.filter_sk_params(plConcurrentHmmSet.get_all_models_log_probabilities, kwargs)
        probs = []
        for oseq in X:
            data = _as_hmm_observation_sequence(oseq)
            l_prob = self.hmm_set.get_all_models_log_probabilities(data)
            prob = [math.exp(lp) for lp in l_prob]
            probs.append(prob)
        return probs

    def predict_log_likelihood(self, X, normalize_by_seq_length=True, **kwargs):
        '''Returns class log_likelihood estimates for the given test data.

# Arguments
            X: array-like, shape `(n_samples, n_features)`
                Test samples where n_samples in the number of samples
                and n_features is the number of features.
            normalize_by_seq_length: If True (default), the log-likelihood is normalized by sequence's length
            kwargs: dictionary arguments
                Legal arguments are the arguments of `plConcurrentHmmSet.get_all_models_log_probabilities`.

# Returns
            proba: array-like, shape `(n_samples, n_classes)`
                Class log_likelihood estimates.
        '''
        if self.hmm_set is None:
            raise RuntimeError('predict_log_likelihood: Undefined self.hmm_set. Did you forget to call fit()?')

#kwargs = self.filter_sk_params(plConcurrentHmmSet.get_models_log_likelihood, kwargs)
        ret = []
        for oseq in X:
            data = _as_hmm_observation_sequence(oseq)
            llk = self.hmm_set.get_models_log_likelihood(data)
            if normalize_by_seq_length:
                sq_ln = len(data)
                llk = [l/sq_ln for l in  llk]
            ret.append(llk)
        return ret

    def score(self, X, Y, **kwargs):
        '''Returns the classification score on the given test data and labels.

# Arguments
            X: array-like, shape `(n_samples, n_features)` or `(n_samples,)` when `n_features` = 1
                Test samples where n_samples in the number of samples
                and n_features is the number of features.
            Y: array-like, shape `(n_samples,)` or `(n_samples, target_variables.dim())`
                True labels for X.
            kwargs: dictionary arguments
                Legal arguments are the arguments of `self.predict`.

# Returns
            score: float
                Accuracy of predictions on X wrt. y.
        '''
        if self.hmm_set is None:
            raise RuntimeError('score: Undefined self.hmm_set. Did you forget to call fit()?')

        if self.metric == 'accuracy':
            from sklearn.metrics import accuracy_score
            kwargs = self.filter_sk_params(self.predict, kwargs)
            predicted_Y = self.predict(X, **kwargs)
            return accuracy_score(Y, predicted_Y)
        elif self.metric == 'dissimilarity-sum':
            dissimitry_matrix = self.hmm_set.compute_dissimilarity_matrix(_XY_to_hmm_data(X, Y, len(self.class_names)))
            return dissimitry_matrix.sum()
        elif self.metric == 'dissimilarity-min':
            dissimitry_matrix = self.hmm_set.compute_dissimilarity_matrix(_XY_to_hmm_data(X, Y, len(self.class_names)))
            min_val = float('inf')
            for i in range(dissimitry_matrix.rows()):
                for j in range(dissimitry_matrix.cols()):
                    if i != j and dissimitry_matrix.at(i,j) < min_val:
                        min_val = dissimitry_matrix.at(i,j)
            return min_val
        else:
            message = 'score: metric {} is not a legal parameter. \
            Allowed ones are accuracy, dissimilarity-sum, and dissimilarity-min'.format(self.metric)
            raise ValueError(message)

    def plot_learning_scores(self):
        '''Plot log-likelihood, AIC, and BIC learning scores
        '''
        if self.hmm_set_learner is None:
            raise RuntimeError('plot_learning_scores: Undefined self.hmm_set. Did you forget to call fit()?')
        self.hmm_set_learner.python_plot_learning_scores(self.candidate_nstates)

class BN_Widget(object):
    """ProBT BN Widget for interactively using instances of plBayesianNetwork for inference.

    This class is based on ipywidgets and is intended to be used in Jupyter notebooks

    """

    def __init__(self,
                 bn, 
                 targets=[], 
                 grid_col_width=300, 
                 grid_ncols=3,
                 dot_rankdir=None,
                 node_img_dict=None,
                 node_img_directory=None,
                 init_evidence=None):
        """Create a Widget for interactively using a plBayesianNetwork instance for inference.

# Arguments
            bn: a plBayesianNetwork instance to be used for interactive inference
            targets: a list of strings with the names of target variables/nodes 
            grid_col_width: the width of the widget grid columns in px
            grid_ncols: the number of widget grid columns
            dot_rankdir: the graph rankdir dot parameter among 'LR', 'RL', 'TB', and 'BT'
            node_img_dict: a dictionary node_name -> image_file_name allowing to replace the standard dot nodes by user images.
            When provided, this allows replacing the standard dot nodes by the user-provided images.
            node_img_directory: a directory path/name in which file images with the same names as 
            nodes/variables are searched. When provided, this allows replacing the standard dot nodes by 
            the user-provided images. This parameter is used iff the parameter 'node_img_dict' above is None
            init_evidence: The initial evidence (observation) as a 'variable name' -> 'variable value' dictionary

        """

        import ipywidgets as widgets

        self.bn = bn
        self.dot_rankdir = dot_rankdir
        self.node_img_dict = node_img_dict if node_img_dict is not None else self._create_node_img_dict(node_img_directory, bn.nodes().get_names())
        self.keep_old_display = False
        self.display_items = []
        self.df = None

        self.algo_type_text = ['SR', 'JT', 'MCMC', 'GIBBS']
        self.algo_switch = {
            self.algo_type_text[0]: PL_SR,
            self.algo_type_text[1]: PL_JT,
            self.algo_type_text[2]: PL_MCMC,
            self.algo_type_text[3]: PL_GIBBS
        }
        self.rankdir_text = ['TB (Top to Bottom)', 'LR (Left to Right)', 'BT (Bottom to Top)', 'RL (Right to Left)']
        self.output_text = ['Marginals', 'Joint', "Marginals' graph"]
        self.unk_text = 'UNKNOWN'
        self.algo_key_text = '__algo__'
        self.output_key_text = '__output__'
        self.target_key_text = '__target__'
        self.rdir_key_text = '__rankdir__'
        self.var_obs_text = '_obs'

        variables = list(set([ v for v in bn.nodes()]) - set([bn.get_node(n) for n in targets]))

        label_variables=[]
        other_variables=[]
        for v in variables:
            if v.get_var_type() == PL_LABEL:
                label_variables.append(v)
            else:
                other_variables.append(v)

        ui_elems = []
        ui_dict = {}
        self.base_ui_dict = {}
        style = {'description_width': '140px'}
        for v in label_variables + other_variables:
            vname = v.name()
            box, bt, cb = self._create_buttons_for_variable(v, style)
            ui_dict[vname] = bt
            self.base_ui_dict[vname] = (bt, cb)
            if cb is not None:
                ui_dict[vname+self.var_obs_text] = cb
            ui_elems.append(box)

        grid = self._create_grid(ui_elems, grid_ncols, grid_col_width)

        switcher = {
            PL_SR: self.algo_type_text[0],
            PL_JT: self.algo_type_text[1],
            PL_MCMC: self.algo_type_text[2],
            PL_GIBBS: self.algo_type_text[3]
        }
        algo_w = widgets.Select(options=self.algo_type_text,
                                value=switcher[self.bn.get_inference_algorithm()],
                                description='Inference algorithm:',
                                disabled=False,
                                continuous_update=False,
                                orientation='horizontal',
                                readout=True,
                                style = style)
        ui_dict[self.algo_key_text] = algo_w

        var_names = self.bn.nodes().get_names()
        vtargets = var_names if targets==[] else targets
        target_w = widgets.SelectMultiple(options=var_names, layout={'width': 'max-content'},
                                          description='Targets:', value=vtargets)
        ui_dict[self.target_key_text] = target_w

        output_w = widgets.RadioButtons(options=self.output_text, description='Output:',
                                        disabled=False, value=self.output_text[2])
        ui_dict[self.output_key_text] = output_w

        sw = {
            'TB': self.rankdir_text[0],
            'LR': self.rankdir_text[1],
            'BT': self.rankdir_text[2],
            'RL': self.rankdir_text[3]
        }
        rval = self.rankdir_text[0] if self.dot_rankdir is None else sw[self.dot_rankdir]
        rankdir_w = widgets.Dropdown(options=self.rankdir_text, layout={'width': 'max-content'},  
                                     description='Graph rankdir:', style=style, value=rval)
        ui_dict[self.rdir_key_text] = rankdir_w

        param_widget = widgets.HBox([algo_w, target_w, output_w, rankdir_w ],
                                     layout=widgets.Layout(border='solid 2px') )

        title = widgets.Label(value='Model: '+self.bn.name())
        self.ui = widgets.VBox([param_widget, title, grid])
        self.out = widgets.interactive_output(self._infer_for_values, ui_dict)
        if init_evidence is not None:
            self._set_state(init_evidence, None)

    def _create_buttons_for_variable(self, variable, style):
        import ipywidgets as widgets

        var_type = variable.get_var_type()
        mn = variable.get_type().get_min()
        mx = variable.get_type().get_max()
        name = variable.name()
        if var_type == PL_INTEGER: 
            b = widgets.IntSlider(value=mn,
                                  min=mn,
                                  max=mx,
                                  step=1,
                                  description=name+':',
                                  continuous_update=False,
                                  disabled=True)
            cb = widgets.Checkbox(value=False, description='Observed')

            def disable_slider(value):
                b.disabled = not value.new
            cb.observe(disable_slider, names=['value'])

            return widgets.VBox([b, cb], style=style, layout=widgets.Layout(border='solid 1px') ), b, cb

        if var_type in [PL_DISCRETE_INTERVAL, PL_CONTINUOUS_INTERVAL, PL_REAL]:
            step = (mx-mn)/500.
            b = widgets.FloatSlider(value=(mn+mx)/2., 
                                    min=mn,
                                    max=mx-step,
                                    step=step,
                                    description=name+':',
                                    continuous_update=False,
                                    disabled=True)
            cb = widgets.Checkbox(value=False, description='Observed')

            def disable_slider(value):
                b.disabled = not value.new
            cb.observe(disable_slider, names=['value'])

            return widgets.VBox([b, cb], style=style, layout=widgets.Layout(border='solid 1px') ), b, cb

        if var_type == PL_LABEL:
            vals = [self.unk_text] + list(plLabelType(variable.get_type()).get_values())
            b = widgets.Dropdown(options=vals, layout={'width': 'max-content'}, 
                                 description=name+':', style=style)
            return b, b, None

    @staticmethod
    def _create_node_img_dict(node_img_directory, node_names):
        import os

        if node_img_directory is None:
            return {}

        files = os.listdir(node_img_directory)
        img_dict = {}
        for f in files:
            fname, fext = os.path.splitext(f)
            try:    
                idx = node_names.index(fname)
                img_dict[node_names[idx]] = os.path.join(node_img_directory, fname + fext) 
            except:
                pass
        return img_dict

    @staticmethod
    def _create_grid(ui_elems, grid_ncols, grid_col_width):
        import ipywidgets as widgets      
        try:
            tmp_col = 'repeat(' + str(grid_ncols) + ',' + str(grid_col_width) + 'px)'
            return widgets.GridBox(ui_elems, layout=widgets.Layout(width='100%',
                                                                   border='solid 2px',
                                                                   grid_template_columns=tmp_col))
        except: #widgets.GridBox does not exist (version < 7.3)
            import math
            nrows = int(math.ceil(len(ui_elems)/float(grid_ncols)))
            return widgets.VBox([ widgets.HBox(ui_elems[r*grid_ncols:(r+1)*grid_ncols]) for r in range(nrows) ],
                                layout=widgets.Layout(width='100%', border='solid 2px'))


    def _infer_for_values(self, **kwargs):
        from IPython.core.display import display
        import matplotlib.pyplot as plt

        if self.keep_old_display and self.display_items:
            display(*self.display_items)
            return

        self.display_items = []
        evidence = {}
        for v in self.bn.nodes():
            name = v.name()
            val = kwargs.get(name, None)
            if val is not None:
                if v.get_var_type() != PL_LABEL:
                    is_obs = kwargs[name+self.var_obs_text]
                    if is_obs:
                        evidence[self.bn.get_node(name)] = val
                else:
                    if val != self.unk_text:
                        evidence[self.bn.get_node(name)] = val

        algo = kwargs[self.algo_key_text]
        targets = kwargs[self.target_key_text]
        output = kwargs[self.output_key_text]
        rankdir = kwargs[self.rdir_key_text]

        self.bn.set_inference_algorithm(self.algo_switch[algo])
        self.dot_rankdir = rankdir[0:2]

        try:
            if output == self.output_text[0]: # marginals
                for t in targets:
                    fig = self.bn.get_belief(t, evidence).python_plot(scale=2)
                    self.display_items.append(fig)
                    plt.close(fig)
            elif output == self.output_text[1]: # joint
                if len(targets) > 0:
                    if len(targets) <= 2:
                        fig = self.bn.get_belief(targets, evidence).python_plot(scale=2)
                        self.display_items.append(fig)
                        plt.close(fig)
                    elif self.bn.get_node(targets).is_discretized():
                        table = self.bn.get_belief_table(targets, evidence)
                        self.display_items.append(table)
                    else:
                        expr = self.bn.get_belief(targets, evidence)
                        self.display_items.append(expr)
            else: # 'Marginal Graph'
                g = self.bn.python_belief_graph(dot_rankdir=self.dot_rankdir,
                                                hard_evidence = evidence,
                                                node_images = self.node_img_dict,
                                                belief_for_nodes=targets,
                                                plot_scale=1)
                self.display_items.append(g)
        except Exception as e:
            print(e)

        if self.df is not None:
            self.display_items.append(self.df)

        display(*self.display_items)

    def run(self):
        """ Display the widget and start the interaction

        """
        from IPython.core.display import display
        display(self.ui, self.out)

    def run_using_dataframe(self, df, inference_targets=[]):
        """ Play the widget using a Pandas Dataframe
# Arguments
            df: the Pandas Dataframe to be used
            inference_targets: a list of strings with the names of target variables/nodes 

        """
        cols_to_keep = list((set(df.columns) - set(inference_targets)).intersection(set(self.base_ui_dict.keys())))
        df = df[cols_to_keep]
        records = df.to_dict('records')
        old_data_record_values = None
        self._reset_to_unknown()
        for i in range(len(records)):
            self.df = df[i:i+1]
            old_data_record_values = self._set_state(records[i], old_data_record_values)
        self.df = None
        self.keep_old_display = False

    def _reset_to_unknown(self):
        self.keep_old_display = True
        for uielm in self.base_ui_dict.values():
            bt = uielm[0]
            cb = uielm[1]
            if cb is not None:
                cb.value = False
            else:
                bt.value = self.unk_text
        self.keep_old_display = False

    def _set_state(self, data_record, old_data_record_values):
        import math
        data_record_values = list(data_record.values())
        last = len(data_record)-1
        if old_data_record_values is not None:
            while last >= 0 and data_record_values[last] == old_data_record_values[last]:
                last = last-1

        for i, d in enumerate(data_record.items()):
            if i > last:
                break
            self.keep_old_display = (i != last)
            nm = d[0]
            val = d[1]
            uielm = self.base_ui_dict[nm]
            bt = uielm[0]
            cb = uielm[1]
            if isinstance(val, str):
                val = val if val != '' else self.unk_text
                bt.value = val
            elif not math.isnan(val):
                bt.value = val
                cb.value = True
            else:
                cb.value = False
        return data_record_values

class plStringStream(_object):
    """

    `plStringStream()`  

    Wrapper for std::stringstream allowing to workaround a bug when using with swig
    Python.  

    Constructors
    ------------
    * `plStringStream()`  

    C++ includes: plStringStream.h

    """

    __swig_setmethods__ = {}
    __setattr__ = lambda self, name, value: _swig_setattr(self, plStringStream, name, value)
    __swig_getmethods__ = {}
    __getattr__ = lambda self, name: _swig_getattr(self, plStringStream, name)
    __repr__ = _swig_repr

    def __init__(self):
        """
        __init__(self) -> plStringStream


        `plStringStream()`  

        """
        this = _probt_python3.new_plStringStream()
        try:
            self.this.append(this)
        except __builtin__.Exception:
            self.this = this

    def write(self, st: 'std::string const &') -> "void":
        """
        write(self, st)


        `write(const std::string &st)`  

        """
        return _probt_python3.plStringStream_write(self, st)


    def read(self) -> "std::string":
        """
        read(self) -> std::string


        `read() const -> std::string`  

        """
        return _probt_python3.plStringStream_read(self)


    def clear(self) -> "void":
        """
        clear(self)


        `clear()`  

        """
        return _probt_python3.plStringStream_clear(self)

    __swig_destroy__ = _probt_python3.delete_plStringStream
    __del__ = lambda self: None
plStringStream_swigregister = _probt_python3.plStringStream_swigregister
plStringStream_swigregister(plStringStream)

# This file is compatible with both classic and new-style classes.


